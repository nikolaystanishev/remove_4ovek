_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         (None, 288, 288, 3)       0         
_________________________________________________________________
conv_1 (Conv2D)              (None, 288, 288, 32)      896       
_________________________________________________________________
norm_1 (BatchNormalization)  (None, 288, 288, 32)      128       
_________________________________________________________________
relu_1 (LeakyReLU)           (None, 288, 288, 32)      0         
_________________________________________________________________
pool_1 (MaxPooling2D)        (None, 144, 144, 32)      0         
_________________________________________________________________
conv_2 (Conv2D)              (None, 144, 144, 64)      18496     
_________________________________________________________________
norm_2 (BatchNormalization)  (None, 144, 144, 64)      256       
_________________________________________________________________
relu_2 (LeakyReLU)           (None, 144, 144, 64)      0         
_________________________________________________________________
pool_2 (MaxPooling2D)        (None, 72, 72, 64)        0         
_________________________________________________________________
conv_3 (Conv2D)              (None, 72, 72, 128)       73856     
_________________________________________________________________
norm_3 (BatchNormalization)  (None, 72, 72, 128)       512       
_________________________________________________________________
relu_3 (LeakyReLU)           (None, 72, 72, 128)       0         
_________________________________________________________________
conv_4 (Conv2D)              (None, 72, 72, 64)        8256      
_________________________________________________________________
norm_4 (BatchNormalization)  (None, 72, 72, 64)        256       
_________________________________________________________________
relu_4 (LeakyReLU)           (None, 72, 72, 64)        0         
_________________________________________________________________
conv_5 (Conv2D)              (None, 72, 72, 128)       73856     
_________________________________________________________________
norm_5 (BatchNormalization)  (None, 72, 72, 128)       512       
_________________________________________________________________
relu_5 (LeakyReLU)           (None, 72, 72, 128)       0         
_________________________________________________________________
pool_3 (MaxPooling2D)        (None, 36, 36, 128)       0         
_________________________________________________________________
conv_6 (Conv2D)              (None, 36, 36, 256)       295168    
_________________________________________________________________
norm_6 (BatchNormalization)  (None, 36, 36, 256)       1024      
_________________________________________________________________
relu_6 (LeakyReLU)           (None, 36, 36, 256)       0         
_________________________________________________________________
conv_7 (Conv2D)              (None, 36, 36, 128)       32896     
_________________________________________________________________
norm_7 (BatchNormalization)  (None, 36, 36, 128)       512       
_________________________________________________________________
relu_7 (LeakyReLU)           (None, 36, 36, 128)       0         
_________________________________________________________________
conv_8 (Conv2D)              (None, 36, 36, 256)       295168    
_________________________________________________________________
norm_8 (BatchNormalization)  (None, 36, 36, 256)       1024      
_________________________________________________________________
relu_8 (LeakyReLU)           (None, 36, 36, 256)       0         
_________________________________________________________________
pool_4 (MaxPooling2D)        (None, 18, 18, 256)       0         
_________________________________________________________________
conv_9 (Conv2D)              (None, 18, 18, 512)       1180160   
_________________________________________________________________
norm_9 (BatchNormalization)  (None, 18, 18, 512)       2048      
_________________________________________________________________
relu_9 (LeakyReLU)           (None, 18, 18, 512)       0         
_________________________________________________________________
conv_10 (Conv2D)             (None, 18, 18, 256)       131328    
_________________________________________________________________
norm_10 (BatchNormalization) (None, 18, 18, 256)       1024      
_________________________________________________________________
relu_10 (LeakyReLU)          (None, 18, 18, 256)       0         
_________________________________________________________________
conv_11 (Conv2D)             (None, 18, 18, 512)       1180160   
_________________________________________________________________
norm_11 (BatchNormalization) (None, 18, 18, 512)       2048      
_________________________________________________________________
relu_11 (LeakyReLU)          (None, 18, 18, 512)       0         
_________________________________________________________________
conv_12 (Conv2D)             (None, 18, 18, 256)       131328    
_________________________________________________________________
norm_12 (BatchNormalization) (None, 18, 18, 256)       1024      
_________________________________________________________________
relu_12 (LeakyReLU)          (None, 18, 18, 256)       0         
_________________________________________________________________
conv_13 (Conv2D)             (None, 18, 18, 512)       1180160   
_________________________________________________________________
norm_13 (BatchNormalization) (None, 18, 18, 512)       2048      
_________________________________________________________________
relu_13 (LeakyReLU)          (None, 18, 18, 512)       0         
_________________________________________________________________
pool_5 (MaxPooling2D)        (None, 9, 9, 512)         0         
_________________________________________________________________
conv_14 (Conv2D)             (None, 9, 9, 1024)        4719616   
_________________________________________________________________
norm_14 (BatchNormalization) (None, 9, 9, 1024)        4096      
_________________________________________________________________
relu_14 (LeakyReLU)          (None, 9, 9, 1024)        0         
_________________________________________________________________
conv_15 (Conv2D)             (None, 9, 9, 1024)        9438208   
_________________________________________________________________
norm_15 (BatchNormalization) (None, 9, 9, 1024)        4096      
_________________________________________________________________
relu_15 (LeakyReLU)          (None, 9, 9, 1024)        0         
_________________________________________________________________
conv_16 (Conv2D)             (None, 9, 9, 5)           5125      
_________________________________________________________________
reshape_1 (Reshape)          (None, 9, 9, 5)           0         
=================================================================
Total params: 18,785,285
Trainable params: 18,774,981
Non-trainable params: 10,304
_________________________________________________________________
+----------+---------------------+----------------+-------------------+---------------------+---------------------+-----------------+
|  Epoch   |       f1_score      |      iou       |        loss       |      precision      |        recall       |     val_loss    |
+----------+---------------------+----------------+-------------------+---------------------+---------------------+-----------------+
| Epoch 1  |          0          |       0        |  0.0238221205192  |          0          |         0.0         | 0.0208867576214 |
| Epoch 2  | 0.10559006211180125 | 0.62305842446  |  0.0118750438696  |       0.53125       | 0.05862068965517241 | 0.0132306355142 |
| Epoch 3  | 0.11931818181818184 | 0.618989332055 |  0.00807006398038 |  0.3387096774193548 | 0.07241379310344828 | 0.0149282904402 |
| Epoch 4  | 0.20792079207920794 | 0.628442134995 |  0.0056774085238  |  0.3684210526315789 | 0.14482758620689656 | 0.0135118670521 |
| Epoch 5  |  0.2577565632458234 | 0.621618316929 |  0.00417781280179 |  0.4186046511627907 | 0.18620689655172415 | 0.0139579938785 |
| Epoch 6  | 0.23357664233576642 | 0.628650109723 |  0.00299566525935 | 0.39669421487603307 | 0.16551724137931034 | 0.0137941707526 |
| Epoch 7  | 0.21635883905013192 | 0.626064643331 |  0.00234692987796 |  0.4606741573033708 |  0.1413793103448276 | 0.0131647822958 |
| Epoch 8  | 0.20259740259740258 | 0.602044570939 |  0.00191100289717 |  0.4105263157894737 | 0.13448275862068965 | 0.0134948434068 |
| Epoch 9  |  0.2621359223300971 | 0.619625400286 |  0.00156605134166 |  0.4426229508196721 | 0.18620689655172415 | 0.0129657797515 |
| Epoch 10 | 0.25066666666666665 | 0.634446477025 |  0.00129398627202 |  0.5529411764705883 | 0.16206896551724137 | 0.0133428586827 |
| Epoch 11 | 0.24810126582278483 | 0.644349176583 |  0.00114286031772 |  0.4666666666666667 | 0.16896551724137931 | 0.0126142161147 |
| Epoch 12 |  0.3073286052009457 | 0.640678980852 | 0.000957367680172 | 0.48872180451127817 | 0.22413793103448276 | 0.0124593464838 |
| Epoch 13 | 0.29484029484029484 | 0.638351417615 | 0.000972690971047 |  0.5128205128205128 | 0.20689655172413793 | 0.0123718733328 |
| Epoch 14 | 0.22826086956521743 | 0.63618896335  | 0.000885072407942 |  0.5384615384615384 | 0.14482758620689656 | 0.0129775551839 |
| Epoch 15 | 0.23978201634877386 | 0.634907326892 | 0.000755275881643 |  0.5714285714285714 | 0.15172413793103448 | 0.0131140846999 |
| Epoch 16 |  0.2349869451697128 | 0.643921322691 | 0.000712216989219 |  0.4838709677419355 | 0.15517241379310345 | 0.0126769716341 |
| Epoch 17 |  0.2825112107623318 | 0.630326069828 | 0.000642772850418 | 0.40384615384615385 | 0.21724137931034482 | 0.0126538074786 |
| Epoch 18 |  0.285024154589372  | 0.656348059774 | 0.000614114992962 | 0.47580645161290325 | 0.20344827586206896 | 0.0125372139437 |
| Epoch 19 | 0.26063829787234044 | 0.65446741484  | 0.000581499799089 |  0.5697674418604651 | 0.16896551724137931 | 0.0127647091905 |
| Epoch 20 | 0.19733333333333333 | 0.667789053309 | 0.000619943217285 | 0.43529411764705883 | 0.12758620689655173 | 0.0128369974874 |
+----------+---------------------+----------------+-------------------+---------------------+---------------------+-----------------+
_________________________________________________________________
+---------------------------------+--------------------+--------------------+-----------------------+---------+-----------------------+
|            Optimizer            |       beta_1       |       beta_2       |         decay         | epsilon |           lr          |
+---------------------------------+--------------------+--------------------+-----------------------+---------+-----------------------+
| <class 'keras.optimizers.Adam'> | 0.8999999761581421 | 0.9990000128746033 | 0.0005000000237487257 |  1e-08  | 9.999999747378752e-05 |
+---------------------------------+--------------------+--------------------+-----------------------+---------+-----------------------+
_________________________________________________________________
+------------+
| Batch Size |
+------------+
|     16     |
+------------+
_________________________________________________________________
+--------------------+-------------------+----------------+---------------------+---------------------+---------------------+
|      Metrics       |        Loss       |      IoU       |      Precision      |        Recall       |       F1 Score      |
+--------------------+-------------------+----------------+---------------------+---------------------+---------------------+
|   Train Metrics    | 0.000495621623998 | 0.812420006121 |  0.9667318982387475 |  0.9562061456569079 |  0.9614402140858777 |
| Validation Metrics |  0.0128369965861  | 0.667789053309 | 0.43529411764705883 | 0.12758620689655173 | 0.19733333333333333 |
|    Test Metrics    |  0.0137316225277  | 0.657951795468 |  0.5471698113207547 | 0.18770226537216828 |  0.2795180722891566 |
+--------------------+-------------------+----------------+---------------------+---------------------+---------------------+
_________________________________________________________________
Time:
    Train Time : 4:45:48.331826
    Full Time  : 5:06:08.292583
_________________________________________________________________
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         (None, 288, 288, 1)       0         
_________________________________________________________________
conv_1 (Conv2D)              (None, 288, 288, 32)      320       
_________________________________________________________________
norm_1 (BatchNormalization)  (None, 288, 288, 32)      128       
_________________________________________________________________
relu_1 (LeakyReLU)           (None, 288, 288, 32)      0         
_________________________________________________________________
pool_1 (MaxPooling2D)        (None, 144, 144, 32)      0         
_________________________________________________________________
conv_2 (Conv2D)              (None, 144, 144, 64)      18496     
_________________________________________________________________
norm_2 (BatchNormalization)  (None, 144, 144, 64)      256       
_________________________________________________________________
relu_2 (LeakyReLU)           (None, 144, 144, 64)      0         
_________________________________________________________________
pool_2 (MaxPooling2D)        (None, 72, 72, 64)        0         
_________________________________________________________________
conv_3 (Conv2D)              (None, 72, 72, 128)       73856     
_________________________________________________________________
norm_3 (BatchNormalization)  (None, 72, 72, 128)       512       
_________________________________________________________________
relu_3 (LeakyReLU)           (None, 72, 72, 128)       0         
_________________________________________________________________
conv_4 (Conv2D)              (None, 72, 72, 64)        8256      
_________________________________________________________________
norm_4 (BatchNormalization)  (None, 72, 72, 64)        256       
_________________________________________________________________
relu_4 (LeakyReLU)           (None, 72, 72, 64)        0         
_________________________________________________________________
conv_5 (Conv2D)              (None, 72, 72, 128)       73856     
_________________________________________________________________
norm_5 (BatchNormalization)  (None, 72, 72, 128)       512       
_________________________________________________________________
relu_5 (LeakyReLU)           (None, 72, 72, 128)       0         
_________________________________________________________________
pool_3 (MaxPooling2D)        (None, 36, 36, 128)       0         
_________________________________________________________________
conv_6 (Conv2D)              (None, 36, 36, 256)       295168    
_________________________________________________________________
norm_6 (BatchNormalization)  (None, 36, 36, 256)       1024      
_________________________________________________________________
relu_6 (LeakyReLU)           (None, 36, 36, 256)       0         
_________________________________________________________________
conv_7 (Conv2D)              (None, 36, 36, 128)       32896     
_________________________________________________________________
norm_7 (BatchNormalization)  (None, 36, 36, 128)       512       
_________________________________________________________________
relu_7 (LeakyReLU)           (None, 36, 36, 128)       0         
_________________________________________________________________
conv_8 (Conv2D)              (None, 36, 36, 256)       295168    
_________________________________________________________________
norm_8 (BatchNormalization)  (None, 36, 36, 256)       1024      
_________________________________________________________________
relu_8 (LeakyReLU)           (None, 36, 36, 256)       0         
_________________________________________________________________
pool_4 (MaxPooling2D)        (None, 18, 18, 256)       0         
_________________________________________________________________
conv_9 (Conv2D)              (None, 18, 18, 512)       1180160   
_________________________________________________________________
norm_9 (BatchNormalization)  (None, 18, 18, 512)       2048      
_________________________________________________________________
relu_9 (LeakyReLU)           (None, 18, 18, 512)       0         
_________________________________________________________________
conv_10 (Conv2D)             (None, 18, 18, 256)       131328    
_________________________________________________________________
norm_10 (BatchNormalization) (None, 18, 18, 256)       1024      
_________________________________________________________________
relu_10 (LeakyReLU)          (None, 18, 18, 256)       0         
_________________________________________________________________
conv_11 (Conv2D)             (None, 18, 18, 512)       1180160   
_________________________________________________________________
norm_11 (BatchNormalization) (None, 18, 18, 512)       2048      
_________________________________________________________________
relu_11 (LeakyReLU)          (None, 18, 18, 512)       0         
_________________________________________________________________
conv_12 (Conv2D)             (None, 18, 18, 256)       131328    
_________________________________________________________________
norm_12 (BatchNormalization) (None, 18, 18, 256)       1024      
_________________________________________________________________
relu_12 (LeakyReLU)          (None, 18, 18, 256)       0         
_________________________________________________________________
conv_13 (Conv2D)             (None, 18, 18, 512)       1180160   
_________________________________________________________________
norm_13 (BatchNormalization) (None, 18, 18, 512)       2048      
_________________________________________________________________
relu_13 (LeakyReLU)          (None, 18, 18, 512)       0         
_________________________________________________________________
pool_5 (MaxPooling2D)        (None, 9, 9, 512)         0         
_________________________________________________________________
conv_14 (Conv2D)             (None, 9, 9, 1024)        4719616   
_________________________________________________________________
norm_14 (BatchNormalization) (None, 9, 9, 1024)        4096      
_________________________________________________________________
relu_14 (LeakyReLU)          (None, 9, 9, 1024)        0         
_________________________________________________________________
conv_15 (Conv2D)             (None, 9, 9, 1024)        9438208   
_________________________________________________________________
norm_15 (BatchNormalization) (None, 9, 9, 1024)        4096      
_________________________________________________________________
relu_15 (LeakyReLU)          (None, 9, 9, 1024)        0         
_________________________________________________________________
conv_16 (Conv2D)             (None, 9, 9, 5)           5125      
_________________________________________________________________
reshape_1 (Reshape)          (None, 9, 9, 5)           0         
=================================================================
Total params: 18,784,709
Trainable params: 18,774,405
Non-trainable params: 10,304
_________________________________________________________________
+----------+---------------------+----------------+-------------------+---------------------+---------------------+------------------+
|  Epoch   |       f1_score      |      iou       |        loss       |      precision      |        recall       |     val_loss     |
+----------+---------------------+----------------+-------------------+---------------------+---------------------+------------------+
| Epoch 1  |          0          |       0        |  0.0250538696873  |          0          |         0.0         | 0.0180268083969  |
| Epoch 2  |  0.1893491124260355 | 0.611738951289 |  0.0115938327367  |  0.6666666666666666 |  0.1103448275862069 | 0.0113679775067  |
| Epoch 3  |  0.3285198555956678 | 0.614857516669 |  0.00838333895329 |  0.3446969696969697 |  0.3137931034482759 | 0.0111664168296  |
| Epoch 4  | 0.30208333333333337 | 0.631565488729 |  0.0061245796484  |  0.3041958041958042 |         0.3         | 0.0115743376495  |
| Epoch 5  |  0.3445544554455445 | 0.627761008626 |  0.00465795258769 |  0.4046511627906977 |         0.3         | 0.0110525684131  |
| Epoch 6  |  0.2949494949494949 | 0.623383665884 |  0.00353918757112 | 0.35609756097560974 |  0.2517241379310345 | 0.0108139147802  |
| Epoch 7  | 0.30935251798561153 | 0.618974695724 |  0.00274731997213 |  0.3233082706766917 |  0.296551724137931  |  0.010861854099  |
| Epoch 8  |  0.3953488372093023 | 0.633910197865 |  0.00207881854957 |  0.3814102564102564 |  0.4103448275862069 | 0.0102029322016  |
| Epoch 9  |  0.3675213675213675 | 0.648937168285 |  0.00172764425255 | 0.48314606741573035 |  0.296551724137931  | 0.0101326318127  |
| Epoch 10 |  0.2874251497005988 | 0.639381971232 |  0.00138652134161 |  0.3412322274881517 |  0.2482758620689655 | 0.0108451903347  |
| Epoch 11 |  0.3333333333333333 | 0.627790507698 |  0.00121150943958 |  0.4476744186046512 |  0.2655172413793103 | 0.0105624270716  |
| Epoch 12 | 0.37404580152671757 | 0.62233177274  |  0.00094487524813 |  0.4188034188034188 | 0.33793103448275863 | 0.0103912327078  |
| Epoch 13 | 0.37009345794392523 | 0.637000272292 | 0.000812361531537 | 0.40408163265306124 |  0.3413793103448276 | 0.0101504249859  |
| Epoch 14 |  0.4015748031496063 | 0.634838859667 | 0.000722790472993 | 0.46788990825688076 | 0.35172413793103446 | 0.0100720243889  |
| Epoch 15 | 0.36323851203501095 | 0.658904558545 | 0.000717623654866 | 0.49700598802395207 | 0.28620689655172415 | 0.0101908116391  |
| Epoch 16 |  0.4520795660036166 | 0.64296876444  | 0.000611312754043 |  0.4752851711026616 | 0.43103448275862066 | 0.00977196980027 |
| Epoch 17 |         0.4         | 0.647033902545 |  0.00055062340589 | 0.45217391304347826 |  0.3586206896551724 | 0.0098965431173  |
| Epoch 18 |  0.3651804670912951 | 0.641343904758 | 0.000506322129324 | 0.47513812154696133 |  0.296551724137931  | 0.0100359196264  |
| Epoch 19 | 0.35320088300220753 | 0.649983017201 | 0.000479714711784 | 0.49079754601226994 | 0.27586206896551724 |  0.010105506517  |
| Epoch 20 | 0.39436619718309857 | 0.643797984268 |  0.00046247609571 | 0.47342995169082125 | 0.33793103448275863 | 0.00990176726613 |
+----------+---------------------+----------------+-------------------+---------------------+---------------------+------------------+
_________________________________________________________________
+---------------------------------+--------------------+--------------------+-----------------------+---------+-----------------------+
|            Optimizer            |       beta_1       |       beta_2       |         decay         | epsilon |           lr          |
+---------------------------------+--------------------+--------------------+-----------------------+---------+-----------------------+
| <class 'keras.optimizers.Adam'> | 0.8999999761581421 | 0.9990000128746033 | 0.0005000000237487257 |  1e-08  | 9.999999747378752e-05 |
+---------------------------------+--------------------+--------------------+-----------------------+---------+-----------------------+
_________________________________________________________________
+------------+
| Batch Size |
+------------+
|     16     |
+------------+
_________________________________________________________________
+--------------------+-------------------+----------------+---------------------+---------------------+---------------------+
|      Metrics       |        Loss       |      IoU       |      Precision      |        Recall       |       F1 Score      |
+--------------------+-------------------+----------------+---------------------+---------------------+---------------------+
|   Train Metrics    | 0.000447399625225 | 0.822859326338 |  0.9394714407502132 |  0.9332204210016937 |  0.9363354979668629 |
| Validation Metrics |  0.00990176726613 | 0.643797984268 | 0.47342995169082125 | 0.33793103448275863 | 0.39436619718309857 |
|    Test Metrics    |  0.0113479455392  | 0.650726119484 | 0.46859903381642515 |  0.313915857605178  |  0.375968992248062  |
+--------------------+-------------------+----------------+---------------------+---------------------+---------------------+
_________________________________________________________________
Time:
    Train Time : 3:09:00.626929
    Full Time  : 3:09:40.519971
_________________________________________________________________
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         (None, 288, 288, 1)       0         
_________________________________________________________________
conv_1 (Conv2D)              (None, 288, 288, 32)      320       
_________________________________________________________________
norm_1 (BatchNormalization)  (None, 288, 288, 32)      128       
_________________________________________________________________
relu_1 (LeakyReLU)           (None, 288, 288, 32)      0         
_________________________________________________________________
pool_1 (MaxPooling2D)        (None, 144, 144, 32)      0         
_________________________________________________________________
conv_2 (Conv2D)              (None, 144, 144, 64)      18496     
_________________________________________________________________
norm_2 (BatchNormalization)  (None, 144, 144, 64)      256       
_________________________________________________________________
relu_2 (LeakyReLU)           (None, 144, 144, 64)      0         
_________________________________________________________________
pool_2 (MaxPooling2D)        (None, 72, 72, 64)        0         
_________________________________________________________________
conv_3 (Conv2D)              (None, 72, 72, 128)       73856     
_________________________________________________________________
norm_3 (BatchNormalization)  (None, 72, 72, 128)       512       
_________________________________________________________________
relu_3 (LeakyReLU)           (None, 72, 72, 128)       0         
_________________________________________________________________
conv_4 (Conv2D)              (None, 72, 72, 64)        8256      
_________________________________________________________________
norm_4 (BatchNormalization)  (None, 72, 72, 64)        256       
_________________________________________________________________
relu_4 (LeakyReLU)           (None, 72, 72, 64)        0         
_________________________________________________________________
conv_5 (Conv2D)              (None, 72, 72, 128)       73856     
_________________________________________________________________
norm_5 (BatchNormalization)  (None, 72, 72, 128)       512       
_________________________________________________________________
relu_5 (LeakyReLU)           (None, 72, 72, 128)       0         
_________________________________________________________________
pool_3 (MaxPooling2D)        (None, 36, 36, 128)       0         
_________________________________________________________________
conv_6 (Conv2D)              (None, 36, 36, 256)       295168    
_________________________________________________________________
norm_6 (BatchNormalization)  (None, 36, 36, 256)       1024      
_________________________________________________________________
relu_6 (LeakyReLU)           (None, 36, 36, 256)       0         
_________________________________________________________________
conv_7 (Conv2D)              (None, 36, 36, 128)       32896     
_________________________________________________________________
norm_7 (BatchNormalization)  (None, 36, 36, 128)       512       
_________________________________________________________________
relu_7 (LeakyReLU)           (None, 36, 36, 128)       0         
_________________________________________________________________
conv_8 (Conv2D)              (None, 36, 36, 256)       295168    
_________________________________________________________________
norm_8 (BatchNormalization)  (None, 36, 36, 256)       1024      
_________________________________________________________________
relu_8 (LeakyReLU)           (None, 36, 36, 256)       0         
_________________________________________________________________
pool_4 (MaxPooling2D)        (None, 18, 18, 256)       0         
_________________________________________________________________
conv_9 (Conv2D)              (None, 18, 18, 512)       1180160   
_________________________________________________________________
norm_9 (BatchNormalization)  (None, 18, 18, 512)       2048      
_________________________________________________________________
relu_9 (LeakyReLU)           (None, 18, 18, 512)       0         
_________________________________________________________________
conv_10 (Conv2D)             (None, 18, 18, 256)       131328    
_________________________________________________________________
norm_10 (BatchNormalization) (None, 18, 18, 256)       1024      
_________________________________________________________________
relu_10 (LeakyReLU)          (None, 18, 18, 256)       0         
_________________________________________________________________
conv_11 (Conv2D)             (None, 18, 18, 512)       1180160   
_________________________________________________________________
norm_11 (BatchNormalization) (None, 18, 18, 512)       2048      
_________________________________________________________________
relu_11 (LeakyReLU)          (None, 18, 18, 512)       0         
_________________________________________________________________
conv_12 (Conv2D)             (None, 18, 18, 256)       131328    
_________________________________________________________________
norm_12 (BatchNormalization) (None, 18, 18, 256)       1024      
_________________________________________________________________
relu_12 (LeakyReLU)          (None, 18, 18, 256)       0         
_________________________________________________________________
conv_13 (Conv2D)             (None, 18, 18, 512)       1180160   
_________________________________________________________________
norm_13 (BatchNormalization) (None, 18, 18, 512)       2048      
_________________________________________________________________
relu_13 (LeakyReLU)          (None, 18, 18, 512)       0         
_________________________________________________________________
pool_5 (MaxPooling2D)        (None, 9, 9, 512)         0         
_________________________________________________________________
conv_14 (Conv2D)             (None, 9, 9, 1024)        4719616   
_________________________________________________________________
norm_14 (BatchNormalization) (None, 9, 9, 1024)        4096      
_________________________________________________________________
relu_14 (LeakyReLU)          (None, 9, 9, 1024)        0         
_________________________________________________________________
conv_15 (Conv2D)             (None, 9, 9, 1024)        9438208   
_________________________________________________________________
norm_15 (BatchNormalization) (None, 9, 9, 1024)        4096      
_________________________________________________________________
relu_15 (LeakyReLU)          (None, 9, 9, 1024)        0         
_________________________________________________________________
conv_16 (Conv2D)             (None, 9, 9, 5)           5125      
_________________________________________________________________
reshape_1 (Reshape)          (None, 9, 9, 5)           0         
=================================================================
Total params: 18,784,709
Trainable params: 18,774,405
Non-trainable params: 10,304
_________________________________________________________________
+----------+---------------------+----------------+------------------+---------------------+---------------------+-----------------+
|  Epoch   |       f1_score      |      iou       |       loss       |      precision      |        recall       |     val_loss    |
+----------+---------------------+----------------+------------------+---------------------+---------------------+-----------------+
| Epoch 1  |          0          |       0        | 0.0285546605838  |          0          |         0.0         | 0.0179038791647 |
| Epoch 2  |  0.1940700808625337 | 0.624208517377 | 0.0120402107587  |  0.4444444444444444 | 0.12413793103448276 |  0.011138096632 |
| Epoch 3  | 0.32394366197183094 | 0.62842692864  | 0.00861650513247 |  0.5073529411764706 | 0.23793103448275862 | 0.0115675622177 |
| Epoch 4  | 0.36328124999999994 | 0.627523588803 | 0.0064481206306  |  0.4189189189189189 | 0.32068965517241377 | 0.0118016925971 |
| Epoch 5  |  0.3518164435946463 | 0.631844925772 | 0.00478509391303 |  0.3948497854077253 | 0.31724137931034485 | 0.0110754937895 |
| Epoch 6  |  0.3203661327231121 | 0.647141695519 | 0.00359795830273 | 0.47619047619047616 |  0.2413793103448276 | 0.0113964716814 |
| Epoch 7  |  0.3273905996758509 | 0.630614380583 | 0.00292950088063 |  0.308868501529052  |  0.3482758620689655 | 0.0115840807858 |
| Epoch 8  |  0.3101123595505618 | 0.638643000513 | 0.00230769830735 | 0.44516129032258067 | 0.23793103448275862 | 0.0109640660005 |
| Epoch 9  | 0.40979955456570155 | 0.626267210585 | 0.00176947877165 |  0.5786163522012578 | 0.31724137931034485 | 0.0109759800196 |
| Epoch 10 |         0.38        | 0.629495089169 | 0.00153803472659 | 0.36774193548387096 |  0.3931034482758621 | 0.0115032782478 |
+----------+---------------------+----------------+------------------+---------------------+---------------------+-----------------+
_________________________________________________________________
+---------------------------------+--------------------+--------------------+-----------------------+---------+-----------------------+
|            Optimizer            |       beta_1       |       beta_2       |         decay         | epsilon |           lr          |
+---------------------------------+--------------------+--------------------+-----------------------+---------+-----------------------+
| <class 'keras.optimizers.Adam'> | 0.8999999761581421 | 0.9990000128746033 | 0.0005000000237487257 |  1e-08  | 9.999999747378752e-05 |
+---------------------------------+--------------------+--------------------+-----------------------+---------+-----------------------+
_________________________________________________________________
+------------+
| Batch Size |
+------------+
|     16     |
+------------+
_________________________________________________________________
+--------------------+------------------+----------------+---------------------+---------------------+--------------------+
|      Metrics       |       Loss       |      IoU       |      Precision      |        Recall       |      F1 Score      |
+--------------------+------------------+----------------+---------------------+---------------------+--------------------+
|   Train Metrics    | 0.00161608186687 | 0.772451280128 |  0.8998787878787878 |  0.8981369465279458 | 0.899007023492371  |
| Validation Metrics | 0.0115032784581  | 0.629495089169 | 0.36774193548387096 |  0.3931034482758621 |        0.38        |
|    Test Metrics    | 0.0127801002874  | 0.626195303295 | 0.34226190476190477 | 0.37216828478964403 | 0.3565891472868217 |
+--------------------+------------------+----------------+---------------------+---------------------+--------------------+
_________________________________________________________________
Time:
    Train Time : 1:21:06.264400
    Full Time  : 1:21:49.067572
_________________________________________________________________
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         (None, 288, 288, 1)       0         
_________________________________________________________________
conv_1 (Conv2D)              (None, 288, 288, 32)      320       
_________________________________________________________________
norm_1 (BatchNormalization)  (None, 288, 288, 32)      128       
_________________________________________________________________
relu_1 (LeakyReLU)           (None, 288, 288, 32)      0         
_________________________________________________________________
pool_1 (MaxPooling2D)        (None, 144, 144, 32)      0         
_________________________________________________________________
conv_2 (Conv2D)              (None, 144, 144, 64)      18496     
_________________________________________________________________
norm_2 (BatchNormalization)  (None, 144, 144, 64)      256       
_________________________________________________________________
relu_2 (LeakyReLU)           (None, 144, 144, 64)      0         
_________________________________________________________________
pool_2 (MaxPooling2D)        (None, 72, 72, 64)        0         
_________________________________________________________________
conv_3 (Conv2D)              (None, 72, 72, 128)       73856     
_________________________________________________________________
norm_3 (BatchNormalization)  (None, 72, 72, 128)       512       
_________________________________________________________________
relu_3 (LeakyReLU)           (None, 72, 72, 128)       0         
_________________________________________________________________
conv_4 (Conv2D)              (None, 72, 72, 64)        8256      
_________________________________________________________________
norm_4 (BatchNormalization)  (None, 72, 72, 64)        256       
_________________________________________________________________
relu_4 (LeakyReLU)           (None, 72, 72, 64)        0         
_________________________________________________________________
conv_5 (Conv2D)              (None, 72, 72, 128)       73856     
_________________________________________________________________
norm_5 (BatchNormalization)  (None, 72, 72, 128)       512       
_________________________________________________________________
relu_5 (LeakyReLU)           (None, 72, 72, 128)       0         
_________________________________________________________________
pool_3 (MaxPooling2D)        (None, 36, 36, 128)       0         
_________________________________________________________________
conv_6 (Conv2D)              (None, 36, 36, 256)       295168    
_________________________________________________________________
norm_6 (BatchNormalization)  (None, 36, 36, 256)       1024      
_________________________________________________________________
relu_6 (LeakyReLU)           (None, 36, 36, 256)       0         
_________________________________________________________________
conv_7 (Conv2D)              (None, 36, 36, 128)       32896     
_________________________________________________________________
norm_7 (BatchNormalization)  (None, 36, 36, 128)       512       
_________________________________________________________________
relu_7 (LeakyReLU)           (None, 36, 36, 128)       0         
_________________________________________________________________
conv_8 (Conv2D)              (None, 36, 36, 256)       295168    
_________________________________________________________________
norm_8 (BatchNormalization)  (None, 36, 36, 256)       1024      
_________________________________________________________________
relu_8 (LeakyReLU)           (None, 36, 36, 256)       0         
_________________________________________________________________
pool_4 (MaxPooling2D)        (None, 18, 18, 256)       0         
_________________________________________________________________
conv_9 (Conv2D)              (None, 18, 18, 512)       1180160   
_________________________________________________________________
norm_9 (BatchNormalization)  (None, 18, 18, 512)       2048      
_________________________________________________________________
relu_9 (LeakyReLU)           (None, 18, 18, 512)       0         
_________________________________________________________________
conv_10 (Conv2D)             (None, 18, 18, 256)       131328    
_________________________________________________________________
norm_10 (BatchNormalization) (None, 18, 18, 256)       1024      
_________________________________________________________________
relu_10 (LeakyReLU)          (None, 18, 18, 256)       0         
_________________________________________________________________
conv_11 (Conv2D)             (None, 18, 18, 512)       1180160   
_________________________________________________________________
norm_11 (BatchNormalization) (None, 18, 18, 512)       2048      
_________________________________________________________________
relu_11 (LeakyReLU)          (None, 18, 18, 512)       0         
_________________________________________________________________
conv_12 (Conv2D)             (None, 18, 18, 256)       131328    
_________________________________________________________________
norm_12 (BatchNormalization) (None, 18, 18, 256)       1024      
_________________________________________________________________
relu_12 (LeakyReLU)          (None, 18, 18, 256)       0         
_________________________________________________________________
conv_13 (Conv2D)             (None, 18, 18, 512)       1180160   
_________________________________________________________________
norm_13 (BatchNormalization) (None, 18, 18, 512)       2048      
_________________________________________________________________
relu_13 (LeakyReLU)          (None, 18, 18, 512)       0         
_________________________________________________________________
pool_5 (MaxPooling2D)        (None, 9, 9, 512)         0         
_________________________________________________________________
conv_14 (Conv2D)             (None, 9, 9, 1024)        4719616   
_________________________________________________________________
norm_14 (BatchNormalization) (None, 9, 9, 1024)        4096      
_________________________________________________________________
relu_14 (LeakyReLU)          (None, 9, 9, 1024)        0         
_________________________________________________________________
conv_15 (Conv2D)             (None, 9, 9, 1024)        9438208   
_________________________________________________________________
norm_15 (BatchNormalization) (None, 9, 9, 1024)        4096      
_________________________________________________________________
relu_15 (LeakyReLU)          (None, 9, 9, 1024)        0         
_________________________________________________________________
conv_16 (Conv2D)             (None, 9, 9, 5)           5125      
_________________________________________________________________
reshape_2 (Reshape)          (None, 9, 9, 5)           0         
=================================================================
Total params: 18,784,709
Trainable params: 18,774,405
Non-trainable params: 10,304
_________________________________________________________________
+----------+---------------------+----------------+------------------+---------------------+---------------------+-----------------+
|  Epoch   |       f1_score      |      iou       |       loss       |      precision      |        recall       |     val_loss    |
+----------+---------------------+----------------+------------------+---------------------+---------------------+-----------------+
| Epoch 1  |          0          |       0        | 0.0241344794537  |          0          |         0.0         | 0.0208117695105 |
| Epoch 2  | 0.22482435597189696 | 0.607121044014 | 0.0114010882848  | 0.35036496350364965 | 0.16551724137931034 | 0.0104499668364 |
| Epoch 3  | 0.28785046728971964 | 0.602286698456 | 0.00808116961711 |  0.3142857142857143 |  0.2655172413793103 | 0.0119626788843 |
| Epoch 4  |  0.2569593147751606 | 0.614074609902 | 0.00608997878761 |  0.3389830508474576 | 0.20689655172413793 | 0.0115614695354 |
| Epoch 5  |  0.2983425414364641 | 0.595991405435 | 0.00451161970332 |  0.3201581027667984 |  0.2793103448275862 | 0.0108392882732 |
| Epoch 6  | 0.26666666666666666 | 0.608283780012 | 0.00345458165764 |        0.375        | 0.20689655172413793 | 0.0119564638083 |
| Epoch 7  |  0.3133802816901408 | 0.607409531716 | 0.00255710055673 | 0.32014388489208634 | 0.30689655172413793 | 0.0111801922622 |
| Epoch 8  | 0.27294117647058824 | 0.612213476201 | 0.00206523159671 | 0.42962962962962964 |         0.2         | 0.0116637803374 |
| Epoch 9  |  0.3478260869565218 | 0.617550735735 | 0.00165218934405 | 0.43523316062176165 |  0.2896551724137931 | 0.0111921475599 |
| Epoch 10 |  0.3094170403587444 | 0.623517224592 | 0.00136607847435 |  0.4423076923076923 | 0.23793103448275862 | 0.0113945561762 |
+----------+---------------------+----------------+------------------+---------------------+---------------------+-----------------+
_________________________________________________________________
+---------------------------------+--------------------+--------------------+-----------------------+---------+-----------------------+
|            Optimizer            |       beta_1       |       beta_2       |         decay         | epsilon |           lr          |
+---------------------------------+--------------------+--------------------+-----------------------+---------+-----------------------+
| <class 'keras.optimizers.Adam'> | 0.8999999761581421 | 0.9990000128746033 | 0.0005000000237487257 |  1e-08  | 9.999999747378752e-05 |
+---------------------------------+--------------------+--------------------+-----------------------+---------+-----------------------+
_________________________________________________________________
+------------+
| Batch Size |
+------------+
|     16     |
+------------+
_________________________________________________________________
+--------------------+-------------------+----------------+---------------------+---------------------+--------------------+
|      Metrics       |        Loss       |      IoU       |      Precision      |        Recall       |      F1 Score      |
+--------------------+-------------------+----------------+---------------------+---------------------+--------------------+
|   Train Metrics    | 0.000966957307554 | 0.775173811145 |  0.9335716046339659 |  0.9164045487539317 | 0.9249084249084248 |
| Validation Metrics |  0.0113945561311  | 0.623517224592 |  0.4423076923076923 | 0.23793103448275862 | 0.3094170403587444 |
|    Test Metrics    |  0.0124334339954  | 0.617778780221 | 0.39226519337016574 |  0.2297734627831715 | 0.2897959183673469 |
+--------------------+-------------------+----------------+---------------------+---------------------+--------------------+
_________________________________________________________________
Time:
    Train Time : 3:09:06.509053
    Full Time  : 3:15:35.684778
_________________________________________________________________
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_3 (InputLayer)         (None, 288, 288, 1)       0         
_________________________________________________________________
conv_1 (Conv2D)              (None, 288, 288, 32)      320       
_________________________________________________________________
norm_1 (BatchNormalization)  (None, 288, 288, 32)      128       
_________________________________________________________________
relu_1 (LeakyReLU)           (None, 288, 288, 32)      0         
_________________________________________________________________
pool_1 (MaxPooling2D)        (None, 144, 144, 32)      0         
_________________________________________________________________
conv_2 (Conv2D)              (None, 144, 144, 64)      18496     
_________________________________________________________________
norm_2 (BatchNormalization)  (None, 144, 144, 64)      256       
_________________________________________________________________
relu_2 (LeakyReLU)           (None, 144, 144, 64)      0         
_________________________________________________________________
pool_2 (MaxPooling2D)        (None, 72, 72, 64)        0         
_________________________________________________________________
conv_3 (Conv2D)              (None, 72, 72, 128)       73856     
_________________________________________________________________
norm_3 (BatchNormalization)  (None, 72, 72, 128)       512       
_________________________________________________________________
relu_3 (LeakyReLU)           (None, 72, 72, 128)       0         
_________________________________________________________________
conv_4 (Conv2D)              (None, 72, 72, 64)        8256      
_________________________________________________________________
norm_4 (BatchNormalization)  (None, 72, 72, 64)        256       
_________________________________________________________________
relu_4 (LeakyReLU)           (None, 72, 72, 64)        0         
_________________________________________________________________
conv_5 (Conv2D)              (None, 72, 72, 128)       73856     
_________________________________________________________________
norm_5 (BatchNormalization)  (None, 72, 72, 128)       512       
_________________________________________________________________
relu_5 (LeakyReLU)           (None, 72, 72, 128)       0         
_________________________________________________________________
pool_3 (MaxPooling2D)        (None, 36, 36, 128)       0         
_________________________________________________________________
conv_6 (Conv2D)              (None, 36, 36, 256)       295168    
_________________________________________________________________
norm_6 (BatchNormalization)  (None, 36, 36, 256)       1024      
_________________________________________________________________
relu_6 (LeakyReLU)           (None, 36, 36, 256)       0         
_________________________________________________________________
conv_7 (Conv2D)              (None, 36, 36, 128)       32896     
_________________________________________________________________
norm_7 (BatchNormalization)  (None, 36, 36, 128)       512       
_________________________________________________________________
relu_7 (LeakyReLU)           (None, 36, 36, 128)       0         
_________________________________________________________________
conv_8 (Conv2D)              (None, 36, 36, 256)       295168    
_________________________________________________________________
norm_8 (BatchNormalization)  (None, 36, 36, 256)       1024      
_________________________________________________________________
relu_8 (LeakyReLU)           (None, 36, 36, 256)       0         
_________________________________________________________________
pool_4 (MaxPooling2D)        (None, 18, 18, 256)       0         
_________________________________________________________________
conv_9 (Conv2D)              (None, 18, 18, 512)       1180160   
_________________________________________________________________
norm_9 (BatchNormalization)  (None, 18, 18, 512)       2048      
_________________________________________________________________
relu_9 (LeakyReLU)           (None, 18, 18, 512)       0         
_________________________________________________________________
conv_10 (Conv2D)             (None, 18, 18, 256)       131328    
_________________________________________________________________
norm_10 (BatchNormalization) (None, 18, 18, 256)       1024      
_________________________________________________________________
relu_10 (LeakyReLU)          (None, 18, 18, 256)       0         
_________________________________________________________________
conv_11 (Conv2D)             (None, 18, 18, 512)       1180160   
_________________________________________________________________
norm_11 (BatchNormalization) (None, 18, 18, 512)       2048      
_________________________________________________________________
relu_11 (LeakyReLU)          (None, 18, 18, 512)       0         
_________________________________________________________________
conv_12 (Conv2D)             (None, 18, 18, 256)       131328    
_________________________________________________________________
norm_12 (BatchNormalization) (None, 18, 18, 256)       1024      
_________________________________________________________________
relu_12 (LeakyReLU)          (None, 18, 18, 256)       0         
_________________________________________________________________
conv_13 (Conv2D)             (None, 18, 18, 512)       1180160   
_________________________________________________________________
norm_13 (BatchNormalization) (None, 18, 18, 512)       2048      
_________________________________________________________________
relu_13 (LeakyReLU)          (None, 18, 18, 512)       0         
_________________________________________________________________
pool_5 (MaxPooling2D)        (None, 9, 9, 512)         0         
_________________________________________________________________
conv_14 (Conv2D)             (None, 9, 9, 1024)        4719616   
_________________________________________________________________
norm_14 (BatchNormalization) (None, 9, 9, 1024)        4096      
_________________________________________________________________
relu_14 (LeakyReLU)          (None, 9, 9, 1024)        0         
_________________________________________________________________
conv_15 (Conv2D)             (None, 9, 9, 1024)        9438208   
_________________________________________________________________
norm_15 (BatchNormalization) (None, 9, 9, 1024)        4096      
_________________________________________________________________
relu_15 (LeakyReLU)          (None, 9, 9, 1024)        0         
_________________________________________________________________
conv_16 (Conv2D)             (None, 9, 9, 5)           5125      
_________________________________________________________________
reshape_3 (Reshape)          (None, 9, 9, 5)           0         
=================================================================
Total params: 18,784,709
Trainable params: 18,774,405
Non-trainable params: 10,304
_________________________________________________________________
+----------+---------------------+----------------+------------------+---------------------+----------------------+-----------------+
|  Epoch   |       f1_score      |      iou       |       loss       |      precision      |        recall        |     val_loss    |
+----------+---------------------+----------------+------------------+---------------------+----------------------+-----------------+
| Epoch 1  | 0.03322259136212625 | 0.556703602168 | 0.0312631330512  | 0.45454545454545453 | 0.017241379310344827 | 0.0202656165667 |
| Epoch 2  | 0.35294117647058826 | 0.625942670982 | 0.0123841863855  |  0.3924050632911392 | 0.32068965517241377  | 0.0123693358393 |
| Epoch 3  |  0.3747680890538034 | 0.625260919815 | 0.0093869976227  | 0.40562248995983935 |  0.3482758620689655  | 0.0123805431349 |
| Epoch 4  | 0.38735177865612647 | 0.620652485245 | 0.00690055821903 |  0.4537037037037037 | 0.33793103448275863  | 0.0116289055816 |
| Epoch 5  | 0.41681901279707495 | 0.603176053301 | 0.00546115149515 | 0.44357976653696496 |  0.3931034482758621  | 0.0114150360647 |
| Epoch 6  | 0.32758620689655177 | 0.626826236538 | 0.00408667759023 |  0.4367816091954023 |  0.2620689655172414  | 0.0116563685419 |
| Epoch 7  |  0.3624161073825503 | 0.635777697461 | 0.00332222153596 |  0.5159235668789809 |  0.2793103448275862  | 0.0122687184222 |
| Epoch 8  |  0.4475806451612903 | 0.640183615667 | 0.00278435965106 |  0.5388349514563107 | 0.38275862068965516  | 0.0099762626473 |
| Epoch 9  |  0.4271457085828344 | 0.641918158197 | 0.00224954059284 |  0.5071090047393365 |  0.3689655172413793  | 0.0105476474029 |
| Epoch 10 |  0.4132231404958678 | 0.640467747873 | 0.00175620384187 |  0.5154639175257731 |  0.3448275862068966  | 0.0111436949923 |
+----------+---------------------+----------------+------------------+---------------------+----------------------+-----------------+
_________________________________________________________________
+---------------------------------+--------------------+--------------------+-----------------------+---------+-----------------------+
|            Optimizer            |       beta_1       |       beta_2       |         decay         | epsilon |           lr          |
+---------------------------------+--------------------+--------------------+-----------------------+---------+-----------------------+
| <class 'keras.optimizers.Adam'> | 0.8999999761581421 | 0.9990000128746033 | 0.0005000000237487257 |  1e-08  | 9.999999747378752e-05 |
+---------------------------------+--------------------+--------------------+-----------------------+---------+-----------------------+
_________________________________________________________________
+------------+
| Batch Size |
+------------+
|     16     |
+------------+
_________________________________________________________________
+--------------------+------------------+----------------+---------------------+--------------------+--------------------+
|      Metrics       |       Loss       |      IoU       |      Precision      |       Recall       |      F1 Score      |
+--------------------+------------------+----------------+---------------------+--------------------+--------------------+
|   Train Metrics    | 0.00145265406193 | 0.770029254629 |  0.9143280998887378 | 0.8947495765787563 | 0.9044328951391012 |
| Validation Metrics | 0.0111436951425  | 0.640467747873 |  0.5154639175257731 | 0.3448275862068966 | 0.4132231404958678 |
|    Test Metrics    | 0.0117358241471  | 0.640392350127 | 0.44502617801047123 | 0.2750809061488673 |        0.34        |
+--------------------+------------------+----------------+---------------------+--------------------+--------------------+
_________________________________________________________________
Time:
    Train Time : 5:08:42.316235
    Full Time  : 5:14:50.201949
_________________________________________________________________
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         (None, 288, 288, 1)       0         
_________________________________________________________________
conv_1 (Conv2D)              (None, 288, 288, 32)      320       
_________________________________________________________________
norm_1 (BatchNormalization)  (None, 288, 288, 32)      128       
_________________________________________________________________
relu_1 (LeakyReLU)           (None, 288, 288, 32)      0         
_________________________________________________________________
pool_1 (MaxPooling2D)        (None, 144, 144, 32)      0         
_________________________________________________________________
conv_2 (Conv2D)              (None, 144, 144, 64)      18496     
_________________________________________________________________
norm_2 (BatchNormalization)  (None, 144, 144, 64)      256       
_________________________________________________________________
relu_2 (LeakyReLU)           (None, 144, 144, 64)      0         
_________________________________________________________________
pool_2 (MaxPooling2D)        (None, 72, 72, 64)        0         
_________________________________________________________________
conv_3 (Conv2D)              (None, 72, 72, 128)       73856     
_________________________________________________________________
norm_3 (BatchNormalization)  (None, 72, 72, 128)       512       
_________________________________________________________________
relu_3 (LeakyReLU)           (None, 72, 72, 128)       0         
_________________________________________________________________
conv_4 (Conv2D)              (None, 72, 72, 64)        8256      
_________________________________________________________________
norm_4 (BatchNormalization)  (None, 72, 72, 64)        256       
_________________________________________________________________
relu_4 (LeakyReLU)           (None, 72, 72, 64)        0         
_________________________________________________________________
conv_5 (Conv2D)              (None, 72, 72, 128)       73856     
_________________________________________________________________
norm_5 (BatchNormalization)  (None, 72, 72, 128)       512       
_________________________________________________________________
relu_5 (LeakyReLU)           (None, 72, 72, 128)       0         
_________________________________________________________________
pool_3 (MaxPooling2D)        (None, 36, 36, 128)       0         
_________________________________________________________________
conv_6 (Conv2D)              (None, 36, 36, 256)       295168    
_________________________________________________________________
norm_6 (BatchNormalization)  (None, 36, 36, 256)       1024      
_________________________________________________________________
relu_6 (LeakyReLU)           (None, 36, 36, 256)       0         
_________________________________________________________________
conv_7 (Conv2D)              (None, 36, 36, 128)       32896     
_________________________________________________________________
norm_7 (BatchNormalization)  (None, 36, 36, 128)       512       
_________________________________________________________________
relu_7 (LeakyReLU)           (None, 36, 36, 128)       0         
_________________________________________________________________
conv_8 (Conv2D)              (None, 36, 36, 256)       295168    
_________________________________________________________________
norm_8 (BatchNormalization)  (None, 36, 36, 256)       1024      
_________________________________________________________________
relu_8 (LeakyReLU)           (None, 36, 36, 256)       0         
_________________________________________________________________
pool_4 (MaxPooling2D)        (None, 18, 18, 256)       0         
_________________________________________________________________
conv_9 (Conv2D)              (None, 18, 18, 512)       1180160   
_________________________________________________________________
norm_9 (BatchNormalization)  (None, 18, 18, 512)       2048      
_________________________________________________________________
relu_9 (LeakyReLU)           (None, 18, 18, 512)       0         
_________________________________________________________________
conv_10 (Conv2D)             (None, 18, 18, 256)       131328    
_________________________________________________________________
norm_10 (BatchNormalization) (None, 18, 18, 256)       1024      
_________________________________________________________________
relu_10 (LeakyReLU)          (None, 18, 18, 256)       0         
_________________________________________________________________
conv_11 (Conv2D)             (None, 18, 18, 512)       1180160   
_________________________________________________________________
norm_11 (BatchNormalization) (None, 18, 18, 512)       2048      
_________________________________________________________________
relu_11 (LeakyReLU)          (None, 18, 18, 512)       0         
_________________________________________________________________
conv_12 (Conv2D)             (None, 18, 18, 256)       131328    
_________________________________________________________________
norm_12 (BatchNormalization) (None, 18, 18, 256)       1024      
_________________________________________________________________
relu_12 (LeakyReLU)          (None, 18, 18, 256)       0         
_________________________________________________________________
conv_13 (Conv2D)             (None, 18, 18, 512)       1180160   
_________________________________________________________________
norm_13 (BatchNormalization) (None, 18, 18, 512)       2048      
_________________________________________________________________
relu_13 (LeakyReLU)          (None, 18, 18, 512)       0         
_________________________________________________________________
pool_5 (MaxPooling2D)        (None, 9, 9, 512)         0         
_________________________________________________________________
conv_14 (Conv2D)             (None, 9, 9, 1024)        4719616   
_________________________________________________________________
norm_14 (BatchNormalization) (None, 9, 9, 1024)        4096      
_________________________________________________________________
relu_14 (LeakyReLU)          (None, 9, 9, 1024)        0         
_________________________________________________________________
conv_15 (Conv2D)             (None, 9, 9, 1024)        9438208   
_________________________________________________________________
norm_15 (BatchNormalization) (None, 9, 9, 1024)        4096      
_________________________________________________________________
relu_15 (LeakyReLU)          (None, 9, 9, 1024)        0         
_________________________________________________________________
conv_16 (Conv2D)             (None, 9, 9, 5)           5125      
_________________________________________________________________
reshape_1 (Reshape)          (None, 9, 9, 5)           0         
=================================================================
Total params: 18,784,709
Trainable params: 18,774,405
Non-trainable params: 10,304
_________________________________________________________________
+----------+----------------------+----------------+-----------------+---------------------+-----------------------+-----------------+
|  Epoch   |       f1_score       |      iou       |       loss      |      precision      |         recall        |     val_loss    |
+----------+----------------------+----------------+-----------------+---------------------+-----------------------+-----------------+
| Epoch 1  |          0           |       0        | 0.0468561254372 |          0          |          0.0          | 0.0198662004644 |
| Epoch 2  |          0           |       0        | 0.0356348255871 |          0          |          0.0          | 0.0226980119102 |
| Epoch 3  |          0           |      nan       | 0.0333848637281 |         0.0         |          0.0          | 0.0244492994201 |
| Epoch 4  |          0           |      nan       | 0.0317914727398 |         0.0         |          0.0          | 0.0264970410255 |
| Epoch 5  |          0           |      nan       |  0.030006786114 |         0.0         |          0.0          | 0.0246709671112 |
| Epoch 6  | 0.006230529595015576 | 0.574538243647 | 0.0285615267316 | 0.03225806451612903 | 0.0034482758620689655 | 0.0241989933195 |
| Epoch 7  |          0           |      nan       | 0.0274001526491 |         0.0         |          0.0          | 0.0236296930741 |
| Epoch 8  |          0           |      nan       | 0.0263432347462 |         0.0         |          0.0          |  0.024220167509 |
| Epoch 9  | 0.006289308176100628 | 0.693665662645 | 0.0252964783614 | 0.03571428571428571 | 0.0034482758620689655 | 0.0218768529594 |
| Epoch 10 | 0.018018018018018018 | 0.699019385284 | 0.0244244533738 | 0.06976744186046512 |  0.010344827586206896 | 0.0229016625352 |
+----------+----------------------+----------------+-----------------+---------------------+-----------------------+-----------------+
_________________________________________________________________
+--------------------------------+-------+----------------------+----------+----------+
|           Optimizer            | decay |          lr          | momentum | nesterov |
+--------------------------------+-------+----------------------+----------+----------+
| <class 'keras.optimizers.SGD'> |  0.0  | 0.009999999776482582 |   0.0    |  False   |
+--------------------------------+-------+----------------------+----------+----------+
_________________________________________________________________
+------------+
| Batch Size |
+------------+
|     16     |
+------------+
_________________________________________________________________
+--------------------+-----------------+----------------+----------------------+----------------------+----------------------+
|      Metrics       |       Loss      |      IoU       |      Precision       |        Recall        |       F1 Score       |
+--------------------+-----------------+----------------+----------------------+----------------------+----------------------+
|   Train Metrics    | 0.0244662878115 | 0.598527746644 |  0.163519115614924   | 0.042947011855794824 | 0.06802721088435373  |
| Validation Metrics | 0.0229016627756 | 0.699019385284 | 0.06976744186046512  | 0.010344827586206896 | 0.018018018018018018 |
|    Test Metrics    | 0.0238417541428 | 0.562822487663 | 0.045454545454545456 | 0.006472491909385114 |  0.0113314447592068  |
+--------------------+-----------------+----------------+----------------------+----------------------+----------------------+
_________________________________________________________________
Time:
    Train Time : 1:18:09.986117
    Dataset Loading Time  : 0:00:38.012478
_________________________________________________________________
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         (None, 288, 288, 1)       0         
_________________________________________________________________
conv_1 (Conv2D)              (None, 288, 288, 32)      320       
_________________________________________________________________
norm_1 (BatchNormalization)  (None, 288, 288, 32)      128       
_________________________________________________________________
relu_1 (LeakyReLU)           (None, 288, 288, 32)      0         
_________________________________________________________________
pool_1 (MaxPooling2D)        (None, 144, 144, 32)      0         
_________________________________________________________________
conv_2 (Conv2D)              (None, 144, 144, 64)      18496     
_________________________________________________________________
norm_2 (BatchNormalization)  (None, 144, 144, 64)      256       
_________________________________________________________________
relu_2 (LeakyReLU)           (None, 144, 144, 64)      0         
_________________________________________________________________
pool_2 (MaxPooling2D)        (None, 72, 72, 64)        0         
_________________________________________________________________
conv_3 (Conv2D)              (None, 72, 72, 128)       73856     
_________________________________________________________________
norm_3 (BatchNormalization)  (None, 72, 72, 128)       512       
_________________________________________________________________
relu_3 (LeakyReLU)           (None, 72, 72, 128)       0         
_________________________________________________________________
conv_4 (Conv2D)              (None, 72, 72, 64)        8256      
_________________________________________________________________
norm_4 (BatchNormalization)  (None, 72, 72, 64)        256       
_________________________________________________________________
relu_4 (LeakyReLU)           (None, 72, 72, 64)        0         
_________________________________________________________________
conv_5 (Conv2D)              (None, 72, 72, 128)       73856     
_________________________________________________________________
norm_5 (BatchNormalization)  (None, 72, 72, 128)       512       
_________________________________________________________________
relu_5 (LeakyReLU)           (None, 72, 72, 128)       0         
_________________________________________________________________
pool_3 (MaxPooling2D)        (None, 36, 36, 128)       0         
_________________________________________________________________
conv_6 (Conv2D)              (None, 36, 36, 256)       295168    
_________________________________________________________________
norm_6 (BatchNormalization)  (None, 36, 36, 256)       1024      
_________________________________________________________________
relu_6 (LeakyReLU)           (None, 36, 36, 256)       0         
_________________________________________________________________
conv_7 (Conv2D)              (None, 36, 36, 128)       32896     
_________________________________________________________________
norm_7 (BatchNormalization)  (None, 36, 36, 128)       512       
_________________________________________________________________
relu_7 (LeakyReLU)           (None, 36, 36, 128)       0         
_________________________________________________________________
conv_8 (Conv2D)              (None, 36, 36, 256)       295168    
_________________________________________________________________
norm_8 (BatchNormalization)  (None, 36, 36, 256)       1024      
_________________________________________________________________
relu_8 (LeakyReLU)           (None, 36, 36, 256)       0         
_________________________________________________________________
pool_4 (MaxPooling2D)        (None, 18, 18, 256)       0         
_________________________________________________________________
conv_9 (Conv2D)              (None, 18, 18, 512)       1180160   
_________________________________________________________________
norm_9 (BatchNormalization)  (None, 18, 18, 512)       2048      
_________________________________________________________________
relu_9 (LeakyReLU)           (None, 18, 18, 512)       0         
_________________________________________________________________
conv_10 (Conv2D)             (None, 18, 18, 256)       131328    
_________________________________________________________________
norm_10 (BatchNormalization) (None, 18, 18, 256)       1024      
_________________________________________________________________
relu_10 (LeakyReLU)          (None, 18, 18, 256)       0         
_________________________________________________________________
conv_11 (Conv2D)             (None, 18, 18, 512)       1180160   
_________________________________________________________________
norm_11 (BatchNormalization) (None, 18, 18, 512)       2048      
_________________________________________________________________
relu_11 (LeakyReLU)          (None, 18, 18, 512)       0         
_________________________________________________________________
conv_12 (Conv2D)             (None, 18, 18, 256)       131328    
_________________________________________________________________
norm_12 (BatchNormalization) (None, 18, 18, 256)       1024      
_________________________________________________________________
relu_12 (LeakyReLU)          (None, 18, 18, 256)       0         
_________________________________________________________________
conv_13 (Conv2D)             (None, 18, 18, 512)       1180160   
_________________________________________________________________
norm_13 (BatchNormalization) (None, 18, 18, 512)       2048      
_________________________________________________________________
relu_13 (LeakyReLU)          (None, 18, 18, 512)       0         
_________________________________________________________________
pool_5 (MaxPooling2D)        (None, 9, 9, 512)         0         
_________________________________________________________________
conv_14 (Conv2D)             (None, 9, 9, 1024)        4719616   
_________________________________________________________________
norm_14 (BatchNormalization) (None, 9, 9, 1024)        4096      
_________________________________________________________________
relu_14 (LeakyReLU)          (None, 9, 9, 1024)        0         
_________________________________________________________________
conv_15 (Conv2D)             (None, 9, 9, 1024)        9438208   
_________________________________________________________________
norm_15 (BatchNormalization) (None, 9, 9, 1024)        4096      
_________________________________________________________________
relu_15 (LeakyReLU)          (None, 9, 9, 1024)        0         
_________________________________________________________________
conv_16 (Conv2D)             (None, 9, 9, 5)           5125      
_________________________________________________________________
reshape_2 (Reshape)          (None, 9, 9, 5)           0         
=================================================================
Total params: 18,784,709
Trainable params: 18,774,405
Non-trainable params: 10,304
_________________________________________________________________
+----------+---------------------+----------------+------------------+--------------------+--------------------+------------------+
|  Epoch   |       f1_score      |      iou       |       loss       |     precision      |       recall       |     val_loss     |
+----------+---------------------+----------------+------------------+--------------------+--------------------+------------------+
| Epoch 1  |  0.5390334572490707 |  0.6368186041  | 0.0223750955105  | 0.5846774193548387 |        0.5         | 0.00829057670349 |
| Epoch 2  | 0.32684824902723736 | 0.643134511915 | 0.0104699268943  |       0.375        | 0.2896551724137931 | 0.0116033816049  |
| Epoch 3  |  0.5896551724137931 | 0.676379169897 | 0.00826440693493 | 0.5896551724137931 | 0.5896551724137931 | 0.00830588384622 |
| Epoch 4  |  0.6310344827586207 | 0.653360942302 | 0.0067661391805  | 0.6310344827586207 | 0.6310344827586207 | 0.0062195445456  |
| Epoch 5  |  0.5834932821497121 | 0.663260861295 | 0.0057893792657  | 0.658008658008658  | 0.5241379310344828 | 0.00759230728351 |
| Epoch 6  |  0.6832740213523132 | 0.665573560877 | 0.00510116760967 | 0.7058823529411765 | 0.6620689655172414 | 0.00690751061625 |
| Epoch 7  |  0.6285714285714287 | 0.686218503903 | 0.00467957697206 | 0.5823529411764706 | 0.6827586206896552 | 0.00808053065632 |
| Epoch 8  |  0.6642984014209592 | 0.680729216802 | 0.00430548602087 | 0.684981684981685  | 0.6448275862068965 | 0.00720784667459 |
| Epoch 9  |  0.6480446927374303 | 0.645441868988 | 0.0040383735438  | 0.7044534412955465 |        0.6         | 0.00674185710358 |
| Epoch 10 |  0.6621160409556314 | 0.649677279088 | 0.00375625280975 | 0.6554054054054054 | 0.6689655172413793 | 0.00720023733353 |
+----------+---------------------+----------------+------------------+--------------------+--------------------+------------------+
_________________________________________________________________
+------------------------------------+-------+---------+-----------------------+--------------------+
|             Optimizer              | decay | epsilon |           lr          |        rho         |
+------------------------------------+-------+---------+-----------------------+--------------------+
| <class 'keras.optimizers.RMSprop'> |  0.0  |  1e-08  | 0.0010000000474974513 | 0.8999999761581421 |
+------------------------------------+-------+---------+-----------------------+--------------------+
_________________________________________________________________
+------------+
| Batch Size |
+------------+
|     16     |
+------------+
_________________________________________________________________
+--------------------+------------------+----------------+--------------------+--------------------+--------------------+
|      Metrics       |       Loss       |      IoU       |     Precision      |       Recall       |      F1 Score      |
+--------------------+------------------+----------------+--------------------+--------------------+--------------------+
|   Train Metrics    | 0.00447342022524 | 0.783586609327 | 0.8986514098896609 | 0.7980885555286716 | 0.8453898891523035 |
| Validation Metrics | 0.00720023733353 | 0.649677279088 | 0.6554054054054054 | 0.6689655172413793 | 0.6621160409556314 |
|    Test Metrics    | 0.00781458922692 | 0.655256854235 | 0.6266666666666667 | 0.6084142394822006 | 0.6174055829228243 |
+--------------------+------------------+----------------+--------------------+--------------------+--------------------+
_________________________________________________________________
Time:
    Train Time : 2:53:03.873400
    Dataset Loading Time  : 0:00:38.012478
_________________________________________________________________
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_3 (InputLayer)         (None, 288, 288, 1)       0         
_________________________________________________________________
conv_1 (Conv2D)              (None, 288, 288, 32)      320       
_________________________________________________________________
norm_1 (BatchNormalization)  (None, 288, 288, 32)      128       
_________________________________________________________________
relu_1 (LeakyReLU)           (None, 288, 288, 32)      0         
_________________________________________________________________
pool_1 (MaxPooling2D)        (None, 144, 144, 32)      0         
_________________________________________________________________
conv_2 (Conv2D)              (None, 144, 144, 64)      18496     
_________________________________________________________________
norm_2 (BatchNormalization)  (None, 144, 144, 64)      256       
_________________________________________________________________
relu_2 (LeakyReLU)           (None, 144, 144, 64)      0         
_________________________________________________________________
pool_2 (MaxPooling2D)        (None, 72, 72, 64)        0         
_________________________________________________________________
conv_3 (Conv2D)              (None, 72, 72, 128)       73856     
_________________________________________________________________
norm_3 (BatchNormalization)  (None, 72, 72, 128)       512       
_________________________________________________________________
relu_3 (LeakyReLU)           (None, 72, 72, 128)       0         
_________________________________________________________________
conv_4 (Conv2D)              (None, 72, 72, 64)        8256      
_________________________________________________________________
norm_4 (BatchNormalization)  (None, 72, 72, 64)        256       
_________________________________________________________________
relu_4 (LeakyReLU)           (None, 72, 72, 64)        0         
_________________________________________________________________
conv_5 (Conv2D)              (None, 72, 72, 128)       73856     
_________________________________________________________________
norm_5 (BatchNormalization)  (None, 72, 72, 128)       512       
_________________________________________________________________
relu_5 (LeakyReLU)           (None, 72, 72, 128)       0         
_________________________________________________________________
pool_3 (MaxPooling2D)        (None, 36, 36, 128)       0         
_________________________________________________________________
conv_6 (Conv2D)              (None, 36, 36, 256)       295168    
_________________________________________________________________
norm_6 (BatchNormalization)  (None, 36, 36, 256)       1024      
_________________________________________________________________
relu_6 (LeakyReLU)           (None, 36, 36, 256)       0         
_________________________________________________________________
conv_7 (Conv2D)              (None, 36, 36, 128)       32896     
_________________________________________________________________
norm_7 (BatchNormalization)  (None, 36, 36, 128)       512       
_________________________________________________________________
relu_7 (LeakyReLU)           (None, 36, 36, 128)       0         
_________________________________________________________________
conv_8 (Conv2D)              (None, 36, 36, 256)       295168    
_________________________________________________________________
norm_8 (BatchNormalization)  (None, 36, 36, 256)       1024      
_________________________________________________________________
relu_8 (LeakyReLU)           (None, 36, 36, 256)       0         
_________________________________________________________________
pool_4 (MaxPooling2D)        (None, 18, 18, 256)       0         
_________________________________________________________________
conv_9 (Conv2D)              (None, 18, 18, 512)       1180160   
_________________________________________________________________
norm_9 (BatchNormalization)  (None, 18, 18, 512)       2048      
_________________________________________________________________
relu_9 (LeakyReLU)           (None, 18, 18, 512)       0         
_________________________________________________________________
conv_10 (Conv2D)             (None, 18, 18, 256)       131328    
_________________________________________________________________
norm_10 (BatchNormalization) (None, 18, 18, 256)       1024      
_________________________________________________________________
relu_10 (LeakyReLU)          (None, 18, 18, 256)       0         
_________________________________________________________________
conv_11 (Conv2D)             (None, 18, 18, 512)       1180160   
_________________________________________________________________
norm_11 (BatchNormalization) (None, 18, 18, 512)       2048      
_________________________________________________________________
relu_11 (LeakyReLU)          (None, 18, 18, 512)       0         
_________________________________________________________________
conv_12 (Conv2D)             (None, 18, 18, 256)       131328    
_________________________________________________________________
norm_12 (BatchNormalization) (None, 18, 18, 256)       1024      
_________________________________________________________________
relu_12 (LeakyReLU)          (None, 18, 18, 256)       0         
_________________________________________________________________
conv_13 (Conv2D)             (None, 18, 18, 512)       1180160   
_________________________________________________________________
norm_13 (BatchNormalization) (None, 18, 18, 512)       2048      
_________________________________________________________________
relu_13 (LeakyReLU)          (None, 18, 18, 512)       0         
_________________________________________________________________
pool_5 (MaxPooling2D)        (None, 9, 9, 512)         0         
_________________________________________________________________
conv_14 (Conv2D)             (None, 9, 9, 1024)        4719616   
_________________________________________________________________
norm_14 (BatchNormalization) (None, 9, 9, 1024)        4096      
_________________________________________________________________
relu_14 (LeakyReLU)          (None, 9, 9, 1024)        0         
_________________________________________________________________
conv_15 (Conv2D)             (None, 9, 9, 1024)        9438208   
_________________________________________________________________
norm_15 (BatchNormalization) (None, 9, 9, 1024)        4096      
_________________________________________________________________
relu_15 (LeakyReLU)          (None, 9, 9, 1024)        0         
_________________________________________________________________
conv_16 (Conv2D)             (None, 9, 9, 5)           5125      
_________________________________________________________________
reshape_3 (Reshape)          (None, 9, 9, 5)           0         
=================================================================
Total params: 18,784,709
Trainable params: 18,774,405
Non-trainable params: 10,304
_________________________________________________________________
+----------+---------------------+----------------+------------------+--------------------+---------------------+------------------+
|  Epoch   |       f1_score      |      iou       |       loss       |     precision      |        recall       |     val_loss     |
+----------+---------------------+----------------+------------------+--------------------+---------------------+------------------+
| Epoch 1  |          0          |       0        | 0.0188539425338  |         0          |         0.0         | 0.0198038110449  |
| Epoch 2  |  0.4646924829157176 | 0.660177770753 | 0.0107231417046  | 0.6845637583892618 | 0.35172413793103446 | 0.00849773641676 |
| Epoch 3  |  0.4911591355599214 | 0.62694866977  | 0.00833061300549 | 0.5707762557077626 | 0.43103448275862066 | 0.00850086895028 |
| Epoch 4  | 0.49694501018329934 | 0.668075498439 | 0.00653025286551 | 0.6069651741293532 |  0.4206896551724138 | 0.00872517958464 |
| Epoch 5  |  0.5207956600361665 | 0.653003055705 | 0.00552860028303 | 0.5475285171102662 |  0.496551724137931  | 0.00875469304681 |
| Epoch 6  |  0.5614035087719299 | 0.66091777902  | 0.00484555601068 | 0.5714285714285714 |  0.5517241379310345 | 0.00813816752165 |
| Epoch 7  |  0.5661764705882353 | 0.664144780528 | 0.00413702268115 | 0.6062992125984252 |  0.5310344827586206 | 0.00831950500968 |
| Epoch 8  |  0.5419847328244275 | 0.651085555648 | 0.00351361595157 | 0.6068376068376068 |  0.4896551724137931 | 0.00875878246922 |
| Epoch 9  |  0.5166340508806262 | 0.65235112212  | 0.00311347101656 | 0.5972850678733032 | 0.45517241379310347 | 0.00903730635201 |
| Epoch 10 |  0.5138632162661737 | 0.649619025472 | 0.00270116559524 | 0.5537848605577689 |  0.4793103448275862 | 0.00899830398961 |
+----------+---------------------+----------------+------------------+--------------------+---------------------+------------------+
_________________________________________________________________
+------------------------------------+-------+---------+----------------------+
|             Optimizer              | decay | epsilon |          lr          |
+------------------------------------+-------+---------+----------------------+
| <class 'keras.optimizers.Adagrad'> |  0.0  |  1e-08  | 0.009999999776482582 |
+------------------------------------+-------+---------+----------------------+
_________________________________________________________________
+------------+
| Batch Size |
+------------+
|     16     |
+------------+
_________________________________________________________________
+--------------------+------------------+----------------+--------------------+--------------------+--------------------+
|      Metrics       |       Loss       |      IoU       |     Precision      |       Recall       |      F1 Score      |
+--------------------+------------------+----------------+--------------------+--------------------+--------------------+
|   Train Metrics    | 0.00236307229676 | 0.814389587957 | 0.9444237687631808 | 0.9210016936849746 | 0.932565688736449  |
| Validation Metrics | 0.0089983041248  | 0.649619025472 | 0.5537848605577689 | 0.4793103448275862 | 0.5138632162661737 |
|    Test Metrics    | 0.00909916906347 | 0.662126099737 | 0.5968379446640316 | 0.4886731391585761 | 0.5373665480427047 |
+--------------------+------------------+----------------+--------------------+--------------------+--------------------+
_________________________________________________________________
Time:
    Train Time : 4:36:30.961521
    Dataset Loading Time  : 0:00:38.012478
_________________________________________________________________
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         (None, 288, 288, 1)       0         
_________________________________________________________________
conv_1 (Conv2D)              (None, 288, 288, 32)      320       
_________________________________________________________________
norm_1 (BatchNormalization)  (None, 288, 288, 32)      128       
_________________________________________________________________
relu_1 (LeakyReLU)           (None, 288, 288, 32)      0         
_________________________________________________________________
pool_1 (MaxPooling2D)        (None, 144, 144, 32)      0         
_________________________________________________________________
conv_2 (Conv2D)              (None, 144, 144, 64)      18496     
_________________________________________________________________
norm_2 (BatchNormalization)  (None, 144, 144, 64)      256       
_________________________________________________________________
relu_2 (LeakyReLU)           (None, 144, 144, 64)      0         
_________________________________________________________________
pool_2 (MaxPooling2D)        (None, 72, 72, 64)        0         
_________________________________________________________________
conv_3 (Conv2D)              (None, 72, 72, 128)       73856     
_________________________________________________________________
norm_3 (BatchNormalization)  (None, 72, 72, 128)       512       
_________________________________________________________________
relu_3 (LeakyReLU)           (None, 72, 72, 128)       0         
_________________________________________________________________
conv_4 (Conv2D)              (None, 72, 72, 64)        8256      
_________________________________________________________________
norm_4 (BatchNormalization)  (None, 72, 72, 64)        256       
_________________________________________________________________
relu_4 (LeakyReLU)           (None, 72, 72, 64)        0         
_________________________________________________________________
conv_5 (Conv2D)              (None, 72, 72, 128)       73856     
_________________________________________________________________
norm_5 (BatchNormalization)  (None, 72, 72, 128)       512       
_________________________________________________________________
relu_5 (LeakyReLU)           (None, 72, 72, 128)       0         
_________________________________________________________________
pool_3 (MaxPooling2D)        (None, 36, 36, 128)       0         
_________________________________________________________________
conv_6 (Conv2D)              (None, 36, 36, 256)       295168    
_________________________________________________________________
norm_6 (BatchNormalization)  (None, 36, 36, 256)       1024      
_________________________________________________________________
relu_6 (LeakyReLU)           (None, 36, 36, 256)       0         
_________________________________________________________________
conv_7 (Conv2D)              (None, 36, 36, 128)       32896     
_________________________________________________________________
norm_7 (BatchNormalization)  (None, 36, 36, 128)       512       
_________________________________________________________________
relu_7 (LeakyReLU)           (None, 36, 36, 128)       0         
_________________________________________________________________
conv_8 (Conv2D)              (None, 36, 36, 256)       295168    
_________________________________________________________________
norm_8 (BatchNormalization)  (None, 36, 36, 256)       1024      
_________________________________________________________________
relu_8 (LeakyReLU)           (None, 36, 36, 256)       0         
_________________________________________________________________
pool_4 (MaxPooling2D)        (None, 18, 18, 256)       0         
_________________________________________________________________
conv_9 (Conv2D)              (None, 18, 18, 512)       1180160   
_________________________________________________________________
norm_9 (BatchNormalization)  (None, 18, 18, 512)       2048      
_________________________________________________________________
relu_9 (LeakyReLU)           (None, 18, 18, 512)       0         
_________________________________________________________________
conv_10 (Conv2D)             (None, 18, 18, 256)       131328    
_________________________________________________________________
norm_10 (BatchNormalization) (None, 18, 18, 256)       1024      
_________________________________________________________________
relu_10 (LeakyReLU)          (None, 18, 18, 256)       0         
_________________________________________________________________
conv_11 (Conv2D)             (None, 18, 18, 512)       1180160   
_________________________________________________________________
norm_11 (BatchNormalization) (None, 18, 18, 512)       2048      
_________________________________________________________________
relu_11 (LeakyReLU)          (None, 18, 18, 512)       0         
_________________________________________________________________
conv_12 (Conv2D)             (None, 18, 18, 256)       131328    
_________________________________________________________________
norm_12 (BatchNormalization) (None, 18, 18, 256)       1024      
_________________________________________________________________
relu_12 (LeakyReLU)          (None, 18, 18, 256)       0         
_________________________________________________________________
conv_13 (Conv2D)             (None, 18, 18, 512)       1180160   
_________________________________________________________________
norm_13 (BatchNormalization) (None, 18, 18, 512)       2048      
_________________________________________________________________
relu_13 (LeakyReLU)          (None, 18, 18, 512)       0         
_________________________________________________________________
pool_5 (MaxPooling2D)        (None, 9, 9, 512)         0         
_________________________________________________________________
conv_14 (Conv2D)             (None, 9, 9, 1024)        4719616   
_________________________________________________________________
norm_14 (BatchNormalization) (None, 9, 9, 1024)        4096      
_________________________________________________________________
relu_14 (LeakyReLU)          (None, 9, 9, 1024)        0         
_________________________________________________________________
conv_15 (Conv2D)             (None, 9, 9, 1024)        9438208   
_________________________________________________________________
norm_15 (BatchNormalization) (None, 9, 9, 1024)        4096      
_________________________________________________________________
relu_15 (LeakyReLU)          (None, 9, 9, 1024)        0         
_________________________________________________________________
conv_16 (Conv2D)             (None, 9, 9, 5)           5125      
_________________________________________________________________
reshape_2 (Reshape)          (None, 9, 9, 5)           0         
=================================================================
Total params: 18,784,709
Trainable params: 18,774,405
Non-trainable params: 10,304
_________________________________________________________________
+----------+---------------------+----------------+------------------+--------------------+---------------------+------------------+
|  Epoch   |       f1_score      |      iou       |       loss       |     precision      |        recall       |     val_loss     |
+----------+---------------------+----------------+------------------+--------------------+---------------------+------------------+
| Epoch 1  |          0          |       0        | 0.0172543577458  |         0          |         0.0         | 0.0214615607214  |
| Epoch 2  |  0.5945945945945945 | 0.638530851762 | 0.00845716648837 | 0.6754385964912281 |  0.5310344827586206 | 0.00800906898334 |
| Epoch 3  | 0.43333333333333335 | 0.659290353613 | 0.00629036036373 | 0.5473684210526316 |  0.3586206896551724 | 0.0102769770029  |
| Epoch 4  | 0.49912739965095987 | 0.655602936245 | 0.00555387527673 | 0.5053003533568905 | 0.49310344827586206 | 0.00902416388835 |
| Epoch 5  |  0.570873786407767  | 0.637627473695 | 0.00458119517871 | 0.6533333333333333 |  0.506896551724138  | 0.00822146019087 |
| Epoch 6  |  0.6405693950177936 | 0.676860848648 | 0.00428864720163 | 0.6617647058823529 |  0.6206896551724138 | 0.00806144540829 |
| Epoch 7  |  0.6530612244897959 | 0.670847631762 | 0.00373603426655 | 0.7068273092369478 |  0.6068965517241379 | 0.00709878405436 |
| Epoch 8  |  0.6666666666666666 | 0.676476800901 | 0.00352362302071 | 0.6227544910179641 |  0.7172413793103448 | 0.00717175376391 |
| Epoch 9  |  0.6386554621848739 | 0.66673987144  | 0.00327775154412 | 0.6229508196721312 |  0.6551724137931034 | 0.00798431130487 |
| Epoch 10 |  0.6761565836298932 | 0.663884850288 | 0.00308173053317 | 0.6985294117647058 |  0.6551724137931034 | 0.00729740113621 |
+----------+---------------------+----------------+------------------+--------------------+---------------------+------------------+
_________________________________________________________________
+---------------------------------+--------------------+--------------------+-------+---------+-----------------------+
|            Optimizer            |       beta_1       |       beta_2       | decay | epsilon |           lr          |
+---------------------------------+--------------------+--------------------+-------+---------+-----------------------+
| <class 'keras.optimizers.Adam'> | 0.8999999761581421 | 0.9990000128746033 |  0.0  |  1e-08  | 0.0010000000474974513 |
+---------------------------------+--------------------+--------------------+-------+---------+-----------------------+
_________________________________________________________________
+------------+
| Batch Size |
+------------+
|     16     |
+------------+
_________________________________________________________________
+--------------------+------------------+----------------+--------------------+--------------------+--------------------+
|      Metrics       |       Loss       |      IoU       |     Precision      |       Recall       |      F1 Score      |
+--------------------+------------------+----------------+--------------------+--------------------+--------------------+
|   Train Metrics    | 0.00326294649376 | 0.793316066851 | 0.9077161690577743 | 0.8496249697556254 | 0.8777104292945073 |
| Validation Metrics | 0.00729740113621 | 0.663884850288 | 0.6985294117647058 | 0.6551724137931034 | 0.6761565836298932 |
|    Test Metrics    | 0.00798083261977 | 0.659545427944 | 0.6867924528301886 | 0.5889967637540453 | 0.6341463414634145 |
+--------------------+------------------+----------------+--------------------+--------------------+--------------------+
_________________________________________________________________
Time:
    Train Time              : 2:56:25.710081
    Dataset Loading Time    : 0:00:40.365766
    Metrics Evaluation Time : 5:48:46.258078
_________________________________________________________________
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         (None, 288, 288, 1)       0         
_________________________________________________________________
conv_1 (Conv2D)              (None, 288, 288, 32)      320       
_________________________________________________________________
norm_1 (BatchNormalization)  (None, 288, 288, 32)      128       
_________________________________________________________________
relu_1 (LeakyReLU)           (None, 288, 288, 32)      0         
_________________________________________________________________
pool_1 (MaxPooling2D)        (None, 144, 144, 32)      0         
_________________________________________________________________
conv_2 (Conv2D)              (None, 144, 144, 64)      18496     
_________________________________________________________________
norm_2 (BatchNormalization)  (None, 144, 144, 64)      256       
_________________________________________________________________
relu_2 (LeakyReLU)           (None, 144, 144, 64)      0         
_________________________________________________________________
pool_2 (MaxPooling2D)        (None, 72, 72, 64)        0         
_________________________________________________________________
conv_3 (Conv2D)              (None, 72, 72, 128)       73856     
_________________________________________________________________
norm_3 (BatchNormalization)  (None, 72, 72, 128)       512       
_________________________________________________________________
relu_3 (LeakyReLU)           (None, 72, 72, 128)       0         
_________________________________________________________________
conv_4 (Conv2D)              (None, 72, 72, 64)        8256      
_________________________________________________________________
norm_4 (BatchNormalization)  (None, 72, 72, 64)        256       
_________________________________________________________________
relu_4 (LeakyReLU)           (None, 72, 72, 64)        0         
_________________________________________________________________
conv_5 (Conv2D)              (None, 72, 72, 128)       73856     
_________________________________________________________________
norm_5 (BatchNormalization)  (None, 72, 72, 128)       512       
_________________________________________________________________
relu_5 (LeakyReLU)           (None, 72, 72, 128)       0         
_________________________________________________________________
pool_3 (MaxPooling2D)        (None, 36, 36, 128)       0         
_________________________________________________________________
conv_6 (Conv2D)              (None, 36, 36, 256)       295168    
_________________________________________________________________
norm_6 (BatchNormalization)  (None, 36, 36, 256)       1024      
_________________________________________________________________
relu_6 (LeakyReLU)           (None, 36, 36, 256)       0         
_________________________________________________________________
conv_7 (Conv2D)              (None, 36, 36, 128)       32896     
_________________________________________________________________
norm_7 (BatchNormalization)  (None, 36, 36, 128)       512       
_________________________________________________________________
relu_7 (LeakyReLU)           (None, 36, 36, 128)       0         
_________________________________________________________________
conv_8 (Conv2D)              (None, 36, 36, 256)       295168    
_________________________________________________________________
norm_8 (BatchNormalization)  (None, 36, 36, 256)       1024      
_________________________________________________________________
relu_8 (LeakyReLU)           (None, 36, 36, 256)       0         
_________________________________________________________________
pool_4 (MaxPooling2D)        (None, 18, 18, 256)       0         
_________________________________________________________________
conv_9 (Conv2D)              (None, 18, 18, 512)       1180160   
_________________________________________________________________
norm_9 (BatchNormalization)  (None, 18, 18, 512)       2048      
_________________________________________________________________
relu_9 (LeakyReLU)           (None, 18, 18, 512)       0         
_________________________________________________________________
conv_10 (Conv2D)             (None, 18, 18, 256)       131328    
_________________________________________________________________
norm_10 (BatchNormalization) (None, 18, 18, 256)       1024      
_________________________________________________________________
relu_10 (LeakyReLU)          (None, 18, 18, 256)       0         
_________________________________________________________________
conv_11 (Conv2D)             (None, 18, 18, 512)       1180160   
_________________________________________________________________
norm_11 (BatchNormalization) (None, 18, 18, 512)       2048      
_________________________________________________________________
relu_11 (LeakyReLU)          (None, 18, 18, 512)       0         
_________________________________________________________________
conv_12 (Conv2D)             (None, 18, 18, 256)       131328    
_________________________________________________________________
norm_12 (BatchNormalization) (None, 18, 18, 256)       1024      
_________________________________________________________________
relu_12 (LeakyReLU)          (None, 18, 18, 256)       0         
_________________________________________________________________
conv_13 (Conv2D)             (None, 18, 18, 512)       1180160   
_________________________________________________________________
norm_13 (BatchNormalization) (None, 18, 18, 512)       2048      
_________________________________________________________________
relu_13 (LeakyReLU)          (None, 18, 18, 512)       0         
_________________________________________________________________
pool_5 (MaxPooling2D)        (None, 9, 9, 512)         0         
_________________________________________________________________
conv_14 (Conv2D)             (None, 9, 9, 1024)        4719616   
_________________________________________________________________
norm_14 (BatchNormalization) (None, 9, 9, 1024)        4096      
_________________________________________________________________
relu_14 (LeakyReLU)          (None, 9, 9, 1024)        0         
_________________________________________________________________
conv_15 (Conv2D)             (None, 9, 9, 1024)        9438208   
_________________________________________________________________
norm_15 (BatchNormalization) (None, 9, 9, 1024)        4096      
_________________________________________________________________
relu_15 (LeakyReLU)          (None, 9, 9, 1024)        0         
_________________________________________________________________
conv_16 (Conv2D)             (None, 9, 9, 5)           5125      
_________________________________________________________________
reshape_1 (Reshape)          (None, 9, 9, 5)           0         
=================================================================
Total params: 18,784,709
Trainable params: 18,774,405
Non-trainable params: 10,304
_________________________________________________________________
+----------+---------------------+----------------+------------------+--------------------+---------------------+------------------+
|  Epoch   |       f1_score      |      iou       |       loss       |     precision      |        recall       |     val_loss     |
+----------+---------------------+----------------+------------------+--------------------+---------------------+------------------+
| Epoch 1  |          0          |       0        |  0.018847322537  |         0          |         0.0         |  0.015351719974  |
| Epoch 2  | 0.46124763705103966 | 0.64229555539  | 0.00860211389597 | 0.5104602510460251 |  0.4206896551724138 | 0.00868055864327 |
| Epoch 3  |  0.581583198707593  | 0.623760994277 | 0.00630447499467 | 0.547112462006079  |  0.6206896551724138 | 0.00918663680674 |
| Epoch 4  |  0.5709090909090908 | 0.662619265482 | 0.00504596792839 | 0.6038461538461538 |  0.5413793103448276 | 0.00901999649021 |
| Epoch 5  |  0.6360294117647058 | 0.66363057941  | 0.00452166339516 | 0.6811023622047244 |  0.596551724137931  | 0.0080570481988  |
| Epoch 6  |  0.6567164179104478 | 0.666112896386 | 0.0040224522316  | 0.6325878594249201 |  0.6827586206896552 | 0.0080795552912  |
| Epoch 7  |  0.6307977736549164 | 0.663211084563 | 0.00370556966044 | 0.6827309236947792 |  0.5862068965517241 | 0.00762824410002 |
| Epoch 8  |  0.4932038834951456 | 0.663305353312 | 0.00355408550949 | 0.5644444444444444 |  0.4379310344827586 | 0.00852980089164 |
| Epoch 9  |  0.5144032921810698 | 0.677413425649 | 0.00328311939477 | 0.6377551020408163 | 0.43103448275862066 | 0.00935987522826 |
| Epoch 10 |  0.5487077534791253 | 0.652577004746 | 0.00311042631168 | 0.647887323943662  | 0.47586206896551725 | 0.00782050270467 |
+----------+---------------------+----------------+------------------+--------------------+---------------------+------------------+
_________________________________________________________________
+-----------------------------------+--------------------+--------------------+-------+---------+-----------------------+
|             Optimizer             |       beta_1       |       beta_2       | decay | epsilon |           lr          |
+-----------------------------------+--------------------+--------------------+-------+---------+-----------------------+
| <class 'keras.optimizers.Adamax'> | 0.8999999761581421 | 0.9990000128746033 |  0.0  |  1e-08  | 0.0020000000949949026 |
+-----------------------------------+--------------------+--------------------+-------+---------+-----------------------+
_________________________________________________________________
+------------+
| Batch Size |
+------------+
|     16     |
+------------+
_________________________________________________________________
+--------------------+------------------+----------------+--------------------+---------------------+--------------------+
|      Metrics       |       Loss       |      IoU       |     Precision      |        Recall       |      F1 Score      |
+--------------------+------------------+----------------+--------------------+---------------------+--------------------+
|   Train Metrics    | 0.00326688075541 | 0.778843062816 | 0.9093889325990034 |  0.8389789499153157 | 0.8727661716586962 |
| Validation Metrics | 0.00782050288493 | 0.652577004746 | 0.647887323943662  | 0.47586206896551725 | 0.5487077534791253 |
|    Test Metrics    | 0.00835352781559 | 0.645215405035 | 0.7009345794392523 |  0.4854368932038835 | 0.5736137667304015 |
+--------------------+------------------+----------------+--------------------+---------------------+--------------------+
_________________________________________________________________
Time:
    Train Time              : 1:20:04.220213
    Dataset Loading Time    : 0:00:40.628484
    Metrics Evaluation Time : 2:19:11.722286
_________________________________________________________________
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         (None, 288, 288, 1)       0         
_________________________________________________________________
conv_1 (Conv2D)              (None, 288, 288, 32)      320       
_________________________________________________________________
norm_1 (BatchNormalization)  (None, 288, 288, 32)      128       
_________________________________________________________________
relu_1 (LeakyReLU)           (None, 288, 288, 32)      0         
_________________________________________________________________
pool_1 (MaxPooling2D)        (None, 144, 144, 32)      0         
_________________________________________________________________
conv_2 (Conv2D)              (None, 144, 144, 64)      18496     
_________________________________________________________________
norm_2 (BatchNormalization)  (None, 144, 144, 64)      256       
_________________________________________________________________
relu_2 (LeakyReLU)           (None, 144, 144, 64)      0         
_________________________________________________________________
pool_2 (MaxPooling2D)        (None, 72, 72, 64)        0         
_________________________________________________________________
conv_3 (Conv2D)              (None, 72, 72, 128)       73856     
_________________________________________________________________
norm_3 (BatchNormalization)  (None, 72, 72, 128)       512       
_________________________________________________________________
relu_3 (LeakyReLU)           (None, 72, 72, 128)       0         
_________________________________________________________________
conv_4 (Conv2D)              (None, 72, 72, 64)        8256      
_________________________________________________________________
norm_4 (BatchNormalization)  (None, 72, 72, 64)        256       
_________________________________________________________________
relu_4 (LeakyReLU)           (None, 72, 72, 64)        0         
_________________________________________________________________
conv_5 (Conv2D)              (None, 72, 72, 128)       73856     
_________________________________________________________________
norm_5 (BatchNormalization)  (None, 72, 72, 128)       512       
_________________________________________________________________
relu_5 (LeakyReLU)           (None, 72, 72, 128)       0         
_________________________________________________________________
pool_3 (MaxPooling2D)        (None, 36, 36, 128)       0         
_________________________________________________________________
conv_6 (Conv2D)              (None, 36, 36, 256)       295168    
_________________________________________________________________
norm_6 (BatchNormalization)  (None, 36, 36, 256)       1024      
_________________________________________________________________
relu_6 (LeakyReLU)           (None, 36, 36, 256)       0         
_________________________________________________________________
conv_7 (Conv2D)              (None, 36, 36, 128)       32896     
_________________________________________________________________
norm_7 (BatchNormalization)  (None, 36, 36, 128)       512       
_________________________________________________________________
relu_7 (LeakyReLU)           (None, 36, 36, 128)       0         
_________________________________________________________________
conv_8 (Conv2D)              (None, 36, 36, 256)       295168    
_________________________________________________________________
norm_8 (BatchNormalization)  (None, 36, 36, 256)       1024      
_________________________________________________________________
relu_8 (LeakyReLU)           (None, 36, 36, 256)       0         
_________________________________________________________________
pool_4 (MaxPooling2D)        (None, 18, 18, 256)       0         
_________________________________________________________________
conv_9 (Conv2D)              (None, 18, 18, 512)       1180160   
_________________________________________________________________
norm_9 (BatchNormalization)  (None, 18, 18, 512)       2048      
_________________________________________________________________
relu_9 (LeakyReLU)           (None, 18, 18, 512)       0         
_________________________________________________________________
conv_10 (Conv2D)             (None, 18, 18, 256)       131328    
_________________________________________________________________
norm_10 (BatchNormalization) (None, 18, 18, 256)       1024      
_________________________________________________________________
relu_10 (LeakyReLU)          (None, 18, 18, 256)       0         
_________________________________________________________________
conv_11 (Conv2D)             (None, 18, 18, 512)       1180160   
_________________________________________________________________
norm_11 (BatchNormalization) (None, 18, 18, 512)       2048      
_________________________________________________________________
relu_11 (LeakyReLU)          (None, 18, 18, 512)       0         
_________________________________________________________________
conv_12 (Conv2D)             (None, 18, 18, 256)       131328    
_________________________________________________________________
norm_12 (BatchNormalization) (None, 18, 18, 256)       1024      
_________________________________________________________________
relu_12 (LeakyReLU)          (None, 18, 18, 256)       0         
_________________________________________________________________
conv_13 (Conv2D)             (None, 18, 18, 512)       1180160   
_________________________________________________________________
norm_13 (BatchNormalization) (None, 18, 18, 512)       2048      
_________________________________________________________________
relu_13 (LeakyReLU)          (None, 18, 18, 512)       0         
_________________________________________________________________
pool_5 (MaxPooling2D)        (None, 9, 9, 512)         0         
_________________________________________________________________
conv_14 (Conv2D)             (None, 9, 9, 1024)        4719616   
_________________________________________________________________
norm_14 (BatchNormalization) (None, 9, 9, 1024)        4096      
_________________________________________________________________
relu_14 (LeakyReLU)          (None, 9, 9, 1024)        0         
_________________________________________________________________
conv_15 (Conv2D)             (None, 9, 9, 1024)        9438208   
_________________________________________________________________
norm_15 (BatchNormalization) (None, 9, 9, 1024)        4096      
_________________________________________________________________
relu_15 (LeakyReLU)          (None, 9, 9, 1024)        0         
_________________________________________________________________
conv_16 (Conv2D)             (None, 9, 9, 5)           5125      
_________________________________________________________________
reshape_1 (Reshape)          (None, 9, 9, 5)           0         
=================================================================
Total params: 18,784,709
Trainable params: 18,774,405
Non-trainable params: 10,304
_________________________________________________________________
+----------+---------------------+----------------+------------------+---------------------+---------------------+------------------+
|  Epoch   |       f1_score      |      iou       |       loss       |      precision      |        recall       |     val_loss     |
+----------+---------------------+----------------+------------------+---------------------+---------------------+------------------+
| Epoch 1  | 0.07238095238095238 | 0.597435108487 | 0.0206446166986  | 0.08085106382978724 | 0.06551724137931035 | 0.0319721353871  |
| Epoch 2  |  0.6950354609929078 | 0.670899064721 | 0.00968744870888 |  0.7153284671532847 |  0.6758620689655173 | 0.00589370227329 |
| Epoch 3  |  0.5447154471544716 | 0.67832805857  | 0.00748394998712 |  0.4486607142857143 |  0.6931034482758621 | 0.00953461863701 |
| Epoch 4  |  0.5323193916349809 | 0.671467412979 | 0.00619209706012 |  0.5932203389830508 |  0.4827586206896552 | 0.00866963956205 |
| Epoch 5  |  0.6129666011787819 | 0.686902335572 | 0.00532478780233 |  0.7123287671232876 |  0.5379310344827586 | 0.00743825599972 |
| Epoch 6  |  0.5569272976680385 | 0.665946331942 | 0.00476470576294 |  0.4624145785876993 |         0.7         | 0.00892213314411 |
| Epoch 7  |  0.523121387283237  | 0.640207204205 | 0.00432315053767 |  0.4502487562189055 |  0.6241379310344828 | 0.00858983274309 |
| Epoch 8  |  0.6655518394648828 | 0.681888884975 | 0.00399935963953 |  0.6461038961038961 |  0.6862068965517242 | 0.00634841294959 |
| Epoch 9  |  0.6820428336079077 | 0.68657107513  | 0.00384347810389 |  0.6529968454258676 |  0.7137931034482758 | 0.00644036359154 |
| Epoch 10 |  0.5927099841521394 | 0.68417701405  | 0.00360998048901 |  0.5483870967741935 |  0.6448275862068965 | 0.00744597621322 |
+----------+---------------------+----------------+------------------+---------------------+---------------------+------------------+
_________________________________________________________________
+----------------------------------+--------------------+--------------------+---------+-----------------------+----------------+
|            Optimizer             |       beta_1       |       beta_2       | epsilon |           lr          | schedule_decay |
+----------------------------------+--------------------+--------------------+---------+-----------------------+----------------+
| <class 'keras.optimizers.Nadam'> | 0.8999999761581421 | 0.9990000128746033 |  1e-08  | 0.0020000000949949026 |     0.004      |
+----------------------------------+--------------------+--------------------+---------+-----------------------+----------------+
_________________________________________________________________
+------------+
| Batch Size |
+------------+
|     16     |
+------------+
_________________________________________________________________
+--------------------+------------------+----------------+--------------------+--------------------+--------------------+
|      Metrics       |       Loss       |      IoU       |     Precision      |       Recall       |      F1 Score      |
+--------------------+------------------+----------------+--------------------+--------------------+--------------------+
|   Train Metrics    | 0.00368584364065 | 0.783521528386 | 0.9098901098901099 | 0.8514396322284055 | 0.8796950190613085 |
| Validation Metrics | 0.00744597613811 | 0.68417701405  | 0.5483870967741935 | 0.6448275862068965 | 0.5927099841521394 |
|    Test Metrics    | 0.00812994935099 | 0.679968011585 | 0.5602240896358543 | 0.6472491909385113 | 0.6006006006006005 |
+--------------------+------------------+----------------+--------------------+--------------------+--------------------+
_________________________________________________________________
Time:
    Train Time              : 1:23:13.441138
    Dataset Loading Time    : 0:00:37.503870
    Metrics Evaluation Time : 2:22:53.453500
_________________________________________________________________
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         (None, 288, 288, 1)       0         
_________________________________________________________________
conv_1 (Conv2D)              (None, 288, 288, 32)      320       
_________________________________________________________________
norm_1 (BatchNormalization)  (None, 288, 288, 32)      128       
_________________________________________________________________
relu_1 (LeakyReLU)           (None, 288, 288, 32)      0         
_________________________________________________________________
pool_1 (MaxPooling2D)        (None, 144, 144, 32)      0         
_________________________________________________________________
conv_2 (Conv2D)              (None, 144, 144, 64)      18496     
_________________________________________________________________
norm_2 (BatchNormalization)  (None, 144, 144, 64)      256       
_________________________________________________________________
relu_2 (LeakyReLU)           (None, 144, 144, 64)      0         
_________________________________________________________________
pool_2 (MaxPooling2D)        (None, 72, 72, 64)        0         
_________________________________________________________________
conv_3 (Conv2D)              (None, 72, 72, 128)       73856     
_________________________________________________________________
norm_3 (BatchNormalization)  (None, 72, 72, 128)       512       
_________________________________________________________________
relu_3 (LeakyReLU)           (None, 72, 72, 128)       0         
_________________________________________________________________
conv_4 (Conv2D)              (None, 72, 72, 64)        8256      
_________________________________________________________________
norm_4 (BatchNormalization)  (None, 72, 72, 64)        256       
_________________________________________________________________
relu_4 (LeakyReLU)           (None, 72, 72, 64)        0         
_________________________________________________________________
conv_5 (Conv2D)              (None, 72, 72, 128)       73856     
_________________________________________________________________
norm_5 (BatchNormalization)  (None, 72, 72, 128)       512       
_________________________________________________________________
relu_5 (LeakyReLU)           (None, 72, 72, 128)       0         
_________________________________________________________________
pool_3 (MaxPooling2D)        (None, 36, 36, 128)       0         
_________________________________________________________________
conv_6 (Conv2D)              (None, 36, 36, 256)       295168    
_________________________________________________________________
norm_6 (BatchNormalization)  (None, 36, 36, 256)       1024      
_________________________________________________________________
relu_6 (LeakyReLU)           (None, 36, 36, 256)       0         
_________________________________________________________________
conv_7 (Conv2D)              (None, 36, 36, 128)       32896     
_________________________________________________________________
norm_7 (BatchNormalization)  (None, 36, 36, 128)       512       
_________________________________________________________________
relu_7 (LeakyReLU)           (None, 36, 36, 128)       0         
_________________________________________________________________
conv_8 (Conv2D)              (None, 36, 36, 256)       295168    
_________________________________________________________________
norm_8 (BatchNormalization)  (None, 36, 36, 256)       1024      
_________________________________________________________________
relu_8 (LeakyReLU)           (None, 36, 36, 256)       0         
_________________________________________________________________
pool_4 (MaxPooling2D)        (None, 18, 18, 256)       0         
_________________________________________________________________
conv_9 (Conv2D)              (None, 18, 18, 512)       1180160   
_________________________________________________________________
norm_9 (BatchNormalization)  (None, 18, 18, 512)       2048      
_________________________________________________________________
relu_9 (LeakyReLU)           (None, 18, 18, 512)       0         
_________________________________________________________________
conv_10 (Conv2D)             (None, 18, 18, 256)       131328    
_________________________________________________________________
norm_10 (BatchNormalization) (None, 18, 18, 256)       1024      
_________________________________________________________________
relu_10 (LeakyReLU)          (None, 18, 18, 256)       0         
_________________________________________________________________
conv_11 (Conv2D)             (None, 18, 18, 512)       1180160   
_________________________________________________________________
norm_11 (BatchNormalization) (None, 18, 18, 512)       2048      
_________________________________________________________________
relu_11 (LeakyReLU)          (None, 18, 18, 512)       0         
_________________________________________________________________
conv_12 (Conv2D)             (None, 18, 18, 256)       131328    
_________________________________________________________________
norm_12 (BatchNormalization) (None, 18, 18, 256)       1024      
_________________________________________________________________
relu_12 (LeakyReLU)          (None, 18, 18, 256)       0         
_________________________________________________________________
conv_13 (Conv2D)             (None, 18, 18, 512)       1180160   
_________________________________________________________________
norm_13 (BatchNormalization) (None, 18, 18, 512)       2048      
_________________________________________________________________
relu_13 (LeakyReLU)          (None, 18, 18, 512)       0         
_________________________________________________________________
pool_5 (MaxPooling2D)        (None, 9, 9, 512)         0         
_________________________________________________________________
conv_14 (Conv2D)             (None, 9, 9, 1024)        4719616   
_________________________________________________________________
norm_14 (BatchNormalization) (None, 9, 9, 1024)        4096      
_________________________________________________________________
relu_14 (LeakyReLU)          (None, 9, 9, 1024)        0         
_________________________________________________________________
conv_15 (Conv2D)             (None, 9, 9, 1024)        9438208   
_________________________________________________________________
norm_15 (BatchNormalization) (None, 9, 9, 1024)        4096      
_________________________________________________________________
relu_15 (LeakyReLU)          (None, 9, 9, 1024)        0         
_________________________________________________________________
conv_16 (Conv2D)             (None, 9, 9, 5)           5125      
_________________________________________________________________
reshape_1 (Reshape)          (None, 9, 9, 5)           0         
=================================================================
Total params: 18,784,709
Trainable params: 18,774,405
Non-trainable params: 10,304
_________________________________________________________________
+----------+---------------------+----------------+------------------+---------------------+---------------------+-----------------+
|  Epoch   |       f1_score      |      iou       |       loss       |      precision      |        recall       |     val_loss    |
+----------+---------------------+----------------+------------------+---------------------+---------------------+-----------------+
| Epoch 1  |          0          |       0        | 0.0270693754716  |          0          |         0.0         | 0.0227420858798 |
| Epoch 2  | 0.18713450292397663 | 0.604551654793 | 0.0135648780119  |  0.6153846153846154 |  0.1103448275862069 | 0.0112100841417 |
| Epoch 3  | 0.25375626043405675 | 0.615190831989 | 0.0105220674217  |  0.2459546925566343 |  0.2620689655172414 | 0.0115490504691 |
| Epoch 4  |  0.3373015873015873 | 0.605106186001 | 0.00833514105333 |  0.397196261682243  | 0.29310344827586204 | 0.0107169263666 |
| Epoch 5  |  0.2919937205651491 | 0.616766295164 | 0.00688294295516 |  0.2680115273775216 | 0.32068965517241377 | 0.0126595779232 |
| Epoch 6  | 0.30798479087452474 | 0.627480427758 | 0.00581402405908 |  0.3432203389830508 |  0.2793103448275862 | 0.0117328079538 |
| Epoch 7  |  0.3276190476190476 | 0.605959561527 | 0.00504594515743 |  0.3659574468085106 |  0.296551724137931  |  0.01074249733  |
| Epoch 8  | 0.30837004405286345 | 0.621755309264 | 0.00435308767431 |  0.4268292682926829 |  0.2413793103448276 | 0.0104846301669 |
| Epoch 9  | 0.35585585585585583 | 0.612475773754 | 0.00387900642813 |  0.512987012987013  | 0.27241379310344827 | 0.0113019208995 |
| Epoch 10 |  0.3299319727891156 | 0.61811168845  | 0.00347071069187 | 0.32550335570469796 | 0.33448275862068966 | 0.0107577457844 |
+----------+---------------------+----------------+------------------+---------------------+---------------------+-----------------+
_________________________________________________________________
+-------------------------------------+-------+---------+-----+------+
|              Optimizer              | decay | epsilon |  lr | rho  |
+-------------------------------------+-------+---------+-----+------+
| <class 'keras.optimizers.Adadelta'> |  0.0  |  1e-08  | 1.0 | 0.95 |
+-------------------------------------+-------+---------+-----+------+
_________________________________________________________________
+------------+
| Batch Size |
+------------+
|     16     |
+------------+
_________________________________________________________________
+--------------------+------------------+----------------+---------------------+---------------------+---------------------+
|      Metrics       |       Loss       |      IoU       |      Precision      |        Recall       |       F1 Score      |
+--------------------+------------------+----------------+---------------------+---------------------+---------------------+
|   Train Metrics    | 0.00342745260267 | 0.728824241868 |  0.8138778460426455 |  0.8173239777401403 |  0.8155972716846743 |
| Validation Metrics | 0.0107577467758  | 0.61811168845  | 0.32550335570469796 | 0.33448275862068966 |  0.3299319727891156 |
|    Test Metrics    | 0.0123576345523  | 0.615552362545 |       0.334375      | 0.34627831715210355 | 0.34022257551669316 |
+--------------------+------------------+----------------+---------------------+---------------------+---------------------+
_________________________________________________________________
Time:
    Train Time              : 1:22:46.222668
    Dataset Loading Time    : 0:00:38.432487
    Metrics Evaluation Time : 2:21:22.055584
_________________________________________________________________
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         (None, 288, 288, 1)       0         
_________________________________________________________________
conv_1 (Conv2D)              (None, 288, 288, 32)      320       
_________________________________________________________________
norm_1 (BatchNormalization)  (None, 288, 288, 32)      128       
_________________________________________________________________
relu_1 (LeakyReLU)           (None, 288, 288, 32)      0         
_________________________________________________________________
pool_1 (MaxPooling2D)        (None, 144, 144, 32)      0         
_________________________________________________________________
conv_2 (Conv2D)              (None, 144, 144, 64)      18496     
_________________________________________________________________
norm_2 (BatchNormalization)  (None, 144, 144, 64)      256       
_________________________________________________________________
relu_2 (LeakyReLU)           (None, 144, 144, 64)      0         
_________________________________________________________________
pool_2 (MaxPooling2D)        (None, 72, 72, 64)        0         
_________________________________________________________________
conv_3 (Conv2D)              (None, 72, 72, 128)       73856     
_________________________________________________________________
norm_3 (BatchNormalization)  (None, 72, 72, 128)       512       
_________________________________________________________________
relu_3 (LeakyReLU)           (None, 72, 72, 128)       0         
_________________________________________________________________
conv_4 (Conv2D)              (None, 72, 72, 64)        8256      
_________________________________________________________________
norm_4 (BatchNormalization)  (None, 72, 72, 64)        256       
_________________________________________________________________
relu_4 (LeakyReLU)           (None, 72, 72, 64)        0         
_________________________________________________________________
conv_5 (Conv2D)              (None, 72, 72, 128)       73856     
_________________________________________________________________
norm_5 (BatchNormalization)  (None, 72, 72, 128)       512       
_________________________________________________________________
relu_5 (LeakyReLU)           (None, 72, 72, 128)       0         
_________________________________________________________________
pool_3 (MaxPooling2D)        (None, 36, 36, 128)       0         
_________________________________________________________________
conv_6 (Conv2D)              (None, 36, 36, 256)       295168    
_________________________________________________________________
norm_6 (BatchNormalization)  (None, 36, 36, 256)       1024      
_________________________________________________________________
relu_6 (LeakyReLU)           (None, 36, 36, 256)       0         
_________________________________________________________________
conv_7 (Conv2D)              (None, 36, 36, 128)       32896     
_________________________________________________________________
norm_7 (BatchNormalization)  (None, 36, 36, 128)       512       
_________________________________________________________________
relu_7 (LeakyReLU)           (None, 36, 36, 128)       0         
_________________________________________________________________
conv_8 (Conv2D)              (None, 36, 36, 256)       295168    
_________________________________________________________________
norm_8 (BatchNormalization)  (None, 36, 36, 256)       1024      
_________________________________________________________________
relu_8 (LeakyReLU)           (None, 36, 36, 256)       0         
_________________________________________________________________
pool_4 (MaxPooling2D)        (None, 18, 18, 256)       0         
_________________________________________________________________
conv_9 (Conv2D)              (None, 18, 18, 512)       1180160   
_________________________________________________________________
norm_9 (BatchNormalization)  (None, 18, 18, 512)       2048      
_________________________________________________________________
relu_9 (LeakyReLU)           (None, 18, 18, 512)       0         
_________________________________________________________________
conv_10 (Conv2D)             (None, 18, 18, 256)       131328    
_________________________________________________________________
norm_10 (BatchNormalization) (None, 18, 18, 256)       1024      
_________________________________________________________________
relu_10 (LeakyReLU)          (None, 18, 18, 256)       0         
_________________________________________________________________
conv_11 (Conv2D)             (None, 18, 18, 512)       1180160   
_________________________________________________________________
norm_11 (BatchNormalization) (None, 18, 18, 512)       2048      
_________________________________________________________________
relu_11 (LeakyReLU)          (None, 18, 18, 512)       0         
_________________________________________________________________
conv_12 (Conv2D)             (None, 18, 18, 256)       131328    
_________________________________________________________________
norm_12 (BatchNormalization) (None, 18, 18, 256)       1024      
_________________________________________________________________
relu_12 (LeakyReLU)          (None, 18, 18, 256)       0         
_________________________________________________________________
conv_13 (Conv2D)             (None, 18, 18, 512)       1180160   
_________________________________________________________________
norm_13 (BatchNormalization) (None, 18, 18, 512)       2048      
_________________________________________________________________
relu_13 (LeakyReLU)          (None, 18, 18, 512)       0         
_________________________________________________________________
pool_5 (MaxPooling2D)        (None, 9, 9, 512)         0         
_________________________________________________________________
conv_14 (Conv2D)             (None, 9, 9, 1024)        4719616   
_________________________________________________________________
norm_14 (BatchNormalization) (None, 9, 9, 1024)        4096      
_________________________________________________________________
relu_14 (LeakyReLU)          (None, 9, 9, 1024)        0         
_________________________________________________________________
conv_15 (Conv2D)             (None, 9, 9, 1024)        9438208   
_________________________________________________________________
norm_15 (BatchNormalization) (None, 9, 9, 1024)        4096      
_________________________________________________________________
relu_15 (LeakyReLU)          (None, 9, 9, 1024)        0         
_________________________________________________________________
conv_16 (Conv2D)             (None, 9, 9, 5)           5125      
_________________________________________________________________
reshape_1 (Reshape)          (None, 9, 9, 5)           0         
=================================================================
Total params: 18,784,709
Trainable params: 18,774,405
Non-trainable params: 10,304
_________________________________________________________________
+----------+---------------------+----------------+------------------+---------------------+---------------------+------------------+
|  Epoch   |       f1_score      |      iou       |       loss       |      precision      |        recall       |     val_loss     |
+----------+---------------------+----------------+------------------+---------------------+---------------------+------------------+
| Epoch 1  |          0          |       0        | 0.0262167123568  |          0          |         0.0         |  0.018080205927  |
| Epoch 2  | 0.20253164556962022 | 0.643957222155 | 0.0115753617917  | 0.38095238095238093 | 0.13793103448275862 | 0.0111541997101  |
| Epoch 3  |  0.2684563758389262 | 0.614354721594 | 0.00819411309671 |  0.3821656050955414 | 0.20689655172413793 | 0.0114952901739  |
| Epoch 4  | 0.41613588110403393 | 0.628013129997 | 0.00605067647781 |  0.5414364640883977 | 0.33793103448275863 | 0.0103037091603  |
| Epoch 5  | 0.41842610364683297 | 0.635847720214 | 0.00462272260629 | 0.47186147186147187 |  0.3758620689655172 | 0.00975703713935 |
| Epoch 6  |  0.4257602862254024 | 0.646543710686 | 0.00343198908512 |  0.4423791821561338 |  0.4103448275862069 | 0.0103638950856  |
| Epoch 7  | 0.46840148698884754 | 0.640159235798 | 0.00254761533999 |  0.5080645161290323 | 0.43448275862068964 | 0.00924388857018 |
| Epoch 8  | 0.45064377682403434 | 0.631388666924 | 0.00201154544657 |  0.5965909090909091 |  0.3620689655172414 | 0.00982286171207 |
| Epoch 9  |        0.476        | 0.647610085636 | 0.00169464169658 |  0.5666666666666667 |  0.4103448275862069 |  0.010244923073  |
| Epoch 10 | 0.49168207024029575 | 0.647854536073 | 0.00151572752866 |  0.5298804780876494 |  0.4586206896551724 | 0.00974155342086 |
+----------+---------------------+----------------+------------------+---------------------+---------------------+------------------+
_________________________________________________________________
+---------------------------------+--------------------+--------------------+-------+---------+-----------------------+
|            Optimizer            |       beta_1       |       beta_2       | decay | epsilon |           lr          |
+---------------------------------+--------------------+--------------------+-------+---------+-----------------------+
| <class 'keras.optimizers.Adam'> | 0.8999999761581421 | 0.9990000128746033 |  0.0  |  1e-08  | 9.999999747378752e-05 |
+---------------------------------+--------------------+--------------------+-------+---------+-----------------------+
_________________________________________________________________
+------------+
| Batch Size |
+------------+
|     16     |
+------------+
_________________________________________________________________
+--------------------+------------------+----------------+---------------------+--------------------+---------------------+
|      Metrics       |       Loss       |      IoU       |      Precision      |       Recall       |       F1 Score      |
+--------------------+------------------+----------------+---------------------+--------------------+---------------------+
|   Train Metrics    | 0.00154689684331 | 0.772877062086 |  0.8859084406294707 | 0.8989837890152431 |  0.8923982226492134 |
| Validation Metrics | 0.0097415533758  | 0.647854536073 |  0.5298804780876494 | 0.4586206896551724 | 0.49168207024029575 |
|    Test Metrics    | 0.0107959170315  | 0.656667371017 | 0.49828178694158076 | 0.4692556634304207 |  0.4833333333333333 |
+--------------------+------------------+----------------+---------------------+--------------------+---------------------+
_________________________________________________________________
Time:
    Train Time              : 1:21:36.924817
    Dataset Loading Time    : 0:00:54.502023
    Metrics Evaluation Time : 2:20:41.716836
_________________________________________________________________
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         (None, 288, 288, 1)       0         
_________________________________________________________________
conv_1 (Conv2D)              (None, 288, 288, 32)      320       
_________________________________________________________________
norm_1 (BatchNormalization)  (None, 288, 288, 32)      128       
_________________________________________________________________
relu_1 (LeakyReLU)           (None, 288, 288, 32)      0         
_________________________________________________________________
pool_1 (MaxPooling2D)        (None, 144, 144, 32)      0         
_________________________________________________________________
conv_2 (Conv2D)              (None, 144, 144, 64)      18496     
_________________________________________________________________
norm_2 (BatchNormalization)  (None, 144, 144, 64)      256       
_________________________________________________________________
relu_2 (LeakyReLU)           (None, 144, 144, 64)      0         
_________________________________________________________________
pool_2 (MaxPooling2D)        (None, 72, 72, 64)        0         
_________________________________________________________________
conv_3 (Conv2D)              (None, 72, 72, 128)       73856     
_________________________________________________________________
norm_3 (BatchNormalization)  (None, 72, 72, 128)       512       
_________________________________________________________________
relu_3 (LeakyReLU)           (None, 72, 72, 128)       0         
_________________________________________________________________
conv_4 (Conv2D)              (None, 72, 72, 64)        8256      
_________________________________________________________________
norm_4 (BatchNormalization)  (None, 72, 72, 64)        256       
_________________________________________________________________
relu_4 (LeakyReLU)           (None, 72, 72, 64)        0         
_________________________________________________________________
conv_5 (Conv2D)              (None, 72, 72, 128)       73856     
_________________________________________________________________
norm_5 (BatchNormalization)  (None, 72, 72, 128)       512       
_________________________________________________________________
relu_5 (LeakyReLU)           (None, 72, 72, 128)       0         
_________________________________________________________________
pool_3 (MaxPooling2D)        (None, 36, 36, 128)       0         
_________________________________________________________________
conv_6 (Conv2D)              (None, 36, 36, 256)       295168    
_________________________________________________________________
norm_6 (BatchNormalization)  (None, 36, 36, 256)       1024      
_________________________________________________________________
relu_6 (LeakyReLU)           (None, 36, 36, 256)       0         
_________________________________________________________________
conv_7 (Conv2D)              (None, 36, 36, 128)       32896     
_________________________________________________________________
norm_7 (BatchNormalization)  (None, 36, 36, 128)       512       
_________________________________________________________________
relu_7 (LeakyReLU)           (None, 36, 36, 128)       0         
_________________________________________________________________
conv_8 (Conv2D)              (None, 36, 36, 256)       295168    
_________________________________________________________________
norm_8 (BatchNormalization)  (None, 36, 36, 256)       1024      
_________________________________________________________________
relu_8 (LeakyReLU)           (None, 36, 36, 256)       0         
_________________________________________________________________
pool_4 (MaxPooling2D)        (None, 18, 18, 256)       0         
_________________________________________________________________
conv_9 (Conv2D)              (None, 18, 18, 512)       1180160   
_________________________________________________________________
norm_9 (BatchNormalization)  (None, 18, 18, 512)       2048      
_________________________________________________________________
relu_9 (LeakyReLU)           (None, 18, 18, 512)       0         
_________________________________________________________________
conv_10 (Conv2D)             (None, 18, 18, 256)       131328    
_________________________________________________________________
norm_10 (BatchNormalization) (None, 18, 18, 256)       1024      
_________________________________________________________________
relu_10 (LeakyReLU)          (None, 18, 18, 256)       0         
_________________________________________________________________
conv_11 (Conv2D)             (None, 18, 18, 512)       1180160   
_________________________________________________________________
norm_11 (BatchNormalization) (None, 18, 18, 512)       2048      
_________________________________________________________________
relu_11 (LeakyReLU)          (None, 18, 18, 512)       0         
_________________________________________________________________
conv_12 (Conv2D)             (None, 18, 18, 256)       131328    
_________________________________________________________________
norm_12 (BatchNormalization) (None, 18, 18, 256)       1024      
_________________________________________________________________
relu_12 (LeakyReLU)          (None, 18, 18, 256)       0         
_________________________________________________________________
conv_13 (Conv2D)             (None, 18, 18, 512)       1180160   
_________________________________________________________________
norm_13 (BatchNormalization) (None, 18, 18, 512)       2048      
_________________________________________________________________
relu_13 (LeakyReLU)          (None, 18, 18, 512)       0         
_________________________________________________________________
pool_5 (MaxPooling2D)        (None, 9, 9, 512)         0         
_________________________________________________________________
conv_14 (Conv2D)             (None, 9, 9, 1024)        4719616   
_________________________________________________________________
norm_14 (BatchNormalization) (None, 9, 9, 1024)        4096      
_________________________________________________________________
relu_14 (LeakyReLU)          (None, 9, 9, 1024)        0         
_________________________________________________________________
conv_15 (Conv2D)             (None, 9, 9, 1024)        9438208   
_________________________________________________________________
norm_15 (BatchNormalization) (None, 9, 9, 1024)        4096      
_________________________________________________________________
relu_15 (LeakyReLU)          (None, 9, 9, 1024)        0         
_________________________________________________________________
conv_16 (Conv2D)             (None, 9, 9, 5)           5125      
_________________________________________________________________
reshape_1 (Reshape)          (None, 9, 9, 5)           0         
=================================================================
Total params: 18,784,709
Trainable params: 18,774,405
Non-trainable params: 10,304
_________________________________________________________________
+----------+--------------------+----------------+-------------------+--------------------+---------------------+------------------+
|  Epoch   |      f1_score      |      iou       |        loss       |     precision      |        recall       |     val_loss     |
+----------+--------------------+----------------+-------------------+--------------------+---------------------+------------------+
| Epoch 1  |         0          |       0        |  0.0173329166282  |         0          |         0.0         | 0.0138449159361  |
| Epoch 2  | 0.4724409448818898 | 0.659589629918 |  0.00824072826591 | 0.5504587155963303 | 0.41379310344827586 | 0.00875620994597 |
| Epoch 3  | 0.5844155844155845 | 0.654762432404 |  0.00629403427777 | 0.5521472392638037 |  0.6206896551724138 | 0.00841686731925 |
| Epoch 4  | 0.574108818011257  | 0.651955684395 |  0.00501631119817 | 0.6296296296296297 |  0.5275862068965518 | 0.00800640631707 |
| Epoch 5  | 0.6020066889632107 | 0.65573434373  |  0.00418592504063 | 0.5844155844155844 |  0.6206896551724138 | 0.00850704422731 |
| Epoch 6  | 0.5982300884955752 | 0.672782575519 |  0.00363178731419 | 0.6145454545454545 |  0.5827586206896552 | 0.00814732201698 |
| Epoch 7  | 0.575187969924812  | 0.638489970756 |  0.00321311522523 | 0.6322314049586777 |  0.5275862068965518 | 0.00821786854536 |
| Epoch 8  | 0.5471698113207547 | 0.678810750606 |  0.00287739694314 | 0.6041666666666666 |         0.5         | 0.00888230719213 |
| Epoch 9  | 0.5868725868725868 | 0.691641277791 |  0.00257905204621 | 0.6666666666666666 |  0.5241379310344828 | 0.00801927467147 |
| Epoch 10 | 0.5932835820895522 | 0.659424196964 |  0.00236620627698 | 0.6463414634146342 |  0.5482758620689655 | 0.00864822055484 |
| Epoch 11 | 0.6793168880455408 | 0.682785352149 |  0.00219604569074 | 0.7552742616033755 |  0.6172413793103448 | 0.0073779134245  |
| Epoch 12 | 0.5964912280701755 | 0.670613735936 |  0.00205829929535 | 0.6860986547085202 |  0.5275862068965518 | 0.00779979530301 |
| Epoch 13 | 0.6408450704225352 | 0.674610881288 |  0.00187691972788 | 0.6546762589928058 |  0.6275862068965518 | 0.00699673279098 |
| Epoch 14 | 0.6083499005964216 | 0.678663061022 |  0.00179250919307 | 0.7183098591549296 |  0.5275862068965518 | 0.00838425124605 |
| Epoch 15 | 0.6828358208955224 | 0.676415527239 |   0.001645788379  | 0.7439024390243902 |  0.6310344827586207 | 0.00742867413247 |
| Epoch 16 | 0.6363636363636364 | 0.68542037846  |  0.00158020631115 | 0.6730769230769231 |  0.603448275862069  | 0.00801162650028 |
| Epoch 17 | 0.5863453815261044 | 0.670937621094 |  0.00152656378408 | 0.7019230769230769 |  0.503448275862069  | 0.00842669083466 |
| Epoch 18 | 0.6315789473684211 | 0.676106214976 |  0.00141695843853 | 0.726457399103139  |  0.5586206896551724 | 0.00780685863367 |
| Epoch 19 | 0.5930470347648262 | 0.681511821328 |  0.00136141591301 | 0.7286432160804021 |         0.5         | 0.00860861325336 |
| Epoch 20 | 0.6749116607773852 | 0.675408956922 |  0.00124353267974 | 0.6920289855072463 |  0.6586206896551724 | 0.00775023904299 |
| Epoch 21 | 0.6029106029106028 | 0.66743543903  |  0.00121968143268 | 0.7591623036649214 |         0.5         | 0.00860583191858 |
| Epoch 22 | 0.5848670756646217 | 0.674404660188 |  0.0011189338192  | 0.7185929648241206 | 0.49310344827586206 | 0.00858557790578 |
| Epoch 23 | 0.6204081632653062 | 0.696157803232 |  0.00106448472091 |        0.76        |  0.5241379310344828 | 0.00818172343556 |
| Epoch 24 | 0.6549019607843137 | 0.689807294571 |  0.00104232792398 | 0.759090909090909  |  0.5758620689655173 | 0.00780829737684 |
| Epoch 25 | 0.6923076923076923 | 0.683505492186 |  0.00100468831927 | 0.782608695652174  |  0.6206896551724138 | 0.00760703633029 |
| Epoch 26 | 0.6238185255198488 | 0.67748910981  |  0.00101104492193 | 0.6903765690376569 |  0.5689655172413793 | 0.00789004552268 |
| Epoch 27 | 0.6048387096774194 | 0.676501483676 | 0.000964806583761 | 0.7281553398058253 |  0.5172413793103449 | 0.00825425554367 |
| Epoch 28 | 0.6577946768060837 | 0.693106565788 | 0.000956461401972 | 0.7330508474576272 |  0.596551724137931  | 0.00777567491957 |
| Epoch 29 | 0.6157112526539278 | 0.685247579755 | 0.000889063329541 | 0.8011049723756906 |         0.5         | 0.00846332484376 |
| Epoch 30 | 0.6706114398422091 |  0.6924512859  | 0.000892139723099 | 0.783410138248848  |  0.5862068965517241 | 0.00780115243528 |
+----------+--------------------+----------------+-------------------+--------------------+---------------------+------------------+
_________________________________________________________________
+---------------------------------+--------------------+--------------------+-----------------------+---------+-----------------------+
|            Optimizer            |       beta_1       |       beta_2       |         decay         | epsilon |           lr          |
+---------------------------------+--------------------+--------------------+-----------------------+---------+-----------------------+
| <class 'keras.optimizers.Adam'> | 0.8999999761581421 | 0.9990000128746033 | 0.0005000000237487257 |  1e-08  | 0.0010000000474974513 |
+---------------------------------+--------------------+--------------------+-----------------------+---------+-----------------------+
_________________________________________________________________
+------------+
| Batch Size |
+------------+
|     16     |
+------------+
_________________________________________________________________
+--------------------+-------------------+----------------+--------------------+--------------------+--------------------+
|      Metrics       |        Loss       |      IoU       |     Precision      |       Recall       |      F1 Score      |
+--------------------+-------------------+----------------+--------------------+--------------------+--------------------+
|   Train Metrics    | 0.000800533681399 | 0.871971336844 | 0.9794016674840608 | 0.9663682555044761 | 0.9728413104372183 |
| Validation Metrics |  0.00780115276575 |  0.6924512859  | 0.783410138248848  | 0.5862068965517241 | 0.6706114398422091 |
|    Test Metrics    |  0.00845221282854 | 0.687511516761 | 0.7633928571428571 | 0.5533980582524272 | 0.6416510318949343 |
+--------------------+-------------------+----------------+--------------------+--------------------+--------------------+
_________________________________________________________________
Time:
    Train Time              : 5:23:56.396568
    Dataset Loading Time    : 0:00:41.579026
    Metrics Evaluation Time : 4:18:56.153262
_________________________________________________________________
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         (None, 288, 288, 1)       0         
_________________________________________________________________
conv_1 (Conv2D)              (None, 288, 288, 32)      320       
_________________________________________________________________
norm_1 (BatchNormalization)  (None, 288, 288, 32)      128       
_________________________________________________________________
relu_1 (Activation)          (None, 288, 288, 32)      0         
_________________________________________________________________
pool_1 (MaxPooling2D)        (None, 144, 144, 32)      0         
_________________________________________________________________
conv_2 (Conv2D)              (None, 144, 144, 64)      18496     
_________________________________________________________________
norm_2 (BatchNormalization)  (None, 144, 144, 64)      256       
_________________________________________________________________
relu_2 (Activation)          (None, 144, 144, 64)      0         
_________________________________________________________________
pool_2 (MaxPooling2D)        (None, 72, 72, 64)        0         
_________________________________________________________________
conv_3 (Conv2D)              (None, 72, 72, 128)       73856     
_________________________________________________________________
norm_3 (BatchNormalization)  (None, 72, 72, 128)       512       
_________________________________________________________________
relu_3 (Activation)          (None, 72, 72, 128)       0         
_________________________________________________________________
conv_4 (Conv2D)              (None, 72, 72, 64)        8256      
_________________________________________________________________
norm_4 (BatchNormalization)  (None, 72, 72, 64)        256       
_________________________________________________________________
relu_4 (Activation)          (None, 72, 72, 64)        0         
_________________________________________________________________
conv_5 (Conv2D)              (None, 72, 72, 128)       73856     
_________________________________________________________________
norm_5 (BatchNormalization)  (None, 72, 72, 128)       512       
_________________________________________________________________
relu_5 (Activation)          (None, 72, 72, 128)       0         
_________________________________________________________________
pool_3 (MaxPooling2D)        (None, 36, 36, 128)       0         
_________________________________________________________________
conv_6 (Conv2D)              (None, 36, 36, 256)       295168    
_________________________________________________________________
norm_6 (BatchNormalization)  (None, 36, 36, 256)       1024      
_________________________________________________________________
relu_6 (Activation)          (None, 36, 36, 256)       0         
_________________________________________________________________
conv_7 (Conv2D)              (None, 36, 36, 128)       32896     
_________________________________________________________________
norm_7 (BatchNormalization)  (None, 36, 36, 128)       512       
_________________________________________________________________
relu_7 (Activation)          (None, 36, 36, 128)       0         
_________________________________________________________________
conv_8 (Conv2D)              (None, 36, 36, 256)       295168    
_________________________________________________________________
norm_8 (BatchNormalization)  (None, 36, 36, 256)       1024      
_________________________________________________________________
relu_8 (Activation)          (None, 36, 36, 256)       0         
_________________________________________________________________
pool_4 (MaxPooling2D)        (None, 18, 18, 256)       0         
_________________________________________________________________
conv_9 (Conv2D)              (None, 18, 18, 512)       1180160   
_________________________________________________________________
norm_9 (BatchNormalization)  (None, 18, 18, 512)       2048      
_________________________________________________________________
relu_9 (Activation)          (None, 18, 18, 512)       0         
_________________________________________________________________
conv_10 (Conv2D)             (None, 18, 18, 256)       131328    
_________________________________________________________________
norm_10 (BatchNormalization) (None, 18, 18, 256)       1024      
_________________________________________________________________
relu_10 (Activation)         (None, 18, 18, 256)       0         
_________________________________________________________________
conv_11 (Conv2D)             (None, 18, 18, 512)       1180160   
_________________________________________________________________
norm_11 (BatchNormalization) (None, 18, 18, 512)       2048      
_________________________________________________________________
relu_11 (Activation)         (None, 18, 18, 512)       0         
_________________________________________________________________
conv_12 (Conv2D)             (None, 18, 18, 256)       131328    
_________________________________________________________________
norm_12 (BatchNormalization) (None, 18, 18, 256)       1024      
_________________________________________________________________
relu_12 (Activation)         (None, 18, 18, 256)       0         
_________________________________________________________________
conv_13 (Conv2D)             (None, 18, 18, 512)       1180160   
_________________________________________________________________
norm_13 (BatchNormalization) (None, 18, 18, 512)       2048      
_________________________________________________________________
relu_13 (Activation)         (None, 18, 18, 512)       0         
_________________________________________________________________
pool_5 (MaxPooling2D)        (None, 9, 9, 512)         0         
_________________________________________________________________
conv_14 (Conv2D)             (None, 9, 9, 1024)        4719616   
_________________________________________________________________
norm_14 (BatchNormalization) (None, 9, 9, 1024)        4096      
_________________________________________________________________
relu_14 (Activation)         (None, 9, 9, 1024)        0         
_________________________________________________________________
conv_15 (Conv2D)             (None, 9, 9, 1024)        9438208   
_________________________________________________________________
norm_15 (BatchNormalization) (None, 9, 9, 1024)        4096      
_________________________________________________________________
relu_15 (Activation)         (None, 9, 9, 1024)        0         
_________________________________________________________________
conv_16 (Conv2D)             (None, 9, 9, 5)           5125      
_________________________________________________________________
reshape_1 (Reshape)          (None, 9, 9, 5)           0         
=================================================================
Total params: 18,784,709
Trainable params: 18,774,405
Non-trainable params: 10,304
_________________________________________________________________
+----------+--------------------+----------------+------------------+--------------------+---------------------+------------------+
|  Epoch   |      f1_score      |      iou       |       loss       |     precision      |        recall       |     val_loss     |
+----------+--------------------+----------------+------------------+--------------------+---------------------+------------------+
| Epoch 1  |         0          |       0        | 0.0170928139416  |         0          |         0.0         | 0.0223845037962  |
| Epoch 2  | 0.5221052631578948 | 0.668825334651 | 0.00829423456559 | 0.6702702702702703 | 0.42758620689655175 | 0.00821351575395 |
| Epoch 3  | 0.6086956521739131 | 0.686755015883 |  0.00607356544   | 0.5909090909090909 |  0.6275862068965518 | 0.00789202576984 |
| Epoch 4  | 0.5884861407249466 | 0.674009262679 | 0.00487932721027 | 0.770949720670391  | 0.47586206896551725 | 0.00787896855224 |
| Epoch 5  | 0.6066536203522505 | 0.675559108559 | 0.00407430550339 | 0.7013574660633484 |  0.5344827586206896 | 0.00807706753333 |
| Epoch 6  | 0.6180555555555556 | 0.691847200754 | 0.00344221641726 | 0.6223776223776224 |  0.6137931034482759 | 0.00737790417888 |
| Epoch 7  | 0.6040061633281971 | 0.677404967103 | 0.00309529633534 | 0.5459610027855153 |  0.6758620689655173 | 0.00823904033149 |
| Epoch 8  | 0.6382252559726963 | 0.688408472207 | 0.00275275269653 | 0.6317567567567568 |  0.6448275862068965 | 0.00751700965808 |
| Epoch 9  | 0.628158844765343  | 0.678304166559 | 0.00242180302175 | 0.6590909090909091 |         0.6         | 0.00768743121936 |
| Epoch 10 | 0.6567717996289425 | 0.682984142568 | 0.00227144872184 | 0.7108433734939759 |  0.6103448275862069 | 0.00658602343361 |
+----------+--------------------+----------------+------------------+--------------------+---------------------+------------------+
_________________________________________________________________
+---------------------------------+--------------------+--------------------+-----------------------+---------+-----------------------+
|            Optimizer            |       beta_1       |       beta_2       |         decay         | epsilon |           lr          |
+---------------------------------+--------------------+--------------------+-----------------------+---------+-----------------------+
| <class 'keras.optimizers.Adam'> | 0.8999999761581421 | 0.9990000128746033 | 0.0005000000237487257 |  1e-08  | 0.0010000000474974513 |
+---------------------------------+--------------------+--------------------+-----------------------+---------+-----------------------+
_________________________________________________________________
+------------+
| Batch Size |
+------------+
|     16     |
+------------+
_________________________________________________________________
+--------------------+------------------+----------------+--------------------+--------------------+--------------------+
|      Metrics       |       Loss       |      IoU       |     Precision      |       Recall       |      F1 Score      |
+--------------------+------------------+----------------+--------------------+--------------------+--------------------+
|   Train Metrics    | 0.00206323225224 | 0.830260654976 | 0.9506311711036121 | 0.9201548511976773 | 0.9351447716235324 |
| Validation Metrics | 0.00658602336602 | 0.682984142568 | 0.7108433734939759 | 0.6103448275862069 | 0.6567717996289425 |
|    Test Metrics    | 0.00751801955724 | 0.690763947602 | 0.7521367521367521 |  0.56957928802589  | 0.6482504604051565 |
+--------------------+------------------+----------------+--------------------+--------------------+--------------------+
_________________________________________________________________
Time:
    Train Time              : 1:22:41.442696
    Dataset Loading Time    : 0:00:49.585950
    Metrics Evaluation Time : 3:43:06.993302
_________________________________________________________________
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         (None, 288, 288, 1)       0         
_________________________________________________________________
conv_1 (Conv2D)              (None, 288, 288, 32)      320       
_________________________________________________________________
norm_1 (BatchNormalization)  (None, 288, 288, 32)      128       
_________________________________________________________________
relu_1 (Activation)          (None, 288, 288, 32)      0         
_________________________________________________________________
pool_1 (MaxPooling2D)        (None, 144, 144, 32)      0         
_________________________________________________________________
conv_2 (Conv2D)              (None, 144, 144, 64)      18496     
_________________________________________________________________
norm_2 (BatchNormalization)  (None, 144, 144, 64)      256       
_________________________________________________________________
relu_2 (Activation)          (None, 144, 144, 64)      0         
_________________________________________________________________
pool_2 (MaxPooling2D)        (None, 72, 72, 64)        0         
_________________________________________________________________
conv_3 (Conv2D)              (None, 72, 72, 128)       73856     
_________________________________________________________________
norm_3 (BatchNormalization)  (None, 72, 72, 128)       512       
_________________________________________________________________
relu_3 (Activation)          (None, 72, 72, 128)       0         
_________________________________________________________________
conv_4 (Conv2D)              (None, 72, 72, 64)        8256      
_________________________________________________________________
norm_4 (BatchNormalization)  (None, 72, 72, 64)        256       
_________________________________________________________________
relu_4 (Activation)          (None, 72, 72, 64)        0         
_________________________________________________________________
conv_5 (Conv2D)              (None, 72, 72, 128)       73856     
_________________________________________________________________
norm_5 (BatchNormalization)  (None, 72, 72, 128)       512       
_________________________________________________________________
relu_5 (Activation)          (None, 72, 72, 128)       0         
_________________________________________________________________
pool_3 (MaxPooling2D)        (None, 36, 36, 128)       0         
_________________________________________________________________
conv_6 (Conv2D)              (None, 36, 36, 256)       295168    
_________________________________________________________________
norm_6 (BatchNormalization)  (None, 36, 36, 256)       1024      
_________________________________________________________________
relu_6 (Activation)          (None, 36, 36, 256)       0         
_________________________________________________________________
conv_7 (Conv2D)              (None, 36, 36, 128)       32896     
_________________________________________________________________
norm_7 (BatchNormalization)  (None, 36, 36, 128)       512       
_________________________________________________________________
relu_7 (Activation)          (None, 36, 36, 128)       0         
_________________________________________________________________
conv_8 (Conv2D)              (None, 36, 36, 256)       295168    
_________________________________________________________________
norm_8 (BatchNormalization)  (None, 36, 36, 256)       1024      
_________________________________________________________________
relu_8 (Activation)          (None, 36, 36, 256)       0         
_________________________________________________________________
pool_4 (MaxPooling2D)        (None, 18, 18, 256)       0         
_________________________________________________________________
conv_9 (Conv2D)              (None, 18, 18, 512)       1180160   
_________________________________________________________________
norm_9 (BatchNormalization)  (None, 18, 18, 512)       2048      
_________________________________________________________________
relu_9 (Activation)          (None, 18, 18, 512)       0         
_________________________________________________________________
conv_10 (Conv2D)             (None, 18, 18, 256)       131328    
_________________________________________________________________
norm_10 (BatchNormalization) (None, 18, 18, 256)       1024      
_________________________________________________________________
relu_10 (Activation)         (None, 18, 18, 256)       0         
_________________________________________________________________
conv_11 (Conv2D)             (None, 18, 18, 512)       1180160   
_________________________________________________________________
norm_11 (BatchNormalization) (None, 18, 18, 512)       2048      
_________________________________________________________________
relu_11 (Activation)         (None, 18, 18, 512)       0         
_________________________________________________________________
conv_12 (Conv2D)             (None, 18, 18, 256)       131328    
_________________________________________________________________
norm_12 (BatchNormalization) (None, 18, 18, 256)       1024      
_________________________________________________________________
relu_12 (Activation)         (None, 18, 18, 256)       0         
_________________________________________________________________
conv_13 (Conv2D)             (None, 18, 18, 512)       1180160   
_________________________________________________________________
norm_13 (BatchNormalization) (None, 18, 18, 512)       2048      
_________________________________________________________________
relu_13 (Activation)         (None, 18, 18, 512)       0         
_________________________________________________________________
pool_5 (MaxPooling2D)        (None, 9, 9, 512)         0         
_________________________________________________________________
conv_14 (Conv2D)             (None, 9, 9, 1024)        4719616   
_________________________________________________________________
norm_14 (BatchNormalization) (None, 9, 9, 1024)        4096      
_________________________________________________________________
relu_14 (Activation)         (None, 9, 9, 1024)        0         
_________________________________________________________________
conv_15 (Conv2D)             (None, 9, 9, 1024)        9438208   
_________________________________________________________________
norm_15 (BatchNormalization) (None, 9, 9, 1024)        4096      
_________________________________________________________________
relu_15 (Activation)         (None, 9, 9, 1024)        0         
_________________________________________________________________
conv_16 (Conv2D)             (None, 9, 9, 5)           5125      
_________________________________________________________________
reshape_1 (Reshape)          (None, 9, 9, 5)           0         
=================================================================
Total params: 18,784,709
Trainable params: 18,774,405
Non-trainable params: 10,304
_________________________________________________________________
+----------+--------------------+----------------+-------------------+--------------------+---------------------+------------------+
|  Epoch   |      f1_score      |      iou       |        loss       |     precision      |        recall       |     val_loss     |
+----------+--------------------+----------------+-------------------+--------------------+---------------------+------------------+
| Epoch 1  |         0          |       0        |  0.0170804849438  |         0          |         0.0         | 0.0164335318991  |
| Epoch 2  | 0.5247933884297521 | 0.68551186492  |  0.0078879028125  | 0.654639175257732  |  0.4379310344827586 | 0.00805430884864 |
| Epoch 3  | 0.5884476534296028 | 0.669465456296 |  0.00583327633808 | 0.6174242424242424 |  0.5620689655172414 | 0.00745630123082 |
| Epoch 4  | 0.5856164383561643 | 0.661453866544 |  0.00463588120587 | 0.5816326530612245 |  0.5896551724137931 | 0.00758318152399 |
| Epoch 5  | 0.6524064171122994 | 0.680766335198 |  0.00393802500787 | 0.6752767527675276 |  0.6310344827586207 | 0.00760891489805 |
| Epoch 6  | 0.630718954248366  | 0.677860816764 |  0.00348232426293 | 0.5993788819875776 |  0.6655172413793103 | 0.00869667986708 |
| Epoch 7  | 0.6179775280898876 | 0.678190554901 |  0.00318169645238 | 0.6762295081967213 |  0.5689655172413793 | 0.00729134441504 |
| Epoch 8  | 0.6150943396226416 | 0.670320438618 |  0.00281118029836 | 0.6791666666666667 |  0.5620689655172414 | 0.00764667293838 |
| Epoch 9  | 0.6110056925996206 | 0.683867752652 |  0.00254699346548 | 0.679324894514768  |  0.5551724137931034 | 0.00815591301709 |
| Epoch 10 | 0.6355475763016158 | 0.681841384317 |  0.00233168767341 | 0.6629213483146067 |  0.6103448275862069 | 0.00713531880249 |
| Epoch 11 | 0.6153846153846154 | 0.680111184448 |  0.00218949862028 | 0.7450980392156863 |  0.5241379310344828 | 0.00788310243778 |
| Epoch 12 | 0.5735849056603772 | 0.678847155995 |  0.00207658620237 | 0.6333333333333333 |  0.5241379310344828 | 0.00835745015572 |
| Epoch 13 | 0.602112676056338  | 0.687124284611 |  0.00197803368093 | 0.6151079136690647 |  0.5896551724137931 | 0.00817103404552 |
| Epoch 14 | 0.5768500948766604 |  0.6850157272  |  0.00174598165597 | 0.6413502109704642 |  0.5241379310344828 | 0.00815565030902 |
| Epoch 15 | 0.6380597014925373 | 0.705031803869 |  0.00164412891857 | 0.6951219512195121 |  0.5896551724137931 | 0.00746267373043 |
| Epoch 16 | 0.5854545454545453 | 0.671820260515 |  0.00161029614312 | 0.6192307692307693 |  0.5551724137931034 | 0.00851696065717 |
| Epoch 17 | 0.5518672199170124 | 0.685384499851 |  0.00144005400592 | 0.6927083333333334 |  0.4586206896551724 | 0.00853520091022 |
| Epoch 18 | 0.6323809523809524 | 0.68639218932  |  0.00134302013089 | 0.7063829787234043 |  0.5724137931034483 | 0.00794815563507 |
| Epoch 19 | 0.6356589147286822 | 0.679795609006 |  0.00118979005026 | 0.7256637168141593 |  0.5655172413793104 | 0.0076918494437  |
| Epoch 20 | 0.6337448559670782 | 0.68652864828  |  0.00121121235774 | 0.7857142857142857 |  0.5310344827586206 | 0.00817770076795 |
| Epoch 21 | 0.5956607495069034 | 0.675671310178 |  0.00110063027461 | 0.695852534562212  |  0.5206896551724138 | 0.00827058005117 |
| Epoch 22 | 0.5868263473053892 | 0.691720627274 |  0.00108646548291 | 0.6966824644549763 |  0.506896551724138  | 0.00833411112187 |
| Epoch 23 | 0.6123260437375746 | 0.689931342312 |  0.00101265919121 | 0.7230046948356808 |  0.5310344827586206 | 0.00791770200275 |
| Epoch 24 | 0.6679035250463822 | 0.687284520916 | 0.000976627147652 | 0.7228915662650602 |  0.6206896551724138 | 0.00715420633975 |
| Epoch 25 | 0.5785440613026821 | 0.688814406579 | 0.000944925339537 | 0.6508620689655172 |  0.5206896551724138 | 0.00878981503868 |
| Epoch 26 | 0.6395112016293278 | 0.684540809526 |  0.00083662502017 | 0.7810945273631841 |  0.5413793103448276 | 0.00796209759409 |
| Epoch 27 | 0.5590062111801242 | 0.683832545897 | 0.000785179350335 | 0.6994818652849741 | 0.46551724137931033 | 0.00896720353874 |
| Epoch 28 | 0.607843137254902  | 0.696833005435 | 0.000735535047866 | 0.7045454545454546 |  0.5344827586206896 | 0.00844248133381 |
| Epoch 29 | 0.5766871165644172 | 0.685279583564 | 0.000743506080675 | 0.7085427135678392 |  0.4862068965517241 | 0.00895487679349 |
| Epoch 30 | 0.5815899581589958 | 0.683287670437 |  0.00073115953028 | 0.7393617021276596 |  0.4793103448275862 | 0.00887301555204 |
+----------+--------------------+----------------+-------------------+--------------------+---------------------+------------------+
_________________________________________________________________
+---------------------------------+--------------------+--------------------+-----------------------+---------+-----------------------+
|            Optimizer            |       beta_1       |       beta_2       |         decay         | epsilon |           lr          |
+---------------------------------+--------------------+--------------------+-----------------------+---------+-----------------------+
| <class 'keras.optimizers.Adam'> | 0.8999999761581421 | 0.9990000128746033 | 0.0005000000237487257 |  1e-08  | 0.0010000000474974513 |
+---------------------------------+--------------------+--------------------+-----------------------+---------+-----------------------+
_________________________________________________________________
+------------+
| Batch Size |
+------------+
|     16     |
+------------+
_________________________________________________________________
+--------------------+------------------+----------------+--------------------+--------------------+--------------------+
|      Metrics       |       Loss       |      IoU       |     Precision      |       Recall       |      F1 Score      |
+--------------------+------------------+----------------+--------------------+--------------------+--------------------+
|   Train Metrics    | 0.00074739353815 | 0.877775883474 | 0.9763154681968014 | 0.9674570529881442 | 0.9718660752263475 |
| Validation Metrics | 0.00887301558208 | 0.683287670437 | 0.7393617021276596 | 0.4793103448275862 | 0.5815899581589958 |
|    Test Metrics    | 0.00921966357818 | 0.690482078364 | 0.7438423645320197 | 0.4886731391585761 |     0.58984375     |
+--------------------+------------------+----------------+--------------------+--------------------+--------------------+
_________________________________________________________________
Time:
    Train Time              : 6:26:39.123809
    Dataset Loading Time    : 0:00:36.142962
    Metrics Evaluation Time : 7:07:29.474502
_________________________________________________________________
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         (None, 288, 288, 1)       0         
_________________________________________________________________
conv_1 (Conv2D)              (None, 288, 288, 32)      320       
_________________________________________________________________
norm_1 (BatchNormalization)  (None, 288, 288, 32)      128       
_________________________________________________________________
relu_1 (Activation)          (None, 288, 288, 32)      0         
_________________________________________________________________
pool_1 (MaxPooling2D)        (None, 144, 144, 32)      0         
_________________________________________________________________
conv_2 (Conv2D)              (None, 144, 144, 64)      18496     
_________________________________________________________________
norm_2 (BatchNormalization)  (None, 144, 144, 64)      256       
_________________________________________________________________
relu_2 (Activation)          (None, 144, 144, 64)      0         
_________________________________________________________________
pool_2 (MaxPooling2D)        (None, 72, 72, 64)        0         
_________________________________________________________________
conv_3 (Conv2D)              (None, 72, 72, 128)       73856     
_________________________________________________________________
norm_3 (BatchNormalization)  (None, 72, 72, 128)       512       
_________________________________________________________________
relu_3 (Activation)          (None, 72, 72, 128)       0         
_________________________________________________________________
conv_4 (Conv2D)              (None, 72, 72, 64)        8256      
_________________________________________________________________
norm_4 (BatchNormalization)  (None, 72, 72, 64)        256       
_________________________________________________________________
relu_4 (Activation)          (None, 72, 72, 64)        0         
_________________________________________________________________
conv_5 (Conv2D)              (None, 72, 72, 128)       73856     
_________________________________________________________________
norm_5 (BatchNormalization)  (None, 72, 72, 128)       512       
_________________________________________________________________
relu_5 (Activation)          (None, 72, 72, 128)       0         
_________________________________________________________________
pool_3 (MaxPooling2D)        (None, 36, 36, 128)       0         
_________________________________________________________________
conv_6 (Conv2D)              (None, 36, 36, 256)       295168    
_________________________________________________________________
norm_6 (BatchNormalization)  (None, 36, 36, 256)       1024      
_________________________________________________________________
relu_6 (Activation)          (None, 36, 36, 256)       0         
_________________________________________________________________
conv_7 (Conv2D)              (None, 36, 36, 128)       32896     
_________________________________________________________________
norm_7 (BatchNormalization)  (None, 36, 36, 128)       512       
_________________________________________________________________
relu_7 (Activation)          (None, 36, 36, 128)       0         
_________________________________________________________________
conv_8 (Conv2D)              (None, 36, 36, 256)       295168    
_________________________________________________________________
norm_8 (BatchNormalization)  (None, 36, 36, 256)       1024      
_________________________________________________________________
relu_8 (Activation)          (None, 36, 36, 256)       0         
_________________________________________________________________
pool_4 (MaxPooling2D)        (None, 18, 18, 256)       0         
_________________________________________________________________
conv_9 (Conv2D)              (None, 18, 18, 512)       1180160   
_________________________________________________________________
norm_9 (BatchNormalization)  (None, 18, 18, 512)       2048      
_________________________________________________________________
relu_9 (Activation)          (None, 18, 18, 512)       0         
_________________________________________________________________
conv_10 (Conv2D)             (None, 18, 18, 256)       131328    
_________________________________________________________________
norm_10 (BatchNormalization) (None, 18, 18, 256)       1024      
_________________________________________________________________
relu_10 (Activation)         (None, 18, 18, 256)       0         
_________________________________________________________________
conv_11 (Conv2D)             (None, 18, 18, 512)       1180160   
_________________________________________________________________
norm_11 (BatchNormalization) (None, 18, 18, 512)       2048      
_________________________________________________________________
relu_11 (Activation)         (None, 18, 18, 512)       0         
_________________________________________________________________
conv_12 (Conv2D)             (None, 18, 18, 256)       131328    
_________________________________________________________________
norm_12 (BatchNormalization) (None, 18, 18, 256)       1024      
_________________________________________________________________
relu_12 (Activation)         (None, 18, 18, 256)       0         
_________________________________________________________________
conv_13 (Conv2D)             (None, 18, 18, 512)       1180160   
_________________________________________________________________
norm_13 (BatchNormalization) (None, 18, 18, 512)       2048      
_________________________________________________________________
relu_13 (Activation)         (None, 18, 18, 512)       0         
_________________________________________________________________
pool_5 (MaxPooling2D)        (None, 9, 9, 512)         0         
_________________________________________________________________
conv_14 (Conv2D)             (None, 9, 9, 1024)        4719616   
_________________________________________________________________
norm_14 (BatchNormalization) (None, 9, 9, 1024)        4096      
_________________________________________________________________
relu_14 (Activation)         (None, 9, 9, 1024)        0         
_________________________________________________________________
conv_15 (Conv2D)             (None, 9, 9, 1024)        9438208   
_________________________________________________________________
norm_15 (BatchNormalization) (None, 9, 9, 1024)        4096      
_________________________________________________________________
relu_15 (Activation)         (None, 9, 9, 1024)        0         
_________________________________________________________________
conv_16 (Conv2D)             (None, 9, 9, 5)           5125      
_________________________________________________________________
reshape_1 (Reshape)          (None, 9, 9, 5)           0         
=================================================================
Total params: 18,784,709
Trainable params: 18,774,405
Non-trainable params: 10,304
_________________________________________________________________
+----------+--------------------+----------------+-------------------+--------------------+---------------------+------------------+
|  Epoch   |      f1_score      |      iou       |        loss       |     precision      |        recall       |     val_loss     |
+----------+--------------------+----------------+-------------------+--------------------+---------------------+------------------+
| Epoch 1  |         0          |      nan       |  0.0176505840345  |        0.0         |         0.0         |  0.037994753329  |
| Epoch 2  | 0.4897119341563786 | 0.661394162531 |  0.00792377777256 | 0.6071428571428571 |  0.4103448275862069 | 0.00830879410909 |
| Epoch 3  | 0.5079365079365079 | 0.662219583513 |  0.00540905431486 | 0.5981308411214953 |  0.4413793103448276 | 0.00838467062661 |
| Epoch 4  | 0.5665399239543727 | 0.667154538533 |  0.00385817563746 | 0.6313559322033898 |  0.5137931034482759 | 0.00789440680115 |
| Epoch 5  | 0.5730550284629982 | 0.665467275827 |  0.00307677468755 | 0.6371308016877637 |  0.5206896551724138 | 0.00825857127746 |
| Epoch 6  | 0.5433962264150943 | 0.658219402333 |  0.00245406268496 |        0.6         |  0.496551724137931  | 0.00812734664989 |
| Epoch 7  | 0.5078125000000001 | 0.647356510882 |  0.00197005968071 | 0.5855855855855856 |  0.4482758620689655 | 0.0083471494877  |
| Epoch 8  |     0.58984375     | 0.658302630087 |  0.00163026313141 | 0.6801801801801802 |  0.5206896551724138 | 0.00794003197863 |
| Epoch 9  | 0.6145038167938932 | 0.668025517997 |  0.00138328391063 | 0.688034188034188  |  0.5551724137931034 | 0.00806260929112 |
| Epoch 10 | 0.5592233009708738 | 0.675962760182 |  0.00117097976022 |        0.64        |  0.496551724137931  | 0.00829686682611 |
| Epoch 11 | 0.5542635658914729 | 0.666599281403 |  0.00101499245948 | 0.6327433628318584 | 0.49310344827586206 | 0.00853004010635 |
| Epoch 12 | 0.5362035225048923 | 0.642174774176 | 0.000942094296953 | 0.6199095022624435 |  0.4724137931034483 | 0.00875433522367 |
| Epoch 13 | 0.5762004175365345 | 0.664067766446 | 0.000851136893731 | 0.7301587301587301 | 0.47586206896551725 | 0.00847852332217 |
| Epoch 14 | 0.5818181818181819 | 0.659040441272 |  0.00079084967281 | 0.7024390243902439 |  0.496551724137931  | 0.00864358013496 |
| Epoch 15 | 0.5656565656565657 | 0.670052296368 | 0.000724868869069 | 0.6829268292682927 |  0.4827586206896552 | 0.00859566330309 |
| Epoch 16 | 0.5680473372781066 | 0.656684418554 | 0.000705404564936 | 0.663594470046083  |  0.496551724137931  | 0.00872048121246 |
| Epoch 17 | 0.5581395348837209 | 0.651069271233 |  0.00062035907369 | 0.6371681415929203 |  0.496551724137931  | 0.00871239389263 |
| Epoch 18 | 0.5863453815261044 | 0.659120451395 |  0.00061647903862 | 0.7019230769230769 |  0.503448275862069  | 0.00869725857891 |
| Epoch 19 | 0.5436893203883495 | 0.665018466868 | 0.000573925203337 | 0.6222222222222222 |  0.4827586206896552 | 0.00889806754346 |
| Epoch 20 | 0.5235173824130879 | 0.66496383382  | 0.000550255524149 | 0.6432160804020101 |  0.4413793103448276 | 0.00905096250015 |
+----------+--------------------+----------------+-------------------+--------------------+---------------------+------------------+
_________________________________________________________________
+---------------------------------+--------------------+--------------------+----------------------+---------+-----------------------+
|            Optimizer            |       beta_1       |       beta_2       |        decay         | epsilon |           lr          |
+---------------------------------+--------------------+--------------------+----------------------+---------+-----------------------+
| <class 'keras.optimizers.Adam'> | 0.8999999761581421 | 0.9990000128746033 | 0.004999999888241291 |  1e-08  | 0.0010000000474974513 |
+---------------------------------+--------------------+--------------------+----------------------+---------+-----------------------+
_________________________________________________________________
+------------+
| Batch Size |
+------------+
|     16     |
+------------+
_________________________________________________________________
+--------------------+-------------------+----------------+--------------------+---------------------+--------------------+
|      Metrics       |        Loss       |      IoU       |     Precision      |        Recall       |      F1 Score      |
+--------------------+-------------------+----------------+--------------------+---------------------+--------------------+
|   Train Metrics    | 0.000496678085854 | 0.878878359517 | 0.9783724340175953 |  0.9686668279699976 | 0.9734954407294834 |
| Validation Metrics |  0.00905096266539 | 0.66496383382  | 0.6432160804020101 |  0.4413793103448276 | 0.5235173824130879 |
|    Test Metrics    |  0.00977570797888 | 0.658123276111 | 0.6306306306306306 | 0.45307443365695793 | 0.5273069679849341 |
+--------------------+-------------------+----------------+--------------------+---------------------+--------------------+
_________________________________________________________________
Time:
    Train Time              : 3:30:57.470749
    Dataset Loading Time    : 0:01:05.171813
    Metrics Evaluation Time : 5:24:41.833508
_________________________________________________________________
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         (None, 288, 288, 1)       0         
_________________________________________________________________
conv_1 (Conv2D)              (None, 288, 288, 32)      320       
_________________________________________________________________
norm_1 (BatchNormalization)  (None, 288, 288, 32)      128       
_________________________________________________________________
relu_1 (LeakyReLU)           (None, 288, 288, 32)      0         
_________________________________________________________________
pool_1 (MaxPooling2D)        (None, 144, 144, 32)      0         
_________________________________________________________________
conv_2 (Conv2D)              (None, 144, 144, 64)      18496     
_________________________________________________________________
norm_2 (BatchNormalization)  (None, 144, 144, 64)      256       
_________________________________________________________________
relu_2 (LeakyReLU)           (None, 144, 144, 64)      0         
_________________________________________________________________
pool_2 (MaxPooling2D)        (None, 72, 72, 64)        0         
_________________________________________________________________
conv_3 (Conv2D)              (None, 72, 72, 128)       73856     
_________________________________________________________________
norm_3 (BatchNormalization)  (None, 72, 72, 128)       512       
_________________________________________________________________
relu_3 (LeakyReLU)           (None, 72, 72, 128)       0         
_________________________________________________________________
conv_4 (Conv2D)              (None, 72, 72, 64)        8256      
_________________________________________________________________
norm_4 (BatchNormalization)  (None, 72, 72, 64)        256       
_________________________________________________________________
relu_4 (LeakyReLU)           (None, 72, 72, 64)        0         
_________________________________________________________________
conv_5 (Conv2D)              (None, 72, 72, 128)       73856     
_________________________________________________________________
norm_5 (BatchNormalization)  (None, 72, 72, 128)       512       
_________________________________________________________________
relu_5 (LeakyReLU)           (None, 72, 72, 128)       0         
_________________________________________________________________
pool_3 (MaxPooling2D)        (None, 36, 36, 128)       0         
_________________________________________________________________
conv_6 (Conv2D)              (None, 36, 36, 256)       295168    
_________________________________________________________________
norm_6 (BatchNormalization)  (None, 36, 36, 256)       1024      
_________________________________________________________________
relu_6 (LeakyReLU)           (None, 36, 36, 256)       0         
_________________________________________________________________
conv_7 (Conv2D)              (None, 36, 36, 128)       32896     
_________________________________________________________________
norm_7 (BatchNormalization)  (None, 36, 36, 128)       512       
_________________________________________________________________
relu_7 (LeakyReLU)           (None, 36, 36, 128)       0         
_________________________________________________________________
conv_8 (Conv2D)              (None, 36, 36, 256)       295168    
_________________________________________________________________
norm_8 (BatchNormalization)  (None, 36, 36, 256)       1024      
_________________________________________________________________
relu_8 (LeakyReLU)           (None, 36, 36, 256)       0         
_________________________________________________________________
pool_4 (MaxPooling2D)        (None, 18, 18, 256)       0         
_________________________________________________________________
conv_9 (Conv2D)              (None, 18, 18, 512)       1180160   
_________________________________________________________________
norm_9 (BatchNormalization)  (None, 18, 18, 512)       2048      
_________________________________________________________________
relu_9 (LeakyReLU)           (None, 18, 18, 512)       0         
_________________________________________________________________
conv_10 (Conv2D)             (None, 18, 18, 256)       131328    
_________________________________________________________________
norm_10 (BatchNormalization) (None, 18, 18, 256)       1024      
_________________________________________________________________
relu_10 (LeakyReLU)          (None, 18, 18, 256)       0         
_________________________________________________________________
conv_11 (Conv2D)             (None, 18, 18, 512)       1180160   
_________________________________________________________________
norm_11 (BatchNormalization) (None, 18, 18, 512)       2048      
_________________________________________________________________
relu_11 (LeakyReLU)          (None, 18, 18, 512)       0         
_________________________________________________________________
conv_12 (Conv2D)             (None, 18, 18, 256)       131328    
_________________________________________________________________
norm_12 (BatchNormalization) (None, 18, 18, 256)       1024      
_________________________________________________________________
relu_12 (LeakyReLU)          (None, 18, 18, 256)       0         
_________________________________________________________________
conv_13 (Conv2D)             (None, 18, 18, 512)       1180160   
_________________________________________________________________
norm_13 (BatchNormalization) (None, 18, 18, 512)       2048      
_________________________________________________________________
relu_13 (LeakyReLU)          (None, 18, 18, 512)       0         
_________________________________________________________________
pool_5 (MaxPooling2D)        (None, 9, 9, 512)         0         
_________________________________________________________________
conv_14 (Conv2D)             (None, 9, 9, 1024)        4719616   
_________________________________________________________________
norm_14 (BatchNormalization) (None, 9, 9, 1024)        4096      
_________________________________________________________________
relu_14 (LeakyReLU)          (None, 9, 9, 1024)        0         
_________________________________________________________________
conv_15 (Conv2D)             (None, 9, 9, 1024)        9438208   
_________________________________________________________________
norm_15 (BatchNormalization) (None, 9, 9, 1024)        4096      
_________________________________________________________________
relu_15 (LeakyReLU)          (None, 9, 9, 1024)        0         
_________________________________________________________________
conv_16 (Conv2D)             (None, 9, 9, 5)           5125      
_________________________________________________________________
reshape_1 (Reshape)          (None, 9, 9, 5)           0         
=================================================================
Total params: 18,784,709
Trainable params: 18,774,405
Non-trainable params: 10,304
_________________________________________________________________
+----------+--------------------+----------------+-------------------+--------------------+---------------------+------------------+
|  Epoch   |      f1_score      |      iou       |        loss       |     precision      |        recall       |     val_loss     |
+----------+--------------------+----------------+-------------------+--------------------+---------------------+------------------+
| Epoch 1  |         0          |       0        |   0.017361358891  |         0          |         0.0         | 0.0179585498427  |
| Epoch 2  | 0.4578833693304536 | 0.660490220801 |  0.00786482698157 | 0.6127167630057804 | 0.36551724137931035 | 0.0082295530686  |
| Epoch 3  | 0.6166950596252129 | 0.660847605126 |  0.0053576267067  | 0.6094276094276094 |  0.6241379310344828 | 0.00742101606222 |
| Epoch 4  | 0.5568627450980392 | 0.671982806129 |  0.0040052171347  | 0.6454545454545455 |  0.4896551724137931 | 0.00806939342029 |
| Epoch 5  | 0.5781818181818182 | 0.656609863294 |  0.00306327331737 | 0.6115384615384616 |  0.5482758620689655 | 0.00806748215109 |
| Epoch 6  | 0.5615384615384615 | 0.651688103055 |  0.0025096741786  | 0.6347826086956522 |  0.503448275862069  | 0.00826486052885 |
| Epoch 7  | 0.5462012320328542 | 0.662304188287 |  0.0020607055913  | 0.6751269035532995 |  0.4586206896551724 | 0.0088806998946  |
| Epoch 8  | 0.5656565656565657 | 0.668409614481 |  0.00170657383305 | 0.6829268292682927 |  0.4827586206896552 | 0.00848905016638 |
| Epoch 9  | 0.5922920892494928 | 0.667096673837 |  0.00142558486282 | 0.7192118226600985 |  0.503448275862069  | 0.00872658002341 |
| Epoch 10 | 0.5404255319148936 | 0.672495633832 |  0.00122011447816 | 0.7055555555555556 |  0.4379310344827586 | 0.00926227858591 |
| Epoch 11 | 0.6042884990253412 | 0.674806676126 |  0.0010842781128  | 0.695067264573991  |  0.5344827586206896 | 0.00814164982688 |
| Epoch 12 | 0.5659574468085107 | 0.671050437351 | 0.000953618368856 | 0.7388888888888889 |  0.4586206896551724 | 0.00873812612507 |
| Epoch 13 | 0.577962577962578  | 0.671847688611 | 0.000826365927856 | 0.7277486910994765 |  0.4793103448275862 | 0.00847819555671 |
| Epoch 14 | 0.5648535564853557 | 0.673630430561 | 0.000774694827942 | 0.7180851063829787 | 0.46551724137931033 | 0.00888343559458 |
| Epoch 15 | 0.5836734693877551 | 0.673294909372 | 0.000740875260008 |       0.715        | 0.49310344827586206 | 0.00877120601194 |
| Epoch 16 | 0.6031746031746031 | 0.675585744218 | 0.000669475286921 | 0.7102803738317757 |  0.5241379310344828 | 0.00836658752674 |
| Epoch 17 | 0.5953307392996109 | 0.664713952891 | 0.000624611586372 | 0.6830357142857143 |  0.5275862068965518 | 0.00858494631886 |
| Epoch 18 | 0.5630252100840336 | 0.676057283149 | 0.000586478660176 | 0.7204301075268817 | 0.46206896551724136 | 0.00865144468844 |
| Epoch 19 | 0.5555555555555556 | 0.675623307618 | 0.000549046489663 | 0.7303370786516854 |  0.4482758620689655 | 0.0089185533955  |
| Epoch 20 | 0.5958333333333332 | 0.671771034901 | 0.000509773607956 | 0.7526315789473684 | 0.49310344827586206 | 0.00854999190497 |
| Epoch 21 | 0.5732217573221757 | 0.675321749313 | 0.000513868474845 | 0.7287234042553191 |  0.4724137931034483 | 0.0086657262948  |
| Epoch 22 | 0.5591836734693878 |  0.6861910192  | 0.000476905192847 |       0.685        |  0.4724137931034483 | 0.00831212849927 |
| Epoch 23 | 0.5614754098360655 | 0.669116252533 | 0.000451709099338 | 0.6919191919191919 |  0.4724137931034483 | 0.00870263597537 |
| Epoch 24 | 0.5789473684210525 | 0.677922451555 | 0.000435354730177 | 0.7009803921568627 | 0.49310344827586206 | 0.00833348832243 |
| Epoch 25 | 0.5485232067510548 | 0.681146411421 | 0.000431136857554 | 0.7065217391304348 |  0.4482758620689655 | 0.00874448268704 |
| Epoch 26 | 0.536082474226804  | 0.677677642673 | 0.000411439252037 | 0.6666666666666666 |  0.4482758620689655 |  0.008689669051  |
| Epoch 27 | 0.5902912621359223 | 0.672432361617 | 0.000395674043273 | 0.6755555555555556 |  0.5241379310344828 | 0.00805189538627 |
| Epoch 28 | 0.5777777777777777 |  0.6779008047  | 0.000398268536369 | 0.697560975609756  | 0.49310344827586206 | 0.00849054789832 |
| Epoch 29 | 0.5738396624472574 | 0.676156485912 | 0.000395600884313 | 0.7391304347826086 |  0.4689655172413793 | 0.00855841095589 |
| Epoch 30 | 0.591549295774648  | 0.67147503164  | 0.000377192100596 | 0.7101449275362319 |  0.506896551724138  | 0.00844422681257 |
+----------+--------------------+----------------+-------------------+--------------------+---------------------+------------------+
_________________________________________________________________
+---------------------------------+--------------------+--------------------+----------------------+---------+-----------------------+
|            Optimizer            |       beta_1       |       beta_2       |        decay         | epsilon |           lr          |
+---------------------------------+--------------------+--------------------+----------------------+---------+-----------------------+
| <class 'keras.optimizers.Adam'> | 0.8999999761581421 | 0.9990000128746033 | 0.004999999888241291 |  1e-08  | 0.0010000000474974513 |
+---------------------------------+--------------------+--------------------+----------------------+---------+-----------------------+
_________________________________________________________________
+------------+
| Batch Size |
+------------+
|     16     |
+------------+
_________________________________________________________________
+--------------------+-------------------+----------------+--------------------+---------------------+--------------------+
|      Metrics       |        Loss       |      IoU       |     Precision      |        Recall       |      F1 Score      |
+--------------------+-------------------+----------------+--------------------+---------------------+--------------------+
|   Train Metrics    | 0.000342479877331 | 0.917029162267 | 0.9840224417611904 |  0.9760464553593031 | 0.9800182204676586 |
| Validation Metrics |  0.00844422685764 | 0.67147503164  | 0.7101449275362319 |  0.506896551724138  | 0.591549295774648  |
|    Test Metrics    |  0.00904293667765 | 0.665249134414 | 0.6830357142857143 | 0.49514563106796117 | 0.5741088180112571 |
+--------------------+-------------------+----------------+--------------------+---------------------+--------------------+
_________________________________________________________________
Time:
    Train Time              : 6:48:00.550354
    Dataset Loading Time    : 0:00:38.512695
    Metrics Evaluation Time : 7:04:30.028599
_________________________________________________________________
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         (None, 288, 288, 1)       0         
_________________________________________________________________
conv_1 (Conv2D)              (None, 288, 288, 32)      320       
_________________________________________________________________
norm_1 (BatchNormalization)  (None, 288, 288, 32)      128       
_________________________________________________________________
relu_1 (LeakyReLU)           (None, 288, 288, 32)      0         
_________________________________________________________________
pool_1 (MaxPooling2D)        (None, 144, 144, 32)      0         
_________________________________________________________________
conv_2 (Conv2D)              (None, 144, 144, 64)      18496     
_________________________________________________________________
norm_2 (BatchNormalization)  (None, 144, 144, 64)      256       
_________________________________________________________________
relu_2 (LeakyReLU)           (None, 144, 144, 64)      0         
_________________________________________________________________
pool_2 (MaxPooling2D)        (None, 72, 72, 64)        0         
_________________________________________________________________
conv_3 (Conv2D)              (None, 72, 72, 128)       73856     
_________________________________________________________________
norm_3 (BatchNormalization)  (None, 72, 72, 128)       512       
_________________________________________________________________
relu_3 (LeakyReLU)           (None, 72, 72, 128)       0         
_________________________________________________________________
conv_4 (Conv2D)              (None, 72, 72, 64)        8256      
_________________________________________________________________
norm_4 (BatchNormalization)  (None, 72, 72, 64)        256       
_________________________________________________________________
relu_4 (LeakyReLU)           (None, 72, 72, 64)        0         
_________________________________________________________________
conv_5 (Conv2D)              (None, 72, 72, 128)       73856     
_________________________________________________________________
norm_5 (BatchNormalization)  (None, 72, 72, 128)       512       
_________________________________________________________________
relu_5 (LeakyReLU)           (None, 72, 72, 128)       0         
_________________________________________________________________
pool_3 (MaxPooling2D)        (None, 36, 36, 128)       0         
_________________________________________________________________
conv_6 (Conv2D)              (None, 36, 36, 256)       295168    
_________________________________________________________________
norm_6 (BatchNormalization)  (None, 36, 36, 256)       1024      
_________________________________________________________________
relu_6 (LeakyReLU)           (None, 36, 36, 256)       0         
_________________________________________________________________
conv_7 (Conv2D)              (None, 36, 36, 128)       32896     
_________________________________________________________________
norm_7 (BatchNormalization)  (None, 36, 36, 128)       512       
_________________________________________________________________
relu_7 (LeakyReLU)           (None, 36, 36, 128)       0         
_________________________________________________________________
conv_8 (Conv2D)              (None, 36, 36, 256)       295168    
_________________________________________________________________
norm_8 (BatchNormalization)  (None, 36, 36, 256)       1024      
_________________________________________________________________
relu_8 (LeakyReLU)           (None, 36, 36, 256)       0         
_________________________________________________________________
pool_4 (MaxPooling2D)        (None, 18, 18, 256)       0         
_________________________________________________________________
conv_9 (Conv2D)              (None, 18, 18, 512)       1180160   
_________________________________________________________________
norm_9 (BatchNormalization)  (None, 18, 18, 512)       2048      
_________________________________________________________________
relu_9 (LeakyReLU)           (None, 18, 18, 512)       0         
_________________________________________________________________
conv_10 (Conv2D)             (None, 18, 18, 256)       131328    
_________________________________________________________________
norm_10 (BatchNormalization) (None, 18, 18, 256)       1024      
_________________________________________________________________
relu_10 (LeakyReLU)          (None, 18, 18, 256)       0         
_________________________________________________________________
conv_11 (Conv2D)             (None, 18, 18, 512)       1180160   
_________________________________________________________________
norm_11 (BatchNormalization) (None, 18, 18, 512)       2048      
_________________________________________________________________
relu_11 (LeakyReLU)          (None, 18, 18, 512)       0         
_________________________________________________________________
conv_12 (Conv2D)             (None, 18, 18, 256)       131328    
_________________________________________________________________
norm_12 (BatchNormalization) (None, 18, 18, 256)       1024      
_________________________________________________________________
relu_12 (LeakyReLU)          (None, 18, 18, 256)       0         
_________________________________________________________________
conv_13 (Conv2D)             (None, 18, 18, 512)       1180160   
_________________________________________________________________
norm_13 (BatchNormalization) (None, 18, 18, 512)       2048      
_________________________________________________________________
relu_13 (LeakyReLU)          (None, 18, 18, 512)       0         
_________________________________________________________________
pool_5 (MaxPooling2D)        (None, 9, 9, 512)         0         
_________________________________________________________________
conv_14 (Conv2D)             (None, 9, 9, 1024)        4719616   
_________________________________________________________________
norm_14 (BatchNormalization) (None, 9, 9, 1024)        4096      
_________________________________________________________________
relu_14 (LeakyReLU)          (None, 9, 9, 1024)        0         
_________________________________________________________________
conv_15 (Conv2D)             (None, 9, 9, 1024)        9438208   
_________________________________________________________________
norm_15 (BatchNormalization) (None, 9, 9, 1024)        4096      
_________________________________________________________________
relu_15 (LeakyReLU)          (None, 9, 9, 1024)        0         
_________________________________________________________________
conv_16 (Conv2D)             (None, 9, 9, 5)           5125      
_________________________________________________________________
reshape_1 (Reshape)          (None, 9, 9, 5)           0         
=================================================================
Total params: 18,784,709
Trainable params: 18,774,405
Non-trainable params: 10,304
_________________________________________________________________
+----------+---------------------+----------------+------------------+---------------------+---------------------+------------------+
|  Epoch   |       f1_score      |      iou       |       loss       |      precision      |        recall       |     val_loss     |
+----------+---------------------+----------------+------------------+---------------------+---------------------+------------------+
| Epoch 1  |         nan         |      nan       | 0.0198824038069  |         nan         |         nan         | 0.0635574585007  |
| Epoch 2  |  0.2368421052631579 | 0.657514703981 | 0.00919844830898 |         0.5         | 0.15517241379310345 | 0.0118515010803  |
| Epoch 3  |  0.653913043478261  | 0.643319632469 | 0.00682642321289 |  0.6596491228070176 |  0.6482758620689655 | 0.00737598051708 |
| Epoch 4  | 0.48239436619718307 | 0.645464193425 | 0.00541704074092 | 0.49280575539568344 |  0.4724137931034483 | 0.00891984994673 |
| Epoch 5  |  0.631578947368421  | 0.671961557826 | 0.00454482516992 |  0.6666666666666666 |         0.6         | 0.00794029099146 |
| Epoch 6  |  0.5925925925925926 | 0.671989227237 | 0.00392559635341 |  0.7346938775510204 |  0.496551724137931  | 0.00747402563631 |
| Epoch 7  |  0.6184448462929475 | 0.683419405813 | 0.00346472634907 |  0.6501901140684411 |  0.5896551724137931 | 0.00759077911836 |
| Epoch 8  |         0.52        | 0.652040866683 | 0.00326646864572 |         0.55        | 0.49310344827586206 | 0.00789867057615 |
| Epoch 9  |  0.5430711610486891 | 0.66369885634  | 0.00292686717813 |  0.5942622950819673 |         0.5         | 0.00831882409271 |
| Epoch 10 | 0.45934959349593496 | 0.654617442698 | 0.00262071706962 |  0.5594059405940595 |  0.3896551724137931 | 0.00834825720578 |
| Epoch 11 |  0.6395348837209303 | 0.674798224483 | 0.0024678424393  |  0.7300884955752213 |  0.5689655172413793 | 0.00799127695181 |
| Epoch 12 |  0.6063829787234042 | 0.684359914738 | 0.00227866280019 |  0.6240875912408759 |  0.5896551724137931 | 0.0076613465264  |
| Epoch 13 |  0.5457943925233646 | 0.677037881685 | 0.00213101345761 |  0.5959183673469388 |  0.503448275862069  | 0.00868875630981 |
| Epoch 14 |  0.5219047619047619 | 0.673302855479 | 0.00205094185882 |  0.5829787234042553 |  0.4724137931034483 | 0.00937451114277 |
| Epoch 15 |  0.5927272727272729 | 0.68918294391  | 0.00189947602581 |  0.6269230769230769 |  0.5620689655172414 | 0.00805545248271 |
| Epoch 16 |  0.5914396887159534 | 0.686597839521 | 0.0018312936238  |  0.6785714285714286 |  0.5241379310344828 | 0.00838881947341 |
| Epoch 17 |  0.6487523992322457 | 0.683527624026 |   0.0017814641   |  0.7316017316017316 |  0.5827586206896552 |  0.007561893653  |
| Epoch 18 |  0.6215722120658135 | 0.688748989509 | 0.00162186251966 |  0.6614785992217899 |  0.5862068965517241 | 0.00793948949825 |
| Epoch 19 |  0.5399239543726235 | 0.677646880612 | 0.00146865580251 |  0.6016949152542372 |  0.4896551724137931 | 0.00818756912204 |
| Epoch 20 |  0.6242544731610338 | 0.69247348204  | 0.00141785237851 |  0.7370892018779343 |  0.5413793103448276 | 0.00811276192807 |
| Epoch 21 |  0.6309751434034417 | 0.691491295737 | 0.00139092492202 |  0.7081545064377682 |  0.5689655172413793 | 0.00780516158369 |
| Epoch 22 |  0.5761467889908256 | 0.689028977158 | 0.00137395783548 |  0.615686274509804  |  0.5413793103448276 | 0.00873711649629 |
| Epoch 23 |  0.5668016194331984 | 0.691730517242 | 0.00132359414204 |  0.6862745098039216 |  0.4827586206896552 | 0.00858587382602 |
| Epoch 24 |  0.6761061946902656 | 0.690664940045 | 0.00132199994979 |  0.6945454545454546 |  0.6586206896551724 | 0.00728074575384 |
| Epoch 25 |  0.6313645621181263 | 0.690833809768 | 0.00129023095299 |  0.7711442786069652 |  0.5344827586206896 | 0.00801947215692 |
| Epoch 26 |  0.6431226765799257 | 0.684690654324 | 0.00125247525584 |  0.6975806451612904 |  0.596551724137931  | 0.00763594560445 |
| Epoch 27 |  0.6429906542056075 | 0.691817825684 | 0.0011617085317  |  0.7020408163265306 |  0.593103448275862  | 0.00777069737594 |
| Epoch 28 |  0.6440677966101694 | 0.696206120483 | 0.00113349028467 |  0.7095435684647303 |  0.5896551724137931 | 0.00755484565912 |
| Epoch 29 |  0.582441113490364  | 0.691329704858 | 0.00108914247204 |  0.768361581920904  |  0.4689655172413793 | 0.00882808892657 |
| Epoch 30 |  0.653306613226453  | 0.683846136606 | 0.00107325446962 |  0.7799043062200957 |  0.5620689655172414 | 0.00721710376562 |
+----------+---------------------+----------------+------------------+---------------------+---------------------+------------------+
_________________________________________________________________
+---------------------------------+--------------------+--------------------+-----------------------+---------+-----------------------+
|            Optimizer            |       beta_1       |       beta_2       |         decay         | epsilon |           lr          |
+---------------------------------+--------------------+--------------------+-----------------------+---------+-----------------------+
| <class 'keras.optimizers.Adam'> | 0.8999999761581421 | 0.9990000128746033 | 0.0005000000237487257 |  1e-08  | 0.0010000000474974513 |
+---------------------------------+--------------------+--------------------+-----------------------+---------+-----------------------+
_________________________________________________________________
+------------+
| Batch Size |
+------------+
|     16     |
+------------+
_________________________________________________________________
+--------------------+------------------+----------------+--------------------+--------------------+--------------------+
|      Metrics       |       Loss       |      IoU       |     Precision      |       Recall       |      F1 Score      |
+--------------------+------------------+----------------+--------------------+--------------------+--------------------+
|   Train Metrics    | 0.00102161979587 | 0.874124203642 | 0.9763643113476055 | 0.9545124606823131 | 0.9653147366489263 |
| Validation Metrics | 0.0072171036154  | 0.683846136606 | 0.7799043062200957 | 0.5620689655172414 | 0.653306613226453  |
|    Test Metrics    | 0.00821409584774 | 0.692005975593 | 0.7358490566037735 | 0.5048543689320388 | 0.5988483685220729 |
+--------------------+------------------+----------------+--------------------+--------------------+--------------------+
_________________________________________________________________
Time:
    Train Time              : 4:48:58.378505
    Dataset Loading Time    : 0:00:46.867904
    Metrics Evaluation Time : 3:26:57.252653
_________________________________________________________________
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         (None, 288, 288, 1)       0         
_________________________________________________________________
conv_1 (Conv2D)              (None, 288, 288, 32)      320       
_________________________________________________________________
norm_1 (BatchNormalization)  (None, 288, 288, 32)      128       
_________________________________________________________________
relu_1 (LeakyReLU)           (None, 288, 288, 32)      0         
_________________________________________________________________
pool_1 (MaxPooling2D)        (None, 144, 144, 32)      0         
_________________________________________________________________
conv_2 (Conv2D)              (None, 144, 144, 64)      18496     
_________________________________________________________________
norm_2 (BatchNormalization)  (None, 144, 144, 64)      256       
_________________________________________________________________
relu_2 (LeakyReLU)           (None, 144, 144, 64)      0         
_________________________________________________________________
pool_2 (MaxPooling2D)        (None, 72, 72, 64)        0         
_________________________________________________________________
conv_3 (Conv2D)              (None, 72, 72, 128)       73856     
_________________________________________________________________
norm_3 (BatchNormalization)  (None, 72, 72, 128)       512       
_________________________________________________________________
relu_3 (LeakyReLU)           (None, 72, 72, 128)       0         
_________________________________________________________________
conv_4 (Conv2D)              (None, 72, 72, 64)        8256      
_________________________________________________________________
norm_4 (BatchNormalization)  (None, 72, 72, 64)        256       
_________________________________________________________________
relu_4 (LeakyReLU)           (None, 72, 72, 64)        0         
_________________________________________________________________
conv_5 (Conv2D)              (None, 72, 72, 128)       73856     
_________________________________________________________________
norm_5 (BatchNormalization)  (None, 72, 72, 128)       512       
_________________________________________________________________
relu_5 (LeakyReLU)           (None, 72, 72, 128)       0         
_________________________________________________________________
pool_3 (MaxPooling2D)        (None, 36, 36, 128)       0         
_________________________________________________________________
conv_6 (Conv2D)              (None, 36, 36, 256)       295168    
_________________________________________________________________
norm_6 (BatchNormalization)  (None, 36, 36, 256)       1024      
_________________________________________________________________
relu_6 (LeakyReLU)           (None, 36, 36, 256)       0         
_________________________________________________________________
conv_7 (Conv2D)              (None, 36, 36, 128)       32896     
_________________________________________________________________
norm_7 (BatchNormalization)  (None, 36, 36, 128)       512       
_________________________________________________________________
relu_7 (LeakyReLU)           (None, 36, 36, 128)       0         
_________________________________________________________________
conv_8 (Conv2D)              (None, 36, 36, 256)       295168    
_________________________________________________________________
norm_8 (BatchNormalization)  (None, 36, 36, 256)       1024      
_________________________________________________________________
relu_8 (LeakyReLU)           (None, 36, 36, 256)       0         
_________________________________________________________________
pool_4 (MaxPooling2D)        (None, 18, 18, 256)       0         
_________________________________________________________________
conv_9 (Conv2D)              (None, 18, 18, 512)       1180160   
_________________________________________________________________
norm_9 (BatchNormalization)  (None, 18, 18, 512)       2048      
_________________________________________________________________
relu_9 (LeakyReLU)           (None, 18, 18, 512)       0         
_________________________________________________________________
conv_10 (Conv2D)             (None, 18, 18, 256)       131328    
_________________________________________________________________
norm_10 (BatchNormalization) (None, 18, 18, 256)       1024      
_________________________________________________________________
relu_10 (LeakyReLU)          (None, 18, 18, 256)       0         
_________________________________________________________________
conv_11 (Conv2D)             (None, 18, 18, 512)       1180160   
_________________________________________________________________
norm_11 (BatchNormalization) (None, 18, 18, 512)       2048      
_________________________________________________________________
relu_11 (LeakyReLU)          (None, 18, 18, 512)       0         
_________________________________________________________________
conv_12 (Conv2D)             (None, 18, 18, 256)       131328    
_________________________________________________________________
norm_12 (BatchNormalization) (None, 18, 18, 256)       1024      
_________________________________________________________________
relu_12 (LeakyReLU)          (None, 18, 18, 256)       0         
_________________________________________________________________
conv_13 (Conv2D)             (None, 18, 18, 512)       1180160   
_________________________________________________________________
norm_13 (BatchNormalization) (None, 18, 18, 512)       2048      
_________________________________________________________________
relu_13 (LeakyReLU)          (None, 18, 18, 512)       0         
_________________________________________________________________
pool_5 (MaxPooling2D)        (None, 9, 9, 512)         0         
_________________________________________________________________
conv_14 (Conv2D)             (None, 9, 9, 1024)        4719616   
_________________________________________________________________
norm_14 (BatchNormalization) (None, 9, 9, 1024)        4096      
_________________________________________________________________
relu_14 (LeakyReLU)          (None, 9, 9, 1024)        0         
_________________________________________________________________
conv_15 (Conv2D)             (None, 9, 9, 1024)        9438208   
_________________________________________________________________
norm_15 (BatchNormalization) (None, 9, 9, 1024)        4096      
_________________________________________________________________
relu_15 (LeakyReLU)          (None, 9, 9, 1024)        0         
_________________________________________________________________
conv_16 (Conv2D)             (None, 9, 9, 5)           5125      
_________________________________________________________________
reshape_1 (Reshape)          (None, 9, 9, 5)           0         
=================================================================
Total params: 18,784,709
Trainable params: 18,774,405
Non-trainable params: 10,304
_________________________________________________________________
+----------+----------------------+----------------+-----------------+---------------------+---------------------+-----------------+
|  Epoch   |       f1_score       |      iou       |       loss      |      precision      |        recall       |     val_loss    |
+----------+----------------------+----------------+-----------------+---------------------+---------------------+-----------------+
| Epoch 1  |         nan          |      nan       | 0.0311646252726 |         nan         |         nan         | 0.0307692895532 |
| Epoch 2  | 0.007001166861143525 | 0.759150183278 | 0.0243153792785 |         1.0         | 0.00351288056206089 | 0.0245942019522 |
| Epoch 3  | 0.02314814814814815  | 0.712197225913 | 0.0233442601514 |         1.0         |  0.0117096018735363 | 0.0236894344091 |
| Epoch 4  |  0.0497737556561086  | 0.74226776136  | 0.0224845657273 |  0.7333333333333333 | 0.02576112412177986 | 0.0237597586215 |
| Epoch 5  |  0.1749502982107356  | 0.683986816884 |  0.021939029155 |  0.5789473684210527 | 0.10304449648711944 | 0.0227194854468 |
| Epoch 6  | 0.09120521172638436  | 0.698112100426 | 0.0211789878761 |  0.6268656716417911 | 0.04918032786885246 | 0.0224736897647 |
| Epoch 7  | 0.004576659038901602 | 0.670403239181 | 0.0205458238576 |         0.1         | 0.00234192037470726 | 0.0338182435036 |
| Epoch 8  |  0.1251167133520075  | 0.640381834347 | 0.0199351692814 |  0.3087557603686636 | 0.07845433255269321 | 0.0229935983419 |
| Epoch 9  | 0.18905472636815918  | 0.677103254912 | 0.0192416430159 |  0.6291390728476821 | 0.11124121779859485 | 0.0213446459025 |
| Epoch 10 | 0.07524752475247524  | 0.617441111112 |  0.018413834687 | 0.24358974358974358 | 0.04449648711943794 | 0.0286164186299 |
+----------+----------------------+----------------+-----------------+---------------------+---------------------+-----------------+
_________________________________________________________________
+---------------------------------+--------------------+--------------------+-----------------------+---------+-----------------------+
|            Optimizer            |       beta_1       |       beta_2       |         decay         | epsilon |           lr          |
+---------------------------------+--------------------+--------------------+-----------------------+---------+-----------------------+
| <class 'keras.optimizers.Adam'> | 0.8999999761581421 | 0.9990000128746033 | 0.0005000000237487257 |  1e-08  | 0.0010000000474974513 |
+---------------------------------+--------------------+--------------------+-----------------------+---------+-----------------------+
_________________________________________________________________
+------------+
| Batch Size |
+------------+
|     16     |
+------------+
_________________________________________________________________
+--------------------+-----------------+----------------+---------------------+---------------------+---------------------+
|      Metrics       |       Loss      |      IoU       |      Precision      |        Recall       |       F1 Score      |
+--------------------+-----------------+----------------+---------------------+---------------------+---------------------+
|   Train Metrics    |  0.027123008712 | 0.628872562223 | 0.26233453670276774 | 0.04410574588616132 |  0.0755152704809191 |
| Validation Metrics | 0.0286164134592 | 0.617441111112 | 0.24358974358974358 | 0.04449648711943794 | 0.07524752475247524 |
|    Test Metrics    | 0.0294333737195 | 0.633890856232 | 0.15714285714285714 | 0.02508551881413911 | 0.04326450344149459 |
+--------------------+-----------------+----------------+---------------------+---------------------+---------------------+
_________________________________________________________________
Time:
    Train Time              : 2:50:17.270211
    Dataset Loading Time    : 0:04:21.890133
    Metrics Evaluation Time : 6:15:45.417454
_________________________________________________________________
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         (None, 288, 288, 1)       0         
_________________________________________________________________
conv_1 (Conv2D)              (None, 288, 288, 32)      320       
_________________________________________________________________
norm_1 (BatchNormalization)  (None, 288, 288, 32)      128       
_________________________________________________________________
relu_1 (LeakyReLU)           (None, 288, 288, 32)      0         
_________________________________________________________________
pool_1 (MaxPooling2D)        (None, 144, 144, 32)      0         
_________________________________________________________________
conv_2 (Conv2D)              (None, 144, 144, 64)      18496     
_________________________________________________________________
norm_2 (BatchNormalization)  (None, 144, 144, 64)      256       
_________________________________________________________________
relu_2 (LeakyReLU)           (None, 144, 144, 64)      0         
_________________________________________________________________
pool_2 (MaxPooling2D)        (None, 72, 72, 64)        0         
_________________________________________________________________
conv_3 (Conv2D)              (None, 72, 72, 128)       73856     
_________________________________________________________________
norm_3 (BatchNormalization)  (None, 72, 72, 128)       512       
_________________________________________________________________
relu_3 (LeakyReLU)           (None, 72, 72, 128)       0         
_________________________________________________________________
conv_4 (Conv2D)              (None, 72, 72, 64)        8256      
_________________________________________________________________
norm_4 (BatchNormalization)  (None, 72, 72, 64)        256       
_________________________________________________________________
relu_4 (LeakyReLU)           (None, 72, 72, 64)        0         
_________________________________________________________________
conv_5 (Conv2D)              (None, 72, 72, 128)       73856     
_________________________________________________________________
norm_5 (BatchNormalization)  (None, 72, 72, 128)       512       
_________________________________________________________________
relu_5 (LeakyReLU)           (None, 72, 72, 128)       0         
_________________________________________________________________
pool_3 (MaxPooling2D)        (None, 36, 36, 128)       0         
_________________________________________________________________
conv_6 (Conv2D)              (None, 36, 36, 256)       295168    
_________________________________________________________________
norm_6 (BatchNormalization)  (None, 36, 36, 256)       1024      
_________________________________________________________________
relu_6 (LeakyReLU)           (None, 36, 36, 256)       0         
_________________________________________________________________
conv_7 (Conv2D)              (None, 36, 36, 128)       32896     
_________________________________________________________________
norm_7 (BatchNormalization)  (None, 36, 36, 128)       512       
_________________________________________________________________
relu_7 (LeakyReLU)           (None, 36, 36, 128)       0         
_________________________________________________________________
conv_8 (Conv2D)              (None, 36, 36, 256)       295168    
_________________________________________________________________
norm_8 (BatchNormalization)  (None, 36, 36, 256)       1024      
_________________________________________________________________
relu_8 (LeakyReLU)           (None, 36, 36, 256)       0         
_________________________________________________________________
pool_4 (MaxPooling2D)        (None, 18, 18, 256)       0         
_________________________________________________________________
conv_9 (Conv2D)              (None, 18, 18, 512)       1180160   
_________________________________________________________________
norm_9 (BatchNormalization)  (None, 18, 18, 512)       2048      
_________________________________________________________________
relu_9 (LeakyReLU)           (None, 18, 18, 512)       0         
_________________________________________________________________
conv_10 (Conv2D)             (None, 18, 18, 256)       131328    
_________________________________________________________________
norm_10 (BatchNormalization) (None, 18, 18, 256)       1024      
_________________________________________________________________
relu_10 (LeakyReLU)          (None, 18, 18, 256)       0         
_________________________________________________________________
conv_11 (Conv2D)             (None, 18, 18, 512)       1180160   
_________________________________________________________________
norm_11 (BatchNormalization) (None, 18, 18, 512)       2048      
_________________________________________________________________
relu_11 (LeakyReLU)          (None, 18, 18, 512)       0         
_________________________________________________________________
conv_12 (Conv2D)             (None, 18, 18, 256)       131328    
_________________________________________________________________
norm_12 (BatchNormalization) (None, 18, 18, 256)       1024      
_________________________________________________________________
relu_12 (LeakyReLU)          (None, 18, 18, 256)       0         
_________________________________________________________________
conv_13 (Conv2D)             (None, 18, 18, 512)       1180160   
_________________________________________________________________
norm_13 (BatchNormalization) (None, 18, 18, 512)       2048      
_________________________________________________________________
relu_13 (LeakyReLU)          (None, 18, 18, 512)       0         
_________________________________________________________________
pool_5 (MaxPooling2D)        (None, 9, 9, 512)         0         
_________________________________________________________________
conv_14 (Conv2D)             (None, 9, 9, 1024)        4719616   
_________________________________________________________________
norm_14 (BatchNormalization) (None, 9, 9, 1024)        4096      
_________________________________________________________________
relu_14 (LeakyReLU)          (None, 9, 9, 1024)        0         
_________________________________________________________________
conv_15 (Conv2D)             (None, 9, 9, 1024)        9438208   
_________________________________________________________________
norm_15 (BatchNormalization) (None, 9, 9, 1024)        4096      
_________________________________________________________________
tanh_1 (Activation)          (None, 9, 9, 1024)        0         
_________________________________________________________________
conv_16 (Conv2D)             (None, 9, 9, 5)           5125      
_________________________________________________________________
reshape_1 (Reshape)          (None, 9, 9, 5)           0         
=================================================================
Total params: 18,784,709
Trainable params: 18,774,405
Non-trainable params: 10,304
_________________________________________________________________
+----------+---------------------+----------------+-----------------+--------------------+---------------------+-----------------+
|  Epoch   |       f1_score      |      iou       |       loss      |     precision      |        recall       |     val_loss    |
+----------+---------------------+----------------+-----------------+--------------------+---------------------+-----------------+
| Epoch 1  |         nan         |      nan       | 0.0380320941912 |        nan         |         nan         | 0.0272338579595 |
| Epoch 2  |         nan         |      nan       | 0.0301351688015 |        nan         |         nan         | 0.0325534779727 |
| Epoch 3  |         nan         |      nan       | 0.0283309411486 |        nan         |         nan         | 0.0299088254571 |
| Epoch 4  |         nan         |      nan       | 0.0263833775105 |        nan         |         nan         | 0.0270979138911 |
| Epoch 5  |         nan         |      nan       | 0.0254767867081 |        nan         |         nan         | 0.0256783919334 |
| Epoch 6  |         nan         |      nan       | 0.0245752594271 |        nan         |         nan         | 0.0253137435764 |
| Epoch 7  | 0.03214695752009185 | 0.688631248181 | 0.0241369071471 | 0.8235294117647058 | 0.01639344262295082 | 0.0244780735373 |
| Epoch 8  | 0.03636363636363636 | 0.717394296395 | 0.0239689623952 | 0.6153846153846154 | 0.01873536299765808 | 0.0255269294083 |
| Epoch 9  |         nan         |      nan       | 0.0234943580372 |        nan         |         nan         | 0.0287657567859 |
| Epoch 10 | 0.01622247972190035 | 0.723951952774 | 0.0232484134147 | 0.7777777777777778 | 0.00819672131147541 |  0.024847566694 |
+----------+---------------------+----------------+-----------------+--------------------+---------------------+-----------------+
_________________________________________________________________
+---------------------------------+--------------------+--------------------+-----------------------+---------+----------------------+
|            Optimizer            |       beta_1       |       beta_2       |         decay         | epsilon |          lr          |
+---------------------------------+--------------------+--------------------+-----------------------+---------+----------------------+
| <class 'keras.optimizers.Adam'> | 0.8999999761581421 | 0.9990000128746033 | 0.0005000000237487257 |  1e-08  | 0.009999999776482582 |
+---------------------------------+--------------------+--------------------+-----------------------+---------+----------------------+
_________________________________________________________________
+------------+
| Batch Size |
+------------+
|     16     |
+------------+
_________________________________________________________________
+--------------------+-----------------+----------------+--------------------+----------------------+----------------------+
|      Metrics       |       Loss      |      IoU       |     Precision      |        Recall        |       F1 Score       |
+--------------------+-----------------+----------------+--------------------+----------------------+----------------------+
|   Train Metrics    | 0.0243014378787 | 0.757253333007 | 0.9176470588235294 | 0.005260318316698139 | 0.010460671897002616 |
| Validation Metrics | 0.0248475681692 | 0.723951952774 | 0.7777777777777778 | 0.00819672131147541  | 0.01622247972190035  |
|    Test Metrics    | 0.0262309871912 | 0.78044621528  |        1.0         | 0.009122006841505131 | 0.01807909604519774  |
+--------------------+-----------------+----------------+--------------------+----------------------+----------------------+
_________________________________________________________________
Time:
    Train Time              : 2:50:46.641034
    Dataset Loading Time    : 0:04:58.508301
    Metrics Evaluation Time : 6:14:04.408607
_________________________________________________________________
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         (None, 288, 288, 1)       0         
_________________________________________________________________
conv_1 (Conv2D)              (None, 288, 288, 32)      320       
_________________________________________________________________
norm_1 (BatchNormalization)  (None, 288, 288, 32)      128       
_________________________________________________________________
relu_1 (LeakyReLU)           (None, 288, 288, 32)      0         
_________________________________________________________________
pool_1 (MaxPooling2D)        (None, 144, 144, 32)      0         
_________________________________________________________________
conv_2 (Conv2D)              (None, 144, 144, 64)      18496     
_________________________________________________________________
norm_2 (BatchNormalization)  (None, 144, 144, 64)      256       
_________________________________________________________________
relu_2 (LeakyReLU)           (None, 144, 144, 64)      0         
_________________________________________________________________
pool_2 (MaxPooling2D)        (None, 72, 72, 64)        0         
_________________________________________________________________
conv_3 (Conv2D)              (None, 72, 72, 128)       73856     
_________________________________________________________________
norm_3 (BatchNormalization)  (None, 72, 72, 128)       512       
_________________________________________________________________
relu_3 (LeakyReLU)           (None, 72, 72, 128)       0         
_________________________________________________________________
conv_4 (Conv2D)              (None, 72, 72, 64)        8256      
_________________________________________________________________
norm_4 (BatchNormalization)  (None, 72, 72, 64)        256       
_________________________________________________________________
relu_4 (LeakyReLU)           (None, 72, 72, 64)        0         
_________________________________________________________________
conv_5 (Conv2D)              (None, 72, 72, 128)       73856     
_________________________________________________________________
norm_5 (BatchNormalization)  (None, 72, 72, 128)       512       
_________________________________________________________________
relu_5 (LeakyReLU)           (None, 72, 72, 128)       0         
_________________________________________________________________
pool_3 (MaxPooling2D)        (None, 36, 36, 128)       0         
_________________________________________________________________
conv_6 (Conv2D)              (None, 36, 36, 256)       295168    
_________________________________________________________________
norm_6 (BatchNormalization)  (None, 36, 36, 256)       1024      
_________________________________________________________________
relu_6 (LeakyReLU)           (None, 36, 36, 256)       0         
_________________________________________________________________
conv_7 (Conv2D)              (None, 36, 36, 128)       32896     
_________________________________________________________________
norm_7 (BatchNormalization)  (None, 36, 36, 128)       512       
_________________________________________________________________
relu_7 (LeakyReLU)           (None, 36, 36, 128)       0         
_________________________________________________________________
conv_8 (Conv2D)              (None, 36, 36, 256)       295168    
_________________________________________________________________
norm_8 (BatchNormalization)  (None, 36, 36, 256)       1024      
_________________________________________________________________
relu_8 (LeakyReLU)           (None, 36, 36, 256)       0         
_________________________________________________________________
pool_4 (MaxPooling2D)        (None, 18, 18, 256)       0         
_________________________________________________________________
conv_9 (Conv2D)              (None, 18, 18, 512)       1180160   
_________________________________________________________________
norm_9 (BatchNormalization)  (None, 18, 18, 512)       2048      
_________________________________________________________________
relu_9 (LeakyReLU)           (None, 18, 18, 512)       0         
_________________________________________________________________
conv_10 (Conv2D)             (None, 18, 18, 256)       131328    
_________________________________________________________________
norm_10 (BatchNormalization) (None, 18, 18, 256)       1024      
_________________________________________________________________
relu_10 (LeakyReLU)          (None, 18, 18, 256)       0         
_________________________________________________________________
conv_11 (Conv2D)             (None, 18, 18, 512)       1180160   
_________________________________________________________________
norm_11 (BatchNormalization) (None, 18, 18, 512)       2048      
_________________________________________________________________
relu_11 (LeakyReLU)          (None, 18, 18, 512)       0         
_________________________________________________________________
conv_12 (Conv2D)             (None, 18, 18, 256)       131328    
_________________________________________________________________
norm_12 (BatchNormalization) (None, 18, 18, 256)       1024      
_________________________________________________________________
relu_12 (LeakyReLU)          (None, 18, 18, 256)       0         
_________________________________________________________________
conv_13 (Conv2D)             (None, 18, 18, 512)       1180160   
_________________________________________________________________
norm_13 (BatchNormalization) (None, 18, 18, 512)       2048      
_________________________________________________________________
relu_13 (LeakyReLU)          (None, 18, 18, 512)       0         
_________________________________________________________________
pool_5 (MaxPooling2D)        (None, 9, 9, 512)         0         
_________________________________________________________________
conv_14 (Conv2D)             (None, 9, 9, 1024)        4719616   
_________________________________________________________________
norm_14 (BatchNormalization) (None, 9, 9, 1024)        4096      
_________________________________________________________________
relu_14 (LeakyReLU)          (None, 9, 9, 1024)        0         
_________________________________________________________________
conv_15 (Conv2D)             (None, 9, 9, 1024)        9438208   
_________________________________________________________________
norm_15 (BatchNormalization) (None, 9, 9, 1024)        4096      
_________________________________________________________________
relu_15 (LeakyReLU)          (None, 9, 9, 1024)        0         
_________________________________________________________________
conv_16 (Conv2D)             (None, 9, 9, 5)           5125      
_________________________________________________________________
reshape_1 (Reshape)          (None, 9, 9, 5)           0         
=================================================================
Total params: 18,784,709
Trainable params: 18,774,405
Non-trainable params: 10,304
_________________________________________________________________
+----------+-----------------------+----------------+-----------------+--------------------+---------------------+-----------------+
|  Epoch   |        f1_score       |      iou       |       loss      |     precision      |        recall       |     val_loss    |
+----------+-----------------------+----------------+-----------------+--------------------+---------------------+-----------------+
| Epoch 1  |          nan          |      nan       | 0.0306094813982 |        nan         |         nan         | 0.0343521745503 |
| Epoch 2  |          nan          |      nan       | 0.0242677438849 |        nan         |         nan         | 0.0304866746664 |
| Epoch 3  | 0.0069284064665127015 | 0.83057926509  | 0.0236129694118 |        0.25        | 0.00351288056206089 | 0.0300481269956 |
| Epoch 4  |  0.020524515393386546 | 0.688066123985 | 0.0227742673365 | 0.391304347826087  | 0.01053864168618267 | 0.0282211503983 |
| Epoch 5  |  0.09586056644880173  | 0.712737688235 |  0.022095542333 |       0.6875       | 0.05152224824355972 | 0.0234011939466 |
| Epoch 6  |  0.14105263157894737  | 0.674574690468 | 0.0214484095205 | 0.6979166666666666 | 0.07845433255269321 | 0.0222302648425 |
| Epoch 7  |  0.11122994652406418  | 0.681648591813 | 0.0210161465816 | 0.6419753086419753 | 0.06088992974238876 | 0.0249267806411 |
| Epoch 8  |          nan          |      nan       |       nan       |        nan         |         nan         |       nan       |
| Epoch 9  |          nan          |      nan       |       nan       |        nan         |         nan         |       nan       |
| Epoch 10 |          nan          |      nan       |       nan       |        nan         |         nan         |       nan       |
| Epoch 11 |          nan          |      nan       |       nan       |        nan         |         nan         |       nan       |
| Epoch 12 |          nan          |      nan       |       nan       |        nan         |         nan         |       nan       |
| Epoch 13 |          nan          |      nan       |       nan       |        nan         |         nan         |       nan       |
| Epoch 14 |          nan          |      nan       |       nan       |        nan         |         nan         |       nan       |
| Epoch 15 |          nan          |      nan       |       nan       |        nan         |         nan         |       nan       |
| Epoch 16 |          nan          |      nan       |       nan       |        nan         |         nan         |       nan       |
| Epoch 17 |          nan          |      nan       |       nan       |        nan         |         nan         |       nan       |
| Epoch 18 |          nan          |      nan       |       nan       |        nan         |         nan         |       nan       |
| Epoch 19 |          nan          |      nan       |       nan       |        nan         |         nan         |       nan       |
| Epoch 20 |          nan          |      nan       |       nan       |        nan         |         nan         |       nan       |
| Epoch 21 |          nan          |      nan       |       nan       |        nan         |         nan         |       nan       |
| Epoch 22 |          nan          |      nan       |       nan       |        nan         |         nan         |       nan       |
| Epoch 23 |          nan          |      nan       |       nan       |        nan         |         nan         |       nan       |
| Epoch 24 |          nan          |      nan       |       nan       |        nan         |         nan         |       nan       |
| Epoch 25 |          nan          |      nan       |       nan       |        nan         |         nan         |       nan       |
| Epoch 26 |          nan          |      nan       |       nan       |        nan         |         nan         |       nan       |
| Epoch 27 |          nan          |      nan       |       nan       |        nan         |         nan         |       nan       |
| Epoch 28 |          nan          |      nan       |       nan       |        nan         |         nan         |       nan       |
| Epoch 29 |          nan          |      nan       |       nan       |        nan         |         nan         |       nan       |
| Epoch 30 |          nan          |      nan       |       nan       |        nan         |         nan         |       nan       |
+----------+-----------------------+----------------+-----------------+--------------------+---------------------+-----------------+
_________________________________________________________________
+---------------------------------+--------------------+--------------------+-----------------------+---------+-----------------------+
|            Optimizer            |       beta_1       |       beta_2       |         decay         | epsilon |           lr          |
+---------------------------------+--------------------+--------------------+-----------------------+---------+-----------------------+
| <class 'keras.optimizers.Adam'> | 0.8999999761581421 | 0.9990000128746033 | 0.0005000000237487257 |  1e-08  | 0.0010000000474974513 |
+---------------------------------+--------------------+--------------------+-----------------------+---------+-----------------------+
_________________________________________________________________
+------------+
| Batch Size |
+------------+
|     16     |
+------------+
_________________________________________________________________
+--------------------+------+-----+-----------+--------+----------+
|      Metrics       | Loss | IoU | Precision | Recall | F1 Score |
+--------------------+------+-----+-----------+--------+----------+
|   Train Metrics    | nan  | nan |    nan    |  nan   |   nan    |
| Validation Metrics | nan  | nan |    nan    |  nan   |   nan    |
|    Test Metrics    | nan  | nan |    nan    |  nan   |   nan    |
+--------------------+------+-----+-----------+--------+----------+
_________________________________________________________________
Time:
    Train Time              : 14:25:11.309655
    Dataset Loading Time    : 0:04:42.190337
    Metrics Evaluation Time : 12:35:17.864454
_________________________________________________________________
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         (None, 288, 288, 1)       0         
_________________________________________________________________
conv_1 (Conv2D)              (None, 288, 288, 32)      320       
_________________________________________________________________
norm_1 (BatchNormalization)  (None, 288, 288, 32)      128       
_________________________________________________________________
relu_1 (LeakyReLU)           (None, 288, 288, 32)      0         
_________________________________________________________________
pool_1 (MaxPooling2D)        (None, 144, 144, 32)      0         
_________________________________________________________________
conv_2 (Conv2D)              (None, 144, 144, 64)      18496     
_________________________________________________________________
norm_2 (BatchNormalization)  (None, 144, 144, 64)      256       
_________________________________________________________________
relu_2 (LeakyReLU)           (None, 144, 144, 64)      0         
_________________________________________________________________
pool_2 (MaxPooling2D)        (None, 72, 72, 64)        0         
_________________________________________________________________
conv_3 (Conv2D)              (None, 72, 72, 128)       73856     
_________________________________________________________________
norm_3 (BatchNormalization)  (None, 72, 72, 128)       512       
_________________________________________________________________
relu_3 (LeakyReLU)           (None, 72, 72, 128)       0         
_________________________________________________________________
conv_4 (Conv2D)              (None, 72, 72, 64)        8256      
_________________________________________________________________
norm_4 (BatchNormalization)  (None, 72, 72, 64)        256       
_________________________________________________________________
relu_4 (LeakyReLU)           (None, 72, 72, 64)        0         
_________________________________________________________________
conv_5 (Conv2D)              (None, 72, 72, 128)       73856     
_________________________________________________________________
norm_5 (BatchNormalization)  (None, 72, 72, 128)       512       
_________________________________________________________________
relu_5 (LeakyReLU)           (None, 72, 72, 128)       0         
_________________________________________________________________
pool_3 (MaxPooling2D)        (None, 36, 36, 128)       0         
_________________________________________________________________
conv_6 (Conv2D)              (None, 36, 36, 256)       295168    
_________________________________________________________________
norm_6 (BatchNormalization)  (None, 36, 36, 256)       1024      
_________________________________________________________________
relu_6 (LeakyReLU)           (None, 36, 36, 256)       0         
_________________________________________________________________
conv_7 (Conv2D)              (None, 36, 36, 128)       32896     
_________________________________________________________________
norm_7 (BatchNormalization)  (None, 36, 36, 128)       512       
_________________________________________________________________
relu_7 (LeakyReLU)           (None, 36, 36, 128)       0         
_________________________________________________________________
conv_8 (Conv2D)              (None, 36, 36, 256)       295168    
_________________________________________________________________
norm_8 (BatchNormalization)  (None, 36, 36, 256)       1024      
_________________________________________________________________
relu_8 (LeakyReLU)           (None, 36, 36, 256)       0         
_________________________________________________________________
pool_4 (MaxPooling2D)        (None, 18, 18, 256)       0         
_________________________________________________________________
conv_9 (Conv2D)              (None, 18, 18, 512)       1180160   
_________________________________________________________________
norm_9 (BatchNormalization)  (None, 18, 18, 512)       2048      
_________________________________________________________________
relu_9 (LeakyReLU)           (None, 18, 18, 512)       0         
_________________________________________________________________
conv_10 (Conv2D)             (None, 18, 18, 256)       131328    
_________________________________________________________________
norm_10 (BatchNormalization) (None, 18, 18, 256)       1024      
_________________________________________________________________
relu_10 (LeakyReLU)          (None, 18, 18, 256)       0         
_________________________________________________________________
conv_11 (Conv2D)             (None, 18, 18, 512)       1180160   
_________________________________________________________________
norm_11 (BatchNormalization) (None, 18, 18, 512)       2048      
_________________________________________________________________
relu_11 (LeakyReLU)          (None, 18, 18, 512)       0         
_________________________________________________________________
conv_12 (Conv2D)             (None, 18, 18, 256)       131328    
_________________________________________________________________
norm_12 (BatchNormalization) (None, 18, 18, 256)       1024      
_________________________________________________________________
relu_12 (LeakyReLU)          (None, 18, 18, 256)       0         
_________________________________________________________________
conv_13 (Conv2D)             (None, 18, 18, 512)       1180160   
_________________________________________________________________
norm_13 (BatchNormalization) (None, 18, 18, 512)       2048      
_________________________________________________________________
relu_13 (LeakyReLU)          (None, 18, 18, 512)       0         
_________________________________________________________________
pool_5 (MaxPooling2D)        (None, 9, 9, 512)         0         
_________________________________________________________________
conv_14 (Conv2D)             (None, 9, 9, 1024)        4719616   
_________________________________________________________________
norm_14 (BatchNormalization) (None, 9, 9, 1024)        4096      
_________________________________________________________________
relu_14 (LeakyReLU)          (None, 9, 9, 1024)        0         
_________________________________________________________________
conv_15 (Conv2D)             (None, 9, 9, 1024)        9438208   
_________________________________________________________________
norm_15 (BatchNormalization) (None, 9, 9, 1024)        4096      
_________________________________________________________________
relu_15 (LeakyReLU)          (None, 9, 9, 1024)        0         
_________________________________________________________________
conv_16 (Conv2D)             (None, 9, 9, 5)           5125      
_________________________________________________________________
reshape_1 (Reshape)          (None, 9, 9, 5)           0         
=================================================================
Total params: 18,784,709
Trainable params: 18,774,405
Non-trainable params: 10,304
_________________________________________________________________
+----------+--------------------+----------------+---------------+--------------------+--------------------+---------------+
|  Epoch   |      f1_score      |      iou       |      loss     |     precision      |       recall       |    val_loss   |
+----------+--------------------+----------------+---------------+--------------------+--------------------+---------------+
| Epoch 1  |        nan         |      nan       |  28.17065445  |        nan         |        0.0         | 58.9835859729 |
| Epoch 2  | 0.5996275605214152 | 0.660698749513 | 12.5298758577 | 0.6518218623481782 | 0.5551724137931034 | 9.54204611624 |
| Epoch 3  | 0.7091932457786116 | 0.684792489483 | 9.53885293128 | 0.7777777777777778 | 0.6517241379310345 | 7.76859337284 |
| Epoch 4  | 0.6491803278688525 | 0.690851184875 | 7.83903065921 |      0.61875       | 0.6827586206896552 | 8.63785123825 |
| Epoch 5  | 0.7306967984934087 |  0.6953364074  | 6.62467643757 | 0.8049792531120332 | 0.6689655172413793 | 7.56222646467 |
| Epoch 6  | 0.693877551020408  | 0.698514189036 | 5.79592887366 | 0.751004016064257  | 0.6448275862068965 | 7.32404715015 |
| Epoch 7  | 0.7213740458015266 | 0.68307849881  | 5.22516809352 | 0.8076923076923077 | 0.6517241379310345 | 7.68743138929 |
| Epoch 8  | 0.7211367673179396 | 0.704112476864 | 4.74479943781 | 0.7435897435897436 |        0.7         | 7.59362734518 |
| Epoch 9  | 0.7190569744597249 | 0.698016025097 | 4.29675795724 | 0.8356164383561644 | 0.6310344827586207 | 7.64223970905 |
| Epoch 10 | 0.6829268292682927 | 0.706517087677 | 3.97109000217 | 0.7489711934156379 | 0.6275862068965518 | 8.21485770133 |
+----------+--------------------+----------------+---------------+--------------------+--------------------+---------------+
_________________________________________________________________
+------------------------------------+-----------------------+---------+-----------------------+--------------------+
|             Optimizer              |         decay         | epsilon |           lr          |        rho         |
+------------------------------------+-----------------------+---------+-----------------------+--------------------+
| <class 'keras.optimizers.RMSprop'> | 0.0005000000237487257 |  1e-08  | 0.0010000000474974513 | 0.8999999761581421 |
+------------------------------------+-----------------------+---------+-----------------------+--------------------+
_________________________________________________________________
+------------+
| Batch Size |
+------------+
|     16     |
+------------+
_________________________________________________________________
+--------------------+---------------+----------------+--------------------+--------------------+--------------------+
|      Metrics       |      Loss     |      IoU       |     Precision      |       Recall       |      F1 Score      |
+--------------------+---------------+----------------+--------------------+--------------------+--------------------+
|   Train Metrics    | 6.91186633754 | 0.829608860454 | 0.9521276595744681 | 0.8878538591821921 | 0.918868160761237  |
| Validation Metrics | 16.2953481982 | 0.706517087677 | 0.7489711934156379 | 0.6275862068965518 | 0.6829268292682927 |
|    Test Metrics    | 20.2783631971 | 0.702114392236 | 0.7450199203187251 | 0.6051779935275081 | 0.6678571428571429 |
+--------------------+---------------+----------------+--------------------+--------------------+--------------------+
_________________________________________________________________
Time:
    Train Time              : 1:12:59.978807
    Dataset Loading Time    : 0:00:42.317179
    Metrics Evaluation Time : 1:45:39.251945
_________________________________________________________________
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         (None, 288, 288, 1)       0         
_________________________________________________________________
conv_1 (Conv2D)              (None, 288, 288, 32)      320       
_________________________________________________________________
norm_1 (BatchNormalization)  (None, 288, 288, 32)      128       
_________________________________________________________________
relu_1 (LeakyReLU)           (None, 288, 288, 32)      0         
_________________________________________________________________
pool_1 (MaxPooling2D)        (None, 144, 144, 32)      0         
_________________________________________________________________
conv_2 (Conv2D)              (None, 144, 144, 64)      18496     
_________________________________________________________________
norm_2 (BatchNormalization)  (None, 144, 144, 64)      256       
_________________________________________________________________
relu_2 (LeakyReLU)           (None, 144, 144, 64)      0         
_________________________________________________________________
pool_2 (MaxPooling2D)        (None, 72, 72, 64)        0         
_________________________________________________________________
conv_3 (Conv2D)              (None, 72, 72, 128)       73856     
_________________________________________________________________
norm_3 (BatchNormalization)  (None, 72, 72, 128)       512       
_________________________________________________________________
relu_3 (LeakyReLU)           (None, 72, 72, 128)       0         
_________________________________________________________________
conv_4 (Conv2D)              (None, 72, 72, 64)        8256      
_________________________________________________________________
norm_4 (BatchNormalization)  (None, 72, 72, 64)        256       
_________________________________________________________________
relu_4 (LeakyReLU)           (None, 72, 72, 64)        0         
_________________________________________________________________
conv_5 (Conv2D)              (None, 72, 72, 128)       73856     
_________________________________________________________________
norm_5 (BatchNormalization)  (None, 72, 72, 128)       512       
_________________________________________________________________
relu_5 (LeakyReLU)           (None, 72, 72, 128)       0         
_________________________________________________________________
pool_3 (MaxPooling2D)        (None, 36, 36, 128)       0         
_________________________________________________________________
conv_6 (Conv2D)              (None, 36, 36, 256)       295168    
_________________________________________________________________
norm_6 (BatchNormalization)  (None, 36, 36, 256)       1024      
_________________________________________________________________
relu_6 (LeakyReLU)           (None, 36, 36, 256)       0         
_________________________________________________________________
conv_7 (Conv2D)              (None, 36, 36, 128)       32896     
_________________________________________________________________
norm_7 (BatchNormalization)  (None, 36, 36, 128)       512       
_________________________________________________________________
relu_7 (LeakyReLU)           (None, 36, 36, 128)       0         
_________________________________________________________________
conv_8 (Conv2D)              (None, 36, 36, 256)       295168    
_________________________________________________________________
norm_8 (BatchNormalization)  (None, 36, 36, 256)       1024      
_________________________________________________________________
relu_8 (LeakyReLU)           (None, 36, 36, 256)       0         
_________________________________________________________________
pool_4 (MaxPooling2D)        (None, 18, 18, 256)       0         
_________________________________________________________________
conv_9 (Conv2D)              (None, 18, 18, 512)       1180160   
_________________________________________________________________
norm_9 (BatchNormalization)  (None, 18, 18, 512)       2048      
_________________________________________________________________
relu_9 (LeakyReLU)           (None, 18, 18, 512)       0         
_________________________________________________________________
conv_10 (Conv2D)             (None, 18, 18, 256)       131328    
_________________________________________________________________
norm_10 (BatchNormalization) (None, 18, 18, 256)       1024      
_________________________________________________________________
relu_10 (LeakyReLU)          (None, 18, 18, 256)       0         
_________________________________________________________________
conv_11 (Conv2D)             (None, 18, 18, 512)       1180160   
_________________________________________________________________
norm_11 (BatchNormalization) (None, 18, 18, 512)       2048      
_________________________________________________________________
relu_11 (LeakyReLU)          (None, 18, 18, 512)       0         
_________________________________________________________________
conv_12 (Conv2D)             (None, 18, 18, 256)       131328    
_________________________________________________________________
norm_12 (BatchNormalization) (None, 18, 18, 256)       1024      
_________________________________________________________________
relu_12 (LeakyReLU)          (None, 18, 18, 256)       0         
_________________________________________________________________
conv_13 (Conv2D)             (None, 18, 18, 512)       1180160   
_________________________________________________________________
norm_13 (BatchNormalization) (None, 18, 18, 512)       2048      
_________________________________________________________________
relu_13 (LeakyReLU)          (None, 18, 18, 512)       0         
_________________________________________________________________
pool_5 (MaxPooling2D)        (None, 9, 9, 512)         0         
_________________________________________________________________
conv_14 (Conv2D)             (None, 9, 9, 1024)        4719616   
_________________________________________________________________
norm_14 (BatchNormalization) (None, 9, 9, 1024)        4096      
_________________________________________________________________
relu_14 (LeakyReLU)          (None, 9, 9, 1024)        0         
_________________________________________________________________
conv_15 (Conv2D)             (None, 9, 9, 1024)        9438208   
_________________________________________________________________
norm_15 (BatchNormalization) (None, 9, 9, 1024)        4096      
_________________________________________________________________
relu_15 (LeakyReLU)          (None, 9, 9, 1024)        0         
_________________________________________________________________
conv_16 (Conv2D)             (None, 9, 9, 5)           5125      
_________________________________________________________________
reshape_1 (Reshape)          (None, 9, 9, 5)           0         
=================================================================
Total params: 18,784,709
Trainable params: 18,774,405
Non-trainable params: 10,304
_________________________________________________________________
+----------+--------------------+----------------+---------------+--------------------+--------------------+---------------+
|  Epoch   |      f1_score      |      iou       |      loss     |     precision      |       recall       |    val_loss   |
+----------+--------------------+----------------+---------------+--------------------+--------------------+---------------+
| Epoch 1  |        nan         |      nan       | 28.1739075823 |        0.0         |        0.0         | 58.2605771711 |
| Epoch 2  | 0.663265306122449  | 0.691986282904 | 15.8420924552 | 0.6543624161073825 | 0.6724137931034483 | 8.48360423119 |
| Epoch 3  | 0.6859205776173286 | 0.694498906198 | 11.8873209369 | 0.7196969696969697 | 0.6551724137931034 | 8.68358684355 |
| Epoch 4  | 0.7518248175182483 | 0.691918373691 |  9.534763784  | 0.7984496124031008 | 0.7103448275862069 | 7.15490064313 |
| Epoch 5  | 0.6280701754385964 | 0.682902562134 | 7.88403599885 | 0.6392857142857142 | 0.6172413793103448 | 8.71069239032 |
| Epoch 6  | 0.7137809187279152 | 0.683383144886 | 6.65605379985 | 0.7318840579710145 | 0.696551724137931  | 8.03639050453 |
| Epoch 7  | 0.6666666666666667 | 0.700460838626 | 5.95019626235 | 0.6861313868613139 | 0.6482758620689655 |  8.4892873764 |
| Epoch 8  | 0.6867256637168142 | 0.684022357582 |  5.288873321  | 0.7054545454545454 | 0.6689655172413793 |  8.6284360578 |
| Epoch 9  | 0.661596958174905  | 0.688703205899 | 4.82551020248 | 0.7372881355932204 |        0.6         | 8.45560229209 |
| Epoch 10 | 0.6571428571428571 | 0.699548329778 |  4.4020556146 |       0.805        | 0.5551724137931034 | 9.38947859118 |
| Epoch 11 | 0.6441351888667993 | 0.680739868357 | 4.07097564384 | 0.7605633802816901 | 0.5586206896551724 | 9.80465745926 |
| Epoch 12 | 0.6254545454545454 | 0.684536989229 | 3.85420781742 | 0.6615384615384615 | 0.593103448275862  | 9.80814242363 |
| Epoch 13 | 0.6412825651302605 | 0.689075897799 | 3.66929388026 | 0.7655502392344498 | 0.5517241379310345 |  9.5825898878 |
| Epoch 14 | 0.6605504587155964 | 0.697618170754 | 3.45133996181 | 0.7058823529411765 | 0.6206896551724138 | 9.10361725284 |
| Epoch 15 | 0.6539792387543253 | 0.692851726434 | 3.32022058032 |      0.65625       | 0.6517241379310345 | 9.41520746293 |
| Epoch 16 | 0.6379928315412187 | 0.693100767996 | 3.15245884088 | 0.664179104477612  | 0.6137931034482759 |  9.5189834564 |
| Epoch 17 | 0.680373831775701  | 0.691455104315 | 2.98684855875 | 0.7428571428571429 | 0.6275862068965518 | 9.01773014376 |
| Epoch 18 | 0.6857142857142856 | 0.705348503557 | 2.89652741258 | 0.7659574468085106 | 0.6206896551724138 | 8.96689321149 |
| Epoch 19 | 0.6766917293233082 | 0.689598226209 | 2.78092675318 | 0.743801652892562  | 0.6206896551724138 | 9.08294231661 |
| Epoch 20 | 0.6415770609318997 | 0.681037231987 | 2.66727979781 | 0.667910447761194  | 0.6172413793103448 | 9.79962002847 |
| Epoch 21 | 0.6900369003690037 | 0.69698811182  | 2.60077618021 | 0.7420634920634921 | 0.6448275862068965 | 8.63382661727 |
| Epoch 22 | 0.6110056925996206 | 0.69391505371  | 2.52166379188 | 0.679324894514768  | 0.5551724137931034 | 10.5333754478 |
| Epoch 23 | 0.6595744680851063 | 0.698225912378 | 2.47935821278 | 0.6788321167883211 | 0.6413793103448275 | 9.54525852203 |
| Epoch 24 | 0.6015037593984963 | 0.697678401094 | 2.40095967457 | 0.6611570247933884 | 0.5517241379310345 | 10.9909582753 |
| Epoch 25 | 0.668918918918919  | 0.689785176095 | 2.34274604151 | 0.6556291390728477 | 0.6827586206896552 | 9.25992484247 |
| Epoch 26 | 0.6805293005671078 | 0.696370303303 | 2.26709918815 | 0.7531380753138075 | 0.6206896551724138 | 9.15528779645 |
| Epoch 27 | 0.6268174474959612 | 0.684075075114 | 2.27525463937 | 0.5896656534954408 | 0.6689655172413793 | 10.6769286433 |
| Epoch 28 | 0.6469565217391304 | 0.686725639643 | 2.19081357785 | 0.6526315789473685 | 0.6413793103448275 | 10.4606655951 |
| Epoch 29 | 0.6567717996289425 | 0.691940311378 | 2.15040350186 | 0.7108433734939759 | 0.6103448275862069 | 9.71269089176 |
| Epoch 30 | 0.6515679442508711 | 0.689901998901 | 2.09587306716 | 0.6584507042253521 | 0.6448275862068965 | 10.5427248555 |
+----------+--------------------+----------------+---------------+--------------------+--------------------+---------------+
_________________________________________________________________
+------------------------------------+-----------------------+---------+-----------------------+--------------------+
|             Optimizer              |         decay         | epsilon |           lr          |        rho         |
+------------------------------------+-----------------------+---------+-----------------------+--------------------+
| <class 'keras.optimizers.RMSprop'> | 0.0005000000237487257 |  1e-08  | 0.0010000000474974513 | 0.8999999761581421 |
+------------------------------------+-----------------------+---------+-----------------------+--------------------+
_________________________________________________________________
+------------+
| Batch Size |
+------------+
|     16     |
+------------+
_________________________________________________________________
+--------------------+---------------+----------------+--------------------+--------------------+--------------------+
|      Metrics       |      Loss     |      IoU       |     Precision      |       Recall       |      F1 Score      |
+--------------------+---------------+----------------+--------------------+--------------------+--------------------+
|   Train Metrics    | 4.04352600126 | 0.877233172807 | 0.9783687492047334 | 0.9301959835470602 | 0.9536744186046512 |
| Validation Metrics | 20.9853124311 | 0.689901998901 | 0.6584507042253521 | 0.6448275862068965 | 0.6515679442508711 |
|    Test Metrics    | 21.1337164602 | 0.689363337636 | 0.6363636363636364 | 0.5889967637540453 | 0.6117647058823529 |
+--------------------+---------------+----------------+--------------------+--------------------+--------------------+
_________________________________________________________________
Time:
    Train Time              : 4:42:55.346397
    Dataset Loading Time    : 0:00:46.128755
    Metrics Evaluation Time : 3:20:35.099278
_________________________________________________________________
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         (None, 288, 288, 1)       0         
_________________________________________________________________
conv_1 (Conv2D)              (None, 288, 288, 32)      320       
_________________________________________________________________
norm_1 (BatchNormalization)  (None, 288, 288, 32)      128       
_________________________________________________________________
relu_1 (LeakyReLU)           (None, 288, 288, 32)      0         
_________________________________________________________________
pool_1 (MaxPooling2D)        (None, 144, 144, 32)      0         
_________________________________________________________________
conv_2 (Conv2D)              (None, 144, 144, 64)      18496     
_________________________________________________________________
norm_2 (BatchNormalization)  (None, 144, 144, 64)      256       
_________________________________________________________________
relu_2 (LeakyReLU)           (None, 144, 144, 64)      0         
_________________________________________________________________
pool_2 (MaxPooling2D)        (None, 72, 72, 64)        0         
_________________________________________________________________
conv_3 (Conv2D)              (None, 72, 72, 128)       73856     
_________________________________________________________________
norm_3 (BatchNormalization)  (None, 72, 72, 128)       512       
_________________________________________________________________
relu_3 (LeakyReLU)           (None, 72, 72, 128)       0         
_________________________________________________________________
conv_4 (Conv2D)              (None, 72, 72, 64)        8256      
_________________________________________________________________
norm_4 (BatchNormalization)  (None, 72, 72, 64)        256       
_________________________________________________________________
relu_4 (LeakyReLU)           (None, 72, 72, 64)        0         
_________________________________________________________________
conv_5 (Conv2D)              (None, 72, 72, 128)       73856     
_________________________________________________________________
norm_5 (BatchNormalization)  (None, 72, 72, 128)       512       
_________________________________________________________________
relu_5 (LeakyReLU)           (None, 72, 72, 128)       0         
_________________________________________________________________
pool_3 (MaxPooling2D)        (None, 36, 36, 128)       0         
_________________________________________________________________
conv_6 (Conv2D)              (None, 36, 36, 256)       295168    
_________________________________________________________________
norm_6 (BatchNormalization)  (None, 36, 36, 256)       1024      
_________________________________________________________________
relu_6 (LeakyReLU)           (None, 36, 36, 256)       0         
_________________________________________________________________
conv_7 (Conv2D)              (None, 36, 36, 128)       32896     
_________________________________________________________________
norm_7 (BatchNormalization)  (None, 36, 36, 128)       512       
_________________________________________________________________
relu_7 (LeakyReLU)           (None, 36, 36, 128)       0         
_________________________________________________________________
conv_8 (Conv2D)              (None, 36, 36, 256)       295168    
_________________________________________________________________
norm_8 (BatchNormalization)  (None, 36, 36, 256)       1024      
_________________________________________________________________
relu_8 (LeakyReLU)           (None, 36, 36, 256)       0         
_________________________________________________________________
pool_4 (MaxPooling2D)        (None, 18, 18, 256)       0         
_________________________________________________________________
conv_9 (Conv2D)              (None, 18, 18, 512)       1180160   
_________________________________________________________________
norm_9 (BatchNormalization)  (None, 18, 18, 512)       2048      
_________________________________________________________________
relu_9 (LeakyReLU)           (None, 18, 18, 512)       0         
_________________________________________________________________
conv_10 (Conv2D)             (None, 18, 18, 256)       131328    
_________________________________________________________________
norm_10 (BatchNormalization) (None, 18, 18, 256)       1024      
_________________________________________________________________
relu_10 (LeakyReLU)          (None, 18, 18, 256)       0         
_________________________________________________________________
conv_11 (Conv2D)             (None, 18, 18, 512)       1180160   
_________________________________________________________________
norm_11 (BatchNormalization) (None, 18, 18, 512)       2048      
_________________________________________________________________
relu_11 (LeakyReLU)          (None, 18, 18, 512)       0         
_________________________________________________________________
conv_12 (Conv2D)             (None, 18, 18, 256)       131328    
_________________________________________________________________
norm_12 (BatchNormalization) (None, 18, 18, 256)       1024      
_________________________________________________________________
relu_12 (LeakyReLU)          (None, 18, 18, 256)       0         
_________________________________________________________________
conv_13 (Conv2D)             (None, 18, 18, 512)       1180160   
_________________________________________________________________
norm_13 (BatchNormalization) (None, 18, 18, 512)       2048      
_________________________________________________________________
relu_13 (LeakyReLU)          (None, 18, 18, 512)       0         
_________________________________________________________________
pool_5 (MaxPooling2D)        (None, 9, 9, 512)         0         
_________________________________________________________________
conv_14 (Conv2D)             (None, 9, 9, 1024)        4719616   
_________________________________________________________________
norm_14 (BatchNormalization) (None, 9, 9, 1024)        4096      
_________________________________________________________________
relu_14 (LeakyReLU)          (None, 9, 9, 1024)        0         
_________________________________________________________________
dropout_1 (Dropout)          (None, 9, 9, 1024)        0         
_________________________________________________________________
conv_15 (Conv2D)             (None, 9, 9, 1024)        9438208   
_________________________________________________________________
norm_15 (BatchNormalization) (None, 9, 9, 1024)        4096      
_________________________________________________________________
relu_15 (LeakyReLU)          (None, 9, 9, 1024)        0         
_________________________________________________________________
dropout_2 (Dropout)          (None, 9, 9, 1024)        0         
_________________________________________________________________
conv_16 (Conv2D)             (None, 9, 9, 5)           5125      
_________________________________________________________________
reshape_1 (Reshape)          (None, 9, 9, 5)           0         
=================================================================
Total params: 18,784,709
Trainable params: 18,774,405
Non-trainable params: 10,304
_________________________________________________________________
+---------+---------------------+----------------+---------------+---------------------+---------------------+---------------+
|  Epoch  |       f1_score      |      iou       |      loss     |      precision      |        recall       |    val_loss   |
+---------+---------------------+----------------+---------------+---------------------+---------------------+---------------+
| Epoch 1 | 0.14869888475836432 | 0.573001889563 | 28.7996520214 | 0.16129032258064516 | 0.13793103448275862 | 11.5787592857 |
| Epoch 2 |  0.5956521739130436 | 0.671888767023 | 14.3702862047 |  0.8058823529411765 |  0.4724137931034483 |  8.6315357762 |
| Epoch 3 |  0.6874999999999999 | 0.66304896157  | 11.6832093572 |  0.7362204724409449 |  0.6448275862068965 | 8.48623609543 |
| Epoch 4 |  0.5813449023861171 | 0.685087885577 | 9.89720682521 |  0.783625730994152  | 0.46206896551724136 | 10.2150129349 |
| Epoch 5 |  0.5316455696202532 | 0.64955045968  | 8.66885061337 |  0.6847826086956522 | 0.43448275862068964 | 9.80026243579 |
+---------+---------------------+----------------+---------------+---------------------+---------------------+---------------+
_________________________________________________________________
+------------------------------------+-----------------------+---------+-----------------------+--------------------+
|             Optimizer              |         decay         | epsilon |           lr          |        rho         |
+------------------------------------+-----------------------+---------+-----------------------+--------------------+
| <class 'keras.optimizers.RMSprop'> | 0.0005000000237487257 |  1e-08  | 0.0010000000474974513 | 0.8999999761581421 |
+------------------------------------+-----------------------+---------+-----------------------+--------------------+
_________________________________________________________________
+------------+
| Batch Size |
+------------+
|     16     |
+------------+
_________________________________________________________________
+--------------------+---------------+----------------+--------------------+---------------------+--------------------+
|      Metrics       |      Loss     |      IoU       |     Precision      |        Recall       |      F1 Score      |
+--------------------+---------------+----------------+--------------------+---------------------+--------------------+
|   Train Metrics    | 20.1256780225 | 0.746882435643 | 0.8994560449201614 |  0.6201306556980402 | 0.7341210168277836 |
| Validation Metrics | 19.4548416138 | 0.64955045968  | 0.6847826086956522 | 0.43448275862068964 | 0.5316455696202532 |
|    Test Metrics    | 22.1924001632 | 0.649875726643 | 0.6994535519125683 | 0.41423948220064727 | 0.5203252032520325 |
+--------------------+---------------+----------------+--------------------+---------------------+--------------------+
_________________________________________________________________
Time:
    Train Time              : 0:34:57.396577
    Dataset Loading Time    : 0:00:42.674278
    Metrics Evaluation Time : 1:23:20.327135
_________________________________________________________________
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         (None, 288, 288, 1)       0         
_________________________________________________________________
conv_1 (Conv2D)              (None, 288, 288, 32)      320       
_________________________________________________________________
norm_1 (BatchNormalization)  (None, 288, 288, 32)      128       
_________________________________________________________________
relu_1 (LeakyReLU)           (None, 288, 288, 32)      0         
_________________________________________________________________
pool_1 (MaxPooling2D)        (None, 144, 144, 32)      0         
_________________________________________________________________
conv_2 (Conv2D)              (None, 144, 144, 64)      18496     
_________________________________________________________________
norm_2 (BatchNormalization)  (None, 144, 144, 64)      256       
_________________________________________________________________
relu_2 (LeakyReLU)           (None, 144, 144, 64)      0         
_________________________________________________________________
pool_2 (MaxPooling2D)        (None, 72, 72, 64)        0         
_________________________________________________________________
conv_3 (Conv2D)              (None, 72, 72, 128)       73856     
_________________________________________________________________
norm_3 (BatchNormalization)  (None, 72, 72, 128)       512       
_________________________________________________________________
relu_3 (LeakyReLU)           (None, 72, 72, 128)       0         
_________________________________________________________________
conv_4 (Conv2D)              (None, 72, 72, 64)        8256      
_________________________________________________________________
norm_4 (BatchNormalization)  (None, 72, 72, 64)        256       
_________________________________________________________________
relu_4 (LeakyReLU)           (None, 72, 72, 64)        0         
_________________________________________________________________
conv_5 (Conv2D)              (None, 72, 72, 128)       73856     
_________________________________________________________________
norm_5 (BatchNormalization)  (None, 72, 72, 128)       512       
_________________________________________________________________
relu_5 (LeakyReLU)           (None, 72, 72, 128)       0         
_________________________________________________________________
pool_3 (MaxPooling2D)        (None, 36, 36, 128)       0         
_________________________________________________________________
conv_6 (Conv2D)              (None, 36, 36, 256)       295168    
_________________________________________________________________
norm_6 (BatchNormalization)  (None, 36, 36, 256)       1024      
_________________________________________________________________
relu_6 (LeakyReLU)           (None, 36, 36, 256)       0         
_________________________________________________________________
conv_7 (Conv2D)              (None, 36, 36, 128)       32896     
_________________________________________________________________
norm_7 (BatchNormalization)  (None, 36, 36, 128)       512       
_________________________________________________________________
relu_7 (LeakyReLU)           (None, 36, 36, 128)       0         
_________________________________________________________________
conv_8 (Conv2D)              (None, 36, 36, 256)       295168    
_________________________________________________________________
norm_8 (BatchNormalization)  (None, 36, 36, 256)       1024      
_________________________________________________________________
relu_8 (LeakyReLU)           (None, 36, 36, 256)       0         
_________________________________________________________________
pool_4 (MaxPooling2D)        (None, 18, 18, 256)       0         
_________________________________________________________________
conv_9 (Conv2D)              (None, 18, 18, 512)       1180160   
_________________________________________________________________
norm_9 (BatchNormalization)  (None, 18, 18, 512)       2048      
_________________________________________________________________
relu_9 (LeakyReLU)           (None, 18, 18, 512)       0         
_________________________________________________________________
conv_10 (Conv2D)             (None, 18, 18, 256)       131328    
_________________________________________________________________
norm_10 (BatchNormalization) (None, 18, 18, 256)       1024      
_________________________________________________________________
relu_10 (LeakyReLU)          (None, 18, 18, 256)       0         
_________________________________________________________________
conv_11 (Conv2D)             (None, 18, 18, 512)       1180160   
_________________________________________________________________
norm_11 (BatchNormalization) (None, 18, 18, 512)       2048      
_________________________________________________________________
relu_11 (LeakyReLU)          (None, 18, 18, 512)       0         
_________________________________________________________________
conv_12 (Conv2D)             (None, 18, 18, 256)       131328    
_________________________________________________________________
norm_12 (BatchNormalization) (None, 18, 18, 256)       1024      
_________________________________________________________________
relu_12 (LeakyReLU)          (None, 18, 18, 256)       0         
_________________________________________________________________
conv_13 (Conv2D)             (None, 18, 18, 512)       1180160   
_________________________________________________________________
norm_13 (BatchNormalization) (None, 18, 18, 512)       2048      
_________________________________________________________________
relu_13 (LeakyReLU)          (None, 18, 18, 512)       0         
_________________________________________________________________
pool_5 (MaxPooling2D)        (None, 9, 9, 512)         0         
_________________________________________________________________
conv_14 (Conv2D)             (None, 9, 9, 1024)        4719616   
_________________________________________________________________
norm_14 (BatchNormalization) (None, 9, 9, 1024)        4096      
_________________________________________________________________
relu_14 (LeakyReLU)          (None, 9, 9, 1024)        0         
_________________________________________________________________
dropout_1 (Dropout)          (None, 9, 9, 1024)        0         
_________________________________________________________________
conv_15 (Conv2D)             (None, 9, 9, 1024)        9438208   
_________________________________________________________________
norm_15 (BatchNormalization) (None, 9, 9, 1024)        4096      
_________________________________________________________________
relu_15 (LeakyReLU)          (None, 9, 9, 1024)        0         
_________________________________________________________________
dropout_2 (Dropout)          (None, 9, 9, 1024)        0         
_________________________________________________________________
conv_16 (Conv2D)             (None, 9, 9, 5)           5125      
_________________________________________________________________
reshape_1 (Reshape)          (None, 9, 9, 5)           0         
=================================================================
Total params: 18,784,709
Trainable params: 18,774,405
Non-trainable params: 10,304
_________________________________________________________________
+----------+---------------------+----------------+---------------+---------------------+---------------------+---------------+
|  Epoch   |       f1_score      |      iou       |      loss     |      precision      |        recall       |    val_loss   |
+----------+---------------------+----------------+---------------+---------------------+---------------------+---------------+
| Epoch 1  | 0.07804878048780488 | 0.560483917593 | 28.2639294719 | 0.13333333333333333 | 0.05517241379310345 | 13.0641715757 |
| Epoch 2  |  0.6475095785440613 | 0.685833093936 | 14.2289614101 |  0.728448275862069  |  0.5827586206896552 |  8.9266271745 |
| Epoch 3  |  0.6703296703296704 | 0.701518345478 | 11.0775001184 |      0.71484375     |  0.6310344827586207 | 8.84117614069 |
| Epoch 4  |  0.6226415094339622 | 0.668909245253 | 9.05577676818 |        0.6875       |  0.5689655172413793 | 9.45588350296 |
| Epoch 5  |  0.5959780621572213 | 0.697391868987 | 7.60078108804 |  0.6342412451361867 |  0.5620689655172414 | 11.9531429045 |
| Epoch 6  |  0.6463878326996197 | 0.706535031949 | 6.59249178273 |  0.7203389830508474 |  0.5862068965517241 | 10.0151726969 |
| Epoch 7  |  0.631578947368421  | 0.67499561595  |  5.8452574709 |  0.6220735785953178 |  0.6413793103448275 | 9.49159037682 |
| Epoch 8  |  0.6617375231053605 | 0.699840601797 | 5.36197666304 |  0.7131474103585658 |  0.6172413793103448 | 8.96590057496 |
| Epoch 9  |  0.6000000000000001 | 0.690256996826 | 4.84078572709 |  0.6954545454545454 |  0.5275862068965518 |  10.168007343 |
| Epoch 10 |  0.6213592233009708 | 0.690594787255 | 4.41904336582 |  0.5853658536585366 |  0.6620689655172414 |  10.715614165 |
| Epoch 11 |  0.6573426573426573 | 0.686097367161 | 4.04538770117 |  0.6666666666666666 |  0.6482758620689655 | 10.0593384466 |
| Epoch 12 |  0.6729678638941399 | 0.699919275685 | 3.80039244381 |  0.7447698744769874 |  0.6137931034482759 | 9.58148547142 |
| Epoch 13 |  0.6631205673758864 | 0.699914507756 | 3.56605585571 |  0.6824817518248175 |  0.6448275862068965 | 10.0870887541 |
| Epoch 14 |  0.5968379446640316 | 0.686607391755 |  3.3551772845 |  0.6990740740740741 |  0.5206896551724138 | 11.4477376784 |
| Epoch 15 |  0.6081632653061224 | 0.69294766781  | 3.10487320087 |        0.745        |  0.5137931034482759 | 10.7064222213 |
| Epoch 16 |  0.667953667953668  | 0.694017855306 | 2.90964382892 |  0.7587719298245614 |  0.596551724137931  | 10.1721800989 |
| Epoch 17 |  0.6592592592592593 | 0.702427354941 | 2.76053926215 |        0.712        |  0.6137931034482759 |  9.7844426555 |
| Epoch 18 |  0.663003663003663  | 0.693080905689 | 2.61441624296 |      0.70703125     |  0.6241379310344828 |  10.348762666 |
| Epoch 19 |  0.6642335766423358 | 0.700283152431 | 2.48011354889 |  0.7054263565891473 |  0.6275862068965518 | 9.41373255945 |
| Epoch 20 |  0.6270270270270271 | 0.696448117364 |  2.4126554528 |  0.6566037735849056 |         0.6         | 10.1132792196 |
| Epoch 21 |  0.6135458167330676 | 0.703547146863 | 2.19384738206 |  0.7264150943396226 |  0.5310344827586206 | 11.1090277703 |
| Epoch 22 |  0.6229508196721312 | 0.684655274908 | 2.19763098691 |  0.6602316602316602 |  0.5896551724137931 | 11.0931802873 |
| Epoch 23 |  0.6414342629482072 | 0.690805668345 | 2.10445331066 |  0.7594339622641509 |  0.5551724137931034 | 10.2864090397 |
| Epoch 24 |  0.6487523992322457 | 0.689020721011 | 1.97839777392 |  0.7316017316017316 |  0.5827586206896552 | 10.2334122504 |
| Epoch 25 |  0.659047619047619  | 0.693185321247 |  1.9091277325 |  0.7361702127659574 |  0.596551724137931  | 10.5401454279 |
| Epoch 26 |  0.6351606805293006 | 0.688847031801 | 1.81349431509 |  0.702928870292887  |  0.5793103448275863 | 10.4871815866 |
| Epoch 27 |  0.634508348794063  | 0.686032693741 | 1.69798288457 |  0.6867469879518072 |  0.5896551724137931 | 10.7945529415 |
| Epoch 28 |  0.6825688073394496 | 0.697020673297 | 1.67857962363 |  0.7294117647058823 |  0.6413793103448275 | 10.4325761641 |
| Epoch 29 |  0.6718446601941747 | 0.70004209973  | 1.56184604503 |  0.7688888888888888 |  0.596551724137931  | 9.76088317748 |
| Epoch 30 |  0.6423611111111112 | 0.696981408284 | 1.48678344072 |  0.6468531468531469 |  0.6379310344827587 | 11.0082062137 |
+----------+---------------------+----------------+---------------+---------------------+---------------------+---------------+
_________________________________________________________________
+---------------------------------+--------------------+--------------------+-----------------------+---------+-----------------------+
|            Optimizer            |       beta_1       |       beta_2       |         decay         | epsilon |           lr          |
+---------------------------------+--------------------+--------------------+-----------------------+---------+-----------------------+
| <class 'keras.optimizers.Adam'> | 0.8999999761581421 | 0.9990000128746033 | 0.0005000000237487257 |  1e-08  | 0.0010000000474974513 |
+---------------------------------+--------------------+--------------------+-----------------------+---------+-----------------------+
_________________________________________________________________
+------------+
| Batch Size |
+------------+
|     16     |
+------------+
_________________________________________________________________
+--------------------+---------------+----------------+--------------------+--------------------+--------------------+
|      Metrics       |      Loss     |      IoU       |     Precision      |       Recall       |      F1 Score      |
+--------------------+---------------+----------------+--------------------+--------------------+--------------------+
|   Train Metrics    | 2.71986332659 | 0.826281088601 | 0.9614210719081919 | 0.952697798209533  | 0.957039557635049  |
| Validation Metrics | 21.8614359825 | 0.696981408284 | 0.6468531468531469 | 0.6379310344827587 | 0.6423611111111112 |
|    Test Metrics    | 24.2928456952 | 0.684582923958 | 0.6341463414634146 | 0.5889967637540453 | 0.610738255033557  |
+--------------------+---------------+----------------+--------------------+--------------------+--------------------+
_________________________________________________________________
Time:
    Train Time              : 4:47:28.851441
    Dataset Loading Time    : 0:00:38.931006
    Metrics Evaluation Time : 3:27:50.618018
_________________________________________________________________
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         (None, 288, 288, 1)       0         
_________________________________________________________________
conv_1 (Conv2D)              (None, 288, 288, 32)      320       
_________________________________________________________________
norm_1 (BatchNormalization)  (None, 288, 288, 32)      128       
_________________________________________________________________
relu_1 (LeakyReLU)           (None, 288, 288, 32)      0         
_________________________________________________________________
pool_1 (MaxPooling2D)        (None, 144, 144, 32)      0         
_________________________________________________________________
conv_2 (Conv2D)              (None, 144, 144, 64)      18496     
_________________________________________________________________
norm_2 (BatchNormalization)  (None, 144, 144, 64)      256       
_________________________________________________________________
relu_2 (LeakyReLU)           (None, 144, 144, 64)      0         
_________________________________________________________________
pool_2 (MaxPooling2D)        (None, 72, 72, 64)        0         
_________________________________________________________________
conv_3 (Conv2D)              (None, 72, 72, 128)       73856     
_________________________________________________________________
norm_3 (BatchNormalization)  (None, 72, 72, 128)       512       
_________________________________________________________________
relu_3 (LeakyReLU)           (None, 72, 72, 128)       0         
_________________________________________________________________
pool_3 (MaxPooling2D)        (None, 36, 36, 128)       0         
_________________________________________________________________
conv_6 (Conv2D)              (None, 36, 36, 256)       295168    
_________________________________________________________________
norm_6 (BatchNormalization)  (None, 36, 36, 256)       1024      
_________________________________________________________________
relu_6 (LeakyReLU)           (None, 36, 36, 256)       0         
_________________________________________________________________
pool_4 (MaxPooling2D)        (None, 18, 18, 256)       0         
_________________________________________________________________
conv_9 (Conv2D)              (None, 18, 18, 512)       1180160   
_________________________________________________________________
norm_9 (BatchNormalization)  (None, 18, 18, 512)       2048      
_________________________________________________________________
relu_9 (LeakyReLU)           (None, 18, 18, 512)       0         
_________________________________________________________________
pool_5 (MaxPooling2D)        (None, 9, 9, 512)         0         
_________________________________________________________________
conv_14 (Conv2D)             (None, 9, 9, 1024)        4719616   
_________________________________________________________________
norm_14 (BatchNormalization) (None, 9, 9, 1024)        4096      
_________________________________________________________________
relu_14 (LeakyReLU)          (None, 9, 9, 1024)        0         
_________________________________________________________________
conv_15 (Conv2D)             (None, 9, 9, 1024)        9438208   
_________________________________________________________________
norm_15 (BatchNormalization) (None, 9, 9, 1024)        4096      
_________________________________________________________________
relu_15 (LeakyReLU)          (None, 9, 9, 1024)        0         
_________________________________________________________________
conv_16 (Conv2D)             (None, 9, 9, 5)           5125      
_________________________________________________________________
reshape_1 (Reshape)          (None, 9, 9, 5)           0         
=================================================================
Total params: 15,743,109
Trainable params: 15,737,029
Non-trainable params: 6,080
_________________________________________________________________
+----------+---------------------+----------------+---------------+---------------------+---------------------+---------------+
|  Epoch   |       f1_score      |      iou       |      loss     |      precision      |        recall       |    val_loss   |
+----------+---------------------+----------------+---------------+---------------------+---------------------+---------------+
| Epoch 1  |         nan         |      nan       | 29.7821827588 |         nan         |         0.0         | 26.8354233157 |
| Epoch 2  | 0.08387096774193549 | 0.616262902884 | 14.4536636672 |         0.65        | 0.04482758620689655 | 17.1706638644 |
| Epoch 3  | 0.22429906542056074 | 0.656581342101 | 9.64727263237 | 0.34782608695652173 | 0.16551724137931034 | 19.4048424382 |
| Epoch 4  |  0.3488372093023256 | 0.655491014081 |  7.2518464997 |  0.5357142857142857 | 0.25862068965517243 | 16.6179456711 |
| Epoch 5  |  0.2295081967213115 | 0.658952796963 | 5.45233771202 |  0.5526315789473685 | 0.14482758620689656 | 18.4126323269 |
| Epoch 6  |  0.3507109004739336 | 0.666021841188 | 4.47007948044 |  0.5606060606060606 | 0.25517241379310346 | 17.3144262068 |
| Epoch 7  | 0.23316062176165803 | 0.660653667352 | 3.65642028971 |       0.46875       | 0.15517241379310345 | 17.7822549574 |
| Epoch 8  | 0.31443298969072164 | 0.655936338043 | 3.21728971754 |  0.6224489795918368 |  0.2103448275862069 |  17.627313214 |
| Epoch 9  |  0.1803713527851459 | 0.643679559373 | 2.69083870994 | 0.39080459770114945 | 0.11724137931034483 | 18.6268601571 |
| Epoch 10 |  0.2577319587628866 | 0.655053813999 | 2.42921431661 |  0.5102040816326531 |  0.1724137931034483 | 17.7904866126 |
| Epoch 11 |  0.2739018087855297 | 0.649309383331 | 2.27144033404 |  0.5463917525773195 | 0.18275862068965518 | 18.2008764821 |
| Epoch 12 |  0.2446808510638298 | 0.679808633071 | 2.22164909943 |  0.5348837209302325 | 0.15862068965517243 | 18.5588342605 |
| Epoch 13 |  0.2638522427440633 | 0.656954147258 |  1.9028134998 |  0.5617977528089888 |  0.1724137931034483 | 17.6044091563 |
| Epoch 14 | 0.15384615384615385 | 0.640066707908 | 1.78609319601 |  0.5416666666666666 |  0.0896551724137931 | 18.7767798208 |
| Epoch 15 |  0.1466275659824047 | 0.672443904287 | 1.63318413418 | 0.49019607843137253 | 0.08620689655172414 | 18.9660533167 |
| Epoch 16 |  0.1894150417827298 | 0.684043605844 | 1.56100508027 |  0.4927536231884058 | 0.11724137931034483 | 18.9881810219 |
| Epoch 17 |  0.2694300518134715 | 0.666983118978 | 1.49809732915 |  0.5416666666666666 |  0.1793103448275862 | 17.8208242232 |
| Epoch 18 |         0.2         | 0.668909286406 | 1.47498114912 |  0.5833333333333334 |  0.1206896551724138 | 18.6406601014 |
| Epoch 19 | 0.20055710306406685 | 0.658349064105 | 1.43083956435 |  0.5217391304347826 | 0.12413793103448276 | 18.5906549269 |
| Epoch 20 | 0.12244897959183673 | 0.666781875047 | 1.39480707155 | 0.39622641509433965 | 0.07241379310344828 | 19.2028051192 |
| Epoch 21 |  0.2191011235955056 | 0.64108597959  | 1.36535354753 |  0.5909090909090909 | 0.13448275862068965 | 18.2510385513 |
| Epoch 22 |  0.2185792349726776 | 0.656261074066 | 1.30693369405 |  0.5263157894736842 | 0.13793103448275862 | 18.1816682508 |
| Epoch 23 | 0.10526315789473684 | 0.641983803043 |  1.2749589567 |  0.5151515151515151 | 0.05862068965517241 | 19.2061780499 |
| Epoch 24 |  0.2222222222222222 | 0.659350793404 | 1.21393243951 |  0.5714285714285714 | 0.13793103448275862 | 18.3356489058 |
| Epoch 25 | 0.21714285714285714 | 0.657969583858 | 1.18227909871 |  0.6333333333333333 |  0.1310344827586207 | 18.5393796736 |
| Epoch 26 | 0.31979695431472077 | 0.661418882651 | 1.20147825369 |  0.6057692307692307 | 0.21724137931034482 |  18.290361589 |
| Epoch 27 | 0.28921568627450983 | 0.673992726186 | 1.22652434305 |         0.5         | 0.20344827586206896 | 17.9639160095 |
| Epoch 28 |  0.2099447513812155 | 0.664732273229 |  1.187393416  |  0.5277777777777778 |  0.1310344827586207 | 18.5365616275 |
| Epoch 29 |  0.2245989304812834 | 0.664291077573 | 1.23362448271 |         0.5         | 0.14482758620689656 | 18.7370599008 |
| Epoch 30 |  0.2687338501291989 | 0.668658052674 | 1.11383254155 |  0.5360824742268041 |  0.1793103448275862 |  18.529802507 |
+----------+---------------------+----------------+---------------+---------------------+---------------------+---------------+
_________________________________________________________________
+---------------------------------+--------------------+--------------------+-----------------------+---------+-----------------------+
|            Optimizer            |       beta_1       |       beta_2       |         decay         | epsilon |           lr          |
+---------------------------------+--------------------+--------------------+-----------------------+---------+-----------------------+
| <class 'keras.optimizers.Adam'> | 0.8999999761581421 | 0.9990000128746033 | 0.0005000000237487257 |  1e-08  | 0.0010000000474974513 |
+---------------------------------+--------------------+--------------------+-----------------------+---------+-----------------------+
_________________________________________________________________
+------------+
| Batch Size |
+------------+
|     16     |
+------------+
_________________________________________________________________
+--------------------+---------------+----------------+--------------------+---------------------+--------------------+
|      Metrics       |      Loss     |      IoU       |     Precision      |        Recall       |      F1 Score      |
+--------------------+---------------+----------------+--------------------+---------------------+--------------------+
|   Train Metrics    | 2.19019800672 | 0.868639664643 | 0.9765084075173096 |  0.9554802806677958 | 0.9658799070563777 |
| Validation Metrics | 36.8404378583 | 0.668658052674 | 0.5360824742268041 |  0.1793103448275862 | 0.2687338501291989 |
|    Test Metrics    | 38.7692718506 | 0.665405910814 | 0.5882352941176471 | 0.22653721682847897 | 0.3271028037383178 |
+--------------------+---------------+----------------+--------------------+---------------------+--------------------+
_________________________________________________________________
Time:
    Train Time              : 2:07:57.234283
    Dataset Loading Time    : 0:00:38.375956
    Metrics Evaluation Time : 0:05:35.553833
_________________________________________________________________
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         (None, 288, 288, 1)       0         
_________________________________________________________________
conv_1 (Conv2D)              (None, 288, 288, 32)      320       
_________________________________________________________________
norm_1 (BatchNormalization)  (None, 288, 288, 32)      128       
_________________________________________________________________
relu_1 (LeakyReLU)           (None, 288, 288, 32)      0         
_________________________________________________________________
pool_1 (MaxPooling2D)        (None, 144, 144, 32)      0         
_________________________________________________________________
conv_2 (Conv2D)              (None, 144, 144, 64)      18496     
_________________________________________________________________
norm_2 (BatchNormalization)  (None, 144, 144, 64)      256       
_________________________________________________________________
relu_2 (LeakyReLU)           (None, 144, 144, 64)      0         
_________________________________________________________________
pool_2 (MaxPooling2D)        (None, 72, 72, 64)        0         
_________________________________________________________________
conv_3 (Conv2D)              (None, 72, 72, 128)       73856     
_________________________________________________________________
norm_3 (BatchNormalization)  (None, 72, 72, 128)       512       
_________________________________________________________________
relu_3 (LeakyReLU)           (None, 72, 72, 128)       0         
_________________________________________________________________
conv_4 (Conv2D)              (None, 72, 72, 64)        8256      
_________________________________________________________________
norm_4 (BatchNormalization)  (None, 72, 72, 64)        256       
_________________________________________________________________
relu_4 (LeakyReLU)           (None, 72, 72, 64)        0         
_________________________________________________________________
conv_5 (Conv2D)              (None, 72, 72, 128)       73856     
_________________________________________________________________
norm_5 (BatchNormalization)  (None, 72, 72, 128)       512       
_________________________________________________________________
relu_5 (LeakyReLU)           (None, 72, 72, 128)       0         
_________________________________________________________________
pool_3 (MaxPooling2D)        (None, 36, 36, 128)       0         
_________________________________________________________________
conv_6 (Conv2D)              (None, 36, 36, 256)       295168    
_________________________________________________________________
norm_6 (BatchNormalization)  (None, 36, 36, 256)       1024      
_________________________________________________________________
relu_6 (LeakyReLU)           (None, 36, 36, 256)       0         
_________________________________________________________________
conv_7 (Conv2D)              (None, 36, 36, 128)       32896     
_________________________________________________________________
norm_7 (BatchNormalization)  (None, 36, 36, 128)       512       
_________________________________________________________________
relu_7 (LeakyReLU)           (None, 36, 36, 128)       0         
_________________________________________________________________
conv_8 (Conv2D)              (None, 36, 36, 256)       295168    
_________________________________________________________________
norm_8 (BatchNormalization)  (None, 36, 36, 256)       1024      
_________________________________________________________________
relu_8 (LeakyReLU)           (None, 36, 36, 256)       0         
_________________________________________________________________
pool_4 (MaxPooling2D)        (None, 18, 18, 256)       0         
_________________________________________________________________
conv_9 (Conv2D)              (None, 18, 18, 512)       1180160   
_________________________________________________________________
norm_9 (BatchNormalization)  (None, 18, 18, 512)       2048      
_________________________________________________________________
relu_9 (LeakyReLU)           (None, 18, 18, 512)       0         
_________________________________________________________________
conv_10 (Conv2D)             (None, 18, 18, 256)       131328    
_________________________________________________________________
norm_10 (BatchNormalization) (None, 18, 18, 256)       1024      
_________________________________________________________________
relu_10 (LeakyReLU)          (None, 18, 18, 256)       0         
_________________________________________________________________
conv_11 (Conv2D)             (None, 18, 18, 512)       1180160   
_________________________________________________________________
norm_11 (BatchNormalization) (None, 18, 18, 512)       2048      
_________________________________________________________________
relu_11 (LeakyReLU)          (None, 18, 18, 512)       0         
_________________________________________________________________
conv_12 (Conv2D)             (None, 18, 18, 256)       131328    
_________________________________________________________________
norm_12 (BatchNormalization) (None, 18, 18, 256)       1024      
_________________________________________________________________
relu_12 (LeakyReLU)          (None, 18, 18, 256)       0         
_________________________________________________________________
conv_13 (Conv2D)             (None, 18, 18, 512)       1180160   
_________________________________________________________________
norm_13 (BatchNormalization) (None, 18, 18, 512)       2048      
_________________________________________________________________
relu_13 (LeakyReLU)          (None, 18, 18, 512)       0         
_________________________________________________________________
pool_5 (MaxPooling2D)        (None, 9, 9, 512)         0         
_________________________________________________________________
conv_14 (Conv2D)             (None, 9, 9, 1024)        4719616   
_________________________________________________________________
norm_14 (BatchNormalization) (None, 9, 9, 1024)        4096      
_________________________________________________________________
relu_14 (LeakyReLU)          (None, 9, 9, 1024)        0         
_________________________________________________________________
conv_15 (Conv2D)             (None, 9, 9, 1024)        9438208   
_________________________________________________________________
norm_15 (BatchNormalization) (None, 9, 9, 1024)        4096      
_________________________________________________________________
relu_15 (LeakyReLU)          (None, 9, 9, 1024)        0         
_________________________________________________________________
conv_16 (Conv2D)             (None, 9, 9, 5)           5125      
_________________________________________________________________
reshape_1 (Reshape)          (None, 9, 9, 5)           0         
=================================================================
Total params: 18,784,709
Trainable params: 18,774,405
Non-trainable params: 10,304
_________________________________________________________________
+----------+--------------------+----------------+---------------+--------------------+---------------------+---------------+
|  Epoch   |      f1_score      |      iou       |      loss     |     precision      |        recall       |    val_loss   |
+----------+--------------------+----------------+---------------+--------------------+---------------------+---------------+
| Epoch 1  |        nan         |      nan       | 26.5196362703 |        nan         |         0.0         | 28.8801918645 |
| Epoch 2  | 0.5780346820809249 | 0.669552909008 | 12.9126424459 | 0.6550218340611353 |  0.5172413793103449 | 9.80838926377 |
| Epoch 3  | 0.5614035087719299 | 0.643672849431 | 9.50214877858 | 0.5714285714285714 |  0.5517241379310345 | 10.8092443712 |
| Epoch 4  | 0.519298245614035  | 0.656436498992 | 7.48860313685 | 0.5285714285714286 |  0.5103448275862069 | 13.8213696018 |
| Epoch 5  | 0.6277873070325901 | 0.675223846377 | 6.12342035498 | 0.6245733788395904 |  0.6310344827586207 | 9.49196704741 |
| Epoch 6  | 0.6059479553903346 | 0.66528815936  | 5.30190710909 | 0.657258064516129  |  0.5620689655172414 |  11.64894144  |
| Epoch 7  | 0.5499999999999999 | 0.680467326095 | 4.81895388332 | 0.532258064516129  |  0.5689655172413793 | 13.2237360862 |
| Epoch 8  | 0.6533575317604357 | 0.692887100679 | 4.42375021271 | 0.6896551724137931 |  0.6206896551724138 | 8.85843767658 |
| Epoch 9  |       0.5875       | 0.667533053532 |  3.9673408158 | 0.7421052631578947 |  0.4862068965517241 | 10.7854544117 |
| Epoch 10 | 0.6812386156648451 | 0.67946640482  | 3.75884205954 | 0.722007722007722  |  0.6448275862068965 | 8.41877262054 |
| Epoch 11 | 0.5532710280373832 | 0.673114115225 | 3.47647912283 | 0.6040816326530613 |  0.5103448275862069 | 10.4770222941 |
| Epoch 12 | 0.5860113421550094 | 0.674990846623 | 3.26635547528 | 0.6485355648535565 |  0.5344827586206896 | 11.2953621803 |
| Epoch 13 | 0.5801801801801801 | 0.675273307391 | 3.01541324702 | 0.6075471698113207 |  0.5551724137931034 | 10.5242747953 |
| Epoch 14 | 0.607638888888889  | 0.66102752174  | 2.73947774618 | 0.6118881118881119 |  0.603448275862069  | 10.6819821942 |
| Epoch 15 |     0.5703125      | 0.671761342403 | 2.69358050717 | 0.6576576576576577 |  0.503448275862069  | 10.9392236279 |
| Epoch 16 | 0.5687022900763359 | 0.667476019974 |  2.5161575837 | 0.6367521367521367 |  0.5137931034482759 | 10.4558896096 |
| Epoch 17 | 0.6641929499072355 | 0.678346295157 | 2.35633030909 | 0.7188755020080321 |  0.6172413793103448 | 9.05623145257 |
| Epoch 18 | 0.6666666666666667 | 0.670204764841 | 2.13226447596 | 0.7727272727272727 |  0.5862068965517241 |  9.261141977  |
| Epoch 19 | 0.5075187969924811 | 0.671885273198 | 2.09545369165 | 0.5578512396694215 | 0.46551724137931033 | 10.9999894481 |
| Epoch 20 | 0.6819787985865724 | 0.672423312506 | 2.02688562412 | 0.6992753623188406 |  0.6655172413793103 | 9.12027428227 |
| Epoch 21 | 0.6040816326530613 | 0.686342525723 | 1.96223881485 |        0.74        |  0.5103448275862069 | 10.6598643641 |
| Epoch 22 | 0.591792656587473  | 0.690300793308 | 1.84179295109 | 0.791907514450867  |  0.4724137931034483 | 10.8494215935 |
| Epoch 23 | 0.6533864541832669 | 0.679852260088 | 1.72651117027 | 0.7735849056603774 |  0.5655172413793104 |  10.513969606 |
| Epoch 24 | 0.5925925925925926 | 0.679451556555 | 1.74938980279 | 0.7346938775510204 |  0.496551724137931  | 10.9581101018 |
| Epoch 25 | 0.679245283018868  | 0.687624380056 | 1.64614279386 |        0.75        |  0.6206896551724138 | 9.07264294163 |
| Epoch 26 | 0.5942622950819673 | 0.689501798608 |  1.5444686662 | 0.7323232323232324 |         0.5         | 11.3011455536 |
| Epoch 27 | 0.6305220883534137 | 0.685037643971 | 1.48301171596 | 0.7548076923076923 |  0.5413793103448276 | 10.4372279259 |
| Epoch 28 | 0.5738045738045737 | 0.688772772405 | 1.47026420597 | 0.7225130890052356 | 0.47586206896551725 | 11.1938458258 |
| Epoch 29 | 0.6593001841620627 | 0.669455080345 | 1.50854102994 | 0.7075098814229249 |  0.6172413793103448 | 9.87199155746 |
| Epoch 30 | 0.6247544204322201 | 0.683639822146 | 1.42642965817 | 0.726027397260274  |  0.5482758620689655 | 10.3913890162 |
+----------+--------------------+----------------+---------------+--------------------+---------------------+---------------+
_________________________________________________________________
+---------------------------------+--------------------+--------------------+-----------------------+---------+-----------------------+
|            Optimizer            |       beta_1       |       beta_2       |         decay         | epsilon |           lr          |
+---------------------------------+--------------------+--------------------+-----------------------+---------+-----------------------+
| <class 'keras.optimizers.Adam'> | 0.8999999761581421 | 0.9990000128746033 | 0.0005000000237487257 |  1e-08  | 0.0010000000474974513 |
+---------------------------------+--------------------+--------------------+-----------------------+---------+-----------------------+
_________________________________________________________________
+------------+
| Batch Size |
+------------+
|     16     |
+------------+
_________________________________________________________________
+--------------------+---------------+----------------+--------------------+--------------------+--------------------+
|      Metrics       |      Loss     |      IoU       |     Precision      |       Recall       |      F1 Score      |
+--------------------+---------------+----------------+--------------------+--------------------+--------------------+
|   Train Metrics    | 2.94035034278 | 0.858165180968 | 0.9708436724565757 | 0.9466489233002662 | 0.9585936542937646 |
| Validation Metrics | 20.6642401911 | 0.683639822146 | 0.726027397260274  | 0.5482758620689655 | 0.6247544204322201 |
|    Test Metrics    | 23.8522244115 | 0.675773969898 |       0.6875       | 0.4627831715210356 | 0.5531914893617021 |
+--------------------+---------------+----------------+--------------------+--------------------+--------------------+
_________________________________________________________________
Time:
    Train Time              : 2:56:42.544220
    Dataset Loading Time    : 0:00:37.932115
    Metrics Evaluation Time : 0:06:09.304736
_________________________________________________________________
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         (None, 288, 288, 1)       0         
_________________________________________________________________
conv_1 (Conv2D)              (None, 288, 288, 32)      320       
_________________________________________________________________
norm_1 (BatchNormalization)  (None, 288, 288, 32)      128       
_________________________________________________________________
relu_1 (LeakyReLU)           (None, 288, 288, 32)      0         
_________________________________________________________________
pool_1 (MaxPooling2D)        (None, 144, 144, 32)      0         
_________________________________________________________________
conv_2 (Conv2D)              (None, 144, 144, 64)      18496     
_________________________________________________________________
norm_2 (BatchNormalization)  (None, 144, 144, 64)      256       
_________________________________________________________________
relu_2 (LeakyReLU)           (None, 144, 144, 64)      0         
_________________________________________________________________
pool_2 (MaxPooling2D)        (None, 72, 72, 64)        0         
_________________________________________________________________
conv_3 (Conv2D)              (None, 72, 72, 128)       73856     
_________________________________________________________________
norm_3 (BatchNormalization)  (None, 72, 72, 128)       512       
_________________________________________________________________
relu_3 (LeakyReLU)           (None, 72, 72, 128)       0         
_________________________________________________________________
conv_4 (Conv2D)              (None, 72, 72, 64)        8256      
_________________________________________________________________
norm_4 (BatchNormalization)  (None, 72, 72, 64)        256       
_________________________________________________________________
relu_4 (LeakyReLU)           (None, 72, 72, 64)        0         
_________________________________________________________________
conv_5 (Conv2D)              (None, 72, 72, 128)       73856     
_________________________________________________________________
norm_5 (BatchNormalization)  (None, 72, 72, 128)       512       
_________________________________________________________________
relu_5 (LeakyReLU)           (None, 72, 72, 128)       0         
_________________________________________________________________
pool_3 (MaxPooling2D)        (None, 36, 36, 128)       0         
_________________________________________________________________
conv_6 (Conv2D)              (None, 36, 36, 256)       295168    
_________________________________________________________________
norm_6 (BatchNormalization)  (None, 36, 36, 256)       1024      
_________________________________________________________________
relu_6 (LeakyReLU)           (None, 36, 36, 256)       0         
_________________________________________________________________
conv_7 (Conv2D)              (None, 36, 36, 128)       32896     
_________________________________________________________________
norm_7 (BatchNormalization)  (None, 36, 36, 128)       512       
_________________________________________________________________
relu_7 (LeakyReLU)           (None, 36, 36, 128)       0         
_________________________________________________________________
conv_8 (Conv2D)              (None, 36, 36, 256)       295168    
_________________________________________________________________
norm_8 (BatchNormalization)  (None, 36, 36, 256)       1024      
_________________________________________________________________
relu_8 (LeakyReLU)           (None, 36, 36, 256)       0         
_________________________________________________________________
pool_4 (MaxPooling2D)        (None, 18, 18, 256)       0         
_________________________________________________________________
conv_9 (Conv2D)              (None, 18, 18, 512)       1180160   
_________________________________________________________________
norm_9 (BatchNormalization)  (None, 18, 18, 512)       2048      
_________________________________________________________________
relu_9 (LeakyReLU)           (None, 18, 18, 512)       0         
_________________________________________________________________
conv_10 (Conv2D)             (None, 18, 18, 256)       131328    
_________________________________________________________________
norm_10 (BatchNormalization) (None, 18, 18, 256)       1024      
_________________________________________________________________
relu_10 (LeakyReLU)          (None, 18, 18, 256)       0         
_________________________________________________________________
conv_11 (Conv2D)             (None, 18, 18, 512)       1180160   
_________________________________________________________________
norm_11 (BatchNormalization) (None, 18, 18, 512)       2048      
_________________________________________________________________
relu_11 (LeakyReLU)          (None, 18, 18, 512)       0         
_________________________________________________________________
conv_12 (Conv2D)             (None, 18, 18, 256)       131328    
_________________________________________________________________
norm_12 (BatchNormalization) (None, 18, 18, 256)       1024      
_________________________________________________________________
relu_12 (LeakyReLU)          (None, 18, 18, 256)       0         
_________________________________________________________________
conv_13 (Conv2D)             (None, 18, 18, 512)       1180160   
_________________________________________________________________
norm_13 (BatchNormalization) (None, 18, 18, 512)       2048      
_________________________________________________________________
relu_13 (LeakyReLU)          (None, 18, 18, 512)       0         
_________________________________________________________________
pool_5 (MaxPooling2D)        (None, 9, 9, 512)         0         
_________________________________________________________________
conv_14 (Conv2D)             (None, 9, 9, 1024)        4719616   
_________________________________________________________________
norm_14 (BatchNormalization) (None, 9, 9, 1024)        4096      
_________________________________________________________________
relu_14 (LeakyReLU)          (None, 9, 9, 1024)        0         
_________________________________________________________________
conv_15 (Conv2D)             (None, 9, 9, 1024)        9438208   
_________________________________________________________________
norm_15 (BatchNormalization) (None, 9, 9, 1024)        4096      
_________________________________________________________________
relu_15 (LeakyReLU)          (None, 9, 9, 1024)        0         
_________________________________________________________________
conv_16 (Conv2D)             (None, 9, 9, 5)           5125      
_________________________________________________________________
reshape_1 (Reshape)          (None, 9, 9, 5)           0         
=================================================================
Total params: 18,784,709
Trainable params: 18,774,405
Non-trainable params: 10,304
_________________________________________________________________
+----------+--------------------+----------------+---------------+--------------------+---------------------+---------------+
|  Epoch   |      f1_score      |      iou       |      loss     |     precision      |        recall       |    val_loss   |
+----------+--------------------+----------------+---------------+--------------------+---------------------+---------------+
| Epoch 1  |        nan         |      nan       | 21.7701373652 |        nan         |         0.0         | 20.5125366949 |
| Epoch 2  | 0.5486381322957199 | 0.668882139408 | 10.5099173108 | 0.6294642857142857 |  0.4862068965517241 | 10.7391794882 |
| Epoch 3  | 0.6148409893992932 | 0.658201998158 | 8.12557098378 | 0.6304347826086957 |         0.6         | 9.80295525828 |
| Epoch 4  | 0.5590994371482176 | 0.666395005743 | 6.65173577416 | 0.6131687242798354 |  0.5137931034482759 | 10.8157041611 |
| Epoch 5  | 0.6298932384341638 | 0.667454038317 | 5.84187560029 | 0.6507352941176471 |  0.6103448275862069 | 9.82114527302 |
| Epoch 6  | 0.5896980461811723 | 0.650963021163 | 4.98172337225 | 0.608058608058608  |  0.5724137931034483 | 9.58557596514 |
| Epoch 7  | 0.6472727272727273 | 0.677077390373 | 4.53299181681 | 0.6846153846153846 |  0.6137931034482759 | 8.97626786078 |
| Epoch 8  | 0.5996908809891808 | 0.678276178461 | 4.12295461003 | 0.5434173669467787 |  0.6689655172413793 | 10.5508512835 |
| Epoch 9  | 0.5749128919860628 | 0.660768656297 | 4.07477967636 | 0.5809859154929577 |  0.5689655172413793 | 10.7139228698 |
| Epoch 10 | 0.5724020442930154 | 0.666637482692 | 3.70751228437 | 0.5656565656565656 |  0.5793103448275863 | 10.5262930162 |
| Epoch 11 | 0.6088495575221239 | 0.680272485222 | 3.71599433398 | 0.6254545454545455 |  0.593103448275862  | 10.2595904566 |
| Epoch 12 | 0.6854130052724078 | 0.686376655895 | 3.49502285829 | 0.6989247311827957 |  0.6724137931034483 | 9.00840216298 |
| Epoch 13 | 0.612641815235008  | 0.69835773676  | 3.18048962303 | 0.5779816513761468 |  0.6517241379310345 | 10.4860969359 |
| Epoch 14 | 0.637478108581436  | 0.699000968167 | 3.05171015317 | 0.6476868327402135 |  0.6275862068965518 | 10.1702569838 |
| Epoch 15 | 0.5657657657657658 | 0.659511725212 | 3.08683396111 | 0.5924528301886792 |  0.5413793103448276 | 11.2859037922 |
| Epoch 16 | 0.621487603305785  | 0.685628237813 | 2.96201164664 | 0.5968253968253968 |  0.6482758620689655 | 10.0879032689 |
| Epoch 17 | 0.6219081272084804 | 0.680636643592 | 2.76905020484 | 0.6376811594202898 |  0.6068965517241379 | 9.69638259949 |
| Epoch 18 | 0.5447619047619047 | 0.702332801808 | 2.68122928372 | 0.6085106382978723 | 0.49310344827586206 | 11.5698701797 |
| Epoch 19 | 0.608695652173913  | 0.672677987069 | 2.56126111166 | 0.6140350877192983 |  0.603448275862069  | 11.5292776477 |
| Epoch 20 | 0.6404494382022471 | 0.679818337542 | 2.50281102387 | 0.7008196721311475 |  0.5896551724137931 | 10.5581151285 |
| Epoch 21 | 0.634508348794063  | 0.67364851981  | 2.38791000556 | 0.6867469879518072 |  0.5896551724137931 | 10.6841534338 |
| Epoch 22 | 0.6150870406189555 | 0.704400617752 | 2.50117477717 | 0.7004405286343612 |  0.5482758620689655 | 10.8437865165 |
| Epoch 23 | 0.6243194192377495 | 0.686842037184 | 2.14920011911 | 0.6590038314176245 |  0.593103448275862  | 10.9330159464 |
| Epoch 24 | 0.6051080550098231 | 0.684245261164 | 2.10944705834 | 0.7031963470319634 |  0.5310344827586206 | 9.93073664942 |
| Epoch 25 | 0.6189555125725339 | 0.694382880524 |  2.0216525328 | 0.7048458149779736 |  0.5517241379310345 | 10.6290483321 |
| Epoch 26 | 0.5641952983725135 | 0.666917308277 | 1.90754360958 | 0.5931558935361216 |  0.5379310344827586 |  11.007040516 |
| Epoch 27 | 0.5799256505576207 | 0.688618328407 | 1.99842616059 | 0.6290322580645161 |  0.5379310344827586 | 11.9745021943 |
| Epoch 28 | 0.6048109965635738 | 0.666993080023 |  2.102542228  | 0.6027397260273972 |  0.6068965517241379 | 11.1123975323 |
| Epoch 29 | 0.6488413547237077 | 0.694111937606 | 1.89383594129 | 0.6715867158671587 |  0.6275862068965518 | 9.53040409088 |
| Epoch 30 | 0.6080586080586081 | 0.683289955365 | 1.65510454066 |     0.6484375      |  0.5724137931034483 | 11.4204591936 |
+----------+--------------------+----------------+---------------+--------------------+---------------------+---------------+
_________________________________________________________________
+---------------------------------+--------------------+--------------------+-----------------------+---------+-----------------------+
|            Optimizer            |       beta_1       |       beta_2       |         decay         | epsilon |           lr          |
+---------------------------------+--------------------+--------------------+-----------------------+---------+-----------------------+
| <class 'keras.optimizers.Adam'> | 0.8999999761581421 | 0.9990000128746033 | 4.999999873689376e-05 |  1e-08  | 0.0010000000474974513 |
+---------------------------------+--------------------+--------------------+-----------------------+---------+-----------------------+
_________________________________________________________________
+------------+
| Batch Size |
+------------+
|     16     |
+------------+
_________________________________________________________________
+--------------------+---------------+----------------+--------------------+--------------------+--------------------+
|      Metrics       |      Loss     |      IoU       |     Precision      |       Recall       |      F1 Score      |
+--------------------+---------------+----------------+--------------------+--------------------+--------------------+
|   Train Metrics    | 3.20931915111 | 0.854084410947 | 0.9706712480058903 | 0.9569320106460198 | 0.9637526652452026 |
| Validation Metrics | 22.5870587749 | 0.683289955365 |     0.6484375      | 0.5724137931034483 | 0.6080586080586081 |
|    Test Metrics    | 23.8306841696 | 0.676214037646 | 0.6199261992619927 | 0.5436893203883495 | 0.5793103448275863 |
+--------------------+---------------+----------------+--------------------+--------------------+--------------------+
_________________________________________________________________
Time:
    Train Time              : 3:26:50.136810
    Dataset Loading Time    : 0:00:39.147897
    Metrics Evaluation Time : 0:06:53.996861
_________________________________________________________________
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         (None, 288, 288, 1)       0         
_________________________________________________________________
conv_1 (Conv2D)              (None, 288, 288, 32)      320       
_________________________________________________________________
norm_1 (BatchNormalization)  (None, 288, 288, 32)      128       
_________________________________________________________________
relu_1 (LeakyReLU)           (None, 288, 288, 32)      0         
_________________________________________________________________
pool_1 (MaxPooling2D)        (None, 144, 144, 32)      0         
_________________________________________________________________
conv_2 (Conv2D)              (None, 144, 144, 64)      18496     
_________________________________________________________________
norm_2 (BatchNormalization)  (None, 144, 144, 64)      256       
_________________________________________________________________
relu_2 (LeakyReLU)           (None, 144, 144, 64)      0         
_________________________________________________________________
pool_2 (MaxPooling2D)        (None, 72, 72, 64)        0         
_________________________________________________________________
conv_3 (Conv2D)              (None, 72, 72, 128)       73856     
_________________________________________________________________
norm_3 (BatchNormalization)  (None, 72, 72, 128)       512       
_________________________________________________________________
relu_3 (LeakyReLU)           (None, 72, 72, 128)       0         
_________________________________________________________________
conv_4 (Conv2D)              (None, 72, 72, 64)        8256      
_________________________________________________________________
norm_4 (BatchNormalization)  (None, 72, 72, 64)        256       
_________________________________________________________________
relu_4 (LeakyReLU)           (None, 72, 72, 64)        0         
_________________________________________________________________
conv_5 (Conv2D)              (None, 72, 72, 128)       73856     
_________________________________________________________________
norm_5 (BatchNormalization)  (None, 72, 72, 128)       512       
_________________________________________________________________
relu_5 (LeakyReLU)           (None, 72, 72, 128)       0         
_________________________________________________________________
pool_3 (MaxPooling2D)        (None, 36, 36, 128)       0         
_________________________________________________________________
conv_6 (Conv2D)              (None, 36, 36, 256)       295168    
_________________________________________________________________
norm_6 (BatchNormalization)  (None, 36, 36, 256)       1024      
_________________________________________________________________
relu_6 (LeakyReLU)           (None, 36, 36, 256)       0         
_________________________________________________________________
conv_7 (Conv2D)              (None, 36, 36, 128)       32896     
_________________________________________________________________
norm_7 (BatchNormalization)  (None, 36, 36, 128)       512       
_________________________________________________________________
relu_7 (LeakyReLU)           (None, 36, 36, 128)       0         
_________________________________________________________________
conv_8 (Conv2D)              (None, 36, 36, 256)       295168    
_________________________________________________________________
norm_8 (BatchNormalization)  (None, 36, 36, 256)       1024      
_________________________________________________________________
relu_8 (LeakyReLU)           (None, 36, 36, 256)       0         
_________________________________________________________________
pool_4 (MaxPooling2D)        (None, 18, 18, 256)       0         
_________________________________________________________________
conv_9 (Conv2D)              (None, 18, 18, 512)       1180160   
_________________________________________________________________
norm_9 (BatchNormalization)  (None, 18, 18, 512)       2048      
_________________________________________________________________
relu_9 (LeakyReLU)           (None, 18, 18, 512)       0         
_________________________________________________________________
conv_10 (Conv2D)             (None, 18, 18, 256)       131328    
_________________________________________________________________
norm_10 (BatchNormalization) (None, 18, 18, 256)       1024      
_________________________________________________________________
relu_10 (LeakyReLU)          (None, 18, 18, 256)       0         
_________________________________________________________________
conv_11 (Conv2D)             (None, 18, 18, 512)       1180160   
_________________________________________________________________
norm_11 (BatchNormalization) (None, 18, 18, 512)       2048      
_________________________________________________________________
relu_11 (LeakyReLU)          (None, 18, 18, 512)       0         
_________________________________________________________________
conv_12 (Conv2D)             (None, 18, 18, 256)       131328    
_________________________________________________________________
norm_12 (BatchNormalization) (None, 18, 18, 256)       1024      
_________________________________________________________________
relu_12 (LeakyReLU)          (None, 18, 18, 256)       0         
_________________________________________________________________
conv_13 (Conv2D)             (None, 18, 18, 512)       1180160   
_________________________________________________________________
norm_13 (BatchNormalization) (None, 18, 18, 512)       2048      
_________________________________________________________________
relu_13 (LeakyReLU)          (None, 18, 18, 512)       0         
_________________________________________________________________
pool_5 (MaxPooling2D)        (None, 9, 9, 512)         0         
_________________________________________________________________
conv_14 (Conv2D)             (None, 9, 9, 1024)        4719616   
_________________________________________________________________
norm_14 (BatchNormalization) (None, 9, 9, 1024)        4096      
_________________________________________________________________
relu_14 (LeakyReLU)          (None, 9, 9, 1024)        0         
_________________________________________________________________
conv_15 (Conv2D)             (None, 9, 9, 1024)        9438208   
_________________________________________________________________
norm_15 (BatchNormalization) (None, 9, 9, 1024)        4096      
_________________________________________________________________
relu_15 (LeakyReLU)          (None, 9, 9, 1024)        0         
_________________________________________________________________
conv_16 (Conv2D)             (None, 9, 9, 5)           5125      
_________________________________________________________________
reshape_1 (Reshape)          (None, 9, 9, 5)           0         
=================================================================
Total params: 18,784,709
Trainable params: 18,774,405
Non-trainable params: 10,304
_________________________________________________________________
+----------+---------------------+----------------+----------------+---------------------+---------------------+---------------+
|  Epoch   |       f1_score      |      iou       |      loss      |      precision      |        recall       |    val_loss   |
+----------+---------------------+----------------+----------------+---------------------+---------------------+---------------+
| Epoch 1  |         nan         |      nan       | 47.0394082106  |         nan         |         0.0         | 20.6290807416 |
| Epoch 2  | 0.21578947368421053 | 0.636682491887 | 15.9660178287  | 0.45555555555555555 |  0.1413793103448276 | 13.5725077045 |
| Epoch 3  |  0.4258064516129032 | 0.627280359418 | 11.5865154887  |         0.4         | 0.45517241379310347 | 15.6593409508 |
| Epoch 4  |  0.4150197628458498 | 0.652349473232 | 8.60557556878  |  0.4861111111111111 |  0.3620689655172414 | 14.3417284258 |
| Epoch 5  |  0.5065666041275798 | 0.646554029079 | 6.89396938911  |  0.5555555555555556 | 0.46551724137931033 | 13.4364204714 |
| Epoch 6  |         0.48        | 0.642066433957 | 5.60308045547  | 0.44776119402985076 |  0.5172413793103449 | 13.4761556502 |
| Epoch 7  |        0.375        | 0.634544574801 | 4.22187248328  |  0.3888888888888889 |  0.3620689655172414 | 16.7470929238 |
| Epoch 8  |  0.455743879472693  | 0.642800483384 | 3.21792628326  |  0.5020746887966805 | 0.41724137931034483 | 13.4219338202 |
| Epoch 9  |  0.5201465201465202 | 0.659686147608 | 2.60457730797  |      0.5546875      |  0.4896551724137931 | 12.5250051252 |
| Epoch 10 |  0.4189189189189189 | 0.650326167368 |  2.2712930327  |  0.6038961038961039 | 0.32068965517241377 | 12.5508812012 |
| Epoch 11 |  0.5241090146750524 | 0.659801580046 | 2.03350525676  |  0.6684491978609626 | 0.43103448275862066 | 12.7667035441 |
| Epoch 12 |  0.4577319587628866 | 0.664384530165 | 1.90525413335  |  0.5692307692307692 | 0.38275862068965516 |  12.858195674 |
| Epoch 13 |  0.453514739229025  | 0.665260024714 |  1.7322636748  |  0.6622516556291391 |  0.3448275862068966 | 13.3569402387 |
| Epoch 14 | 0.44490644490644493 | 0.669498185984 | 1.62227735324  |  0.5602094240837696 |  0.3689655172413793 | 12.5427884133 |
| Epoch 15 |  0.5203252032520325 | 0.663615742262 | 1.51722835739  |  0.6336633663366337 |  0.4413793103448276 |  12.686475077 |
| Epoch 16 |  0.4981684981684981 | 0.670915312001 | 1.49807078343  |       0.53125       |  0.4689655172413793 | 12.6804942469 |
| Epoch 17 | 0.49042145593869735 | 0.645282031013 |  1.4338352393  |  0.5517241379310345 |  0.4413793103448276 | 12.1369248052 |
| Epoch 18 | 0.49691991786447637 | 0.673263962633 | 1.35388276412  |  0.6142131979695431 | 0.41724137931034483 | 12.5970734935 |
| Epoch 19 |  0.4722792607802875 | 0.671448160428 | 1.17909952567  |  0.583756345177665  | 0.39655172413793105 | 12.7205565668 |
| Epoch 20 |  0.5640074211502782 | 0.679512876195 | 1.04216264054  |  0.6104417670682731 |  0.5241379310344828 | 11.5984230042 |
| Epoch 21 |  0.5222672064777328 | 0.65781488868  | 0.97415551057  |  0.6323529411764706 | 0.44482758620689655 | 12.8015039198 |
| Epoch 22 | 0.49166666666666664 | 0.665680797215 | 1.13709302303  |  0.6210526315789474 |  0.4068965517241379 | 12.7561008084 |
| Epoch 23 |  0.5269461077844312 | 0.663728681109 | 1.16584874585  |  0.6255924170616114 | 0.45517241379310347 |  12.536448694 |
| Epoch 24 |  0.553191489361702  | 0.676385830016 | 1.25696363594  |  0.6299559471365639 | 0.49310344827586206 | 12.4028998344 |
| Epoch 25 |  0.5343511450381679 | 0.650691902776 | 1.12180848985  |  0.5982905982905983 |  0.4827586206896552 | 12.7479895315 |
| Epoch 26 |  0.526530612244898  | 0.659309851951 | 1.02188310821  |        0.645        | 0.44482758620689655 | 12.1926364899 |
| Epoch 27 |  0.5208333333333334 | 0.675845113979 | 0.900138464704 |  0.6578947368421053 | 0.43103448275862066 | 12.2966269216 |
| Epoch 28 |  0.5050505050505051 | 0.685038438675 | 0.789376075552 |  0.6097560975609756 | 0.43103448275862066 | 12.3840798101 |
| Epoch 29 |  0.5412262156448203 | 0.678251050493 | 0.74761112227  |  0.6994535519125683 |  0.4413793103448276 | 12.7015418699 |
| Epoch 30 |  0.6000000000000001 | 0.678570688485 | 0.760377453957 |  0.6782608695652174 |  0.5379310344827586 | 11.8532680388 |
+----------+---------------------+----------------+----------------+---------------------+---------------------+---------------+
_________________________________________________________________
+---------------------------------+--------------------+--------------------+-----------------------+---------+-----------------------+
|            Optimizer            |       beta_1       |       beta_2       |         decay         | epsilon |           lr          |
+---------------------------------+--------------------+--------------------+-----------------------+---------+-----------------------+
| <class 'keras.optimizers.Adam'> | 0.8999999761581421 | 0.9990000128746033 | 4.999999873689376e-05 |  1e-08  | 9.999999747378752e-05 |
+---------------------------------+--------------------+--------------------+-----------------------+---------+-----------------------+
_________________________________________________________________
+------------+
| Batch Size |
+------------+
|     16     |
+------------+
_________________________________________________________________
+--------------------+---------------+----------------+--------------------+---------------------+--------------------+
|      Metrics       |      Loss     |      IoU       |     Precision      |        Recall       |      F1 Score      |
+--------------------+---------------+----------------+--------------------+---------------------+--------------------+
|   Train Metrics    | 1.74517613149 | 0.831704344681 | 0.9688948524030251 |  0.960924268086136  | 0.9648931000971817 |
| Validation Metrics |  23.580309714 | 0.678570688485 | 0.6782608695652174 |  0.5379310344827586 | 0.6000000000000001 |
|    Test Metrics    | 25.4029241993 | 0.691222426004 | 0.6834862385321101 | 0.48220064724919093 | 0.5654648956356737 |
+--------------------+---------------+----------------+--------------------+---------------------+--------------------+
_________________________________________________________________
Time:
    Train Time              : 3:00:30.700941
    Dataset Loading Time    : 0:00:41.499018
    Metrics Evaluation Time : 0:09:46.836826
_________________________________________________________________
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         (None, 288, 288, 1)       0         
_________________________________________________________________
conv_1 (Conv2D)              (None, 288, 288, 32)      320       
_________________________________________________________________
norm_1 (BatchNormalization)  (None, 288, 288, 32)      128       
_________________________________________________________________
relu_1 (LeakyReLU)           (None, 288, 288, 32)      0         
_________________________________________________________________
pool_1 (MaxPooling2D)        (None, 144, 144, 32)      0         
_________________________________________________________________
conv_2 (Conv2D)              (None, 144, 144, 64)      18496     
_________________________________________________________________
norm_2 (BatchNormalization)  (None, 144, 144, 64)      256       
_________________________________________________________________
relu_2 (LeakyReLU)           (None, 144, 144, 64)      0         
_________________________________________________________________
pool_2 (MaxPooling2D)        (None, 72, 72, 64)        0         
_________________________________________________________________
conv_3 (Conv2D)              (None, 72, 72, 128)       73856     
_________________________________________________________________
norm_3 (BatchNormalization)  (None, 72, 72, 128)       512       
_________________________________________________________________
relu_3 (LeakyReLU)           (None, 72, 72, 128)       0         
_________________________________________________________________
conv_4 (Conv2D)              (None, 72, 72, 64)        8256      
_________________________________________________________________
norm_4 (BatchNormalization)  (None, 72, 72, 64)        256       
_________________________________________________________________
relu_4 (LeakyReLU)           (None, 72, 72, 64)        0         
_________________________________________________________________
conv_5 (Conv2D)              (None, 72, 72, 128)       73856     
_________________________________________________________________
norm_5 (BatchNormalization)  (None, 72, 72, 128)       512       
_________________________________________________________________
relu_5 (LeakyReLU)           (None, 72, 72, 128)       0         
_________________________________________________________________
pool_3 (MaxPooling2D)        (None, 36, 36, 128)       0         
_________________________________________________________________
conv_6 (Conv2D)              (None, 36, 36, 256)       295168    
_________________________________________________________________
norm_6 (BatchNormalization)  (None, 36, 36, 256)       1024      
_________________________________________________________________
relu_6 (LeakyReLU)           (None, 36, 36, 256)       0         
_________________________________________________________________
conv_7 (Conv2D)              (None, 36, 36, 128)       32896     
_________________________________________________________________
norm_7 (BatchNormalization)  (None, 36, 36, 128)       512       
_________________________________________________________________
relu_7 (LeakyReLU)           (None, 36, 36, 128)       0         
_________________________________________________________________
conv_8 (Conv2D)              (None, 36, 36, 256)       295168    
_________________________________________________________________
norm_8 (BatchNormalization)  (None, 36, 36, 256)       1024      
_________________________________________________________________
relu_8 (LeakyReLU)           (None, 36, 36, 256)       0         
_________________________________________________________________
pool_4 (MaxPooling2D)        (None, 18, 18, 256)       0         
_________________________________________________________________
conv_9 (Conv2D)              (None, 18, 18, 512)       1180160   
_________________________________________________________________
norm_9 (BatchNormalization)  (None, 18, 18, 512)       2048      
_________________________________________________________________
relu_9 (LeakyReLU)           (None, 18, 18, 512)       0         
_________________________________________________________________
conv_10 (Conv2D)             (None, 18, 18, 256)       131328    
_________________________________________________________________
norm_10 (BatchNormalization) (None, 18, 18, 256)       1024      
_________________________________________________________________
relu_10 (LeakyReLU)          (None, 18, 18, 256)       0         
_________________________________________________________________
conv_11 (Conv2D)             (None, 18, 18, 512)       1180160   
_________________________________________________________________
norm_11 (BatchNormalization) (None, 18, 18, 512)       2048      
_________________________________________________________________
relu_11 (LeakyReLU)          (None, 18, 18, 512)       0         
_________________________________________________________________
conv_12 (Conv2D)             (None, 18, 18, 256)       131328    
_________________________________________________________________
norm_12 (BatchNormalization) (None, 18, 18, 256)       1024      
_________________________________________________________________
relu_12 (LeakyReLU)          (None, 18, 18, 256)       0         
_________________________________________________________________
conv_13 (Conv2D)             (None, 18, 18, 512)       1180160   
_________________________________________________________________
norm_13 (BatchNormalization) (None, 18, 18, 512)       2048      
_________________________________________________________________
relu_13 (LeakyReLU)          (None, 18, 18, 512)       0         
_________________________________________________________________
pool_5 (MaxPooling2D)        (None, 9, 9, 512)         0         
_________________________________________________________________
conv_14 (Conv2D)             (None, 9, 9, 1024)        4719616   
_________________________________________________________________
norm_14 (BatchNormalization) (None, 9, 9, 1024)        4096      
_________________________________________________________________
relu_14 (LeakyReLU)          (None, 9, 9, 1024)        0         
_________________________________________________________________
conv_15 (Conv2D)             (None, 9, 9, 1024)        9438208   
_________________________________________________________________
norm_15 (BatchNormalization) (None, 9, 9, 1024)        4096      
_________________________________________________________________
relu_15 (LeakyReLU)          (None, 9, 9, 1024)        0         
_________________________________________________________________
conv_16 (Conv2D)             (None, 9, 9, 5)           5125      
_________________________________________________________________
reshape_1 (Reshape)          (None, 9, 9, 5)           0         
=================================================================
Total params: 18,784,709
Trainable params: 18,774,405
Non-trainable params: 10,304
_________________________________________________________________
+----------+---------------------+----------------+---------------+--------------------+---------------------+---------------+
|  Epoch   |       f1_score      |      iou       |      loss     |     precision      |        recall       |    val_loss   |
+----------+---------------------+----------------+---------------+--------------------+---------------------+---------------+
| Epoch 1  |         nan         |      nan       | 22.9626569184 |        nan         |         0.0         | 19.0609328362 |
| Epoch 2  | 0.44863731656184486 | 0.643065609351 | 11.5342323738 | 0.5721925133689839 |  0.3689655172413793 |  10.796513619 |
| Epoch 3  |  0.5836177474402731 | 0.665379329663 | 8.27914799459 | 0.5777027027027027 |  0.5896551724137931 | 10.3999520271 |
| Epoch 4  |  0.6072727272727273 | 0.688567073926 | 6.82070188006 | 0.6423076923076924 |  0.5758620689655173 | 8.37512508515 |
| Epoch 5  |  0.5030674846625767 | 0.64025513616  | 5.91575251367 | 0.4530386740331492 |  0.5655172413793104 | 11.0313513356 |
| Epoch 6  |  0.6113207547169811 | 0.675196948887 | 5.17062627755 |       0.675        |  0.5586206896551724 | 10.0331977106 |
| Epoch 7  |  0.5186335403726707 | 0.65869218533  | 4.77557127836 | 0.4717514124293785 |  0.5758620689655173 | 12.3291352487 |
| Epoch 8  |  0.5684931506849314 | 0.668721261707 |  4.2840650781 | 0.564625850340136  |  0.5724137931034483 |  10.424481115 |
| Epoch 9  |  0.6348684210526315 | 0.65333155833  | 4.02593871284 | 0.6069182389937107 |  0.6655172413793103 | 9.64338793293 |
| Epoch 10 |  0.5513698630136987 | 0.644311186981 | 3.78778537329 | 0.5476190476190477 |  0.5551724137931034 | 9.74476986547 |
| Epoch 11 |  0.6129597197898423 | 0.661246395182 | 3.60782888484 | 0.6227758007117438 |  0.603448275862069  | 9.82931730824 |
| Epoch 12 |  0.6525285481239804 | 0.679800992537 | 3.35535511311 | 0.6191950464396285 |  0.6896551724137931 | 8.76861455364 |
| Epoch 13 | 0.43298969072164956 | 0.666423418316 | 3.45055314836 | 0.4315068493150685 | 0.43448275862068964 | 12.1665259023 |
| Epoch 14 |  0.5925925925925926 | 0.633678770346 | 3.69113016118 | 0.6064981949458483 |  0.5793103448275863 | 10.1953388952 |
| Epoch 15 |  0.6056074766355141 | 0.675548852685 | 3.15746780986 | 0.6612244897959184 |  0.5586206896551724 | 10.5645802713 |
| Epoch 16 |  0.584070796460177  | 0.672659652025 | 2.88127168809 |        0.6         |  0.5689655172413793 | 11.2647302228 |
| Epoch 17 |  0.5561312607944733 | 0.676146297702 | 2.69467222031 | 0.5570934256055363 |  0.5551724137931034 | 11.0089964405 |
| Epoch 18 |  0.6140939597315436 | 0.681274865619 | 2.73504942187 | 0.5980392156862745 |  0.6310344827586207 |  10.266713973 |
| Epoch 19 |  0.5677179962894248 | 0.688396166409 | 2.56825517963 | 0.6144578313253012 |  0.5275862068965518 | 11.6445431402 |
| Epoch 20 |  0.5508771929824562 | 0.64988273959  | 2.52312163952 | 0.5607142857142857 |  0.5413793103448276 |  11.365493313 |
| Epoch 21 |  0.584070796460177  | 0.698282400897 | 2.39468776923 |        0.6         |  0.5689655172413793 | 10.4663463254 |
| Epoch 22 |  0.5616883116883117 | 0.664148527488 | 2.35327932952 | 0.5306748466257669 |  0.596551724137931  | 12.2963667531 |
| Epoch 23 |  0.6308724832214765 | 0.678156730328 | 2.29333404928 | 0.6143790849673203 |  0.6482758620689655 | 10.1501777403 |
| Epoch 24 |  0.5503355704697986 | 0.681928001028 |  2.2471629748 | 0.5359477124183006 |  0.5655172413793104 |  12.063503573 |
| Epoch 25 |  0.5480572597137015 |  0.6998988589  | 2.02356857341 | 0.6733668341708543 | 0.46206896551724136 | 11.2202013077 |
| Epoch 26 |  0.6524064171122994 | 0.697543720548 | 2.07465288847 | 0.6752767527675276 |  0.6310344827586207 | 9.71799427463 |
| Epoch 27 |  0.5858951175406871 | 0.683732849389 | 2.05025714691 | 0.6159695817490495 |  0.5586206896551724 | 10.8534741248 |
| Epoch 28 |  0.556836902800659  | 0.687251912415 | 1.97451516742 | 0.5331230283911672 |  0.5827586206896552 | 11.7421976828 |
| Epoch 29 |  0.5270758122743682 | 0.689713999817 | 2.06985736966 | 0.553030303030303  |  0.503448275862069  | 12.7638198791 |
| Epoch 30 |  0.6029411764705882 | 0.707568582382 | 1.82184049031 | 0.6456692913385826 |  0.5655172413793104 | 10.5837245449 |
+----------+---------------------+----------------+---------------+--------------------+---------------------+---------------+
_________________________________________________________________
+---------------------------------+--------------------+--------------------+-----------------------+---------+-----------------------+
|            Optimizer            |       beta_1       |       beta_2       |         decay         | epsilon |           lr          |
+---------------------------------+--------------------+--------------------+-----------------------+---------+-----------------------+
| <class 'keras.optimizers.Adam'> | 0.8999999761581421 | 0.9990000128746033 | 9.999999974752427e-07 |  1e-08  | 0.0010000000474974513 |
+---------------------------------+--------------------+--------------------+-----------------------+---------+-----------------------+
_________________________________________________________________
+------------+
| Batch Size |
+------------+
|     16     |
+------------+
_________________________________________________________________
+--------------------+---------------+----------------+--------------------+--------------------+--------------------+
|      Metrics       |      Loss     |      IoU       |     Precision      |       Recall       |      F1 Score      |
+--------------------+---------------+----------------+--------------------+--------------------+--------------------+
|   Train Metrics    |  3.7807497954 | 0.840475236884 | 0.9502135448444173 | 0.9420517783692233 | 0.9461150598384059 |
| Validation Metrics | 20.9336309125 | 0.707568582382 | 0.6456692913385826 | 0.5655172413793104 | 0.6029411764705882 |
|    Test Metrics    | 22.4911932176 | 0.698478667327 | 0.6459143968871596 | 0.5372168284789643 | 0.5865724381625442 |
+--------------------+---------------+----------------+--------------------+--------------------+--------------------+
_________________________________________________________________
Time:
    Train Time              : 2:56:39.933449
    Dataset Loading Time    : 0:00:39.994361
    Metrics Evaluation Time : 0:07:02.140452
_________________________________________________________________
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         (None, 288, 288, 1)       0         
_________________________________________________________________
conv_1 (Conv2D)              (None, 288, 288, 32)      320       
_________________________________________________________________
norm_1 (BatchNormalization)  (None, 288, 288, 32)      128       
_________________________________________________________________
relu_1 (LeakyReLU)           (None, 288, 288, 32)      0         
_________________________________________________________________
pool_1 (MaxPooling2D)        (None, 144, 144, 32)      0         
_________________________________________________________________
conv_2 (Conv2D)              (None, 144, 144, 64)      18496     
_________________________________________________________________
norm_2 (BatchNormalization)  (None, 144, 144, 64)      256       
_________________________________________________________________
relu_2 (LeakyReLU)           (None, 144, 144, 64)      0         
_________________________________________________________________
pool_2 (MaxPooling2D)        (None, 72, 72, 64)        0         
_________________________________________________________________
conv_3 (Conv2D)              (None, 72, 72, 128)       73856     
_________________________________________________________________
norm_3 (BatchNormalization)  (None, 72, 72, 128)       512       
_________________________________________________________________
relu_3 (LeakyReLU)           (None, 72, 72, 128)       0         
_________________________________________________________________
drop_1 (Dropout)             (None, 72, 72, 128)       0         
_________________________________________________________________
conv_4 (Conv2D)              (None, 72, 72, 64)        8256      
_________________________________________________________________
norm_4 (BatchNormalization)  (None, 72, 72, 64)        256       
_________________________________________________________________
relu_4 (LeakyReLU)           (None, 72, 72, 64)        0         
_________________________________________________________________
drop_2 (Dropout)             (None, 72, 72, 64)        0         
_________________________________________________________________
conv_5 (Conv2D)              (None, 72, 72, 128)       73856     
_________________________________________________________________
norm_5 (BatchNormalization)  (None, 72, 72, 128)       512       
_________________________________________________________________
relu_5 (LeakyReLU)           (None, 72, 72, 128)       0         
_________________________________________________________________
pool_3 (MaxPooling2D)        (None, 36, 36, 128)       0         
_________________________________________________________________
conv_6 (Conv2D)              (None, 36, 36, 256)       295168    
_________________________________________________________________
norm_6 (BatchNormalization)  (None, 36, 36, 256)       1024      
_________________________________________________________________
relu_6 (LeakyReLU)           (None, 36, 36, 256)       0         
_________________________________________________________________
drop_3 (Dropout)             (None, 36, 36, 256)       0         
_________________________________________________________________
conv_7 (Conv2D)              (None, 36, 36, 128)       32896     
_________________________________________________________________
norm_7 (BatchNormalization)  (None, 36, 36, 128)       512       
_________________________________________________________________
relu_7 (LeakyReLU)           (None, 36, 36, 128)       0         
_________________________________________________________________
drop_4 (Dropout)             (None, 36, 36, 128)       0         
_________________________________________________________________
conv_8 (Conv2D)              (None, 36, 36, 256)       295168    
_________________________________________________________________
norm_8 (BatchNormalization)  (None, 36, 36, 256)       1024      
_________________________________________________________________
relu_8 (LeakyReLU)           (None, 36, 36, 256)       0         
_________________________________________________________________
pool_4 (MaxPooling2D)        (None, 18, 18, 256)       0         
_________________________________________________________________
conv_9 (Conv2D)              (None, 18, 18, 512)       1180160   
_________________________________________________________________
norm_9 (BatchNormalization)  (None, 18, 18, 512)       2048      
_________________________________________________________________
relu_9 (LeakyReLU)           (None, 18, 18, 512)       0         
_________________________________________________________________
drop_5 (Dropout)             (None, 18, 18, 512)       0         
_________________________________________________________________
conv_10 (Conv2D)             (None, 18, 18, 256)       131328    
_________________________________________________________________
norm_10 (BatchNormalization) (None, 18, 18, 256)       1024      
_________________________________________________________________
relu_10 (LeakyReLU)          (None, 18, 18, 256)       0         
_________________________________________________________________
drop_6 (Dropout)             (None, 18, 18, 256)       0         
_________________________________________________________________
conv_11 (Conv2D)             (None, 18, 18, 512)       1180160   
_________________________________________________________________
norm_11 (BatchNormalization) (None, 18, 18, 512)       2048      
_________________________________________________________________
relu_11 (LeakyReLU)          (None, 18, 18, 512)       0         
_________________________________________________________________
drop_7 (Dropout)             (None, 18, 18, 512)       0         
_________________________________________________________________
conv_12 (Conv2D)             (None, 18, 18, 256)       131328    
_________________________________________________________________
norm_12 (BatchNormalization) (None, 18, 18, 256)       1024      
_________________________________________________________________
relu_12 (LeakyReLU)          (None, 18, 18, 256)       0         
_________________________________________________________________
drop_8 (Dropout)             (None, 18, 18, 256)       0         
_________________________________________________________________
conv_13 (Conv2D)             (None, 18, 18, 512)       1180160   
_________________________________________________________________
norm_13 (BatchNormalization) (None, 18, 18, 512)       2048      
_________________________________________________________________
relu_13 (LeakyReLU)          (None, 18, 18, 512)       0         
_________________________________________________________________
pool_5 (MaxPooling2D)        (None, 9, 9, 512)         0         
_________________________________________________________________
conv_14 (Conv2D)             (None, 9, 9, 1024)        4719616   
_________________________________________________________________
norm_14 (BatchNormalization) (None, 9, 9, 1024)        4096      
_________________________________________________________________
relu_14 (LeakyReLU)          (None, 9, 9, 1024)        0         
_________________________________________________________________
drop_9 (Dropout)             (None, 9, 9, 1024)        0         
_________________________________________________________________
conv_15 (Conv2D)             (None, 9, 9, 1024)        9438208   
_________________________________________________________________
norm_15 (BatchNormalization) (None, 9, 9, 1024)        4096      
_________________________________________________________________
relu_15 (LeakyReLU)          (None, 9, 9, 1024)        0         
_________________________________________________________________
drop_10 (Dropout)            (None, 9, 9, 1024)        0         
_________________________________________________________________
conv_16 (Conv2D)             (None, 9, 9, 5)           5125      
_________________________________________________________________
reshape_1 (Reshape)          (None, 9, 9, 5)           0         
=================================================================
Total params: 18,784,709
Trainable params: 18,774,405
Non-trainable params: 10,304
_________________________________________________________________
+----------+----------+-----+------+-----------+--------+----------+
|  Epoch   | f1_score | iou | loss | precision | recall | val_loss |
+----------+----------+-----+------+-----------+--------+----------+
| Epoch 1  |   nan    | nan | nan  |    nan    |  0.0   |   nan    |
| Epoch 2  |   nan    | nan | nan  |    nan    |  0.0   |   nan    |
| Epoch 3  |   nan    | nan | nan  |    nan    |  0.0   |   nan    |
| Epoch 4  |   nan    | nan | nan  |    nan    |  0.0   |   nan    |
| Epoch 5  |   nan    | nan | nan  |    nan    |  0.0   |   nan    |
| Epoch 6  |   nan    | nan | nan  |    nan    |  0.0   |   nan    |
| Epoch 7  |   nan    | nan | nan  |    nan    |  0.0   |   nan    |
| Epoch 8  |   nan    | nan | nan  |    nan    |  0.0   |   nan    |
| Epoch 9  |   nan    | nan | nan  |    nan    |  0.0   |   nan    |
| Epoch 10 |   nan    | nan | nan  |    nan    |  0.0   |   nan    |
| Epoch 11 |   nan    | nan | nan  |    nan    |  0.0   |   nan    |
| Epoch 12 |   nan    | nan | nan  |    nan    |  0.0   |   nan    |
| Epoch 13 |   nan    | nan | nan  |    nan    |  0.0   |   nan    |
| Epoch 14 |   nan    | nan | nan  |    nan    |  0.0   |   nan    |
| Epoch 15 |   nan    | nan | nan  |    nan    |  0.0   |   nan    |
| Epoch 16 |   nan    | nan | nan  |    nan    |  0.0   |   nan    |
| Epoch 17 |   nan    | nan | nan  |    nan    |  0.0   |   nan    |
| Epoch 18 |   nan    | nan | nan  |    nan    |  0.0   |   nan    |
| Epoch 19 |   nan    | nan | nan  |    nan    |  0.0   |   nan    |
| Epoch 20 |   nan    | nan | nan  |    nan    |  0.0   |   nan    |
| Epoch 21 |   nan    | nan | nan  |    nan    |  0.0   |   nan    |
| Epoch 22 |   nan    | nan | nan  |    nan    |  0.0   |   nan    |
| Epoch 23 |   nan    | nan | nan  |    nan    |  0.0   |   nan    |
| Epoch 24 |   nan    | nan | nan  |    nan    |  0.0   |   nan    |
| Epoch 25 |   nan    | nan | nan  |    nan    |  0.0   |   nan    |
| Epoch 26 |   nan    | nan | nan  |    nan    |  0.0   |   nan    |
| Epoch 27 |   nan    | nan | nan  |    nan    |  0.0   |   nan    |
| Epoch 28 |   nan    | nan | nan  |    nan    |  0.0   |   nan    |
| Epoch 29 |   nan    | nan | nan  |    nan    |  0.0   |   nan    |
| Epoch 30 |   nan    | nan | nan  |    nan    |  0.0   |   nan    |
+----------+----------+-----+------+-----------+--------+----------+
_________________________________________________________________
+---------------------------------+--------------------+--------------------+-----------------------+---------+-----------------------+
|            Optimizer            |       beta_1       |       beta_2       |         decay         | epsilon |           lr          |
+---------------------------------+--------------------+--------------------+-----------------------+---------+-----------------------+
| <class 'keras.optimizers.Adam'> | 0.8999999761581421 | 0.9990000128746033 | 0.0005000000237487257 |  1e-08  | 0.0010000000474974513 |
+---------------------------------+--------------------+--------------------+-----------------------+---------+-----------------------+
_________________________________________________________________
+------------+
| Batch Size |
+------------+
|     16     |
+------------+
_________________________________________________________________
+--------------------+------+-----+-----------+--------+----------+
|      Metrics       | Loss | IoU | Precision | Recall | F1 Score |
+--------------------+------+-----+-----------+--------+----------+
|   Train Metrics    | nan  | nan |    nan    |  0.0   |   nan    |
| Validation Metrics | nan  | nan |    nan    |  0.0   |   nan    |
|    Test Metrics    | nan  | nan |    nan    |  0.0   |   nan    |
+--------------------+------+-----+-----------+--------+----------+
_________________________________________________________________
Time:
    Train Time              : 3:01:03.289623
    Dataset Loading Time    : 0:00:37.623257
    Metrics Evaluation Time : 0:05:56.397286
_________________________________________________________________
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         (None, 288, 288, 1)       0         
_________________________________________________________________
conv_1 (Conv2D)              (None, 288, 288, 32)      320       
_________________________________________________________________
norm_1 (BatchNormalization)  (None, 288, 288, 32)      128       
_________________________________________________________________
relu_1 (LeakyReLU)           (None, 288, 288, 32)      0         
_________________________________________________________________
pool_1 (MaxPooling2D)        (None, 144, 144, 32)      0         
_________________________________________________________________
conv_2 (Conv2D)              (None, 144, 144, 64)      18496     
_________________________________________________________________
norm_2 (BatchNormalization)  (None, 144, 144, 64)      256       
_________________________________________________________________
relu_2 (LeakyReLU)           (None, 144, 144, 64)      0         
_________________________________________________________________
pool_2 (MaxPooling2D)        (None, 72, 72, 64)        0         
_________________________________________________________________
conv_3 (Conv2D)              (None, 72, 72, 128)       73856     
_________________________________________________________________
norm_3 (BatchNormalization)  (None, 72, 72, 128)       512       
_________________________________________________________________
relu_3 (LeakyReLU)           (None, 72, 72, 128)       0         
_________________________________________________________________
drop_1 (Dropout)             (None, 72, 72, 128)       0         
_________________________________________________________________
conv_4 (Conv2D)              (None, 72, 72, 64)        8256      
_________________________________________________________________
norm_4 (BatchNormalization)  (None, 72, 72, 64)        256       
_________________________________________________________________
relu_4 (LeakyReLU)           (None, 72, 72, 64)        0         
_________________________________________________________________
drop_2 (Dropout)             (None, 72, 72, 64)        0         
_________________________________________________________________
conv_5 (Conv2D)              (None, 72, 72, 128)       73856     
_________________________________________________________________
norm_5 (BatchNormalization)  (None, 72, 72, 128)       512       
_________________________________________________________________
relu_5 (LeakyReLU)           (None, 72, 72, 128)       0         
_________________________________________________________________
pool_3 (MaxPooling2D)        (None, 36, 36, 128)       0         
_________________________________________________________________
conv_6 (Conv2D)              (None, 36, 36, 256)       295168    
_________________________________________________________________
norm_6 (BatchNormalization)  (None, 36, 36, 256)       1024      
_________________________________________________________________
relu_6 (LeakyReLU)           (None, 36, 36, 256)       0         
_________________________________________________________________
drop_3 (Dropout)             (None, 36, 36, 256)       0         
_________________________________________________________________
conv_7 (Conv2D)              (None, 36, 36, 128)       32896     
_________________________________________________________________
norm_7 (BatchNormalization)  (None, 36, 36, 128)       512       
_________________________________________________________________
relu_7 (LeakyReLU)           (None, 36, 36, 128)       0         
_________________________________________________________________
drop_4 (Dropout)             (None, 36, 36, 128)       0         
_________________________________________________________________
conv_8 (Conv2D)              (None, 36, 36, 256)       295168    
_________________________________________________________________
norm_8 (BatchNormalization)  (None, 36, 36, 256)       1024      
_________________________________________________________________
relu_8 (LeakyReLU)           (None, 36, 36, 256)       0         
_________________________________________________________________
pool_4 (MaxPooling2D)        (None, 18, 18, 256)       0         
_________________________________________________________________
conv_9 (Conv2D)              (None, 18, 18, 512)       1180160   
_________________________________________________________________
norm_9 (BatchNormalization)  (None, 18, 18, 512)       2048      
_________________________________________________________________
relu_9 (LeakyReLU)           (None, 18, 18, 512)       0         
_________________________________________________________________
drop_5 (Dropout)             (None, 18, 18, 512)       0         
_________________________________________________________________
conv_10 (Conv2D)             (None, 18, 18, 256)       131328    
_________________________________________________________________
norm_10 (BatchNormalization) (None, 18, 18, 256)       1024      
_________________________________________________________________
relu_10 (LeakyReLU)          (None, 18, 18, 256)       0         
_________________________________________________________________
drop_6 (Dropout)             (None, 18, 18, 256)       0         
_________________________________________________________________
conv_11 (Conv2D)             (None, 18, 18, 512)       1180160   
_________________________________________________________________
norm_11 (BatchNormalization) (None, 18, 18, 512)       2048      
_________________________________________________________________
relu_11 (LeakyReLU)          (None, 18, 18, 512)       0         
_________________________________________________________________
drop_7 (Dropout)             (None, 18, 18, 512)       0         
_________________________________________________________________
conv_12 (Conv2D)             (None, 18, 18, 256)       131328    
_________________________________________________________________
norm_12 (BatchNormalization) (None, 18, 18, 256)       1024      
_________________________________________________________________
relu_12 (LeakyReLU)          (None, 18, 18, 256)       0         
_________________________________________________________________
drop_8 (Dropout)             (None, 18, 18, 256)       0         
_________________________________________________________________
conv_13 (Conv2D)             (None, 18, 18, 512)       1180160   
_________________________________________________________________
norm_13 (BatchNormalization) (None, 18, 18, 512)       2048      
_________________________________________________________________
relu_13 (LeakyReLU)          (None, 18, 18, 512)       0         
_________________________________________________________________
pool_5 (MaxPooling2D)        (None, 9, 9, 512)         0         
_________________________________________________________________
conv_14 (Conv2D)             (None, 9, 9, 1024)        4719616   
_________________________________________________________________
norm_14 (BatchNormalization) (None, 9, 9, 1024)        4096      
_________________________________________________________________
relu_14 (LeakyReLU)          (None, 9, 9, 1024)        0         
_________________________________________________________________
drop_9 (Dropout)             (None, 9, 9, 1024)        0         
_________________________________________________________________
conv_15 (Conv2D)             (None, 9, 9, 1024)        9438208   
_________________________________________________________________
norm_15 (BatchNormalization) (None, 9, 9, 1024)        4096      
_________________________________________________________________
relu_15 (LeakyReLU)          (None, 9, 9, 1024)        0         
_________________________________________________________________
drop_10 (Dropout)            (None, 9, 9, 1024)        0         
_________________________________________________________________
conv_16 (Conv2D)             (None, 9, 9, 5)           5125      
_________________________________________________________________
reshape_1 (Reshape)          (None, 9, 9, 5)           0         
=================================================================
Total params: 18,784,709
Trainable params: 18,774,405
Non-trainable params: 10,304
_________________________________________________________________
+----------+----------------------+----------------+---------------+----------------------+-----------------------+---------------+
|  Epoch   |       f1_score       |      iou       |      loss     |      precision       |         recall        |    val_loss   |
+----------+----------------------+----------------+---------------+----------------------+-----------------------+---------------+
| Epoch 1  |         nan          |      nan       | 72.7441007335 |         nan          |          0.0          |  47.486341661 |
| Epoch 2  |         nan          |      nan       | 40.9582324314 |         nan          |          0.0          | 44.2237404854 |
| Epoch 3  |         nan          |      nan       | 37.0844963699 |         nan          |          0.0          |  50.416921431 |
| Epoch 4  |         nan          |      nan       | 34.6333402052 |         nan          |          0.0          | 55.4129536536 |
| Epoch 5  |         nan          |      nan       | 32.9848606177 |         nan          |          0.0          |  51.880636892 |
| Epoch 6  |         nan          |      nan       | 30.5062248991 |         nan          |          0.0          | 38.9486117209 |
| Epoch 7  |         nan          |      nan       | 27.3955569328 |         nan          |          0.0          | 33.1321438205 |
| Epoch 8  |         nan          |      nan       | 25.0980061533 |         nan          |          0.0          | 22.6125935585 |
| Epoch 9  | 0.004889975550122249 | 0.543986021902 | 23.0243555345 | 0.008403361344537815 | 0.0034482758620689655 | 15.8369731595 |
| Epoch 10 | 0.037243947858472994 | 0.527913843123 |  22.153029799 | 0.04048582995951417  |  0.034482758620689655 |  17.446919472 |
| Epoch 11 |         nan          |      nan       | 21.3202871942 |         0.0          |          0.0          |  22.114675768 |
| Epoch 12 |         nan          |      nan       |  20.90421305  |         0.0          |          0.0          | 22.8628492048 |
| Epoch 13 |         nan          |      nan       | 20.4587426955 |         0.0          |          0.0          | 26.2416193562 |
| Epoch 14 |         nan          |      nan       | 20.0539997662 |         0.0          |          0.0          | 24.8921536476 |
| Epoch 15 |         nan          |      nan       |  19.73295549  |         0.0          |          0.0          | 27.2690126973 |
| Epoch 16 |         nan          |      nan       | 19.4840593491 |         0.0          |          0.0          | 28.7493668833 |
| Epoch 17 |         nan          |      nan       | 18.9811168035 |         0.0          |          0.0          | 33.5689213045 |
| Epoch 18 |         nan          |      nan       | 18.5093200374 |         0.0          |          0.0          | 35.6902911279 |
| Epoch 19 |         nan          |      nan       | 18.2512930477 |         0.0          |          0.0          | 34.6916159353 |
| Epoch 20 |         nan          |      nan       | 18.0116947703 |         0.0          |          0.0          | 35.8080238835 |
| Epoch 21 |         nan          |      nan       | 17.7555566886 |         0.0          |          0.0          | 34.7484709832 |
| Epoch 22 |         nan          |      nan       | 17.5677862772 |         0.0          |          0.0          |  34.091212611 |
| Epoch 23 |         nan          |      nan       | 17.3694962834 |         0.0          |          0.0          | 34.4454424458 |
| Epoch 24 |         nan          |      nan       | 17.2525188554 |         0.0          |          0.0          | 32.3148078918 |
| Epoch 25 |         nan          |      nan       | 17.1183428889 |         0.0          |          0.0          | 32.0161503823 |
| Epoch 26 |         nan          |      nan       | 16.8634695648 |         0.0          |          0.0          | 31.5923381928 |
| Epoch 27 |         nan          |      nan       | 16.7698395077 |         0.0          |          0.0          | 30.8748513499 |
| Epoch 28 |         nan          |      nan       | 16.5663091453 |         0.0          |          0.0          | 27.9166750754 |
| Epoch 29 |         nan          |      nan       | 16.4364238313 |         0.0          |          0.0          | 28.0462620028 |
| Epoch 30 |         nan          |      nan       | 16.2711526527 |         0.0          |          0.0          | 29.0985786069 |
+----------+----------------------+----------------+---------------+----------------------+-----------------------+---------------+
_________________________________________________________________
+---------------------------------+--------------------+--------------------+-----------------------+---------+-----------------------+
|            Optimizer            |       beta_1       |       beta_2       |         decay         | epsilon |           lr          |
+---------------------------------+--------------------+--------------------+-----------------------+---------+-----------------------+
| <class 'keras.optimizers.Adam'> | 0.8999999761581421 | 0.9990000128746033 | 0.0005000000237487257 |  1e-08  | 9.999999747378752e-05 |
+---------------------------------+--------------------+--------------------+-----------------------+---------+-----------------------+
_________________________________________________________________
+------------+
| Batch Size |
+------------+
|     16     |
+------------+
_________________________________________________________________
+--------------------+---------------+---------------+----------------------+----------------------+----------------------+
|      Metrics       |      Loss     |      IoU      |      Precision       |        Recall        |       F1 Score       |
+--------------------+---------------+---------------+----------------------+----------------------+----------------------+
|   Train Metrics    | 123.782277472 | 0.59691255075 | 0.004015215553677092 | 0.002298572465521413 | 0.002923526696414833 |
| Validation Metrics | 58.0851420741 |      nan      |         0.0          |         0.0          |         nan          |
|    Test Metrics    | 65.3172047523 |      nan      |         0.0          |         0.0          |         nan          |
+--------------------+---------------+---------------+----------------------+----------------------+----------------------+
_________________________________________________________________
Time:
    Train Time              : 3:05:26.861097
    Dataset Loading Time    : 0:00:38.774332
    Metrics Evaluation Time : 0:06:06.871085
_________________________________________________________________
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         (None, 288, 288, 1)       0         
_________________________________________________________________
conv_1 (Conv2D)              (None, 288, 288, 32)      320       
_________________________________________________________________
norm_1 (BatchNormalization)  (None, 288, 288, 32)      128       
_________________________________________________________________
relu_1 (LeakyReLU)           (None, 288, 288, 32)      0         
_________________________________________________________________
pool_1 (MaxPooling2D)        (None, 144, 144, 32)      0         
_________________________________________________________________
conv_2 (Conv2D)              (None, 144, 144, 64)      18496     
_________________________________________________________________
norm_2 (BatchNormalization)  (None, 144, 144, 64)      256       
_________________________________________________________________
relu_2 (LeakyReLU)           (None, 144, 144, 64)      0         
_________________________________________________________________
pool_2 (MaxPooling2D)        (None, 72, 72, 64)        0         
_________________________________________________________________
conv_3 (Conv2D)              (None, 72, 72, 128)       73856     
_________________________________________________________________
norm_3 (BatchNormalization)  (None, 72, 72, 128)       512       
_________________________________________________________________
relu_3 (LeakyReLU)           (None, 72, 72, 128)       0         
_________________________________________________________________
drop_1 (Dropout)             (None, 72, 72, 128)       0         
_________________________________________________________________
conv_4 (Conv2D)              (None, 72, 72, 64)        8256      
_________________________________________________________________
norm_4 (BatchNormalization)  (None, 72, 72, 64)        256       
_________________________________________________________________
relu_4 (LeakyReLU)           (None, 72, 72, 64)        0         
_________________________________________________________________
drop_2 (Dropout)             (None, 72, 72, 64)        0         
_________________________________________________________________
conv_5 (Conv2D)              (None, 72, 72, 128)       73856     
_________________________________________________________________
norm_5 (BatchNormalization)  (None, 72, 72, 128)       512       
_________________________________________________________________
relu_5 (LeakyReLU)           (None, 72, 72, 128)       0         
_________________________________________________________________
pool_3 (MaxPooling2D)        (None, 36, 36, 128)       0         
_________________________________________________________________
conv_6 (Conv2D)              (None, 36, 36, 256)       295168    
_________________________________________________________________
norm_6 (BatchNormalization)  (None, 36, 36, 256)       1024      
_________________________________________________________________
relu_6 (LeakyReLU)           (None, 36, 36, 256)       0         
_________________________________________________________________
drop_3 (Dropout)             (None, 36, 36, 256)       0         
_________________________________________________________________
conv_7 (Conv2D)              (None, 36, 36, 128)       32896     
_________________________________________________________________
norm_7 (BatchNormalization)  (None, 36, 36, 128)       512       
_________________________________________________________________
relu_7 (LeakyReLU)           (None, 36, 36, 128)       0         
_________________________________________________________________
drop_4 (Dropout)             (None, 36, 36, 128)       0         
_________________________________________________________________
conv_8 (Conv2D)              (None, 36, 36, 256)       295168    
_________________________________________________________________
norm_8 (BatchNormalization)  (None, 36, 36, 256)       1024      
_________________________________________________________________
relu_8 (LeakyReLU)           (None, 36, 36, 256)       0         
_________________________________________________________________
pool_4 (MaxPooling2D)        (None, 18, 18, 256)       0         
_________________________________________________________________
conv_9 (Conv2D)              (None, 18, 18, 512)       1180160   
_________________________________________________________________
norm_9 (BatchNormalization)  (None, 18, 18, 512)       2048      
_________________________________________________________________
relu_9 (LeakyReLU)           (None, 18, 18, 512)       0         
_________________________________________________________________
drop_5 (Dropout)             (None, 18, 18, 512)       0         
_________________________________________________________________
conv_10 (Conv2D)             (None, 18, 18, 256)       131328    
_________________________________________________________________
norm_10 (BatchNormalization) (None, 18, 18, 256)       1024      
_________________________________________________________________
relu_10 (LeakyReLU)          (None, 18, 18, 256)       0         
_________________________________________________________________
drop_6 (Dropout)             (None, 18, 18, 256)       0         
_________________________________________________________________
conv_11 (Conv2D)             (None, 18, 18, 512)       1180160   
_________________________________________________________________
norm_11 (BatchNormalization) (None, 18, 18, 512)       2048      
_________________________________________________________________
relu_11 (LeakyReLU)          (None, 18, 18, 512)       0         
_________________________________________________________________
drop_7 (Dropout)             (None, 18, 18, 512)       0         
_________________________________________________________________
conv_12 (Conv2D)             (None, 18, 18, 256)       131328    
_________________________________________________________________
norm_12 (BatchNormalization) (None, 18, 18, 256)       1024      
_________________________________________________________________
relu_12 (LeakyReLU)          (None, 18, 18, 256)       0         
_________________________________________________________________
drop_8 (Dropout)             (None, 18, 18, 256)       0         
_________________________________________________________________
conv_13 (Conv2D)             (None, 18, 18, 512)       1180160   
_________________________________________________________________
norm_13 (BatchNormalization) (None, 18, 18, 512)       2048      
_________________________________________________________________
relu_13 (LeakyReLU)          (None, 18, 18, 512)       0         
_________________________________________________________________
pool_5 (MaxPooling2D)        (None, 9, 9, 512)         0         
_________________________________________________________________
conv_14 (Conv2D)             (None, 9, 9, 1024)        4719616   
_________________________________________________________________
norm_14 (BatchNormalization) (None, 9, 9, 1024)        4096      
_________________________________________________________________
relu_14 (LeakyReLU)          (None, 9, 9, 1024)        0         
_________________________________________________________________
drop_9 (Dropout)             (None, 9, 9, 1024)        0         
_________________________________________________________________
conv_15 (Conv2D)             (None, 9, 9, 1024)        9438208   
_________________________________________________________________
norm_15 (BatchNormalization) (None, 9, 9, 1024)        4096      
_________________________________________________________________
relu_15 (LeakyReLU)          (None, 9, 9, 1024)        0         
_________________________________________________________________
drop_10 (Dropout)            (None, 9, 9, 1024)        0         
_________________________________________________________________
conv_16 (Conv2D)             (None, 9, 9, 5)           5125      
_________________________________________________________________
reshape_1 (Reshape)          (None, 9, 9, 5)           0         
=================================================================
Total params: 18,784,709
Trainable params: 18,774,405
Non-trainable params: 10,304
_________________________________________________________________
+-----------+-----------------------+----------------+---------------+-----------------------+-----------------------+---------------+
|   Epoch   |        f1_score       |      iou       |      loss     |       precision       |         recall        |    val_loss   |
+-----------+-----------------------+----------------+---------------+-----------------------+-----------------------+---------------+
|  Epoch 1  |          nan          |      nan       | 68.4795827535 |          nan          |          0.0          | 36.0695204581 |
|  Epoch 2  |          nan          |      nan       | 41.4238539798 |          nan          |          0.0          | 39.9572926183 |
|  Epoch 3  |          nan          |      nan       | 37.2092883706 |          nan          |          0.0          | 39.7500258415 |
|  Epoch 4  |          nan          |      nan       | 34.4782207808 |          nan          |          0.0          |  41.187026793 |
|  Epoch 5  |          nan          |      nan       | 30.6494854325 |          nan          |          0.0          | 42.2969012722 |
|  Epoch 6  |          nan          |      nan       | 28.6555462706 |          nan          |          0.0          | 42.9584357969 |
|  Epoch 7  |          nan          |      nan       | 27.0674734124 |          nan          |          0.0          | 44.4941433322 |
|  Epoch 8  |          nan          |      nan       | 25.6735163323 |          nan          |          0.0          | 46.1276298646 |
|  Epoch 9  |          nan          |      nan       | 23.6557565933 |          nan          |          0.0          | 30.5022771897 |
|  Epoch 10 |          nan          |      nan       |  22.048131314 |          nan          |          0.0          | 16.2593027546 |
|  Epoch 11 |          nan          |      nan       | 21.3382355367 |          0.0          |          0.0          | 20.0695598356 |
|  Epoch 12 |          nan          |      nan       | 20.7152533011 |          0.0          |          0.0          | 24.2933344072 |
|  Epoch 13 |          nan          |      nan       | 20.4026620789 |          0.0          |          0.0          | 29.0471164949 |
|  Epoch 14 |          nan          |      nan       | 19.9106159694 |          0.0          |          0.0          | 33.5343702993 |
|  Epoch 15 |          nan          |      nan       | 19.5764975286 |          0.0          |          0.0          |  35.181329358 |
|  Epoch 16 |          nan          |      nan       | 19.3062071345 |          0.0          |          0.0          | 35.1796413545 |
|  Epoch 17 |          nan          |      nan       | 19.0319319868 |          0.0          |          0.0          | 35.1725281746 |
|  Epoch 18 |          nan          |      nan       | 18.7714291473 |          0.0          |          0.0          | 34.9337173585 |
|  Epoch 19 |          nan          |      nan       |  18.495373272 |          0.0          |          0.0          | 37.0935854758 |
|  Epoch 20 |          nan          |      nan       | 18.2691081064 |          0.0          |          0.0          | 35.4716524924 |
|  Epoch 21 |          nan          |      nan       | 18.1440213994 |          0.0          |          0.0          | 36.5915846671 |
|  Epoch 22 |          nan          |      nan       | 18.0559543664 |          0.0          |          0.0          | 37.3152011133 |
|  Epoch 23 |          nan          |      nan       | 17.8106686728 |          0.0          |          0.0          | 36.8784780195 |
|  Epoch 24 |          nan          |      nan       | 17.7253170868 |          0.0          |          0.0          | 38.6648344224 |
|  Epoch 25 |          nan          |      nan       | 17.5724183886 |          0.0          |          0.0          | 37.4742293819 |
|  Epoch 26 |          nan          |      nan       | 17.4647582192 |          0.0          |          0.0          | 36.8996001213 |
|  Epoch 27 |          nan          |      nan       | 17.3163019085 |          0.0          |          0.0          | 36.3512110556 |
|  Epoch 28 |          nan          |      nan       | 17.1618310843 |          0.0          |          0.0          |  37.593670322 |
|  Epoch 29 |          nan          |      nan       | 17.0728945615 |          0.0          |          0.0          | 37.4365244219 |
|  Epoch 30 |          nan          |      nan       | 16.9975365657 |          0.0          |          0.0          | 38.2941356782 |
|  Epoch 31 |          nan          |      nan       | 16.8987297613 |          0.0          |          0.0          | 33.3128628269 |
|  Epoch 32 |          nan          |      nan       | 16.6482105803 |          0.0          |          0.0          | 34.4196699819 |
|  Epoch 33 |          nan          |      nan       | 16.5086885897 |          0.0          |          0.0          | 37.5586194684 |
|  Epoch 34 |          nan          |      nan       | 16.4856825818 |          0.0          |          0.0          | 35.2403671511 |
|  Epoch 35 |  0.005235602094240837 | 0.568986711221 |  16.326960708 |  0.004219409282700422 |  0.006896551724137931 | 33.0146931064 |
|  Epoch 36 |  0.005689900426742531 | 0.557039043999 | 16.1322916592 |  0.004842615012106538 |  0.006896551724137931 | 30.2820876952 |
|  Epoch 37 | 0.0023094688221709007 | 0.640260884023 | 16.0088804056 |  0.001736111111111111 | 0.0034482758620689655 | 33.5459982349 |
|  Epoch 38 |  0.00199203187250996  | 0.578694513431 | 15.8395767841 | 0.0014005602240896359 | 0.0034482758620689655 | 36.8685151992 |
|  Epoch 39 |  0.013875123885034688 | 0.550023562485 | 15.8019863376 |  0.009735744089012517 |  0.02413793103448276  | 34.4817146793 |
|  Epoch 40 |  0.015841584158415842 | 0.541866450242 | 15.6809217867 |  0.011111111111111112 |  0.027586206896551724 | 32.9983260862 |
|  Epoch 41 |  0.034224598930481284 | 0.554580954722 | 15.5307182399 |  0.024806201550387597 |  0.05517241379310345  | 29.0764866491 |
|  Epoch 42 |  0.014042126379137413 | 0.557583664509 | 15.3185900965 |  0.009900990099009901 |  0.02413793103448276  | 33.1279666039 |
|  Epoch 43 |  0.025806451612903226 | 0.550373552426 | 15.2304515661 |  0.01761006289308176  |  0.04827586206896552  | 34.1963580962 |
|  Epoch 44 |  0.023593466424682397 | 0.548870975837 | 15.1352511504 |  0.01600985221674877  |  0.04482758620689655  | 35.2096657292 |
|  Epoch 45 |  0.03412322274881517  | 0.548993662639 | 15.0705848849 |  0.023529411764705882 |  0.06206896551724138  |  32.792955337 |
|  Epoch 46 |  0.04747162022703818  | 0.552316883834 | 14.9515863839 |  0.033873343151693665 |  0.07931034482758621  | 28.9394138705 |
|  Epoch 47 |  0.06991720331186753  | 0.576969894898 | 14.7740422359 |  0.04767879548306148  |   0.1310344827586207  | 30.5695264878 |
|  Epoch 48 |  0.06751824817518248  | 0.578649334967 | 14.7177116841 |  0.04590570719602978  |  0.12758620689655173  | 30.8801730987 |
|  Epoch 49 |  0.04887218045112782  | 0.572325127736 | 14.6692079325 |  0.03359173126614987  |   0.0896551724137931  | 30.1101489529 |
|  Epoch 50 |  0.09247506799637352  | 0.590624558754 | 14.5717708285 |  0.06273062730627306  |  0.17586206896551723  |  30.729321449 |
|  Epoch 51 |  0.07296538821328344  | 0.58200079331  | 14.5096223062 |  0.05006418485237484  |  0.13448275862068965  | 29.7622507772 |
|  Epoch 52 |   0.1110065851364064  | 0.584419464662 | 14.4466780568 |  0.07632600258732213  |  0.20344827586206896  | 28.7216137302 |
|  Epoch 53 |   0.0851063829787234  | 0.564757294967 | 14.3510092415 |  0.05815423514538559  |  0.15862068965517243  | 30.4211807866 |
|  Epoch 54 |   0.1424446583253128  | 0.595888916841 | 14.2575696283 |  0.09879839786381843  |  0.25517241379310346  | 27.5558720866 |
|  Epoch 55 |  0.20202020202020202  | 0.594078859321 |  14.265139666 |   0.1376720901126408  |   0.3793103448275862  | 27.9039670267 |
|  Epoch 56 |  0.17463235294117643  | 0.594937195191 | 14.1422201481 |  0.11904761904761904  |   0.3275862068965517  | 28.1978880359 |
|  Epoch 57 |   0.1636520241171404  | 0.596664412007 | 14.0627634382 |  0.10907003444316878  |   0.3275862068965517  | 32.0599765778 |
|  Epoch 58 |  0.17502278942570645  | 0.598236120662 |  13.996032257 |  0.11895910780669144  |   0.3310344827586207  | 28.0652415368 |
|  Epoch 59 |  0.20821917808219176  | 0.597047735721 | 13.9891549463 |  0.14161490683229813  |   0.3931034482758621  | 28.2580088339 |
|  Epoch 60 |  0.22792022792022792  | 0.598745060855 |  13.970763612 |  0.15727391874180865  |  0.41379310344827586  |  26.103816863 |
|  Epoch 61 |  0.22103386809269163  | 0.601568026182 | 13.8077023531 |  0.14903846153846154  |  0.42758620689655175  | 28.6341704707 |
|  Epoch 62 |  0.20995475113122175  | 0.601217940339 | 13.8325470338 |   0.1423312883435583  |          0.4          |  27.059278242 |
|  Epoch 63 |  0.22325581395348834  | 0.609382165961 | 13.7298727991 |  0.15286624203821655  |  0.41379310344827586  | 25.8755742965 |
|  Epoch 64 |   0.2148471615720524  | 0.626442371304 | 13.6585139656 |  0.14385964912280702  |   0.4241379310344828  | 28.9644861529 |
|  Epoch 65 |  0.22683982683982687  | 0.631435990108 | 13.6915409801 |  0.15144508670520232  |   0.4517241379310345  | 29.4718872809 |
|  Epoch 66 |  0.23893805309734512  | 0.612757385235 | 13.6329239759 |  0.16071428571428573  |  0.46551724137931033  | 28.1346131602 |
|  Epoch 67 |  0.23076923076923075  | 0.625251605739 | 13.5649947733 |  0.15579710144927536  |  0.44482758620689655  |  28.172635909 |
|  Epoch 68 |  0.24770642201834864  | 0.620565101234 | 13.4901527516 |        0.16875        |  0.46551724137931033  |  26.250406819 |
|  Epoch 69 |  0.24049513704686118  | 0.627118744472 |  13.373934926 |  0.16171224732461356  |   0.4689655172413793  | 27.1936228352 |
|  Epoch 70 |  0.24489795918367344  | 0.644383716943 | 13.4299019308 |  0.16487455197132617  |  0.47586206896551725  |  28.890592452 |
|  Epoch 71 |  0.25626740947075205  | 0.646019824483 | 13.3204112283 |  0.17534942820838628  |  0.47586206896551725  | 27.0210015082 |
|  Epoch 72 |  0.25444340505144997  | 0.648462233928 |  13.341761797 |  0.17458279845956354  |   0.4689655172413793  | 26.9825983355 |
|  Epoch 73 |  0.25183823529411764  | 0.652068070525 | 13.3015122369 |  0.17167919799498746  |   0.4724137931034483  | 27.2829065631 |
|  Epoch 74 |  0.26235399820305483  | 0.654108788676 | 13.2468005001 |  0.17739975698663427  |   0.503448275862069   |  29.320568823 |
|  Epoch 75 |   0.2554399243140965  | 0.652726374661 | 13.1879681533 |   0.1760104302477184  |  0.46551724137931033  |  25.397731658 |
|  Epoch 76 |   0.2438580527752502  | 0.652089457993 | 13.1057054865 |  0.16563658838071693  |  0.46206896551724136  | 27.4370546649 |
|  Epoch 77 |  0.24007386888273316  | 0.646610422385 | 13.1075818609 |  0.16393442622950818  |   0.4482758620689655  | 26.8860124157 |
|  Epoch 78 |  0.23681776133209992  | 0.647079272161 | 13.0955721419 |  0.16182048040455121  |   0.4413793103448276  | 26.5507760817 |
|  Epoch 79 |  0.24909747292418774  | 0.649448444865 | 13.0112104472 |   0.1687041564792176  |  0.47586206896551725  | 27.6830191458 |
|  Epoch 80 |  0.25443786982248523  | 0.658362992579 | 12.9877526694 |   0.1781767955801105  |  0.44482758620689655  | 24.4430095303 |
|  Epoch 81 |  0.27631578947368424  | 0.648069485334 | 12.9615490946 |  0.18992248062015504  |   0.506896551724138   | 26.1737525079 |
|  Epoch 82 |  0.26478873239436623  | 0.651741989891 |  12.920444058 |  0.18193548387096775  |   0.4862068965517241  | 25.6119080205 |
|  Epoch 83 |   0.2774451097804392  | 0.65302979047  | 12.8751600762 |   0.1952247191011236  |   0.4793103448275862  | 24.1364507983 |
|  Epoch 84 |   0.2711864406779661  | 0.653542771212 | 12.8570233931 |  0.19074333800841514  |   0.4689655172413793  |  24.072355455 |
|  Epoch 85 |  0.27988338192419826  | 0.648269533728 | 12.8858182662 |  0.19485791610284167  |   0.496551724137931   | 24.9475360993 |
|  Epoch 86 |  0.28087649402390436  | 0.652682728416 | 12.7572727671 |  0.19747899159663865  |   0.4862068965517241  | 23.4916860519 |
|  Epoch 87 |   0.2911266201395813  | 0.654204637624 | 12.7425253393 |  0.20476858345021037  |   0.503448275862069   | 23.5618480559 |
|  Epoch 88 |   0.273339749759384   | 0.644249819932 | 12.6632188416 |  0.18958611481975968  |   0.4896551724137931  | 24.6471960006 |
|  Epoch 89 |  0.27436140018921473  | 0.648443470673 | 12.5930404276 |  0.18904823989569752  |          0.5          | 25.4356119094 |
|  Epoch 90 |  0.26433430515063167  | 0.651824146679 |  12.645979924 |  0.18403247631935046  |   0.4689655172413793  | 24.5055732727 |
|  Epoch 91 |   0.267591674925669   | 0.654934753485 | 12.6853463027 |  0.18776077885952713  |  0.46551724137931033  |  23.658659289 |
|  Epoch 92 |   0.2527363184079602  |  0.6534841762  | 12.5855095098 |  0.17762237762237762  |   0.4379310344827586  | 23.9573981377 |
|  Epoch 93 |    0.24953095684803   | 0.649055176759 | 12.5579727444 |   0.1713917525773196  |   0.4586206896551724  |  26.283844794 |
|  Epoch 94 |   0.2688588007736944  | 0.651756581974 |  12.545275926 |   0.1868279569892473  |   0.4793103448275862  | 24.6247378319 |
|  Epoch 95 |   0.273190621814475   | 0.646792519775 |  12.501424546 |   0.1939218523878437  |  0.46206896551724136  | 23.3335257499 |
|  Epoch 96 |   0.2841880341880342  | 0.647442037252 | 12.5152542811 |  0.20588235294117646  |   0.4586206896551724  | 21.9232160507 |
|  Epoch 97 |   0.2669404517453799  | 0.645370140333 | 12.3867056251 |  0.19005847953216373  |   0.4482758620689655  |  22.724344069 |
|  Epoch 98 |   0.2630992196209588  | 0.652184929483 | 12.3566000238 |  0.19439868204283361  |   0.4068965517241379  | 21.2435438095 |
|  Epoch 99 |   0.2641509433962264  | 0.645506520861 | 12.2571364916 |   0.1897590361445783  |  0.43448275862068964  | 22.7998541555 |
| Epoch 100 |  0.25600000000000006  | 0.644248697516 | 12.3768474469 |  0.18028169014084508  |   0.4413793103448276  | 23.5141182561 |
| Epoch 101 |   0.2709251101321586  | 0.634768821121 |  12.327600596 |  0.19902912621359223  |   0.4241379310344828  |  21.515840838 |
| Epoch 102 |  0.26892430278884466  | 0.639003770433 | 12.2708533409 |  0.18907563025210083  |  0.46551724137931033  |  23.258176496 |
| Epoch 103 |   0.2679127725856698  | 0.638672205148 |  12.26578316  |  0.19167904903417535  |  0.44482758620689655  | 22.5084421712 |
| Epoch 104 |  0.27133479212253825  | 0.635300910536 | 12.2102294375 |   0.1987179487179487  |  0.42758620689655175  | 21.5226230006 |
| Epoch 105 |   0.2662337662337662  | 0.634621274592 | 12.1972140444 |  0.19400630914826497  |   0.4241379310344828  | 21.5375579711 |
| Epoch 106 |  0.25396825396825395  | 0.627684884324 |  12.187884238 |   0.183206106870229   |  0.41379310344827586  | 21.9870623927 |
| Epoch 107 |  0.25922023182297155  | 0.629459748217 | 12.1572231041 |  0.18664643399089528  |   0.4241379310344828  |  22.153011322 |
| Epoch 108 |   0.2601279317697228  | 0.624883117374 | 12.1073374148 |   0.1882716049382716  |   0.4206896551724138  | 21.9001802014 |
| Epoch 109 |  0.24675324675324678  | 0.627214716795 |  12.02942548  |  0.17981072555205047  |   0.3931034482758621  | 21.5041536516 |
| Epoch 110 |  0.24282560706401765  | 0.626216220441 | 12.0468247761 |  0.17857142857142858  |   0.3793103448275862  | 21.2207360421 |
| Epoch 111 |   0.2479908151549943  | 0.626422669648 | 12.1034730773 |  0.18588640275387264  |   0.3724137931034483  |  20.482269041 |
| Epoch 112 |  0.24819277108433738  | 0.627125077609 | 12.0800771371 |  0.19074074074074074  |  0.35517241379310344  |  19.865706413 |
| Epoch 113 |   0.2371020856201976  | 0.628122591218 | 11.9995262528 |  0.17391304347826086  |   0.3724137931034483  | 21.3669173948 |
| Epoch 114 |  0.22419533851276363  | 0.628125204445 | 11.9531690722 |  0.16530278232405893  |   0.3482758620689655  | 21.1832078503 |
| Epoch 115 |  0.25871766029246346  | 0.632224276405 | 12.0121152141 |  0.19198664440734559  |  0.39655172413793105  | 20.6742312524 |
| Epoch 116 |   0.2749445676274945  | 0.62455138829  | 11.9752537928 |  0.20261437908496732  |  0.42758620689655175  | 21.0527632313 |
| Epoch 117 |   0.2724177071509648  | 0.63116591849  | 11.8922168912 |  0.20304568527918782  |  0.41379310344827586  |  20.359719984 |
| Epoch 118 |   0.2623318385650224  | 0.63076374049  | 11.9239244888 |  0.19435215946843853  |  0.40344827586206894  | 20.5907170696 |
| Epoch 119 |  0.26771653543307083  | 0.630558626698 | 11.8859646605 |   0.1986644407345576  |   0.4103448275862069  | 20.5735769579 |
| Epoch 120 |   0.2662037037037037  | 0.625625224907 | 11.8004421547 |  0.20034843205574912  |  0.39655172413793105  | 19.9817017586 |
| Epoch 121 |   0.2784810126582279  | 0.623873064199 | 11.8954395623 |  0.20898100172711573  |  0.41724137931034483  | 20.0458361103 |
| Epoch 122 |   0.2847058823529412  | 0.626530618957 | 11.8088022435 |  0.21607142857142858  |  0.41724137931034483  | 19.7100838077 |
| Epoch 123 |  0.24913494809688583  | 0.630916411001 | 11.6815213145 |  0.18717504332755633  |   0.3724137931034483  | 20.1869206582 |
| Epoch 124 |   0.2793572311495674  | 0.623011923758 | 11.6856006202 |  0.21772639691714837  |   0.3896551724137931  | 18.9423506337 |
| Epoch 125 |  0.28439306358381505  | 0.624166873728 | 11.7303922424 |  0.21391304347826087  |   0.4241379310344828  | 19.8655567784 |
| Epoch 126 |  0.27383863080684595  | 0.627716255451 | 11.7524824312 |  0.21212121212121213  |  0.38620689655172413  | 19.1792414265 |
| Epoch 127 |   0.2491017964071856  | 0.627005131832 | 11.7482055703 |   0.1908256880733945  |   0.3586206896551724  | 19.3515447186 |
| Epoch 128 |   0.2838541666666667  | 0.623497375633 |  11.631678861 |   0.2280334728033473  |   0.3758620689655172  | 18.4021973764 |
| Epoch 129 |  0.26838709677419353  | 0.632473043123 | 11.6917728285 |  0.21443298969072164  |   0.3586206896551724  | 18.0801678319 |
| Epoch 130 |   0.2736842105263158  | 0.630729227512 | 11.5712429137 |  0.22127659574468084  |   0.3586206896551724  | 17.8541677537 |
| Epoch 131 |  0.25490196078431376  | 0.628443951469 | 11.6489822343 |  0.19771863117870722  |   0.3586206896551724  | 19.1936184668 |
| Epoch 132 |  0.28645161290322585  | 0.625222748332 | 11.5681847817 |   0.2288659793814433  |  0.38275862068965516  | 18.2081480949 |
| Epoch 133 |   0.267515923566879   | 0.624955972783 | 11.5626064552 |  0.21212121212121213  |   0.3620689655172414  | 18.4710016558 |
| Epoch 134 |  0.26771653543307083  | 0.626332588092 | 11.5579516015 |  0.21610169491525424  |  0.35172413793103446  | 18.2124532884 |
| Epoch 135 |  0.27586206896551724  | 0.619764317121 | 11.4980356679 |  0.22988505747126436  |   0.3448275862068966  | 17.2661158039 |
| Epoch 136 |   0.259946949602122   | 0.623022290656 | 11.5310364761 |  0.21120689655172414  |  0.33793103448275863  | 17.6911076269 |
| Epoch 137 |  0.27434842249657065  | 0.623389557731 | 11.4885515453 |  0.22779043280182232  |   0.3448275862068966  | 17.1869861849 |
| Epoch 138 |   0.2583222370173102  | 0.624117300413 | 11.4457050196 |   0.210412147505423   |  0.33448275862068966  | 17.6627360928 |
| Epoch 139 |  0.24631860776439093  | 0.62793884753  | 11.4675182147 |   0.2013129102844639  |  0.31724137931034485  | 17.6427628917 |
| Epoch 140 |   0.2647887323943662  | 0.622376574155 | 11.4413945024 |  0.22380952380952382  |  0.32413793103448274  |  16.890728489 |
| Epoch 141 |  0.26704545454545453  | 0.62394264835  | 11.4590604868 |  0.22705314009661837  |  0.32413793103448274  | 16.9180663324 |
| Epoch 142 |   0.2540983606557377  | 0.628391423924 | 11.3041670502 |  0.21040723981900453  |  0.32068965517241377  | 17.2854202024 |
| Epoch 143 |  0.25136612021857924  | 0.61978343695  | 11.4125057166 |   0.2081447963800905  |  0.31724137931034485  | 17.5235845504 |
| Epoch 144 |   0.2492836676217765  | 0.627209776322 | 11.3827249067 |  0.21323529411764705  |          0.3          |  16.812603489 |
| Epoch 145 |          0.25         | 0.621413140176 | 11.3895822422 |  0.21428571428571427  |          0.3          | 16.7660812255 |
| Epoch 146 |   0.2589928057553956  | 0.618402400027 | 11.3730625772 |   0.2222222222222222  |   0.3103448275862069  | 16.7178008479 |
| Epoch 147 |   0.2622478386167147  | 0.623082758102 | 11.3115244863 |  0.22524752475247525  |   0.3137931034482759  |  16.776082285 |
| Epoch 148 |   0.2441700960219479  | 0.622145444911 | 11.2700436137 |  0.20273348519362186  |  0.30689655172413793  | 17.2682182558 |
| Epoch 149 |  0.26382978723404255  | 0.622254315383 | 11.2905755494 |  0.22409638554216868  |  0.32068965517241377  | 16.7804274405 |
| Epoch 150 |  0.23978201634877383  | 0.617360516624 | 11.3378198322 |   0.1981981981981982  |  0.30344827586206896  | 17.4593089319 |
| Epoch 151 |  0.24705882352941178  | 0.617293860506 | 11.2652268107 |   0.2153846153846154  |   0.2896551724137931  | 16.4064245839 |
| Epoch 152 |  0.23448275862068962  | 0.62194750186  | 11.2785529397 |  0.19540229885057472  |  0.29310344827586204  |  17.232181426 |
| Epoch 153 |  0.26111908177905313  | 0.614173174894 |  11.164934326 |  0.22358722358722358  |   0.3137931034482759  | 16.6789441263 |
| Epoch 154 |   0.2336578581363004  | 0.615411737473 | 11.2190823486 |   0.1958041958041958  |   0.2896551724137931  | 17.2279288384 |
| Epoch 155 |  0.25392296718972895  | 0.609892096968 | 11.1275591693 |  0.21654501216545013  |  0.30689655172413793  | 16.7752566799 |
| Epoch 156 |   0.2496328928046989  | 0.610682597135 | 11.2360993068 |  0.21739130434782608  |  0.29310344827586204  | 16.5729588539 |
| Epoch 157 |  0.23209169054441262  | 0.612920813165 | 11.2146218397 |  0.19852941176470587  |   0.2793103448275862  | 16.7309909021 |
| Epoch 158 |  0.23831070889894415  | 0.611293887536 | 11.1678059619 |  0.21179624664879357  |  0.27241379310344827  | 16.0008162222 |
| Epoch 159 |  0.24961948249619484  | 0.613707386191 | 11.1128659285 |  0.22343324250681199  |   0.2827586206896552  | 15.9884491274 |
| Epoch 160 |  0.22674418604651161  | 0.60845289428  | 11.1720742732 |  0.19597989949748743  |   0.2689655172413793  | 16.6752506072 |
| Epoch 161 |  0.22156573116691286  | 0.606445505427 |  11.067293908 |   0.1937984496124031  |  0.25862068965517243  | 16.7372362075 |
| Epoch 162 |  0.24545454545454548  | 0.610549708725 | 11.1423500195 |  0.21891891891891893  |   0.2793103448275862  | 16.1882934878 |
| Epoch 163 |  0.22451994091580502  | 0.60257269987  | 11.0663879923 |  0.19638242894056848  |   0.2620689655172414  | 16.5758552859 |
| Epoch 164 |  0.23867069486404832  | 0.608231531411 | 11.1015742408 |  0.21236559139784947  |  0.27241379310344827  | 16.1430836339 |
| Epoch 165 |   0.2630792227204783  | 0.607912194488 | 11.0383923427 |  0.23218997361477572  |  0.30344827586206896  | 16.1388690087 |
| Epoch 166 |   0.2626582278481013  | 0.604411130493 | 11.0048155313 |  0.24269005847953215  |  0.28620689655172415  | 15.6573639224 |
| Epoch 167 |  0.25460122699386506  | 0.606202103401 |  11.064524919 |   0.2292817679558011  |  0.28620689655172415  | 15.8189643429 |
| Epoch 168 |  0.24729520865533233  | 0.610462747864 | 10.9464966346 |  0.22408963585434175  |  0.27586206896551724  | 15.8719048654 |
| Epoch 169 |  0.24215246636771298  | 0.613212729553 | 11.0715476187 |  0.21372031662269128  |   0.2793103448275862  | 16.1702471702 |
| Epoch 170 |  0.24687499999999998  | 0.611614724506 | 10.9500165272 |   0.2257142857142857  |  0.27241379310344827  | 15.6962578989 |
| Epoch 171 |   0.2422360248447205  | 0.611086464979 | 10.9009631198 |  0.22033898305084745  |   0.2689655172413793  | 15.5687340767 |
| Epoch 172 |  0.24844720496894407  | 0.612639012088 | 10.9660466904 |  0.22598870056497175  |  0.27586206896551724  | 15.4662283313 |
| Epoch 173 |  0.24528301886792453  | 0.610287611977 | 10.9423443947 |   0.2254335260115607  |   0.2689655172413793  | 15.3375005414 |
| Epoch 174 |  0.24413145539906103  | 0.611359230563 | 10.9609548362 |  0.22349570200573066  |   0.2689655172413793  | 15.3914321776 |
| Epoch 175 |  0.23529411764705882  | 0.604237814818 | 11.0103460394 |  0.21348314606741572  |   0.2620689655172414  | 15.5950471509 |
| Epoch 176 |  0.20095693779904306  | 0.604207677583 | 10.9075029459 |  0.18694362017804153  |  0.21724137931034482  | 15.9179976063 |
| Epoch 177 |   0.2379421221864952  | 0.600955023357 | 10.8808273499 |  0.22289156626506024  |  0.25517241379310346  | 15.5158531743 |
| Epoch 178 |   0.2362459546925566  | 0.603187430208 | 10.8712710028 |   0.2225609756097561  |   0.2517241379310345  | 15.4383769497 |
| Epoch 179 |   0.2187004754358162  | 0.605647721907 | 10.9045336825 |  0.20234604105571846  |  0.23793103448275862  | 15.6683739078 |
| Epoch 180 |   0.2097026604068858  | 0.603738764283 | 10.8136877195 |  0.19197707736389685  |  0.23103448275862068  | 15.7802211392 |
| Epoch 181 |  0.22719999999999999  | 0.603048297495 | 10.9062828038 |  0.21194029850746268  |  0.24482758620689654  |  15.282812703 |
| Epoch 182 |  0.21970920840064623  | 0.605996230908 | 10.9272156316 |   0.2066869300911854  |  0.23448275862068965  |  15.237615493 |
| Epoch 183 |   0.1962025316455696  | 0.606867267474 | 10.8697010647 |  0.18128654970760233  |  0.21379310344827587  | 15.5163628363 |
| Epoch 184 |  0.19801980198019803  | 0.609621257497 | 10.8227346401 |   0.189873417721519   |  0.20689655172413793  |  15.267730313 |
| Epoch 185 |  0.20701168614357263  | 0.611611383968 | 10.8042006811 |  0.20064724919093851  |  0.21379310344827587  | 15.0284180795 |
| Epoch 186 |  0.21775544388609716  | 0.607904473747 | 10.8164085209 |  0.21172638436482086  |  0.22413793103448276  | 14.9452225162 |
| Epoch 187 |   0.1950413223140496  | 0.609273846446 | 10.7296664826 |   0.1873015873015873  |  0.20344827586206896  | 15.2288574403 |
| Epoch 188 |   0.2079207920792079  | 0.608032651606 | 10.7264551572 |  0.19936708860759494  |  0.21724137931034482  | 14.9771820499 |
| Epoch 189 |  0.19967266775777415  | 0.610390548768 | 10.7330215261 |  0.19003115264797507  |   0.2103448275862069  | 15.0270911494 |
| Epoch 190 |  0.18789808917197454  | 0.610879837272 | 10.7276396409 |  0.17455621301775148  |  0.20344827586206896  | 15.4316365642 |
| Epoch 191 |  0.20159999999999997  | 0.601944456884 | 10.7847849111 |   0.1880597014925373  |  0.21724137931034482  | 15.2789564748 |
| Epoch 192 |   0.1824212271973466  | 0.610204100345 | 10.6775764302 |   0.1757188498402556  |   0.1896551724137931  | 15.1758838777 |
| Epoch 193 |   0.1893687707641196  | 0.612999538545 | 10.6706628404 |  0.18269230769230768  |  0.19655172413793104  | 15.1442541922 |
| Epoch 194 |   0.1950413223140496  | 0.610256904163 | 10.6890913172 |   0.1873015873015873  |  0.20344827586206896  | 15.1082449267 |
| Epoch 195 |   0.2108731466227348  | 0.608940136285 | 10.5933864038 |  0.20189274447949526  |   0.2206896551724138  | 14.9682088667 |
| Epoch 196 |   0.1967741935483871  | 0.606537261264 | 10.6653959749 |  0.18484848484848485  |   0.2103448275862069  | 15.2341525478 |
| Epoch 197 |  0.20261437908496735  | 0.605891826026 |   10.6949773  |  0.19254658385093168  |  0.21379310344827587  | 15.1519049675 |
| Epoch 198 |         0.1984        | 0.604386016792 | 10.6648108336 |  0.18507462686567164  |  0.21379310344827587  | 15.3387342268 |
| Epoch 199 |  0.19999999999999998  | 0.60164106462  | 10.6262068261 |   0.1935483870967742  |  0.20689655172413793  | 15.1401619142 |
| Epoch 200 |  0.21297836938435938  | 0.602559232419 | 10.5880627499 |   0.2057877813504823  |   0.2206896551724138  | 14.7479203132 |
+-----------+-----------------------+----------------+---------------+-----------------------+-----------------------+---------------+
_________________________________________________________________
+---------------------------------+--------------------+--------------------+-----------------------+---------+-----------------------+
|            Optimizer            |       beta_1       |       beta_2       |         decay         | epsilon |           lr          |
+---------------------------------+--------------------+--------------------+-----------------------+---------+-----------------------+
| <class 'keras.optimizers.Adam'> | 0.8999999761581421 | 0.9990000128746033 | 0.0005000000237487257 |  1e-08  | 9.999999747378752e-05 |
+---------------------------------+--------------------+--------------------+-----------------------+---------+-----------------------+
_________________________________________________________________
+------------+
| Batch Size |
+------------+
|     16     |
+------------+
_________________________________________________________________
+--------------------+---------------+----------------+---------------------+---------------------+---------------------+
|      Metrics       |      Loss     |      IoU       |      Precision      |        Recall       |       F1 Score      |
+--------------------+---------------+----------------+---------------------+---------------------+---------------------+
|   Train Metrics    | 40.9074480004 | 0.61935414125  | 0.41620905131603864 |  0.2659085410113719 |  0.3244998892743781 |
| Validation Metrics | 29.3688157605 | 0.602559232419 |  0.2057877813504823 |  0.2206896551724138 | 0.21297836938435938 |
|    Test Metrics    |  34.340186396 | 0.615870590313 | 0.18446601941747573 | 0.18446601941747573 |  0.1844660194174757 |
+--------------------+---------------+----------------+---------------------+---------------------+---------------------+
_________________________________________________________________
Time:
    Train Time              : 1 day, 5:15:35.765079
    Dataset Loading Time    : 0:00:39.901402
    Metrics Evaluation Time : 0:37:09.133587
_________________________________________________________________
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         (None, 288, 288, 1)       0         
_________________________________________________________________
conv_1 (Conv2D)              (None, 288, 288, 32)      320       
_________________________________________________________________
norm_1 (BatchNormalization)  (None, 288, 288, 32)      128       
_________________________________________________________________
relu_1 (LeakyReLU)           (None, 288, 288, 32)      0         
_________________________________________________________________
pool_1 (MaxPooling2D)        (None, 144, 144, 32)      0         
_________________________________________________________________
conv_2 (Conv2D)              (None, 144, 144, 64)      18496     
_________________________________________________________________
norm_2 (BatchNormalization)  (None, 144, 144, 64)      256       
_________________________________________________________________
relu_2 (LeakyReLU)           (None, 144, 144, 64)      0         
_________________________________________________________________
pool_2 (MaxPooling2D)        (None, 72, 72, 64)        0         
_________________________________________________________________
conv_3 (Conv2D)              (None, 72, 72, 128)       73856     
_________________________________________________________________
norm_3 (BatchNormalization)  (None, 72, 72, 128)       512       
_________________________________________________________________
relu_3 (LeakyReLU)           (None, 72, 72, 128)       0         
_________________________________________________________________
drop_1 (Dropout)             (None, 72, 72, 128)       0         
_________________________________________________________________
conv_4 (Conv2D)              (None, 72, 72, 64)        8256      
_________________________________________________________________
norm_4 (BatchNormalization)  (None, 72, 72, 64)        256       
_________________________________________________________________
relu_4 (LeakyReLU)           (None, 72, 72, 64)        0         
_________________________________________________________________
drop_2 (Dropout)             (None, 72, 72, 64)        0         
_________________________________________________________________
conv_5 (Conv2D)              (None, 72, 72, 128)       73856     
_________________________________________________________________
norm_5 (BatchNormalization)  (None, 72, 72, 128)       512       
_________________________________________________________________
relu_5 (LeakyReLU)           (None, 72, 72, 128)       0         
_________________________________________________________________
pool_3 (MaxPooling2D)        (None, 36, 36, 128)       0         
_________________________________________________________________
conv_6 (Conv2D)              (None, 36, 36, 256)       295168    
_________________________________________________________________
norm_6 (BatchNormalization)  (None, 36, 36, 256)       1024      
_________________________________________________________________
relu_6 (LeakyReLU)           (None, 36, 36, 256)       0         
_________________________________________________________________
drop_3 (Dropout)             (None, 36, 36, 256)       0         
_________________________________________________________________
conv_7 (Conv2D)              (None, 36, 36, 128)       32896     
_________________________________________________________________
norm_7 (BatchNormalization)  (None, 36, 36, 128)       512       
_________________________________________________________________
relu_7 (LeakyReLU)           (None, 36, 36, 128)       0         
_________________________________________________________________
drop_4 (Dropout)             (None, 36, 36, 128)       0         
_________________________________________________________________
conv_8 (Conv2D)              (None, 36, 36, 256)       295168    
_________________________________________________________________
norm_8 (BatchNormalization)  (None, 36, 36, 256)       1024      
_________________________________________________________________
relu_8 (LeakyReLU)           (None, 36, 36, 256)       0         
_________________________________________________________________
pool_4 (MaxPooling2D)        (None, 18, 18, 256)       0         
_________________________________________________________________
conv_9 (Conv2D)              (None, 18, 18, 512)       1180160   
_________________________________________________________________
norm_9 (BatchNormalization)  (None, 18, 18, 512)       2048      
_________________________________________________________________
relu_9 (LeakyReLU)           (None, 18, 18, 512)       0         
_________________________________________________________________
drop_5 (Dropout)             (None, 18, 18, 512)       0         
_________________________________________________________________
conv_10 (Conv2D)             (None, 18, 18, 256)       131328    
_________________________________________________________________
norm_10 (BatchNormalization) (None, 18, 18, 256)       1024      
_________________________________________________________________
relu_10 (LeakyReLU)          (None, 18, 18, 256)       0         
_________________________________________________________________
drop_6 (Dropout)             (None, 18, 18, 256)       0         
_________________________________________________________________
conv_11 (Conv2D)             (None, 18, 18, 512)       1180160   
_________________________________________________________________
norm_11 (BatchNormalization) (None, 18, 18, 512)       2048      
_________________________________________________________________
relu_11 (LeakyReLU)          (None, 18, 18, 512)       0         
_________________________________________________________________
drop_7 (Dropout)             (None, 18, 18, 512)       0         
_________________________________________________________________
conv_12 (Conv2D)             (None, 18, 18, 256)       131328    
_________________________________________________________________
norm_12 (BatchNormalization) (None, 18, 18, 256)       1024      
_________________________________________________________________
relu_12 (LeakyReLU)          (None, 18, 18, 256)       0         
_________________________________________________________________
drop_8 (Dropout)             (None, 18, 18, 256)       0         
_________________________________________________________________
conv_13 (Conv2D)             (None, 18, 18, 512)       1180160   
_________________________________________________________________
norm_13 (BatchNormalization) (None, 18, 18, 512)       2048      
_________________________________________________________________
relu_13 (LeakyReLU)          (None, 18, 18, 512)       0         
_________________________________________________________________
pool_5 (MaxPooling2D)        (None, 9, 9, 512)         0         
_________________________________________________________________
conv_14 (Conv2D)             (None, 9, 9, 1024)        4719616   
_________________________________________________________________
norm_14 (BatchNormalization) (None, 9, 9, 1024)        4096      
_________________________________________________________________
relu_14 (LeakyReLU)          (None, 9, 9, 1024)        0         
_________________________________________________________________
drop_9 (Dropout)             (None, 9, 9, 1024)        0         
_________________________________________________________________
conv_15 (Conv2D)             (None, 9, 9, 1024)        9438208   
_________________________________________________________________
norm_15 (BatchNormalization) (None, 9, 9, 1024)        4096      
_________________________________________________________________
relu_15 (LeakyReLU)          (None, 9, 9, 1024)        0         
_________________________________________________________________
drop_10 (Dropout)            (None, 9, 9, 1024)        0         
_________________________________________________________________
conv_16 (Conv2D)             (None, 9, 9, 5)           5125      
_________________________________________________________________
reshape_1 (Reshape)          (None, 9, 9, 5)           0         
=================================================================
Total params: 18,784,709
Trainable params: 18,774,405
Non-trainable params: 10,304
_________________________________________________________________
+----------+----------------------+----------------+---------------+----------------------+-----------------------+---------------+
|  Epoch   |       f1_score       |      iou       |      loss     |      precision       |         recall        |    val_loss   |
+----------+----------------------+----------------+---------------+----------------------+-----------------------+---------------+
| Epoch 1  |         nan          |      nan       | 66.1857985515 |         nan          |          0.0          | 39.6472005536 |
| Epoch 2  |  0.1262135922330097  | 0.541697836392 | 28.9442861691 | 0.21311475409836064  |   0.0896551724137931  | 20.1876583099 |
| Epoch 3  | 0.04143646408839779  | 0.53672834505  | 23.1050942261 | 0.03456221198156682  |  0.05172413793103448  | 26.2477971969 |
| Epoch 4  |         nan          |      nan       | 20.9799164992 |         0.0          |          0.0          | 31.4990468179 |
| Epoch 5  |         nan          |      nan       | 20.1451419168 |         0.0          |          0.0          | 31.3688404945 |
| Epoch 6  |         nan          |      nan       | 19.2340744709 |         0.0          |          0.0          |  36.466659669 |
| Epoch 7  |         nan          |      nan       | 18.6560380247 |         0.0          |          0.0          | 50.7506117052 |
| Epoch 8  |         nan          |      nan       | 17.9990807442 |         0.0          |          0.0          | 62.6284621454 |
| Epoch 9  |         nan          |      nan       | 17.4697289036 |         0.0          |          0.0          | 55.5435309872 |
| Epoch 10 |         nan          |      nan       | 17.0322413553 |         0.0          |          0.0          | 61.8427911574 |
| Epoch 11 |         nan          |      nan       | 16.5321235367 |         0.0          |          0.0          |  79.608044532 |
| Epoch 12 |         nan          |      nan       | 16.1314137669 |         0.0          |          0.0          | 68.4812218451 |
| Epoch 13 |         nan          |      nan       | 15.6945494541 |         0.0          |          0.0          | 74.9227237086 |
| Epoch 14 |         nan          |      nan       | 15.3877752148 |         0.0          |          0.0          | 82.6803401824 |
| Epoch 15 |         nan          |      nan       | 14.9380490826 |         0.0          |          0.0          | 83.2241796678 |
| Epoch 16 |         nan          |      nan       | 14.5655869938 |         0.0          |          0.0          | 74.9175486411 |
| Epoch 17 |         nan          |      nan       | 14.1430963982 |         0.0          |          0.0          | 77.4959135978 |
| Epoch 18 |         nan          |      nan       | 13.7741811838 |         0.0          |          0.0          | 76.7538759785 |
| Epoch 19 |         nan          |      nan       | 13.4502926623 |         0.0          |          0.0          |  79.439248608 |
| Epoch 20 | 0.00554016620498615  | 0.504915794959 |  13.255428153 | 0.014084507042253521 | 0.0034482758620689655 | 74.8828693513 |
| Epoch 21 | 0.006289308176100628 | 0.52548043996  | 12.8959904241 | 0.03571428571428571  | 0.0034482758620689655 | 90.5178520449 |
| Epoch 22 | 0.005361930294906166 | 0.749881591531 | 12.6646726766 | 0.012048192771084338 | 0.0034482758620689655 | 71.2892005674 |
| Epoch 23 | 0.006006006006006006 | 0.829854496836 | 12.3755091154 | 0.023255813953488372 | 0.0034482758620689655 | 78.3092481552 |
| Epoch 24 | 0.013729977116704805 | 0.571978431471 | 12.1283209753 | 0.02040816326530612  |  0.010344827586206896 | 68.4519436744 |
| Epoch 25 | 0.014814814814814815 | 0.601253344045 | 11.9002213869 | 0.02608695652173913  |  0.010344827586206896 | 66.3289785077 |
| Epoch 26 | 0.024449877750611245 | 0.593921204657 | 11.6614482199 | 0.04201680672268908  |  0.017241379310344827 | 64.8319453578 |
| Epoch 27 | 0.011299435028248588 | 0.593290345607 | 11.4181899436 |       0.03125        |  0.006896551724137931 |  72.279359879 |
| Epoch 28 | 0.024213075060532687 | 0.568526012054 | 11.2026281018 | 0.04065040650406504  |  0.017241379310344827 | 59.4141796481 |
| Epoch 29 | 0.029197080291970802 | 0.556375242443 | 10.9987015914 | 0.049586776859504134 |  0.020689655172413793 | 62.3500636931 |
| Epoch 30 | 0.03619909502262443  | 0.567361308131 | 10.8449635582 | 0.05263157894736842  |  0.027586206896551724 | 55.0970847837 |
+----------+----------------------+----------------+---------------+----------------------+-----------------------+---------------+
_________________________________________________________________
+---------------------------------+--------------------+--------------------+-----------------------+---------+-----------------------+
|            Optimizer            |       beta_1       |       beta_2       |         decay         | epsilon |           lr          |
+---------------------------------+--------------------+--------------------+-----------------------+---------+-----------------------+
| <class 'keras.optimizers.Adam'> | 0.8999999761581421 | 0.9990000128746033 | 0.0005000000237487257 |  1e-08  | 9.999999747378752e-05 |
+---------------------------------+--------------------+--------------------+-----------------------+---------+-----------------------+
_________________________________________________________________
+------------+
| Batch Size |
+------------+
|     16     |
+------------+
_________________________________________________________________
+--------------------+---------------+----------------+----------------------+----------------------+----------------------+
|      Metrics       |      Loss     |      IoU       |      Precision       |        Recall        |       F1 Score       |
+--------------------+---------------+----------------+----------------------+----------------------+----------------------+
|   Train Metrics    | 183.642275555 | 0.563605583534 | 0.09357798165137615  | 0.024679409629808857 | 0.039058012636415854 |
| Validation Metrics | 109.791481756 | 0.567361308131 | 0.05263157894736842  | 0.027586206896551724 | 0.03619909502262443  |
|    Test Metrics    | 116.062057495 | 0.578780428484 | 0.050955414012738856 | 0.025889967637540454 | 0.03433476394849786  |
+--------------------+---------------+----------------+----------------------+----------------------+----------------------+
_________________________________________________________________
Time:
    Train Time              : 3:05:28.804291
    Dataset Loading Time    : 0:00:39.560739
    Metrics Evaluation Time : 0:09:34.764175
_________________________________________________________________
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         (None, 288, 288, 1)       0         
_________________________________________________________________
conv_1 (Conv2D)              (None, 288, 288, 32)      320       
_________________________________________________________________
norm_1 (BatchNormalization)  (None, 288, 288, 32)      128       
_________________________________________________________________
relu_1 (LeakyReLU)           (None, 288, 288, 32)      0         
_________________________________________________________________
pool_1 (MaxPooling2D)        (None, 144, 144, 32)      0         
_________________________________________________________________
conv_2 (Conv2D)              (None, 144, 144, 64)      18496     
_________________________________________________________________
norm_2 (BatchNormalization)  (None, 144, 144, 64)      256       
_________________________________________________________________
relu_2 (LeakyReLU)           (None, 144, 144, 64)      0         
_________________________________________________________________
pool_2 (MaxPooling2D)        (None, 72, 72, 64)        0         
_________________________________________________________________
conv_3 (Conv2D)              (None, 72, 72, 128)       73856     
_________________________________________________________________
norm_3 (BatchNormalization)  (None, 72, 72, 128)       512       
_________________________________________________________________
relu_3 (LeakyReLU)           (None, 72, 72, 128)       0         
_________________________________________________________________
drop_1 (Dropout)             (None, 72, 72, 128)       0         
_________________________________________________________________
conv_4 (Conv2D)              (None, 72, 72, 64)        8256      
_________________________________________________________________
norm_4 (BatchNormalization)  (None, 72, 72, 64)        256       
_________________________________________________________________
relu_4 (LeakyReLU)           (None, 72, 72, 64)        0         
_________________________________________________________________
drop_2 (Dropout)             (None, 72, 72, 64)        0         
_________________________________________________________________
conv_5 (Conv2D)              (None, 72, 72, 128)       73856     
_________________________________________________________________
norm_5 (BatchNormalization)  (None, 72, 72, 128)       512       
_________________________________________________________________
relu_5 (LeakyReLU)           (None, 72, 72, 128)       0         
_________________________________________________________________
pool_3 (MaxPooling2D)        (None, 36, 36, 128)       0         
_________________________________________________________________
conv_6 (Conv2D)              (None, 36, 36, 256)       295168    
_________________________________________________________________
norm_6 (BatchNormalization)  (None, 36, 36, 256)       1024      
_________________________________________________________________
relu_6 (LeakyReLU)           (None, 36, 36, 256)       0         
_________________________________________________________________
drop_3 (Dropout)             (None, 36, 36, 256)       0         
_________________________________________________________________
conv_7 (Conv2D)              (None, 36, 36, 128)       32896     
_________________________________________________________________
norm_7 (BatchNormalization)  (None, 36, 36, 128)       512       
_________________________________________________________________
relu_7 (LeakyReLU)           (None, 36, 36, 128)       0         
_________________________________________________________________
drop_4 (Dropout)             (None, 36, 36, 128)       0         
_________________________________________________________________
conv_8 (Conv2D)              (None, 36, 36, 256)       295168    
_________________________________________________________________
norm_8 (BatchNormalization)  (None, 36, 36, 256)       1024      
_________________________________________________________________
relu_8 (LeakyReLU)           (None, 36, 36, 256)       0         
_________________________________________________________________
pool_4 (MaxPooling2D)        (None, 18, 18, 256)       0         
_________________________________________________________________
conv_9 (Conv2D)              (None, 18, 18, 512)       1180160   
_________________________________________________________________
norm_9 (BatchNormalization)  (None, 18, 18, 512)       2048      
_________________________________________________________________
relu_9 (LeakyReLU)           (None, 18, 18, 512)       0         
_________________________________________________________________
drop_5 (Dropout)             (None, 18, 18, 512)       0         
_________________________________________________________________
conv_10 (Conv2D)             (None, 18, 18, 256)       131328    
_________________________________________________________________
norm_10 (BatchNormalization) (None, 18, 18, 256)       1024      
_________________________________________________________________
relu_10 (LeakyReLU)          (None, 18, 18, 256)       0         
_________________________________________________________________
drop_6 (Dropout)             (None, 18, 18, 256)       0         
_________________________________________________________________
conv_11 (Conv2D)             (None, 18, 18, 512)       1180160   
_________________________________________________________________
norm_11 (BatchNormalization) (None, 18, 18, 512)       2048      
_________________________________________________________________
relu_11 (LeakyReLU)          (None, 18, 18, 512)       0         
_________________________________________________________________
drop_7 (Dropout)             (None, 18, 18, 512)       0         
_________________________________________________________________
conv_12 (Conv2D)             (None, 18, 18, 256)       131328    
_________________________________________________________________
norm_12 (BatchNormalization) (None, 18, 18, 256)       1024      
_________________________________________________________________
relu_12 (LeakyReLU)          (None, 18, 18, 256)       0         
_________________________________________________________________
drop_8 (Dropout)             (None, 18, 18, 256)       0         
_________________________________________________________________
conv_13 (Conv2D)             (None, 18, 18, 512)       1180160   
_________________________________________________________________
norm_13 (BatchNormalization) (None, 18, 18, 512)       2048      
_________________________________________________________________
relu_13 (LeakyReLU)          (None, 18, 18, 512)       0         
_________________________________________________________________
pool_5 (MaxPooling2D)        (None, 9, 9, 512)         0         
_________________________________________________________________
conv_14 (Conv2D)             (None, 9, 9, 1024)        4719616   
_________________________________________________________________
norm_14 (BatchNormalization) (None, 9, 9, 1024)        4096      
_________________________________________________________________
relu_14 (LeakyReLU)          (None, 9, 9, 1024)        0         
_________________________________________________________________
drop_9 (Dropout)             (None, 9, 9, 1024)        0         
_________________________________________________________________
conv_15 (Conv2D)             (None, 9, 9, 1024)        9438208   
_________________________________________________________________
norm_15 (BatchNormalization) (None, 9, 9, 1024)        4096      
_________________________________________________________________
relu_15 (LeakyReLU)          (None, 9, 9, 1024)        0         
_________________________________________________________________
drop_10 (Dropout)            (None, 9, 9, 1024)        0         
_________________________________________________________________
conv_16 (Conv2D)             (None, 9, 9, 5)           5125      
_________________________________________________________________
reshape_1 (Reshape)          (None, 9, 9, 5)           0         
=================================================================
Total params: 18,784,709
Trainable params: 18,774,405
Non-trainable params: 10,304
_________________________________________________________________
+-----------+-----------------------+----------------+---------------+----------------------+-----------------------+---------------+
|   Epoch   |        f1_score       |      iou       |      loss     |      precision       |         recall        |    val_loss   |
+-----------+-----------------------+----------------+---------------+----------------------+-----------------------+---------------+
|  Epoch 1  |          nan          |      nan       | 62.8978852911 |         nan          |          0.0          |  41.26787038  |
|  Epoch 2  |          nan          |      nan       | 29.5483832017 |         0.0          |          0.0          | 39.1852021986 |
|  Epoch 3  |          nan          |      nan       | 23.2276721174 |         0.0          |          0.0          | 71.6060135134 |
|  Epoch 4  |          nan          |      nan       |  21.11920542  |         0.0          |          0.0          | 63.3940092517 |
|  Epoch 5  |          nan          |      nan       | 20.3174848202 |         0.0          |          0.0          | 60.7834077651 |
|  Epoch 6  |          nan          |      nan       | 19.3508363983 |         0.0          |          0.0          | 49.2328706557 |
|  Epoch 7  |          nan          |      nan       | 18.8598890958 |         0.0          |          0.0          | 46.3289760467 |
|  Epoch 8  |          nan          |      nan       | 18.3814567588 |         0.0          |          0.0          | 45.2539959569 |
|  Epoch 9  |          nan          |      nan       | 17.9913973901 |         0.0          |          0.0          | 40.5843448024 |
|  Epoch 10 |          nan          |      nan       | 17.5878227376 |         0.0          |          0.0          | 40.1822520841 |
|  Epoch 11 |          nan          |      nan       |  16.95568971  |         0.0          |          0.0          | 34.1169293311 |
|  Epoch 12 |          nan          |      nan       | 16.5757820665 |         0.0          |          0.0          | 32.1947917323 |
|  Epoch 13 |          nan          |      nan       | 16.0507786735 |         0.0          |          0.0          | 39.0463846883 |
|  Epoch 14 |          nan          |      nan       | 15.6175385392 |         0.0          |          0.0          | 34.2715255368 |
|  Epoch 15 |          nan          |      nan       | 15.1474616388 |         0.0          |          0.0          | 37.7408079332 |
|  Epoch 16 |          nan          |      nan       | 14.7671899207 |         0.0          |          0.0          | 40.5477621017 |
|  Epoch 17 |          nan          |      nan       | 14.4566023191 |         0.0          |          0.0          | 46.3363142936 |
|  Epoch 18 |          nan          |      nan       | 14.1069986121 |         0.0          |          0.0          | 40.1531925817 |
|  Epoch 19 |          nan          |      nan       | 13.7422930878 |         0.0          |          0.0          |  43.250096598 |
|  Epoch 20 |  0.004434589800443458 | 0.512647776848 | 13.4769830768 | 0.006211180124223602 | 0.0034482758620689655 | 36.1670219052 |
|  Epoch 21 |  0.015355086372360844 | 0.52875158316  | 13.1546678003 | 0.017316017316017316 |  0.013793103448275862 | 33.5736967517 |
|  Epoch 22 |  0.004651162790697674 | 0.500015794338 | 12.9429227482 | 0.007142857142857143 | 0.0034482758620689655 | 40.7225286422 |
|  Epoch 23 |  0.004962779156327543 | 0.516620020271 | 12.6698839683 | 0.008849557522123894 | 0.0034482758620689655 | 42.7083345229 |
|  Epoch 24 |  0.004962779156327543 | 0.545342131738 | 12.3682738826 | 0.008849557522123894 | 0.0034482758620689655 | 44.1796112061 |
|  Epoch 25 |  0.003838771593090211 | 0.573644073949 | 12.1017216258 | 0.004329004329004329 | 0.0034482758620689655 | 33.8392419507 |
|  Epoch 26 |          nan          |      nan       | 11.8362577234 |         0.0          |          0.0          |  44.783924595 |
|  Epoch 27 |          nan          |      nan       | 11.6876904833 |         0.0          |          0.0          | 42.3131609271 |
|  Epoch 28 |          nan          |      nan       | 11.4674296343 |         0.0          |          0.0          | 43.6387485381 |
|  Epoch 29 | 0.0045871559633027525 | 0.544522485805 | 11.2331445925 | 0.00684931506849315  | 0.0034482758620689655 | 36.0271664896 |
|  Epoch 30 |          nan          |      nan       | 11.0634959584 |         0.0          |          0.0          | 36.1391471124 |
|  Epoch 31 |          nan          |      nan       | 10.9809418615 |         0.0          |          0.0          | 47.5801889973 |
|  Epoch 32 |          nan          |      nan       | 10.7501608928 |         0.0          |          0.0          | 40.3144928717 |
|  Epoch 33 |          nan          |      nan       | 10.5975940395 |         0.0          |          0.0          | 40.8415807293 |
|  Epoch 34 |          nan          |      nan       |  10.520732978 |         0.0          |          0.0          |  44.719833251 |
|  Epoch 35 |          nan          |      nan       | 10.3355553338 |         0.0          |          0.0          | 41.0194643082 |
|  Epoch 36 |          nan          |      nan       | 10.1902392251 |         0.0          |          0.0          | 45.3685420867 |
|  Epoch 37 |          nan          |      nan       | 10.0526955956 |         0.0          |          0.0          | 46.7848559964 |
|  Epoch 38 |          nan          |      nan       | 9.95975984886 |         0.0          |          0.0          | 45.6653987515 |
|  Epoch 39 |          nan          |      nan       | 9.85135605007 |         0.0          |          0.0          | 47.4839649816 |
|  Epoch 40 |  0.004878048780487805 | 0.508570015505 |  9.7126987188 | 0.008333333333333333 | 0.0034482758620689655 | 42.7127931656 |
|  Epoch 41 |  0.00554016620498615  | 0.513627972048 | 9.60084259843 | 0.014084507042253521 | 0.0034482758620689655 | 47.9450718049 |
|  Epoch 42 |          nan          |      nan       | 9.45842862149 |         0.0          |          0.0          | 47.0857748216 |
|  Epoch 43 |  0.00510204081632653  | 0.56784115587  | 9.42865985889 | 0.00980392156862745  | 0.0034482758620689655 | 43.7458851722 |
|  Epoch 44 |  0.004761904761904762 | 0.588909186162 | 9.28854009769 | 0.007692307692307693 | 0.0034482758620689655 | 40.8141447498 |
|  Epoch 45 |  0.004705882352941177 | 0.525626658343 | 9.18488582956 | 0.007407407407407408 | 0.0034482758620689655 | 42.9266107621 |
|  Epoch 46 |  0.009324009324009324 | 0.560683353964 | 9.08503323053 | 0.014388489208633094 |  0.006896551724137931 | 40.4410393007 |
|  Epoch 47 |  0.005221932114882506 | 0.540982417897 | 9.03918650749 | 0.010752688172043012 | 0.0034482758620689655 | 46.4056338649 |
|  Epoch 48 |  0.01279317697228145  | 0.554631963525 | 8.92369953052 | 0.01675977653631285  |  0.010344827586206896 | 39.9194849076 |
|  Epoch 49 |  0.005333333333333333 | 0.52804386691  | 8.91211225456 | 0.011764705882352941 | 0.0034482758620689655 | 47.0136760589 |
|  Epoch 50 | 0.0049504950495049506 |  0.5603278012  | 8.80553585659 | 0.008771929824561403 | 0.0034482758620689655 | 43.6697179733 |
|  Epoch 51 |  0.005037783375314861 | 0.583174812845 | 8.75033905661 | 0.009345794392523364 | 0.0034482758620689655 | 45.4153884149 |
|  Epoch 52 |  0.005128205128205128 | 0.602063008918 | 8.68867826462 |         0.01         | 0.0034482758620689655 | 45.0887141074 |
|  Epoch 53 | 0.0051813471502590676 | 0.571357687092 | 8.60878256591 | 0.010416666666666666 | 0.0034482758620689655 | 46.0587134823 |
|  Epoch 54 |  0.014563106796116504 | 0.544491719708 | 8.54175513373 | 0.02459016393442623  |  0.010344827586206896 | 41.2355069806 |
|  Epoch 55 |  0.005115089514066496 | 0.596194665961 | 8.52069628208 | 0.009900990099009901 | 0.0034482758620689655 | 45.6395408876 |
|  Epoch 56 | 0.0055248618784530384 | 0.562047484668 | 8.38235563518 | 0.013888888888888888 | 0.0034482758620689655 | 47.9612316009 |
|  Epoch 57 |  0.010152284263959392 | 0.545097153342 | 8.33515986002 | 0.019230769230769232 |  0.006896551724137931 | 45.6794096424 |
|  Epoch 58 |  0.005235602094240837 | 0.594780558145 | 8.27576651819 | 0.010869565217391304 | 0.0034482758620689655 | 45.1225630237 |
|  Epoch 59 |  0.010152284263959392 | 0.54582410372  | 8.26265488009 | 0.019230769230769232 |  0.006896551724137931 | 45.0127798511 |
|  Epoch 60 |  0.005494505494505494 | 0.587661902327 |  8.2625790255 | 0.013513513513513514 | 0.0034482758620689655 | 51.3574137534 |
|  Epoch 61 |  0.014527845036319612 | 0.534158955814 | 8.16597676297 | 0.024390243902439025 |  0.010344827586206896 | 44.8579563018 |
|  Epoch 62 |  0.014527845036319612 | 0.547301718208 | 8.11191482536 | 0.024390243902439025 |  0.010344827586206896 | 44.6485657231 |
|  Epoch 63 |  0.00975609756097561  | 0.553193262079 | 8.05684334649 | 0.016666666666666666 |  0.006896551724137931 | 45.3965161231 |
|  Epoch 64 |  0.009174311926605505 | 0.563382620107 | 7.96555691056 |  0.0136986301369863  |  0.006896551724137931 | 43.1919392001 |
|  Epoch 65 | 0.0056179775280898875 | 0.590233665615 | 7.93164557234 | 0.015151515151515152 | 0.0034482758620689655 | 49.6751786509 |
|  Epoch 66 |  0.005194805194805194 | 0.554636778381 | 7.86046597601 | 0.010526315789473684 | 0.0034482758620689655 | 46.3678510112 |
|  Epoch 67 |  0.005249343832020997 | 0.592156972853 | 7.92757836178 | 0.01098901098901099  | 0.0034482758620689655 |  47.859957172 |
|  Epoch 68 |  0.010050251256281407 | 0.552227730139 |  7.8271685227 | 0.018518518518518517 |  0.006896551724137931 | 46.5518613015 |
|  Epoch 69 |  0.005434782608695652 | 0.603451262943 | 7.81032172644 | 0.01282051282051282  | 0.0034482758620689655 | 48.8951889776 |
|  Epoch 70 |  0.015915119363395226 | 0.54073920263  | 7.74924868401 | 0.034482758620689655 |  0.010344827586206896 | 48.8394041984 |
|  Epoch 71 |  0.010362694300518135 | 0.588638273976 | 7.67884358892 | 0.020833333333333332 |  0.006896551724137931 | 46.4764193873 |
|  Epoch 72 |  0.009876543209876543 | 0.578549504679 | 7.65405139133 | 0.017391304347826087 |  0.006896551724137931 | 44.0670095874 |
|  Epoch 73 |  0.02262443438914027  | 0.552305958648 |  7.5911555657 | 0.03289473684210526  |  0.017241379310344827 | 42.6703007606 |
|  Epoch 74 |  0.005263157894736842 | 0.548455590981 | 7.64190453024 | 0.011111111111111112 | 0.0034482758620689655 |  45.74286184  |
|  Epoch 75 |  0.010101010101010102 | 0.556321777453 | 7.58321986073 | 0.018867924528301886 |  0.006896551724137931 | 44.2566146851 |
|  Epoch 76 |  0.014354066985645933 | 0.559560216257 | 7.47870149153 |      0.0234375       |  0.010344827586206896 | 44.1185311348 |
|  Epoch 77 |  0.005291005291005292 | 0.574691387272 | 7.41053161637 | 0.011363636363636364 | 0.0034482758620689655 | 46.2609636861 |
|  Epoch 78 |   0.0136986301369863  | 0.543864560268 | 7.37859316993 | 0.02027027027027027  |  0.010344827586206896 | 43.5079634882 |
|  Epoch 79 |  0.010362694300518135 | 0.534936425823 | 7.38911519047 | 0.020833333333333332 |  0.006896551724137931 |  45.343599381 |
|  Epoch 80 |   0.0103359173126615  | 0.527355120243 | 7.28920401644 | 0.020618556701030927 |  0.006896551724137931 | 46.0574552474 |
|  Epoch 81 |  0.018691588785046728 | 0.538530344502 | 7.30745285805 | 0.028985507246376812 |  0.013793103448275862 | 42.5465197409 |
|  Epoch 82 |  0.009828009828009828 | 0.549676367886 | 7.25741465618 | 0.017094017094017096 |  0.006896551724137931 |  43.369275493 |
|  Epoch 83 |  0.019184652278177457 | 0.544097049263 | 7.20980913157 | 0.031496062992125984 |  0.013793103448275862 | 43.7825593025 |
|  Epoch 84 |  0.02386634844868735  | 0.566363720122 | 7.16896923135 | 0.03875968992248062  |  0.017241379310344827 | 43.5737773526 |
|  Epoch 85 |  0.028037383177570093 | 0.584072065801 | 7.13396724159 | 0.043478260869565216 |  0.020689655172413793 | 43.5794939841 |
|  Epoch 86 |  0.02962962962962963  | 0.575524127315 | 7.17021409113 | 0.05217391304347826  |  0.020689655172413793 | 44.5251480841 |
|  Epoch 87 |  0.014814814814814815 | 0.546837483798 | 7.07709720028 | 0.02608695652173913  |  0.010344827586206896 | 45.9365468179 |
|  Epoch 88 |  0.027649769585253458 | 0.567912544516 | 7.03914260098 | 0.041666666666666664 |  0.020689655172413793 | 42.3896218577 |
|  Epoch 89 |  0.02392344497607656  | 0.545059528258 | 7.08979946622 |      0.0390625       |  0.017241379310344827 | 43.2581355187 |
|  Epoch 90 |  0.03349282296650718  | 0.54648086401  | 7.02278248335 |      0.0546875       |  0.02413793103448276  | 43.5355844805 |
|  Epoch 91 |  0.03225806451612903  | 0.556900697845 | 6.99086150333 | 0.04861111111111111  |  0.02413793103448276  | 41.1338776619 |
|  Epoch 92 |  0.023529411764705882 | 0.561137086694 | 6.90314152759 | 0.037037037037037035 |  0.017241379310344827 | 44.0584599895 |
|  Epoch 93 |  0.027149321266968323 | 0.562120109651 | 6.90416340493 | 0.039473684210526314 |  0.020689655172413793 | 41.1707763672 |
|  Epoch 94 |  0.030107526881720432 | 0.564860596994 | 6.91046368945 |         0.04         |  0.02413793103448276  | 41.0954742432 |
|  Epoch 95 |  0.02392344497607656  | 0.558129800143 | 6.84750502168 |      0.0390625       |  0.017241379310344827 | 45.2401428223 |
|  Epoch 96 |  0.037383177570093455 | 0.558097691265 | 6.79668007558 | 0.057971014492753624 |  0.027586206896551724 | 41.6702014554 |
|  Epoch 97 |  0.019184652278177457 | 0.569547464325 | 6.89348340135 | 0.031496062992125984 |  0.013793103448275862 | 43.2015656502 |
|  Epoch 98 |  0.022935779816513763 | 0.557565012707 | 6.78738236327 | 0.03424657534246575  |  0.017241379310344827 | 40.3208589861 |
|  Epoch 99 |  0.01818181818181818  | 0.552394870565 | 6.76385863797 | 0.02666666666666667  |  0.013793103448275862 | 40.9737087373 |
| Epoch 100 |  0.018475750577367205 | 0.550599610579 | 6.74926964146 | 0.027972027972027972 |  0.013793103448275862 | 40.4622242835 |
+-----------+-----------------------+----------------+---------------+----------------------+-----------------------+---------------+
_________________________________________________________________
+---------------------------------+--------------------+--------------------+-----------------------+---------+-----------------------+
|            Optimizer            |       beta_1       |       beta_2       |         decay         | epsilon |           lr          |
+---------------------------------+--------------------+--------------------+-----------------------+---------+-----------------------+
| <class 'keras.optimizers.Adam'> | 0.8999999761581421 | 0.9990000128746033 | 0.0005000000237487257 |  1e-08  | 9.999999747378752e-05 |
+---------------------------------+--------------------+--------------------+-----------------------+---------+-----------------------+
_________________________________________________________________
+------------+
| Batch Size |
+------------+
|     16     |
+------------+
_________________________________________________________________
+--------------------+---------------+----------------+----------------------+----------------------+----------------------+
|      Metrics       |      Loss     |      IoU       |      Precision       |        Recall        |       F1 Score       |
+--------------------+---------------+----------------+----------------------+----------------------+----------------------+
|   Train Metrics    | 136.721089657 | 0.569026124698 |  0.0578537170263789  | 0.023348657149770143 | 0.03327012584037235  |
| Validation Metrics | 80.4804333102 | 0.550599610579 | 0.027972027972027972 | 0.013793103448275862 | 0.018475750577367205 |
|    Test Metrics    | 84.7303831039 | 0.568266685625 | 0.05389221556886228  | 0.02912621359223301  | 0.03781512605042017  |
+--------------------+---------------+----------------+----------------------+----------------------+----------------------+
_________________________________________________________________
Time:
    Train Time              : 10:33:47.810507
    Dataset Loading Time    : 0:00:38.219861
    Metrics Evaluation Time : 0:09:56.154947
_________________________________________________________________
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         (None, 288, 288, 1)       0         
_________________________________________________________________
conv_1 (Conv2D)              (None, 288, 288, 32)      320       
_________________________________________________________________
norm_1 (BatchNormalization)  (None, 288, 288, 32)      128       
_________________________________________________________________
relu_1 (LeakyReLU)           (None, 288, 288, 32)      0         
_________________________________________________________________
pool_1 (MaxPooling2D)        (None, 144, 144, 32)      0         
_________________________________________________________________
conv_2 (Conv2D)              (None, 144, 144, 64)      18496     
_________________________________________________________________
norm_2 (BatchNormalization)  (None, 144, 144, 64)      256       
_________________________________________________________________
relu_2 (LeakyReLU)           (None, 144, 144, 64)      0         
_________________________________________________________________
pool_2 (MaxPooling2D)        (None, 72, 72, 64)        0         
_________________________________________________________________
conv_3 (Conv2D)              (None, 72, 72, 128)       73856     
_________________________________________________________________
norm_3 (BatchNormalization)  (None, 72, 72, 128)       512       
_________________________________________________________________
relu_3 (LeakyReLU)           (None, 72, 72, 128)       0         
_________________________________________________________________
drop_1 (Dropout)             (None, 72, 72, 128)       0         
_________________________________________________________________
conv_4 (Conv2D)              (None, 72, 72, 64)        8256      
_________________________________________________________________
norm_4 (BatchNormalization)  (None, 72, 72, 64)        256       
_________________________________________________________________
relu_4 (LeakyReLU)           (None, 72, 72, 64)        0         
_________________________________________________________________
drop_2 (Dropout)             (None, 72, 72, 64)        0         
_________________________________________________________________
conv_5 (Conv2D)              (None, 72, 72, 128)       73856     
_________________________________________________________________
norm_5 (BatchNormalization)  (None, 72, 72, 128)       512       
_________________________________________________________________
relu_5 (LeakyReLU)           (None, 72, 72, 128)       0         
_________________________________________________________________
pool_3 (MaxPooling2D)        (None, 36, 36, 128)       0         
_________________________________________________________________
conv_6 (Conv2D)              (None, 36, 36, 256)       295168    
_________________________________________________________________
norm_6 (BatchNormalization)  (None, 36, 36, 256)       1024      
_________________________________________________________________
relu_6 (LeakyReLU)           (None, 36, 36, 256)       0         
_________________________________________________________________
drop_3 (Dropout)             (None, 36, 36, 256)       0         
_________________________________________________________________
conv_7 (Conv2D)              (None, 36, 36, 128)       32896     
_________________________________________________________________
norm_7 (BatchNormalization)  (None, 36, 36, 128)       512       
_________________________________________________________________
relu_7 (LeakyReLU)           (None, 36, 36, 128)       0         
_________________________________________________________________
drop_4 (Dropout)             (None, 36, 36, 128)       0         
_________________________________________________________________
conv_8 (Conv2D)              (None, 36, 36, 256)       295168    
_________________________________________________________________
norm_8 (BatchNormalization)  (None, 36, 36, 256)       1024      
_________________________________________________________________
relu_8 (LeakyReLU)           (None, 36, 36, 256)       0         
_________________________________________________________________
pool_4 (MaxPooling2D)        (None, 18, 18, 256)       0         
_________________________________________________________________
conv_9 (Conv2D)              (None, 18, 18, 512)       1180160   
_________________________________________________________________
norm_9 (BatchNormalization)  (None, 18, 18, 512)       2048      
_________________________________________________________________
relu_9 (LeakyReLU)           (None, 18, 18, 512)       0         
_________________________________________________________________
drop_5 (Dropout)             (None, 18, 18, 512)       0         
_________________________________________________________________
conv_10 (Conv2D)             (None, 18, 18, 256)       131328    
_________________________________________________________________
norm_10 (BatchNormalization) (None, 18, 18, 256)       1024      
_________________________________________________________________
relu_10 (LeakyReLU)          (None, 18, 18, 256)       0         
_________________________________________________________________
drop_6 (Dropout)             (None, 18, 18, 256)       0         
_________________________________________________________________
conv_11 (Conv2D)             (None, 18, 18, 512)       1180160   
_________________________________________________________________
norm_11 (BatchNormalization) (None, 18, 18, 512)       2048      
_________________________________________________________________
relu_11 (LeakyReLU)          (None, 18, 18, 512)       0         
_________________________________________________________________
drop_7 (Dropout)             (None, 18, 18, 512)       0         
_________________________________________________________________
conv_12 (Conv2D)             (None, 18, 18, 256)       131328    
_________________________________________________________________
norm_12 (BatchNormalization) (None, 18, 18, 256)       1024      
_________________________________________________________________
relu_12 (LeakyReLU)          (None, 18, 18, 256)       0         
_________________________________________________________________
drop_8 (Dropout)             (None, 18, 18, 256)       0         
_________________________________________________________________
conv_13 (Conv2D)             (None, 18, 18, 512)       1180160   
_________________________________________________________________
norm_13 (BatchNormalization) (None, 18, 18, 512)       2048      
_________________________________________________________________
relu_13 (LeakyReLU)          (None, 18, 18, 512)       0         
_________________________________________________________________
pool_5 (MaxPooling2D)        (None, 9, 9, 512)         0         
_________________________________________________________________
conv_14 (Conv2D)             (None, 9, 9, 1024)        4719616   
_________________________________________________________________
norm_14 (BatchNormalization) (None, 9, 9, 1024)        4096      
_________________________________________________________________
relu_14 (LeakyReLU)          (None, 9, 9, 1024)        0         
_________________________________________________________________
drop_9 (Dropout)             (None, 9, 9, 1024)        0         
_________________________________________________________________
conv_15 (Conv2D)             (None, 9, 9, 1024)        9438208   
_________________________________________________________________
norm_15 (BatchNormalization) (None, 9, 9, 1024)        4096      
_________________________________________________________________
relu_15 (LeakyReLU)          (None, 9, 9, 1024)        0         
_________________________________________________________________
drop_10 (Dropout)            (None, 9, 9, 1024)        0         
_________________________________________________________________
conv_16 (Conv2D)             (None, 9, 9, 5)           5125      
_________________________________________________________________
reshape_1 (Reshape)          (None, 9, 9, 5)           0         
=================================================================
Total params: 18,784,709
Trainable params: 18,774,405
Non-trainable params: 10,304
_________________________________________________________________
+----------+----------+-----+---------------+-----------+--------+---------------+
|  Epoch   | f1_score | iou |      loss     | precision | recall |    val_loss   |
+----------+----------+-----+---------------+-----------+--------+---------------+
| Epoch 1  |   nan    | nan | 105.235459048 |    nan    |  0.0   | 42.5918266542 |
| Epoch 2  |   nan    | nan | 47.6058120599 |    nan    |  0.0   | 37.2947588275 |
| Epoch 3  |   nan    | nan | 41.1952286831 |    nan    |  0.0   | 34.1716314746 |
| Epoch 4  |   nan    | nan | 34.3329580151 |    nan    |  0.0   | 32.3509264915 |
| Epoch 5  |   nan    | nan | 31.1976080674 |    nan    |  0.0   | 32.4579472696 |
| Epoch 6  |   nan    | nan | 30.1998829088 |    nan    |  0.0   | 31.6994857788 |
| Epoch 7  |   nan    | nan | 29.6100819024 |    nan    |  0.0   | 33.9695446876 |
| Epoch 8  |   nan    | nan | 28.8597530323 |    nan    |  0.0   | 35.1328205601 |
| Epoch 9  |   nan    | nan | 28.1765217269 |    nan    |  0.0   | 35.6469455227 |
| Epoch 10 |   nan    | nan | 27.2268984981 |    nan    |  0.0   | 35.9123436712 |
| Epoch 11 |   nan    | nan | 26.2364306365 |    nan    |  0.0   | 36.3383003358 |
| Epoch 12 |   nan    | nan | 25.5464704131 |    nan    |  0.0   | 35.1331900935 |
| Epoch 13 |   nan    | nan | 24.9511540897 |    nan    |  0.0   | 34.5952510218 |
| Epoch 14 |   nan    | nan | 24.5573448317 |    nan    |  0.0   | 34.8028237743 |
| Epoch 15 |   nan    | nan | 24.1833338242 |    nan    |  0.0   | 32.0056485822 |
| Epoch 16 |   nan    | nan | 23.9182357046 |    nan    |  0.0   | 31.9439067225 |
| Epoch 17 |   nan    | nan | 23.6276989177 |    nan    |  0.0   | 30.2715080015 |
| Epoch 18 |   nan    | nan | 23.3689006248 |    nan    |  0.0   | 30.1829706623 |
| Epoch 19 |   nan    | nan | 23.0555499118 |    nan    |  0.0   | 29.7873678515 |
| Epoch 20 |   nan    | nan |  22.767099137 |    nan    |  0.0   | 29.4345856943 |
| Epoch 21 |   nan    | nan |  22.473115971 |    nan    |  0.0   | 29.1893267478 |
| Epoch 22 |   nan    | nan | 22.0898565629 |    nan    |  0.0   | 30.4861518491 |
| Epoch 23 |   nan    | nan |  21.806406924 |    nan    |  0.0   | 28.8468610087 |
| Epoch 24 |   nan    | nan | 21.5360764933 |    nan    |  0.0   | 28.6023990877 |
| Epoch 25 |   nan    | nan | 21.4385183839 |    nan    |  0.0   | 28.3278681232 |
| Epoch 26 |   nan    | nan | 21.1794878902 |    nan    |  0.0   | 27.9615733239 |
| Epoch 27 |   nan    | nan |  20.841725892 |    nan    |  0.0   | 28.2719672418 |
| Epoch 28 |   nan    | nan | 20.6962305587 |    nan    |  0.0   | 27.4248459108 |
| Epoch 29 |   nan    | nan |  20.617003698 |    nan    |  0.0   | 28.1897061256 |
| Epoch 30 |   nan    | nan | 20.3853388655 |    nan    |  0.0   | 27.7630927178 |
+----------+----------+-----+---------------+-----------+--------+---------------+
_________________________________________________________________
+---------------------------------+--------------------+--------------------+-----------------------+---------+-----------------------+
|            Optimizer            |       beta_1       |       beta_2       |         decay         | epsilon |           lr          |
+---------------------------------+--------------------+--------------------+-----------------------+---------+-----------------------+
| <class 'keras.optimizers.Adam'> | 0.8999999761581421 | 0.9990000128746033 | 0.0005000000237487257 |  1e-08  | 9.999999747378752e-05 |
+---------------------------------+--------------------+--------------------+-----------------------+---------+-----------------------+
_________________________________________________________________
+------------+
| Batch Size |
+------------+
|     16     |
+------------+
_________________________________________________________________
+--------------------+---------------+-----+-----------+--------+----------+
|      Metrics       |      Loss     | IoU | Precision | Recall | F1 Score |
+--------------------+---------------+-----+-----------+--------+----------+
|   Train Metrics    | 93.0198660018 | nan |    nan    |  0.0   |   nan    |
| Validation Metrics | 55.2973871539 | nan |    nan    |  0.0   |   nan    |
|    Test Metrics    | 58.9892738096 | nan |    nan    |  0.0   |   nan    |
+--------------------+---------------+-----+-----------+--------+----------+
_________________________________________________________________
Time:
    Train Time              : 3:06:40.105706
    Dataset Loading Time    : 0:00:40.403576
    Metrics Evaluation Time : 0:07:10.815312
_________________________________________________________________
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         (None, 288, 288, 1)       0         
_________________________________________________________________
conv_1 (Conv2D)              (None, 288, 288, 32)      320       
_________________________________________________________________
norm_1 (BatchNormalization)  (None, 288, 288, 32)      128       
_________________________________________________________________
relu_1 (LeakyReLU)           (None, 288, 288, 32)      0         
_________________________________________________________________
pool_1 (MaxPooling2D)        (None, 144, 144, 32)      0         
_________________________________________________________________
conv_2 (Conv2D)              (None, 144, 144, 64)      18496     
_________________________________________________________________
norm_2 (BatchNormalization)  (None, 144, 144, 64)      256       
_________________________________________________________________
relu_2 (LeakyReLU)           (None, 144, 144, 64)      0         
_________________________________________________________________
pool_2 (MaxPooling2D)        (None, 72, 72, 64)        0         
_________________________________________________________________
conv_3 (Conv2D)              (None, 72, 72, 128)       73856     
_________________________________________________________________
norm_3 (BatchNormalization)  (None, 72, 72, 128)       512       
_________________________________________________________________
relu_3 (LeakyReLU)           (None, 72, 72, 128)       0         
_________________________________________________________________
drop_1 (Dropout)             (None, 72, 72, 128)       0         
_________________________________________________________________
conv_4 (Conv2D)              (None, 72, 72, 64)        8256      
_________________________________________________________________
norm_4 (BatchNormalization)  (None, 72, 72, 64)        256       
_________________________________________________________________
relu_4 (LeakyReLU)           (None, 72, 72, 64)        0         
_________________________________________________________________
drop_2 (Dropout)             (None, 72, 72, 64)        0         
_________________________________________________________________
conv_5 (Conv2D)              (None, 72, 72, 128)       73856     
_________________________________________________________________
norm_5 (BatchNormalization)  (None, 72, 72, 128)       512       
_________________________________________________________________
relu_5 (LeakyReLU)           (None, 72, 72, 128)       0         
_________________________________________________________________
pool_3 (MaxPooling2D)        (None, 36, 36, 128)       0         
_________________________________________________________________
conv_6 (Conv2D)              (None, 36, 36, 256)       295168    
_________________________________________________________________
norm_6 (BatchNormalization)  (None, 36, 36, 256)       1024      
_________________________________________________________________
relu_6 (LeakyReLU)           (None, 36, 36, 256)       0         
_________________________________________________________________
drop_3 (Dropout)             (None, 36, 36, 256)       0         
_________________________________________________________________
conv_7 (Conv2D)              (None, 36, 36, 128)       32896     
_________________________________________________________________
norm_7 (BatchNormalization)  (None, 36, 36, 128)       512       
_________________________________________________________________
relu_7 (LeakyReLU)           (None, 36, 36, 128)       0         
_________________________________________________________________
drop_4 (Dropout)             (None, 36, 36, 128)       0         
_________________________________________________________________
conv_8 (Conv2D)              (None, 36, 36, 256)       295168    
_________________________________________________________________
norm_8 (BatchNormalization)  (None, 36, 36, 256)       1024      
_________________________________________________________________
relu_8 (LeakyReLU)           (None, 36, 36, 256)       0         
_________________________________________________________________
pool_4 (MaxPooling2D)        (None, 18, 18, 256)       0         
_________________________________________________________________
conv_9 (Conv2D)              (None, 18, 18, 512)       1180160   
_________________________________________________________________
norm_9 (BatchNormalization)  (None, 18, 18, 512)       2048      
_________________________________________________________________
relu_9 (LeakyReLU)           (None, 18, 18, 512)       0         
_________________________________________________________________
drop_5 (Dropout)             (None, 18, 18, 512)       0         
_________________________________________________________________
conv_10 (Conv2D)             (None, 18, 18, 256)       131328    
_________________________________________________________________
norm_10 (BatchNormalization) (None, 18, 18, 256)       1024      
_________________________________________________________________
relu_10 (LeakyReLU)          (None, 18, 18, 256)       0         
_________________________________________________________________
drop_6 (Dropout)             (None, 18, 18, 256)       0         
_________________________________________________________________
conv_11 (Conv2D)             (None, 18, 18, 512)       1180160   
_________________________________________________________________
norm_11 (BatchNormalization) (None, 18, 18, 512)       2048      
_________________________________________________________________
relu_11 (LeakyReLU)          (None, 18, 18, 512)       0         
_________________________________________________________________
drop_7 (Dropout)             (None, 18, 18, 512)       0         
_________________________________________________________________
conv_12 (Conv2D)             (None, 18, 18, 256)       131328    
_________________________________________________________________
norm_12 (BatchNormalization) (None, 18, 18, 256)       1024      
_________________________________________________________________
relu_12 (LeakyReLU)          (None, 18, 18, 256)       0         
_________________________________________________________________
drop_8 (Dropout)             (None, 18, 18, 256)       0         
_________________________________________________________________
conv_13 (Conv2D)             (None, 18, 18, 512)       1180160   
_________________________________________________________________
norm_13 (BatchNormalization) (None, 18, 18, 512)       2048      
_________________________________________________________________
relu_13 (LeakyReLU)          (None, 18, 18, 512)       0         
_________________________________________________________________
pool_5 (MaxPooling2D)        (None, 9, 9, 512)         0         
_________________________________________________________________
conv_14 (Conv2D)             (None, 9, 9, 1024)        4719616   
_________________________________________________________________
norm_14 (BatchNormalization) (None, 9, 9, 1024)        4096      
_________________________________________________________________
relu_14 (LeakyReLU)          (None, 9, 9, 1024)        0         
_________________________________________________________________
drop_9 (Dropout)             (None, 9, 9, 1024)        0         
_________________________________________________________________
conv_15 (Conv2D)             (None, 9, 9, 1024)        9438208   
_________________________________________________________________
norm_15 (BatchNormalization) (None, 9, 9, 1024)        4096      
_________________________________________________________________
relu_15 (LeakyReLU)          (None, 9, 9, 1024)        0         
_________________________________________________________________
drop_10 (Dropout)            (None, 9, 9, 1024)        0         
_________________________________________________________________
conv_16 (Conv2D)             (None, 9, 9, 5)           5125      
_________________________________________________________________
reshape_1 (Reshape)          (None, 9, 9, 5)           0         
=================================================================
Total params: 18,784,709
Trainable params: 18,774,405
Non-trainable params: 10,304
_________________________________________________________________
+----------+----------+-----+---------------+-----------+--------+---------------+
|  Epoch   | f1_score | iou |      loss     | precision | recall |    val_loss   |
+----------+----------+-----+---------------+-----------+--------+---------------+
| Epoch 1  |   nan    | nan | 44.6085204095 |    nan    |  0.0   | 46.9437154954 |
| Epoch 2  |   nan    | nan | 31.8651782122 |    nan    |  0.0   | 42.3181611338 |
| Epoch 3  |   nan    | nan | 26.1693268499 |    nan    |  0.0   | 74.0269861529 |
| Epoch 4  |   nan    | nan | 22.4107475603 |    nan    |  0.0   | 56.8510529303 |
| Epoch 5  |   nan    | nan | 19.3827613982 |    nan    |  0.0   | 66.6824456492 |
| Epoch 6  |   nan    | nan | 18.2564269015 |    nan    |  0.0   | 60.4544169518 |
| Epoch 7  |   nan    | nan | 17.4127247392 |    nan    |  0.0   | 55.0382406173 |
| Epoch 8  |   nan    | nan | 16.8836484717 |    nan    |  0.0   | 68.9198421355 |
| Epoch 9  |   nan    | nan | 16.3674059551 |    nan    |  0.0   | 77.8510854167 |
| Epoch 10 |   nan    | nan | 15.8711038365 |    nan    |  0.0   | 75.3325881958 |
| Epoch 11 |   nan    | nan | 15.5495072161 |    nan    |  0.0   | 83.9810776249 |
| Epoch 12 |   nan    | nan | 15.2295333995 |    nan    |  0.0   | 93.6656353858 |
| Epoch 13 |   nan    | nan | 14.8396756429 |    nan    |  0.0   | 67.6426549112 |
| Epoch 14 |   nan    | nan |  14.433346494 |    nan    |  0.0   |  57.533589763 |
| Epoch 15 |   nan    | nan | 14.2171825383 |    nan    |  0.0   |  47.892214006 |
| Epoch 16 |   nan    | nan | 13.9972592468 |    nan    |  0.0   | 52.2685831131 |
| Epoch 17 |   nan    | nan | 13.7726367223 |    nan    |  0.0   | 29.5344801257 |
| Epoch 18 |   nan    | nan | 13.5666892087 |    nan    |  0.0   | 28.1781034162 |
| Epoch 19 |   nan    | nan | 13.3741201883 |    nan    |  0.0   | 37.9064226458 |
| Epoch 20 |   nan    | nan | 13.1584604232 |    nan    |  0.0   | 41.3027934413 |
| Epoch 21 |   nan    | nan | 12.8336086749 |    nan    |  0.0   | 30.7359331193 |
| Epoch 22 |   nan    | nan | 12.8354805844 |    nan    |  0.0   | 42.1631533715 |
| Epoch 23 |   nan    | nan | 12.7501109672 |    nan    |  0.0   | 45.9315542406 |
| Epoch 24 |   nan    | nan |  12.517052515 |    nan    |  0.0   | 60.2206237547 |
| Epoch 25 |   nan    | nan | 12.3596361447 |    nan    |  0.0   | 42.4228882328 |
| Epoch 26 |   nan    | nan | 12.2047811413 |    nan    |  0.0   | 36.3251891598 |
| Epoch 27 |   nan    | nan | 12.0925430191 |    nan    |  0.0   | 48.2343875516 |
| Epoch 28 |   nan    | nan | 11.9111581312 |    nan    |  0.0   | 63.1868972778 |
| Epoch 29 |   nan    | nan | 11.7404479029 |    nan    |  0.0   |  37.71386165  |
| Epoch 30 |   nan    | nan | 11.7685638349 |    nan    |  0.0   | 64.3854797117 |
+----------+----------+-----+---------------+-----------+--------+---------------+
_________________________________________________________________
+---------------------------------+--------------------+--------------------+-----------------------+---------+-----------------------+
|            Optimizer            |       beta_1       |       beta_2       |         decay         | epsilon |           lr          |
+---------------------------------+--------------------+--------------------+-----------------------+---------+-----------------------+
| <class 'keras.optimizers.Adam'> | 0.8999999761581421 | 0.9990000128746033 | 0.0005000000237487257 |  1e-08  | 0.0010000000474974513 |
+---------------------------------+--------------------+--------------------+-----------------------+---------+-----------------------+
_________________________________________________________________
+------------+
| Batch Size |
+------------+
|     16     |
+------------+
_________________________________________________________________
+--------------------+---------------+-----+-----------+--------+----------+
|      Metrics       |      Loss     | IoU | Precision | Recall | F1 Score |
+--------------------+---------------+-----+-----------+--------+----------+
|   Train Metrics    |   258.140436  | nan |    nan    |  0.0   |   nan    |
| Validation Metrics | 128.181677541 | nan |    nan    |  0.0   |   nan    |
|    Test Metrics    | 139.571680869 | nan |    nan    |  0.0   |   nan    |
+--------------------+---------------+-----+-----------+--------+----------+
_________________________________________________________________
Time:
    Train Time              : 3:06:01.951907
    Dataset Loading Time    : 0:00:41.397789
    Metrics Evaluation Time : 0:06:08.673588
_________________________________________________________________
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         (None, 288, 288, 1)       0         
_________________________________________________________________
conv_1 (Conv2D)              (None, 288, 288, 32)      320       
_________________________________________________________________
norm_1 (BatchNormalization)  (None, 288, 288, 32)      128       
_________________________________________________________________
relu_1 (LeakyReLU)           (None, 288, 288, 32)      0         
_________________________________________________________________
pool_1 (MaxPooling2D)        (None, 144, 144, 32)      0         
_________________________________________________________________
conv_2 (Conv2D)              (None, 144, 144, 64)      18496     
_________________________________________________________________
norm_2 (BatchNormalization)  (None, 144, 144, 64)      256       
_________________________________________________________________
relu_2 (LeakyReLU)           (None, 144, 144, 64)      0         
_________________________________________________________________
pool_2 (MaxPooling2D)        (None, 72, 72, 64)        0         
_________________________________________________________________
conv_3 (Conv2D)              (None, 72, 72, 128)       73856     
_________________________________________________________________
norm_3 (BatchNormalization)  (None, 72, 72, 128)       512       
_________________________________________________________________
relu_3 (LeakyReLU)           (None, 72, 72, 128)       0         
_________________________________________________________________
conv_4 (Conv2D)              (None, 72, 72, 64)        8256      
_________________________________________________________________
norm_4 (BatchNormalization)  (None, 72, 72, 64)        256       
_________________________________________________________________
relu_4 (LeakyReLU)           (None, 72, 72, 64)        0         
_________________________________________________________________
conv_5 (Conv2D)              (None, 72, 72, 128)       73856     
_________________________________________________________________
norm_5 (BatchNormalization)  (None, 72, 72, 128)       512       
_________________________________________________________________
relu_5 (LeakyReLU)           (None, 72, 72, 128)       0         
_________________________________________________________________
pool_3 (MaxPooling2D)        (None, 36, 36, 128)       0         
_________________________________________________________________
conv_6 (Conv2D)              (None, 36, 36, 256)       295168    
_________________________________________________________________
norm_6 (BatchNormalization)  (None, 36, 36, 256)       1024      
_________________________________________________________________
relu_6 (LeakyReLU)           (None, 36, 36, 256)       0         
_________________________________________________________________
conv_7 (Conv2D)              (None, 36, 36, 128)       32896     
_________________________________________________________________
norm_7 (BatchNormalization)  (None, 36, 36, 128)       512       
_________________________________________________________________
relu_7 (LeakyReLU)           (None, 36, 36, 128)       0         
_________________________________________________________________
conv_8 (Conv2D)              (None, 36, 36, 256)       295168    
_________________________________________________________________
norm_8 (BatchNormalization)  (None, 36, 36, 256)       1024      
_________________________________________________________________
relu_8 (LeakyReLU)           (None, 36, 36, 256)       0         
_________________________________________________________________
pool_4 (MaxPooling2D)        (None, 18, 18, 256)       0         
_________________________________________________________________
conv_9 (Conv2D)              (None, 18, 18, 512)       1180160   
_________________________________________________________________
norm_9 (BatchNormalization)  (None, 18, 18, 512)       2048      
_________________________________________________________________
relu_9 (LeakyReLU)           (None, 18, 18, 512)       0         
_________________________________________________________________
conv_10 (Conv2D)             (None, 18, 18, 256)       131328    
_________________________________________________________________
norm_10 (BatchNormalization) (None, 18, 18, 256)       1024      
_________________________________________________________________
relu_10 (LeakyReLU)          (None, 18, 18, 256)       0         
_________________________________________________________________
conv_11 (Conv2D)             (None, 18, 18, 512)       1180160   
_________________________________________________________________
norm_11 (BatchNormalization) (None, 18, 18, 512)       2048      
_________________________________________________________________
relu_11 (LeakyReLU)          (None, 18, 18, 512)       0         
_________________________________________________________________
conv_12 (Conv2D)             (None, 18, 18, 256)       131328    
_________________________________________________________________
norm_12 (BatchNormalization) (None, 18, 18, 256)       1024      
_________________________________________________________________
relu_12 (LeakyReLU)          (None, 18, 18, 256)       0         
_________________________________________________________________
conv_13 (Conv2D)             (None, 18, 18, 512)       1180160   
_________________________________________________________________
norm_13 (BatchNormalization) (None, 18, 18, 512)       2048      
_________________________________________________________________
relu_13 (LeakyReLU)          (None, 18, 18, 512)       0         
_________________________________________________________________
pool_5 (MaxPooling2D)        (None, 9, 9, 512)         0         
_________________________________________________________________
conv_14 (Conv2D)             (None, 9, 9, 1024)        4719616   
_________________________________________________________________
norm_14 (BatchNormalization) (None, 9, 9, 1024)        4096      
_________________________________________________________________
relu_14 (LeakyReLU)          (None, 9, 9, 1024)        0         
_________________________________________________________________
conv_15 (Conv2D)             (None, 9, 9, 1024)        9438208   
_________________________________________________________________
norm_15 (BatchNormalization) (None, 9, 9, 1024)        4096      
_________________________________________________________________
relu_15 (LeakyReLU)          (None, 9, 9, 1024)        0         
_________________________________________________________________
conv_16 (Conv2D)             (None, 9, 9, 5)           5125      
_________________________________________________________________
reshape_1 (Reshape)          (None, 9, 9, 5)           0         
=================================================================
Total params: 18,784,709
Trainable params: 18,774,405
Non-trainable params: 10,304
_________________________________________________________________
+----------+--------------------+----------------+---------------+--------------------+--------------------+---------------+
|  Epoch   |      f1_score      |      iou       |      loss     |     precision      |       recall       |    val_loss   |
+----------+--------------------+----------------+---------------+--------------------+--------------------+---------------+
| Epoch 1  |        nan         |      nan       |  28.518784236 |        nan         |        0.0         | 84.9459091925 |
| Epoch 2  | 0.7650273224043715 | 0.695635332935 | 14.9320240815 | 0.8108108108108109 | 0.7241379310344828 | 6.10968648234 |
| Epoch 3  | 0.6921739130434782 | 0.680532917331 | 11.9126522382 | 0.6982456140350877 | 0.6862068965517242 | 7.68623495102 |
| Epoch 4  | 0.7338129496402878 | 0.689331261729 | 9.79213048398 | 0.7669172932330827 | 0.7034482758620689 | 7.32426414182 |
| Epoch 5  | 0.7353463587921847 | 0.669829747694 | 8.50782632263 | 0.7582417582417582 | 0.7137931034482758 | 7.66945437462 |
| Epoch 6  | 0.6407766990291262 | 0.688212248499 | 7.48455375831 | 0.6036585365853658 | 0.6827586206896552 |  8.2678669345 |
| Epoch 7  | 0.7118055555555556 | 0.698996207146 |  6.8692845085 | 0.7167832167832168 | 0.7068965517241379 | 7.13629111936 |
| Epoch 8  | 0.6856060606060607 | 0.690674597651 | 6.35341532293 | 0.7605042016806722 | 0.6241379310344828 | 8.02664696786 |
| Epoch 9  | 0.7534722222222222 | 0.682165033882 | 5.97095429686 | 0.7587412587412588 | 0.7482758620689656 | 6.32662394739 |
| Epoch 10 | 0.7086882453151618 | 0.705971206341 | 5.64397828496 | 0.7003367003367004 | 0.7172413793103448 | 7.57858663221 |
| Epoch 11 | 0.7422303473491773 | 0.694265112629 | 5.36667398528 | 0.7898832684824902 |        0.7         | 7.17390092727 |
| Epoch 12 | 0.7214285714285713 | 0.696493305229 | 5.04224201107 | 0.7481481481481481 | 0.696551724137931  | 7.51912444638 |
| Epoch 13 | 0.7084870848708487 | 0.679161626843 | 4.83642444042 | 0.7619047619047619 | 0.6620689655172414 | 7.40474551724 |
| Epoch 14 | 0.7472924187725632 | 0.697490684559 | 4.63245225245 | 0.7840909090909091 | 0.7137931034482758 | 6.85414820333 |
| Epoch 15 | 0.7302752293577982 | 0.686334090792 | 4.40679340895 | 0.7803921568627451 | 0.6862068965517242 | 6.85404083806 |
| Epoch 16 | 0.7092436974789915 | 0.691235048483 | 4.25193863528 | 0.6918032786885245 | 0.7275862068965517 | 7.16126024339 |
| Epoch 17 | 0.6943942133815552 | 0.698670396168 | 4.07989406838 | 0.7300380228136882 | 0.6620689655172414 | 8.32572924706 |
| Epoch 18 | 0.696551724137931  | 0.700566163573 | 3.87606684162 | 0.696551724137931  | 0.696551724137931  | 8.03849861699 |
| Epoch 19 | 0.6914062500000001 | 0.690537793827 | 3.76278351387 | 0.7972972972972973 | 0.6103448275862069 | 8.48682456632 |
| Epoch 20 | 0.6044624746450304 | 0.689979356244 | 3.53773371652 | 0.7339901477832512 | 0.5137931034482759 | 10.2474838688 |
| Epoch 21 | 0.7037643207855974 | 0.69581637065  | 3.57329667622 | 0.6697819314641744 | 0.7413793103448276 | 8.00809188043 |
| Epoch 22 | 0.7181328545780971 | 0.694841007297 | 3.40110132579 | 0.7490636704119851 | 0.6896551724137931 | 7.73998170514 |
| Epoch 23 | 0.7351351351351352 | 0.677084252461 | 3.34770033046 | 0.769811320754717  | 0.7034482758620689 | 7.45764892332 |
| Epoch 24 | 0.7142857142857142 | 0.688744190702 | 3.29490336179 |     0.76171875     | 0.6724137931034483 | 8.17425094112 |
| Epoch 25 | 0.6930379746835443 | 0.690064734182 | 3.23824211086 | 0.6403508771929824 | 0.7551724137931034 |  8.1992555203 |
| Epoch 26 | 0.7092198581560284 | 0.700986141447 | 3.17538787668 | 0.7299270072992701 | 0.6896551724137931 | 7.89162248181 |
| Epoch 27 | 0.6846846846846846 | 0.688912888123 | 3.07407662774 | 0.7169811320754716 | 0.6551724137931034 | 8.67938380088 |
| Epoch 28 | 0.7075812274368232 | 0.684706539333 | 2.97173489836 | 0.7424242424242424 | 0.6758620689655173 | 7.97955459164 |
| Epoch 29 | 0.6785079928952044 | 0.689440271329 |  2.9878491786 | 0.6996336996336996 | 0.6586206896551724 | 8.53625251401 |
| Epoch 30 | 0.7109515260323159 | 0.687830188102 |  2.9144124096 | 0.7415730337078652 | 0.6827586206896552 |  8.3124459482 |
+----------+--------------------+----------------+---------------+--------------------+--------------------+---------------+
_________________________________________________________________
+------------------------------------+-----------------------+---------+-----------------------+--------------------+
|             Optimizer              |         decay         | epsilon |           lr          |        rho         |
+------------------------------------+-----------------------+---------+-----------------------+--------------------+
| <class 'keras.optimizers.RMSprop'> | 9.999999747378752e-06 |  1e-08  | 0.0010000000474974513 | 0.8999999761581421 |
+------------------------------------+-----------------------+---------+-----------------------+--------------------+
_________________________________________________________________
+------------+
| Batch Size |
+------------+
|     16     |
+------------+
_________________________________________________________________
+--------------------+---------------+----------------+--------------------+--------------------+--------------------+
|      Metrics       |      Loss     |      IoU       |     Precision      |       Recall       |      F1 Score      |
+--------------------+---------------+----------------+--------------------+--------------------+--------------------+
|   Train Metrics    | 5.84111662981 | 0.835048328226 | 0.9725274725274725 | 0.8993467215097992 | 0.9345065996228787 |
| Validation Metrics | 16.6155853271 | 0.687830188102 | 0.7415730337078652 | 0.6827586206896552 | 0.7109515260323159 |
|    Test Metrics    |  19.950118834 | 0.686720944975 | 0.7290076335877863 | 0.6181229773462783 | 0.6690017513134852 |
+--------------------+---------------+----------------+--------------------+--------------------+--------------------+
_________________________________________________________________
Time:
    Train Time              : 2:56:20.914114
    Dataset Loading Time    : 0:00:37.170022
    Metrics Evaluation Time : 0:06:23.223616
_________________________________________________________________
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         (None, 288, 288, 1)       0         
_________________________________________________________________
conv_1 (Conv2D)              (None, 288, 288, 32)      320       
_________________________________________________________________
norm_1 (BatchNormalization)  (None, 288, 288, 32)      128       
_________________________________________________________________
relu_1 (LeakyReLU)           (None, 288, 288, 32)      0         
_________________________________________________________________
pool_1 (MaxPooling2D)        (None, 144, 144, 32)      0         
_________________________________________________________________
conv_2 (Conv2D)              (None, 144, 144, 64)      18496     
_________________________________________________________________
norm_2 (BatchNormalization)  (None, 144, 144, 64)      256       
_________________________________________________________________
relu_2 (LeakyReLU)           (None, 144, 144, 64)      0         
_________________________________________________________________
pool_2 (MaxPooling2D)        (None, 72, 72, 64)        0         
_________________________________________________________________
conv_3 (Conv2D)              (None, 72, 72, 128)       73856     
_________________________________________________________________
norm_3 (BatchNormalization)  (None, 72, 72, 128)       512       
_________________________________________________________________
relu_3 (LeakyReLU)           (None, 72, 72, 128)       0         
_________________________________________________________________
conv_4 (Conv2D)              (None, 72, 72, 64)        8256      
_________________________________________________________________
norm_4 (BatchNormalization)  (None, 72, 72, 64)        256       
_________________________________________________________________
relu_4 (LeakyReLU)           (None, 72, 72, 64)        0         
_________________________________________________________________
conv_5 (Conv2D)              (None, 72, 72, 128)       73856     
_________________________________________________________________
norm_5 (BatchNormalization)  (None, 72, 72, 128)       512       
_________________________________________________________________
relu_5 (LeakyReLU)           (None, 72, 72, 128)       0         
_________________________________________________________________
pool_3 (MaxPooling2D)        (None, 36, 36, 128)       0         
_________________________________________________________________
conv_6 (Conv2D)              (None, 36, 36, 256)       295168    
_________________________________________________________________
norm_6 (BatchNormalization)  (None, 36, 36, 256)       1024      
_________________________________________________________________
relu_6 (LeakyReLU)           (None, 36, 36, 256)       0         
_________________________________________________________________
conv_7 (Conv2D)              (None, 36, 36, 128)       32896     
_________________________________________________________________
norm_7 (BatchNormalization)  (None, 36, 36, 128)       512       
_________________________________________________________________
relu_7 (LeakyReLU)           (None, 36, 36, 128)       0         
_________________________________________________________________
conv_8 (Conv2D)              (None, 36, 36, 256)       295168    
_________________________________________________________________
norm_8 (BatchNormalization)  (None, 36, 36, 256)       1024      
_________________________________________________________________
relu_8 (LeakyReLU)           (None, 36, 36, 256)       0         
_________________________________________________________________
pool_4 (MaxPooling2D)        (None, 18, 18, 256)       0         
_________________________________________________________________
conv_9 (Conv2D)              (None, 18, 18, 512)       1180160   
_________________________________________________________________
norm_9 (BatchNormalization)  (None, 18, 18, 512)       2048      
_________________________________________________________________
relu_9 (LeakyReLU)           (None, 18, 18, 512)       0         
_________________________________________________________________
conv_10 (Conv2D)             (None, 18, 18, 256)       131328    
_________________________________________________________________
norm_10 (BatchNormalization) (None, 18, 18, 256)       1024      
_________________________________________________________________
relu_10 (LeakyReLU)          (None, 18, 18, 256)       0         
_________________________________________________________________
conv_11 (Conv2D)             (None, 18, 18, 512)       1180160   
_________________________________________________________________
norm_11 (BatchNormalization) (None, 18, 18, 512)       2048      
_________________________________________________________________
relu_11 (LeakyReLU)          (None, 18, 18, 512)       0         
_________________________________________________________________
conv_12 (Conv2D)             (None, 18, 18, 256)       131328    
_________________________________________________________________
norm_12 (BatchNormalization) (None, 18, 18, 256)       1024      
_________________________________________________________________
relu_12 (LeakyReLU)          (None, 18, 18, 256)       0         
_________________________________________________________________
conv_13 (Conv2D)             (None, 18, 18, 512)       1180160   
_________________________________________________________________
norm_13 (BatchNormalization) (None, 18, 18, 512)       2048      
_________________________________________________________________
relu_13 (LeakyReLU)          (None, 18, 18, 512)       0         
_________________________________________________________________
pool_5 (MaxPooling2D)        (None, 9, 9, 512)         0         
_________________________________________________________________
conv_14 (Conv2D)             (None, 9, 9, 1024)        4719616   
_________________________________________________________________
norm_14 (BatchNormalization) (None, 9, 9, 1024)        4096      
_________________________________________________________________
relu_14 (LeakyReLU)          (None, 9, 9, 1024)        0         
_________________________________________________________________
conv_15 (Conv2D)             (None, 9, 9, 1024)        9438208   
_________________________________________________________________
norm_15 (BatchNormalization) (None, 9, 9, 1024)        4096      
_________________________________________________________________
relu_15 (LeakyReLU)          (None, 9, 9, 1024)        0         
_________________________________________________________________
conv_16 (Conv2D)             (None, 9, 9, 5)           5125      
_________________________________________________________________
reshape_1 (Reshape)          (None, 9, 9, 5)           0         
=================================================================
Total params: 18,784,709
Trainable params: 18,774,405
Non-trainable params: 10,304
_________________________________________________________________
+---------+--------------------+---------------+---------------+-----------+---------------------+---------------+
|  Epoch  |      f1_score      |      iou      |      loss     | precision |        recall       |    val_loss   |
+---------+--------------------+---------------+---------------+-----------+---------------------+---------------+
| Epoch 1 |        nan         |      nan      | 30.8875813915 |    nan    |         0.0         | 94.5688641456 |
| Epoch 2 | 0.4111111111111111 | 0.66198897922 | 15.2322804313 |   0.444   | 0.38275862068965516 | 14.0665020481 |
+---------+--------------------+---------------+---------------+-----------+---------------------+---------------+
_________________________________________________________________
+------------------------------------+-----------------------+---------+-----------------------+--------------------+
|             Optimizer              |         decay         | epsilon |           lr          |        rho         |
+------------------------------------+-----------------------+---------+-----------------------+--------------------+
| <class 'keras.optimizers.RMSprop'> | 9.999999747378752e-06 |  1e-08  | 0.0010000000474974513 | 0.8999999761581421 |
+------------------------------------+-----------------------+---------+-----------------------+--------------------+
_________________________________________________________________
+------------+
| Batch Size |
+------------+
|     16     |
+------------+
_________________________________________________________________
+--------------------+---------------+----------------+--------------------+---------------------+--------------------+
|      Metrics       |      Loss     |      IoU       |     Precision      |        Recall       |      F1 Score      |
+--------------------+---------------+----------------+--------------------+---------------------+--------------------+
|   Train Metrics    | 37.4049128019 | 0.737232759262 | 0.6584443644220381 |  0.4424147108637793 | 0.529232995658466  |
| Validation Metrics | 28.2996184441 | 0.66198897922  |       0.444        | 0.38275862068965516 | 0.4111111111111111 |
|    Test Metrics    | 31.3120259931 |   0.66557253   | 0.4046692607003891 |  0.3365695792880259 | 0.3674911660777386 |
+--------------------+---------------+----------------+--------------------+---------------------+--------------------+
_________________________________________________________________
Time:
    Train Time              : 0:12:15.202425
    Dataset Loading Time    : 0:00:40.656766
    Metrics Evaluation Time : 0:04:23.837726
_________________________________________________________________
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         (None, 288, 288, 1)       0         
_________________________________________________________________
conv_1 (Conv2D)              (None, 288, 288, 32)      320       
_________________________________________________________________
norm_1 (BatchNormalization)  (None, 288, 288, 32)      128       
_________________________________________________________________
relu_1 (LeakyReLU)           (None, 288, 288, 32)      0         
_________________________________________________________________
pool_1 (MaxPooling2D)        (None, 144, 144, 32)      0         
_________________________________________________________________
conv_2 (Conv2D)              (None, 144, 144, 64)      18496     
_________________________________________________________________
norm_2 (BatchNormalization)  (None, 144, 144, 64)      256       
_________________________________________________________________
relu_2 (LeakyReLU)           (None, 144, 144, 64)      0         
_________________________________________________________________
pool_2 (MaxPooling2D)        (None, 72, 72, 64)        0         
_________________________________________________________________
conv_3 (Conv2D)              (None, 72, 72, 128)       73856     
_________________________________________________________________
norm_3 (BatchNormalization)  (None, 72, 72, 128)       512       
_________________________________________________________________
relu_3 (LeakyReLU)           (None, 72, 72, 128)       0         
_________________________________________________________________
conv_4 (Conv2D)              (None, 72, 72, 64)        8256      
_________________________________________________________________
norm_4 (BatchNormalization)  (None, 72, 72, 64)        256       
_________________________________________________________________
relu_4 (LeakyReLU)           (None, 72, 72, 64)        0         
_________________________________________________________________
conv_5 (Conv2D)              (None, 72, 72, 128)       73856     
_________________________________________________________________
norm_5 (BatchNormalization)  (None, 72, 72, 128)       512       
_________________________________________________________________
relu_5 (LeakyReLU)           (None, 72, 72, 128)       0         
_________________________________________________________________
pool_3 (MaxPooling2D)        (None, 36, 36, 128)       0         
_________________________________________________________________
conv_6 (Conv2D)              (None, 36, 36, 256)       295168    
_________________________________________________________________
norm_6 (BatchNormalization)  (None, 36, 36, 256)       1024      
_________________________________________________________________
relu_6 (LeakyReLU)           (None, 36, 36, 256)       0         
_________________________________________________________________
conv_7 (Conv2D)              (None, 36, 36, 128)       32896     
_________________________________________________________________
norm_7 (BatchNormalization)  (None, 36, 36, 128)       512       
_________________________________________________________________
relu_7 (LeakyReLU)           (None, 36, 36, 128)       0         
_________________________________________________________________
conv_8 (Conv2D)              (None, 36, 36, 256)       295168    
_________________________________________________________________
norm_8 (BatchNormalization)  (None, 36, 36, 256)       1024      
_________________________________________________________________
relu_8 (LeakyReLU)           (None, 36, 36, 256)       0         
_________________________________________________________________
pool_4 (MaxPooling2D)        (None, 18, 18, 256)       0         
_________________________________________________________________
conv_9 (Conv2D)              (None, 18, 18, 512)       1180160   
_________________________________________________________________
norm_9 (BatchNormalization)  (None, 18, 18, 512)       2048      
_________________________________________________________________
relu_9 (LeakyReLU)           (None, 18, 18, 512)       0         
_________________________________________________________________
conv_10 (Conv2D)             (None, 18, 18, 256)       131328    
_________________________________________________________________
norm_10 (BatchNormalization) (None, 18, 18, 256)       1024      
_________________________________________________________________
relu_10 (LeakyReLU)          (None, 18, 18, 256)       0         
_________________________________________________________________
conv_11 (Conv2D)             (None, 18, 18, 512)       1180160   
_________________________________________________________________
norm_11 (BatchNormalization) (None, 18, 18, 512)       2048      
_________________________________________________________________
relu_11 (LeakyReLU)          (None, 18, 18, 512)       0         
_________________________________________________________________
conv_12 (Conv2D)             (None, 18, 18, 256)       131328    
_________________________________________________________________
norm_12 (BatchNormalization) (None, 18, 18, 256)       1024      
_________________________________________________________________
relu_12 (LeakyReLU)          (None, 18, 18, 256)       0         
_________________________________________________________________
conv_13 (Conv2D)             (None, 18, 18, 512)       1180160   
_________________________________________________________________
norm_13 (BatchNormalization) (None, 18, 18, 512)       2048      
_________________________________________________________________
relu_13 (LeakyReLU)          (None, 18, 18, 512)       0         
_________________________________________________________________
pool_5 (MaxPooling2D)        (None, 9, 9, 512)         0         
_________________________________________________________________
conv_14 (Conv2D)             (None, 9, 9, 1024)        4719616   
_________________________________________________________________
norm_14 (BatchNormalization) (None, 9, 9, 1024)        4096      
_________________________________________________________________
relu_14 (LeakyReLU)          (None, 9, 9, 1024)        0         
_________________________________________________________________
conv_15 (Conv2D)             (None, 9, 9, 1024)        9438208   
_________________________________________________________________
norm_15 (BatchNormalization) (None, 9, 9, 1024)        4096      
_________________________________________________________________
relu_15 (LeakyReLU)          (None, 9, 9, 1024)        0         
_________________________________________________________________
conv_16 (Conv2D)             (None, 9, 9, 5)           5125      
_________________________________________________________________
reshape_1 (Reshape)          (None, 9, 9, 5)           0         
=================================================================
Total params: 18,784,709
Trainable params: 18,774,405
Non-trainable params: 10,304
_________________________________________________________________
+----------+---------------------+----------------+---------------+---------------------+---------------------+---------------+
|  Epoch   |       f1_score      |      iou       |      loss     |      precision      |        recall       |    val_loss   |
+----------+---------------------+----------------+---------------+---------------------+---------------------+---------------+
| Epoch 1  |         nan         |      nan       |  33.123866498 |         nan         |         0.0         |  25.845794124 |
| Epoch 2  | 0.09638554216867469 | 0.631020719583 | 14.2402821087 | 0.38095238095238093 | 0.05517241379310345 | 14.9907445908 |
| Epoch 3  |  0.3971631205673759 | 0.645139185702 | 9.61194306718 |  0.631578947368421  |  0.2896551724137931 | 12.2035387716 |
| Epoch 4  | 0.44017094017094016 | 0.618358006038 | 6.93289737669 |  0.5786516853932584 | 0.35517241379310344 | 11.3536517236 |
| Epoch 5  | 0.46296296296296297 | 0.622096960128 | 5.42184619418 |  0.704225352112676  |  0.3448275862068966 | 11.5295016843 |
| Epoch 6  | 0.44028103044496486 | 0.63877227568  | 4.47520630599 |  0.6861313868613139 | 0.32413793103448274 | 12.7234159131 |
| Epoch 7  |  0.5366876310272536 | 0.651181078136 | 3.74516557377 |  0.6844919786096256 |  0.4413793103448276 | 11.5708880578 |
| Epoch 8  | 0.48722986247544203 | 0.650328629364 | 3.23414563306 |  0.5662100456621004 | 0.42758620689655175 | 12.6660087339 |
| Epoch 9  |  0.5151515151515151 | 0.639636619089 | 2.91666093904 |  0.6918604651162791 |  0.4103448275862069 | 12.4818114311 |
| Epoch 10 |  0.5359477124183006 | 0.66319419343  | 2.52364329383 |  0.727810650887574  |  0.4241379310344828 | 11.5463996703 |
| Epoch 11 |  0.4794520547945206 | 0.649385015415 | 2.43464719715 |  0.7094594594594594 |  0.3620689655172414 | 13.2111080539 |
| Epoch 12 |  0.4886128364389234 | 0.657380218095 | 2.27865339565 |  0.6113989637305699 |  0.4068965517241379 | 12.1906346044 |
| Epoch 13 |         0.45        | 0.653728419855 | 2.17314412029 |         0.66        |  0.3413793103448276 | 12.7586833277 |
| Epoch 14 |  0.5188470066518848 | 0.666210590159 | 1.99532843709 |  0.7267080745341615 | 0.40344827586206894 | 12.3042386578 |
| Epoch 15 |  0.5412667946257197 | 0.658724726133 | 1.91586709622 |  0.6103896103896104 |  0.4862068965517241 | 12.0136615076 |
| Epoch 16 |  0.4601366742596811 | 0.664591664914 | 1.77886855103 |  0.6778523489932886 |  0.3482758620689655 |  12.922632402 |
| Epoch 17 |  0.3538461538461538 | 0.682200814695 | 1.75716070966 |         0.69        | 0.23793103448275862 | 14.9532549766 |
| Epoch 18 | 0.49884526558891457 | 0.662763678918 | 1.68601924196 |  0.7552447552447552 |  0.3724137931034483 | 13.0446966848 |
| Epoch 19 |  0.5831775700934579 | 0.669081662223 | 1.58239027271 |  0.636734693877551  |  0.5379310344827586 | 12.6051835399 |
| Epoch 20 |  0.5741444866920151 | 0.682981177868 | 1.56192718788 |  0.6398305084745762 |  0.5206896551724138 | 12.0372573176 |
| Epoch 21 |  0.4087591240875913 | 0.68880355617  | 1.59138115107 |  0.6942148760330579 |  0.2896551724137931 | 13.4516573875 |
| Epoch 22 |   0.58195211786372  | 0.682765497306 | 1.50699588946 |  0.6245059288537549 |  0.5448275862068965 | 11.5151526543 |
| Epoch 23 |  0.5303643724696357 | 0.679910639886 | 1.46617043288 |  0.6421568627450981 |  0.4517241379310345 | 12.4385289531 |
| Epoch 24 |  0.579256360078278  | 0.688017993743 | 1.50278699504 |  0.669683257918552  |  0.5103448275862069 | 11.6405282174 |
| Epoch 25 |  0.5574387947269303 | 0.677019509828 | 1.45195074693 |  0.6141078838174274 |  0.5103448275862069 | 12.2011302825 |
| Epoch 26 |  0.5084033613445378 | 0.692808263865 | 1.40943172143 |  0.6505376344086021 | 0.41724137931034483 | 12.3991816275 |
| Epoch 27 |  0.4593967517401392 | 0.691263328181 | 1.35879510356 |  0.7021276595744681 |  0.3413793103448276 |  12.805282762 |
| Epoch 28 |  0.5306122448979592 | 0.694692031812 | 1.33931299495 |         0.65        |  0.4482758620689655 | 13.4725189824 |
| Epoch 29 |  0.5213849287169042 | 0.688161909076 | 1.34835231627 |  0.6368159203980099 |  0.4413793103448276 |  12.762669471 |
| Epoch 30 |  0.5477031802120141 | 0.670209093932 | 1.37645138854 |  0.5615942028985508 |  0.5344827586206896 | 11.5647174158 |
+----------+---------------------+----------------+---------------+---------------------+---------------------+---------------+
_________________________________________________________________
+------------------------------------+-----------------------+---------+-----------------------+--------------------+
|             Optimizer              |         decay         | epsilon |           lr          |        rho         |
+------------------------------------+-----------------------+---------+-----------------------+--------------------+
| <class 'keras.optimizers.RMSprop'> | 9.999999974752427e-07 |  1e-08  | 9.999999747378752e-05 | 0.8999999761581421 |
+------------------------------------+-----------------------+---------+-----------------------+--------------------+
_________________________________________________________________
+------------+
| Batch Size |
+------------+
|     16     |
+------------+
_________________________________________________________________
+--------------------+---------------+----------------+--------------------+--------------------+--------------------+
|      Metrics       |      Loss     |      IoU       |     Precision      |       Recall       |      F1 Score      |
+--------------------+---------------+----------------+--------------------+--------------------+--------------------+
|   Train Metrics    | 2.87480648291 | 0.832127179592 | 0.9646365422396856 | 0.9503992257440116 | 0.9574649603900062 |
| Validation Metrics | 23.0587273259 | 0.670209093932 | 0.5615942028985508 | 0.5344827586206896 | 0.5477031802120141 |
|    Test Metrics    | 25.6955782983 | 0.665880111191 | 0.5755395683453237 | 0.517799352750809  | 0.545144804088586  |
+--------------------+---------------+----------------+--------------------+--------------------+--------------------+
_________________________________________________________________
Time:
    Train Time              : 2:55:19.438826
    Dataset Loading Time    : 0:00:38.122317
    Metrics Evaluation Time : 0:06:21.127933
_________________________________________________________________
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         (None, 288, 288, 1)       0         
_________________________________________________________________
conv_1 (Conv2D)              (None, 288, 288, 32)      320       
_________________________________________________________________
norm_1 (BatchNormalization)  (None, 288, 288, 32)      128       
_________________________________________________________________
relu_1 (LeakyReLU)           (None, 288, 288, 32)      0         
_________________________________________________________________
pool_1 (MaxPooling2D)        (None, 144, 144, 32)      0         
_________________________________________________________________
conv_2 (Conv2D)              (None, 144, 144, 64)      18496     
_________________________________________________________________
norm_2 (BatchNormalization)  (None, 144, 144, 64)      256       
_________________________________________________________________
relu_2 (LeakyReLU)           (None, 144, 144, 64)      0         
_________________________________________________________________
pool_2 (MaxPooling2D)        (None, 72, 72, 64)        0         
_________________________________________________________________
conv_3 (Conv2D)              (None, 72, 72, 128)       73856     
_________________________________________________________________
norm_3 (BatchNormalization)  (None, 72, 72, 128)       512       
_________________________________________________________________
relu_3 (LeakyReLU)           (None, 72, 72, 128)       0         
_________________________________________________________________
conv_4 (Conv2D)              (None, 72, 72, 64)        8256      
_________________________________________________________________
norm_4 (BatchNormalization)  (None, 72, 72, 64)        256       
_________________________________________________________________
relu_4 (LeakyReLU)           (None, 72, 72, 64)        0         
_________________________________________________________________
conv_5 (Conv2D)              (None, 72, 72, 128)       73856     
_________________________________________________________________
norm_5 (BatchNormalization)  (None, 72, 72, 128)       512       
_________________________________________________________________
relu_5 (LeakyReLU)           (None, 72, 72, 128)       0         
_________________________________________________________________
pool_3 (MaxPooling2D)        (None, 36, 36, 128)       0         
_________________________________________________________________
conv_6 (Conv2D)              (None, 36, 36, 256)       295168    
_________________________________________________________________
norm_6 (BatchNormalization)  (None, 36, 36, 256)       1024      
_________________________________________________________________
relu_6 (LeakyReLU)           (None, 36, 36, 256)       0         
_________________________________________________________________
conv_7 (Conv2D)              (None, 36, 36, 128)       32896     
_________________________________________________________________
norm_7 (BatchNormalization)  (None, 36, 36, 128)       512       
_________________________________________________________________
relu_7 (LeakyReLU)           (None, 36, 36, 128)       0         
_________________________________________________________________
conv_8 (Conv2D)              (None, 36, 36, 256)       295168    
_________________________________________________________________
norm_8 (BatchNormalization)  (None, 36, 36, 256)       1024      
_________________________________________________________________
relu_8 (LeakyReLU)           (None, 36, 36, 256)       0         
_________________________________________________________________
pool_4 (MaxPooling2D)        (None, 18, 18, 256)       0         
_________________________________________________________________
conv_9 (Conv2D)              (None, 18, 18, 512)       1180160   
_________________________________________________________________
norm_9 (BatchNormalization)  (None, 18, 18, 512)       2048      
_________________________________________________________________
relu_9 (LeakyReLU)           (None, 18, 18, 512)       0         
_________________________________________________________________
conv_10 (Conv2D)             (None, 18, 18, 256)       131328    
_________________________________________________________________
norm_10 (BatchNormalization) (None, 18, 18, 256)       1024      
_________________________________________________________________
relu_10 (LeakyReLU)          (None, 18, 18, 256)       0         
_________________________________________________________________
conv_11 (Conv2D)             (None, 18, 18, 512)       1180160   
_________________________________________________________________
norm_11 (BatchNormalization) (None, 18, 18, 512)       2048      
_________________________________________________________________
relu_11 (LeakyReLU)          (None, 18, 18, 512)       0         
_________________________________________________________________
conv_12 (Conv2D)             (None, 18, 18, 256)       131328    
_________________________________________________________________
norm_12 (BatchNormalization) (None, 18, 18, 256)       1024      
_________________________________________________________________
relu_12 (LeakyReLU)          (None, 18, 18, 256)       0         
_________________________________________________________________
conv_13 (Conv2D)             (None, 18, 18, 512)       1180160   
_________________________________________________________________
norm_13 (BatchNormalization) (None, 18, 18, 512)       2048      
_________________________________________________________________
relu_13 (LeakyReLU)          (None, 18, 18, 512)       0         
_________________________________________________________________
pool_5 (MaxPooling2D)        (None, 9, 9, 512)         0         
_________________________________________________________________
conv_14 (Conv2D)             (None, 9, 9, 1024)        4719616   
_________________________________________________________________
norm_14 (BatchNormalization) (None, 9, 9, 1024)        4096      
_________________________________________________________________
relu_14 (LeakyReLU)          (None, 9, 9, 1024)        0         
_________________________________________________________________
conv_15 (Conv2D)             (None, 9, 9, 1024)        9438208   
_________________________________________________________________
norm_15 (BatchNormalization) (None, 9, 9, 1024)        4096      
_________________________________________________________________
relu_15 (LeakyReLU)          (None, 9, 9, 1024)        0         
_________________________________________________________________
conv_16 (Conv2D)             (None, 9, 9, 5)           5125      
_________________________________________________________________
reshape_1 (Reshape)          (None, 9, 9, 5)           0         
=================================================================
Total params: 18,784,709
Trainable params: 18,774,405
Non-trainable params: 10,304
_________________________________________________________________
+----------+--------------------+----------------+---------------+--------------------+---------------------+---------------+
|  Epoch   |      f1_score      |      iou       |      loss     |     precision      |        recall       |    val_loss   |
+----------+--------------------+----------------+---------------+--------------------+---------------------+---------------+
| Epoch 1  |        nan         |      nan       | 27.0244013769 |        nan         |         0.0         |  61.903802318 |
| Epoch 2  | 0.598705501618123  | 0.648094708668 | 12.9186526143 | 0.5640243902439024 |  0.6379310344827587 | 8.13778341201 |
| Epoch 3  | 0.6092124814264487 | 0.690499718935 | 10.0693202422 | 0.5352480417754569 |  0.7068965517241379 | 9.74785664774 |
| Epoch 4  | 0.6845425867507886 | 0.680186493526 | 8.30538307925 | 0.6308139534883721 |  0.7482758620689656 | 7.67273553725 |
| Epoch 5  | 0.5700483091787439 | 0.671823076094 |  6.9555191115 | 0.5347432024169184 |  0.6103448275862069 | 9.48294997215 |
| Epoch 6  | 0.6361904761904763 | 0.680303945985 | 6.13254555584 | 0.7106382978723405 |  0.5758620689655173 | 9.21916391004 |
| Epoch 7  | 0.6962699822380106 | 0.703874645418 | 5.56416907617 | 0.717948717948718  |  0.6758620689655173 | 7.69077836314 |
| Epoch 8  | 0.6542056074766354 | 0.683965735848 | 5.07707346826 | 0.7142857142857143 |  0.603448275862069  | 8.64557273926 |
| Epoch 9  | 0.5871886120996441 | 0.671283901255 | 4.70452084404 | 0.6066176470588235 |  0.5689655172413793 | 8.86521554762 |
| Epoch 10 | 0.7093023255813954 | 0.677890249831 | 4.33867399811 | 0.8097345132743363 |  0.6310344827586207 | 7.92784570879 |
| Epoch 11 | 0.6779026217228465 | 0.67374313993  | 4.07786252291 | 0.7418032786885246 |  0.6241379310344828 | 8.59673046297 |
| Epoch 12 | 0.7016885553470918 | 0.685820939043 | 3.89241869996 | 0.7695473251028807 |  0.6448275862068965 | 8.18103707221 |
| Epoch 13 | 0.5933609958506224 | 0.676689610908 | 3.70472032975 | 0.7447916666666666 | 0.49310344827586206 | 10.3086768427 |
| Epoch 14 | 0.6752411575562701 |  0.6860467747  | 3.49839885272 | 0.6325301204819277 |  0.7241379310344828 | 8.77477224412 |
| Epoch 15 | 0.721915285451197  | 0.685658192595 | 3.41693693717 | 0.7747035573122529 |  0.6758620689655173 | 7.90985040511 |
| Epoch 16 | 0.7013888888888888 | 0.683187457615 | 3.25704738006 | 0.7062937062937062 |  0.696551724137931  | 8.49395736571 |
| Epoch 17 | 0.6705882352941176 | 0.684265791239 | 3.16611979573 | 0.7772727272727272 |  0.5896551724137931 | 8.96933038773 |
| Epoch 18 | 0.7024221453287197 | 0.701815976037 | 3.05563024256 | 0.7048611111111112 |         0.7         | 8.75994091649 |
| Epoch 19 | 0.718995290423862  | 0.684175603578 | 2.92992540597 | 0.659942363112392  |  0.7896551724137931 | 8.25043976691 |
| Epoch 20 | 0.6737967914438503 | 0.696570955312 | 2.81501175999 | 0.6974169741697417 |  0.6517241379310345 | 8.73714693131 |
| Epoch 21 | 0.6563106796116506 | 0.684710518313 |  2.7810653633 | 0.7511111111111111 |  0.5827586206896552 | 9.55311649076 |
| Epoch 22 | 0.6523437500000001 | 0.700908726148 | 2.70546857175 | 0.7522522522522522 |  0.5758620689655173 | 8.96457106067 |
| Epoch 23 | 0.6747404844290658 | 0.700786969574 | 2.58115595572 | 0.6770833333333334 |  0.6724137931034483 | 8.80779317118 |
| Epoch 24 | 0.6725663716814159 | 0.675825236955 | 2.54273043705 | 0.6909090909090909 |  0.6551724137931034 | 8.96518598064 |
| Epoch 25 | 0.6297029702970297 | 0.677468368574 | 2.50640660247 | 0.7395348837209302 |  0.5482758620689655 | 10.6768799443 |
| Epoch 26 | 0.6762589928057554 | 0.674795645066 |  2.4929056225 | 0.706766917293233  |  0.6482758620689655 | 8.85323115318 |
| Epoch 27 | 0.6815642458100559 | 0.693559189311 | 2.41733794665 | 0.7408906882591093 |  0.6310344827586207 | 9.45392579417 |
| Epoch 28 | 0.697841726618705  | 0.67917822787  | 2.38841317366 | 0.7293233082706767 |  0.6689655172413793 | 8.90250159848 |
| Epoch 29 | 0.6336633663366337 | 0.688957958936 | 2.26057724734 | 0.7441860465116279 |  0.5517241379310345 | 10.1999690148 |
| Epoch 30 | 0.6594594594594594 | 0.702006465703 | 2.22969666759 | 0.690566037735849  |  0.6310344827586207 | 9.24668150563 |
+----------+--------------------+----------------+---------------+--------------------+---------------------+---------------+
_________________________________________________________________
+------------------------------------+-----------------------+---------+-----------------------+--------------------+
|             Optimizer              |         decay         | epsilon |           lr          |        rho         |
+------------------------------------+-----------------------+---------+-----------------------+--------------------+
| <class 'keras.optimizers.RMSprop'> | 9.999999747378752e-06 |  1e-08  | 0.0010000000474974513 | 0.8999999761581421 |
+------------------------------------+-----------------------+---------+-----------------------+--------------------+
_________________________________________________________________
+------------+
| Batch Size |
+------------+
|     16     |
+------------+
_________________________________________________________________
+--------------------+---------------+----------------+--------------------+--------------------+--------------------+
|      Metrics       |      Loss     |      IoU       |     Precision      |       Recall       |      F1 Score      |
+--------------------+---------------+----------------+--------------------+--------------------+--------------------+
|   Train Metrics    | 4.15242634731 | 0.858199501896 | 0.9751898734177216 | 0.9320106460198403 | 0.9531114685141655 |
| Validation Metrics | 18.4433512534 | 0.702006465703 | 0.690566037735849  | 0.6310344827586207 | 0.6594594594594594 |
|    Test Metrics    |  20.755645875 | 0.699689460505 | 0.6917562724014337 | 0.6245954692556634 | 0.6564625850340136 |
+--------------------+---------------+----------------+--------------------+--------------------+--------------------+
_________________________________________________________________
Time:
    Train Time              : 2:54:36.986198
    Dataset Loading Time    : 0:00:37.810979
    Metrics Evaluation Time : 0:06:12.327525
_________________________________________________________________
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         (None, 288, 288, 1)       0         
_________________________________________________________________
conv_1 (Conv2D)              (None, 288, 288, 32)      320       
_________________________________________________________________
norm_1 (BatchNormalization)  (None, 288, 288, 32)      128       
_________________________________________________________________
relu_1 (LeakyReLU)           (None, 288, 288, 32)      0         
_________________________________________________________________
drop_1 (Dropout)             (None, 288, 288, 32)      0         
_________________________________________________________________
pool_1 (MaxPooling2D)        (None, 144, 144, 32)      0         
_________________________________________________________________
conv_2 (Conv2D)              (None, 144, 144, 64)      18496     
_________________________________________________________________
norm_2 (BatchNormalization)  (None, 144, 144, 64)      256       
_________________________________________________________________
relu_2 (LeakyReLU)           (None, 144, 144, 64)      0         
_________________________________________________________________
drop_2 (Dropout)             (None, 144, 144, 64)      0         
_________________________________________________________________
pool_2 (MaxPooling2D)        (None, 72, 72, 64)        0         
_________________________________________________________________
conv_3 (Conv2D)              (None, 72, 72, 128)       73856     
_________________________________________________________________
norm_3 (BatchNormalization)  (None, 72, 72, 128)       512       
_________________________________________________________________
relu_3 (LeakyReLU)           (None, 72, 72, 128)       0         
_________________________________________________________________
drop_3 (Dropout)             (None, 72, 72, 128)       0         
_________________________________________________________________
conv_4 (Conv2D)              (None, 72, 72, 64)        8256      
_________________________________________________________________
norm_4 (BatchNormalization)  (None, 72, 72, 64)        256       
_________________________________________________________________
relu_4 (LeakyReLU)           (None, 72, 72, 64)        0         
_________________________________________________________________
drop_4 (Dropout)             (None, 72, 72, 64)        0         
_________________________________________________________________
conv_5 (Conv2D)              (None, 72, 72, 128)       73856     
_________________________________________________________________
norm_5 (BatchNormalization)  (None, 72, 72, 128)       512       
_________________________________________________________________
relu_5 (LeakyReLU)           (None, 72, 72, 128)       0         
_________________________________________________________________
drop_5 (Dropout)             (None, 72, 72, 128)       0         
_________________________________________________________________
pool_3 (MaxPooling2D)        (None, 36, 36, 128)       0         
_________________________________________________________________
conv_6 (Conv2D)              (None, 36, 36, 256)       295168    
_________________________________________________________________
norm_6 (BatchNormalization)  (None, 36, 36, 256)       1024      
_________________________________________________________________
relu_6 (LeakyReLU)           (None, 36, 36, 256)       0         
_________________________________________________________________
drop_6 (Dropout)             (None, 36, 36, 256)       0         
_________________________________________________________________
conv_7 (Conv2D)              (None, 36, 36, 128)       32896     
_________________________________________________________________
norm_7 (BatchNormalization)  (None, 36, 36, 128)       512       
_________________________________________________________________
relu_7 (LeakyReLU)           (None, 36, 36, 128)       0         
_________________________________________________________________
drop_7 (Dropout)             (None, 36, 36, 128)       0         
_________________________________________________________________
conv_8 (Conv2D)              (None, 36, 36, 256)       295168    
_________________________________________________________________
norm_8 (BatchNormalization)  (None, 36, 36, 256)       1024      
_________________________________________________________________
relu_8 (LeakyReLU)           (None, 36, 36, 256)       0         
_________________________________________________________________
drop_8 (Dropout)             (None, 36, 36, 256)       0         
_________________________________________________________________
pool_4 (MaxPooling2D)        (None, 18, 18, 256)       0         
_________________________________________________________________
conv_9 (Conv2D)              (None, 18, 18, 512)       1180160   
_________________________________________________________________
norm_9 (BatchNormalization)  (None, 18, 18, 512)       2048      
_________________________________________________________________
relu_9 (LeakyReLU)           (None, 18, 18, 512)       0         
_________________________________________________________________
drop_9 (Dropout)             (None, 18, 18, 512)       0         
_________________________________________________________________
conv_10 (Conv2D)             (None, 18, 18, 256)       131328    
_________________________________________________________________
norm_10 (BatchNormalization) (None, 18, 18, 256)       1024      
_________________________________________________________________
relu_10 (LeakyReLU)          (None, 18, 18, 256)       0         
_________________________________________________________________
drop_10 (Dropout)            (None, 18, 18, 256)       0         
_________________________________________________________________
conv_11 (Conv2D)             (None, 18, 18, 512)       1180160   
_________________________________________________________________
norm_11 (BatchNormalization) (None, 18, 18, 512)       2048      
_________________________________________________________________
relu_11 (LeakyReLU)          (None, 18, 18, 512)       0         
_________________________________________________________________
drop_11 (Dropout)            (None, 18, 18, 512)       0         
_________________________________________________________________
conv_12 (Conv2D)             (None, 18, 18, 256)       131328    
_________________________________________________________________
norm_12 (BatchNormalization) (None, 18, 18, 256)       1024      
_________________________________________________________________
relu_12 (LeakyReLU)          (None, 18, 18, 256)       0         
_________________________________________________________________
drop_12 (Dropout)            (None, 18, 18, 256)       0         
_________________________________________________________________
conv_13 (Conv2D)             (None, 18, 18, 512)       1180160   
_________________________________________________________________
norm_13 (BatchNormalization) (None, 18, 18, 512)       2048      
_________________________________________________________________
relu_13 (LeakyReLU)          (None, 18, 18, 512)       0         
_________________________________________________________________
drop_13 (Dropout)            (None, 18, 18, 512)       0         
_________________________________________________________________
pool_5 (MaxPooling2D)        (None, 9, 9, 512)         0         
_________________________________________________________________
conv_14 (Conv2D)             (None, 9, 9, 1024)        4719616   
_________________________________________________________________
norm_14 (BatchNormalization) (None, 9, 9, 1024)        4096      
_________________________________________________________________
relu_14 (LeakyReLU)          (None, 9, 9, 1024)        0         
_________________________________________________________________
drop_14 (Dropout)            (None, 9, 9, 1024)        0         
_________________________________________________________________
conv_15 (Conv2D)             (None, 9, 9, 1024)        9438208   
_________________________________________________________________
norm_15 (BatchNormalization) (None, 9, 9, 1024)        4096      
_________________________________________________________________
relu_15 (LeakyReLU)          (None, 9, 9, 1024)        0         
_________________________________________________________________
drop_15 (Dropout)            (None, 9, 9, 1024)        0         
_________________________________________________________________
conv_16 (Conv2D)             (None, 9, 9, 5)           5125      
_________________________________________________________________
reshape_1 (Reshape)          (None, 9, 9, 5)           0         
=================================================================
Total params: 18,784,709
Trainable params: 18,774,405
Non-trainable params: 10,304
_________________________________________________________________
+----------+----------+-----+---------------+-----------+--------+---------------+
|  Epoch   | f1_score | iou |      loss     | precision | recall |    val_loss   |
+----------+----------+-----+---------------+-----------+--------+---------------+
| Epoch 1  |   nan    | nan | 36.0636845844 |    nan    |  0.0   | 87.8992348948 |
| Epoch 2  |   nan    | nan | 17.6577658424 |    nan    |  0.0   | 89.1164757513 |
| Epoch 3  |   nan    | nan | 15.0951192377 |    nan    |  0.0   | 29.9050003175 |
| Epoch 4  |   nan    | nan | 13.7584887337 |    nan    |  0.0   | 24.1613080425 |
| Epoch 5  |   nan    | nan | 12.8451550227 |    nan    |  0.0   |  25.017406279 |
| Epoch 6  |   nan    | nan | 12.2753496009 |    nan    |  0.0   | 29.7113134938 |
| Epoch 7  |   nan    | nan | 11.7936291497 |    nan    |  0.0   | 28.0743285764 |
| Epoch 8  |   nan    | nan | 11.3101997005 |    nan    |  0.0   | 31.4853171072 |
| Epoch 9  |   nan    | nan | 10.8128668575 |    nan    |  0.0   | 28.7462997437 |
| Epoch 10 |   nan    | nan | 10.3980401008 |    nan    |  0.0   | 29.0101221761 |
| Epoch 11 |   nan    | nan | 9.87448027974 |    nan    |  0.0   | 38.3787555079 |
| Epoch 12 |   nan    | nan | 9.58702729782 |    nan    |  0.0   | 32.1496658325 |
| Epoch 13 |   nan    | nan |  9.3424326396 |    nan    |  0.0   |  28.514531597 |
| Epoch 14 |   nan    | nan |  9.0480799679 |    nan    |  0.0   | 32.2841605525 |
| Epoch 15 |   nan    | nan | 8.73463333772 |    nan    |  0.0   | 32.8011403853 |
| Epoch 16 |   nan    | nan | 8.50175036481 |    nan    |  0.0   | 26.3621828633 |
| Epoch 17 |   nan    | nan | 8.29831975089 |    nan    |  0.0   | 27.4203264175 |
| Epoch 18 |   nan    | nan | 8.06714151315 |    nan    |  0.0   | 33.6316229297 |
| Epoch 19 |   nan    | nan | 7.91020569636 |    nan    |  0.0   | 28.8034836554 |
| Epoch 20 |   nan    | nan |  7.7078160235 |    nan    |  0.0   | 32.8869771034 |
| Epoch 21 |   nan    | nan | 7.60602178316 |    nan    |  0.0   | 31.5398409444 |
| Epoch 22 |   nan    | nan | 7.43065281551 |    nan    |  0.0   | 30.0775122489 |
| Epoch 23 |   nan    | nan | 7.35630875448 |    nan    |  0.0   |  27.818145752 |
| Epoch 24 |   nan    | nan | 7.21986947741 |    nan    |  0.0   |  29.827858771 |
| Epoch 25 |   nan    | nan |  6.971543408  |    nan    |  0.0   | 27.3505146888 |
| Epoch 26 |   nan    | nan |  6.8765329964 |    nan    |  0.0   | 29.3254871984 |
| Epoch 27 |   nan    | nan | 6.86212348817 |    nan    |  0.0   | 28.1033946622 |
| Epoch 28 |   nan    | nan | 6.70738464962 |    nan    |  0.0   | 30.1967746365 |
| Epoch 29 |   nan    | nan | 6.67536378028 |    nan    |  0.0   | 32.2022421437 |
| Epoch 30 |   nan    | nan | 6.50644257022 |    nan    |  0.0   | 32.3604756017 |
+----------+----------+-----+---------------+-----------+--------+---------------+
_________________________________________________________________
+------------------------------------+-----------------------+---------+-----------------------+--------------------+
|             Optimizer              |         decay         | epsilon |           lr          |        rho         |
+------------------------------------+-----------------------+---------+-----------------------+--------------------+
| <class 'keras.optimizers.RMSprop'> | 9.999999747378752e-06 |  1e-08  | 0.0010000000474974513 | 0.8999999761581421 |
+------------------------------------+-----------------------+---------+-----------------------+--------------------+
_________________________________________________________________
+------------+
| Batch Size |
+------------+
|     16     |
+------------+
_________________________________________________________________
+--------------------+---------------+-----+-----------+--------+----------+
|      Metrics       |      Loss     | IoU | Precision | Recall | F1 Score |
+--------------------+---------------+-----+-----------+--------+----------+
|   Train Metrics    | 113.360863422 | nan |    nan    |  0.0   |   nan    |
| Validation Metrics | 64.4615480977 | nan |    nan    |  0.0   |   nan    |
|    Test Metrics    | 68.7237691572 | nan |    nan    |  0.0   |   nan    |
+--------------------+---------------+-----+-----------+--------+----------+
_________________________________________________________________
Time:
    Train Time              : 3:36:28.837953
    Dataset Loading Time    : 0:00:40.404468
    Metrics Evaluation Time : 0:06:07.059180
_________________________________________________________________
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         (None, 288, 288, 1)       0         
_________________________________________________________________
conv_1 (Conv2D)              (None, 288, 288, 32)      320       
_________________________________________________________________
norm_1 (BatchNormalization)  (None, 288, 288, 32)      128       
_________________________________________________________________
relu_1 (LeakyReLU)           (None, 288, 288, 32)      0         
_________________________________________________________________
pool_1 (MaxPooling2D)        (None, 144, 144, 32)      0         
_________________________________________________________________
conv_2 (Conv2D)              (None, 144, 144, 64)      18496     
_________________________________________________________________
norm_2 (BatchNormalization)  (None, 144, 144, 64)      256       
_________________________________________________________________
relu_2 (LeakyReLU)           (None, 144, 144, 64)      0         
_________________________________________________________________
pool_2 (MaxPooling2D)        (None, 72, 72, 64)        0         
_________________________________________________________________
conv_3 (Conv2D)              (None, 72, 72, 128)       73856     
_________________________________________________________________
norm_3 (BatchNormalization)  (None, 72, 72, 128)       512       
_________________________________________________________________
relu_3 (LeakyReLU)           (None, 72, 72, 128)       0         
_________________________________________________________________
conv_4 (Conv2D)              (None, 72, 72, 64)        8256      
_________________________________________________________________
norm_4 (BatchNormalization)  (None, 72, 72, 64)        256       
_________________________________________________________________
relu_4 (LeakyReLU)           (None, 72, 72, 64)        0         
_________________________________________________________________
conv_5 (Conv2D)              (None, 72, 72, 128)       73856     
_________________________________________________________________
norm_5 (BatchNormalization)  (None, 72, 72, 128)       512       
_________________________________________________________________
relu_5 (LeakyReLU)           (None, 72, 72, 128)       0         
_________________________________________________________________
pool_3 (MaxPooling2D)        (None, 36, 36, 128)       0         
_________________________________________________________________
conv_6 (Conv2D)              (None, 36, 36, 256)       295168    
_________________________________________________________________
norm_6 (BatchNormalization)  (None, 36, 36, 256)       1024      
_________________________________________________________________
relu_6 (LeakyReLU)           (None, 36, 36, 256)       0         
_________________________________________________________________
conv_7 (Conv2D)              (None, 36, 36, 128)       32896     
_________________________________________________________________
norm_7 (BatchNormalization)  (None, 36, 36, 128)       512       
_________________________________________________________________
relu_7 (LeakyReLU)           (None, 36, 36, 128)       0         
_________________________________________________________________
conv_8 (Conv2D)              (None, 36, 36, 256)       295168    
_________________________________________________________________
norm_8 (BatchNormalization)  (None, 36, 36, 256)       1024      
_________________________________________________________________
relu_8 (LeakyReLU)           (None, 36, 36, 256)       0         
_________________________________________________________________
pool_4 (MaxPooling2D)        (None, 18, 18, 256)       0         
_________________________________________________________________
conv_9 (Conv2D)              (None, 18, 18, 512)       1180160   
_________________________________________________________________
norm_9 (BatchNormalization)  (None, 18, 18, 512)       2048      
_________________________________________________________________
relu_9 (LeakyReLU)           (None, 18, 18, 512)       0         
_________________________________________________________________
conv_10 (Conv2D)             (None, 18, 18, 256)       131328    
_________________________________________________________________
norm_10 (BatchNormalization) (None, 18, 18, 256)       1024      
_________________________________________________________________
relu_10 (LeakyReLU)          (None, 18, 18, 256)       0         
_________________________________________________________________
conv_11 (Conv2D)             (None, 18, 18, 512)       1180160   
_________________________________________________________________
norm_11 (BatchNormalization) (None, 18, 18, 512)       2048      
_________________________________________________________________
relu_11 (LeakyReLU)          (None, 18, 18, 512)       0         
_________________________________________________________________
conv_12 (Conv2D)             (None, 18, 18, 256)       131328    
_________________________________________________________________
norm_12 (BatchNormalization) (None, 18, 18, 256)       1024      
_________________________________________________________________
relu_12 (LeakyReLU)          (None, 18, 18, 256)       0         
_________________________________________________________________
conv_13 (Conv2D)             (None, 18, 18, 512)       1180160   
_________________________________________________________________
norm_13 (BatchNormalization) (None, 18, 18, 512)       2048      
_________________________________________________________________
relu_13 (LeakyReLU)          (None, 18, 18, 512)       0         
_________________________________________________________________
pool_5 (MaxPooling2D)        (None, 9, 9, 512)         0         
_________________________________________________________________
conv_14 (Conv2D)             (None, 9, 9, 1024)        4719616   
_________________________________________________________________
norm_14 (BatchNormalization) (None, 9, 9, 1024)        4096      
_________________________________________________________________
relu_14 (LeakyReLU)          (None, 9, 9, 1024)        0         
_________________________________________________________________
conv_15 (Conv2D)             (None, 9, 9, 1024)        9438208   
_________________________________________________________________
norm_15 (BatchNormalization) (None, 9, 9, 1024)        4096      
_________________________________________________________________
relu_15 (LeakyReLU)          (None, 9, 9, 1024)        0         
_________________________________________________________________
conv_16 (Conv2D)             (None, 9, 9, 5)           5125      
_________________________________________________________________
reshape_1 (Reshape)          (None, 9, 9, 5)           0         
=================================================================
Total params: 18,784,709
Trainable params: 18,774,405
Non-trainable params: 10,304
_________________________________________________________________
+----------+----------------------+----------------+---------------+--------------------+---------------------+---------------+
|  Epoch   |       f1_score       |      iou       |      loss     |     precision      |        recall       |    val_loss   |
+----------+----------------------+----------------+---------------+--------------------+---------------------+---------------+
| Epoch 1  |         nan          |      nan       | 43.1375311556 |        nan         |         0.0         | 41.8224291229 |
| Epoch 2  |         nan          |      nan       | 32.5150173976 |        nan         |         0.0         | 37.1989558182 |
| Epoch 3  |         nan          |      nan       |  30.936029602 |        0.0         |         0.0         | 48.3084730759 |
| Epoch 4  | 0.018518518518518517 | 0.792631264548 | 29.9284518532 |        0.8         | 0.00936768149882904 | 31.5160960007 |
| Epoch 5  | 0.011614401858304297 | 0.765534649008 |  29.142711351 | 0.7142857142857143 | 0.00585480093676815 |  29.286935936 |
| Epoch 6  | 0.06674082313681869  | 0.698063541703 | 28.4706977556 | 0.6666666666666666 |  0.0351288056206089 |  30.401213501 |
| Epoch 7  | 0.06850828729281767  | 0.733436652535 | 27.8853919566 | 0.6078431372549019 | 0.03629976580796253 | 29.5008307114 |
| Epoch 8  | 0.12861736334405144  | 0.708431634252 | 27.2760130384 | 0.759493670886076  |  0.0702576112412178 | 27.8138644791 |
| Epoch 9  |  0.1161825726141079  | 0.653208356203 | 26.7083670717 | 0.509090909090909  | 0.06557377049180328 | 28.7925523148 |
| Epoch 10 | 0.17337461300309595  | 0.664970272515 | 26.2737317204 | 0.7304347826086957 | 0.09836065573770492 | 27.2418344154 |
+----------+----------------------+----------------+---------------+--------------------+---------------------+---------------+
_________________________________________________________________
+------------------------------------+-----------------------+---------+-----------------------+--------------------+
|             Optimizer              |         decay         | epsilon |           lr          |        rho         |
+------------------------------------+-----------------------+---------+-----------------------+--------------------+
| <class 'keras.optimizers.RMSprop'> | 9.999999747378752e-06 |  1e-08  | 0.0010000000474974513 | 0.8999999761581421 |
+------------------------------------+-----------------------+---------+-----------------------+--------------------+
_________________________________________________________________
+------------+
| Batch Size |
+------------+
|     16     |
+------------+
_________________________________________________________________
+--------------------+---------------+----------------+--------------------+---------------------+---------------------+
|      Metrics       |      Loss     |      IoU       |     Precision      |        Recall       |       F1 Score      |
+--------------------+---------------+----------------+--------------------+---------------------+---------------------+
|   Train Metrics    | 51.6883356315 | 0.681765128925 | 0.7597402597402597 | 0.11046668465066091 | 0.19288742345737164 |
| Validation Metrics | 54.0213235474 | 0.664970272515 | 0.7304347826086957 | 0.09836065573770492 | 0.17337461300309595 |
|    Test Metrics    | 54.8721102295 | 0.679120044882 | 0.6299212598425197 | 0.09122006841505131 | 0.15936254980079684 |
+--------------------+---------------+----------------+--------------------+---------------------+---------------------+
_________________________________________________________________
Time:
    Train Time              : 1:56:40.567774
    Dataset Loading Time    : 0:04:54.865856
    Metrics Evaluation Time : 0:11:03.119163
_________________________________________________________________
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         (None, 288, 288, 1)       0         
_________________________________________________________________
conv_1 (Conv2D)              (None, 288, 288, 32)      320       
_________________________________________________________________
norm_1 (BatchNormalization)  (None, 288, 288, 32)      128       
_________________________________________________________________
relu_1 (LeakyReLU)           (None, 288, 288, 32)      0         
_________________________________________________________________
pool_1 (MaxPooling2D)        (None, 144, 144, 32)      0         
_________________________________________________________________
conv_2 (Conv2D)              (None, 144, 144, 64)      18496     
_________________________________________________________________
norm_2 (BatchNormalization)  (None, 144, 144, 64)      256       
_________________________________________________________________
relu_2 (LeakyReLU)           (None, 144, 144, 64)      0         
_________________________________________________________________
pool_2 (MaxPooling2D)        (None, 72, 72, 64)        0         
_________________________________________________________________
conv_3 (Conv2D)              (None, 72, 72, 128)       73856     
_________________________________________________________________
norm_3 (BatchNormalization)  (None, 72, 72, 128)       512       
_________________________________________________________________
relu_3 (LeakyReLU)           (None, 72, 72, 128)       0         
_________________________________________________________________
conv_4 (Conv2D)              (None, 72, 72, 64)        8256      
_________________________________________________________________
norm_4 (BatchNormalization)  (None, 72, 72, 64)        256       
_________________________________________________________________
relu_4 (LeakyReLU)           (None, 72, 72, 64)        0         
_________________________________________________________________
conv_5 (Conv2D)              (None, 72, 72, 128)       73856     
_________________________________________________________________
norm_5 (BatchNormalization)  (None, 72, 72, 128)       512       
_________________________________________________________________
relu_5 (LeakyReLU)           (None, 72, 72, 128)       0         
_________________________________________________________________
pool_3 (MaxPooling2D)        (None, 36, 36, 128)       0         
_________________________________________________________________
conv_6 (Conv2D)              (None, 36, 36, 256)       295168    
_________________________________________________________________
norm_6 (BatchNormalization)  (None, 36, 36, 256)       1024      
_________________________________________________________________
relu_6 (LeakyReLU)           (None, 36, 36, 256)       0         
_________________________________________________________________
conv_7 (Conv2D)              (None, 36, 36, 128)       32896     
_________________________________________________________________
norm_7 (BatchNormalization)  (None, 36, 36, 128)       512       
_________________________________________________________________
relu_7 (LeakyReLU)           (None, 36, 36, 128)       0         
_________________________________________________________________
conv_8 (Conv2D)              (None, 36, 36, 256)       295168    
_________________________________________________________________
norm_8 (BatchNormalization)  (None, 36, 36, 256)       1024      
_________________________________________________________________
relu_8 (LeakyReLU)           (None, 36, 36, 256)       0         
_________________________________________________________________
pool_4 (MaxPooling2D)        (None, 18, 18, 256)       0         
_________________________________________________________________
conv_9 (Conv2D)              (None, 18, 18, 512)       1180160   
_________________________________________________________________
norm_9 (BatchNormalization)  (None, 18, 18, 512)       2048      
_________________________________________________________________
relu_9 (LeakyReLU)           (None, 18, 18, 512)       0         
_________________________________________________________________
conv_10 (Conv2D)             (None, 18, 18, 256)       131328    
_________________________________________________________________
norm_10 (BatchNormalization) (None, 18, 18, 256)       1024      
_________________________________________________________________
relu_10 (LeakyReLU)          (None, 18, 18, 256)       0         
_________________________________________________________________
conv_11 (Conv2D)             (None, 18, 18, 512)       1180160   
_________________________________________________________________
norm_11 (BatchNormalization) (None, 18, 18, 512)       2048      
_________________________________________________________________
relu_11 (LeakyReLU)          (None, 18, 18, 512)       0         
_________________________________________________________________
conv_12 (Conv2D)             (None, 18, 18, 256)       131328    
_________________________________________________________________
norm_12 (BatchNormalization) (None, 18, 18, 256)       1024      
_________________________________________________________________
relu_12 (LeakyReLU)          (None, 18, 18, 256)       0         
_________________________________________________________________
conv_13 (Conv2D)             (None, 18, 18, 512)       1180160   
_________________________________________________________________
norm_13 (BatchNormalization) (None, 18, 18, 512)       2048      
_________________________________________________________________
relu_13 (LeakyReLU)          (None, 18, 18, 512)       0         
_________________________________________________________________
pool_5 (MaxPooling2D)        (None, 9, 9, 512)         0         
_________________________________________________________________
conv_14 (Conv2D)             (None, 9, 9, 1024)        4719616   
_________________________________________________________________
norm_14 (BatchNormalization) (None, 9, 9, 1024)        4096      
_________________________________________________________________
relu_14 (LeakyReLU)          (None, 9, 9, 1024)        0         
_________________________________________________________________
conv_15 (Conv2D)             (None, 9, 9, 1024)        9438208   
_________________________________________________________________
norm_15 (BatchNormalization) (None, 9, 9, 1024)        4096      
_________________________________________________________________
relu_15 (LeakyReLU)          (None, 9, 9, 1024)        0         
_________________________________________________________________
conv_16 (Conv2D)             (None, 9, 9, 5)           5125      
_________________________________________________________________
reshape_1 (Reshape)          (None, 9, 9, 5)           0         
=================================================================
Total params: 18,784,709
Trainable params: 18,774,405
Non-trainable params: 10,304
_________________________________________________________________
+----------+----------------------+----------------+---------------+---------------------+----------------------+---------------+
|  Epoch   |       f1_score       |      iou       |      loss     |      precision      |        recall        |    val_loss   |
+----------+----------------------+----------------+---------------+---------------------+----------------------+---------------+
| Epoch 1  |         nan          |      nan       | 40.6673529172 |         nan         |         0.0          | 47.8818766785 |
| Epoch 2  | 0.002336448598130841 | 0.615218806351 | 31.8433655276 |         0.5         | 0.00117096018735363  | 31.8123515472 |
| Epoch 3  |         nan          |      nan       | 30.4038072617 |         nan         |         0.0          |  37.20315979  |
| Epoch 4  | 0.006993006993006993 | 0.790873338989 | 29.4716728897 |         0.75        | 0.00351288056206089  | 32.2992876053 |
| Epoch 5  | 0.006984866123399301 | 0.602190402601 | 28.6617614822 |         0.6         | 0.00351288056206089  | 36.0275534134 |
| Epoch 6  | 0.020833333333333332 | 0.674884919043 | 28.0311482695 |         0.9         | 0.01053864168618267  | 35.4732119598 |
| Epoch 7  |  0.1094420600858369  | 0.691321561182 |  27.386413075 |  0.6538461538461539 | 0.059718969555035126 | 28.3799730377 |
| Epoch 8  | 0.05842696629213483  |  0.6976412137  | 26.7379811476 |  0.7222222222222222 | 0.03044496487119438  | 29.2343190765 |
| Epoch 9  | 0.13897280966767375  | 0.711756874989 | 26.1453107011 | 0.49640287769784175 | 0.08079625292740047  |  33.92602388  |
| Epoch 10 |  0.1483739837398374  | 0.690461500707 | 25.6623546652 |  0.5615384615384615 | 0.08548009367681499  | 27.1037339401 |
| Epoch 11 |         nan          |      nan       |      nan      |         nan         |         0.0          |      nan      |
| Epoch 12 |         nan          |      nan       |      nan      |         nan         |         0.0          |      nan      |
| Epoch 13 |         nan          |      nan       |      nan      |         nan         |         0.0          |      nan      |
| Epoch 14 |         nan          |      nan       |      nan      |         nan         |         0.0          |      nan      |
| Epoch 15 |         nan          |      nan       |      nan      |         nan         |         0.0          |      nan      |
| Epoch 16 |         nan          |      nan       |      nan      |         nan         |         0.0          |      nan      |
| Epoch 17 |         nan          |      nan       |      nan      |         nan         |         0.0          |      nan      |
| Epoch 18 |         nan          |      nan       |      nan      |         nan         |         0.0          |      nan      |
| Epoch 19 |         nan          |      nan       |      nan      |         nan         |         0.0          |      nan      |
| Epoch 20 |         nan          |      nan       |      nan      |         nan         |         0.0          |      nan      |
| Epoch 21 |         nan          |      nan       |      nan      |         nan         |         0.0          |      nan      |
| Epoch 22 |         nan          |      nan       |      nan      |         nan         |         0.0          |      nan      |
| Epoch 23 |         nan          |      nan       |      nan      |         nan         |         0.0          |      nan      |
| Epoch 24 |         nan          |      nan       |      nan      |         nan         |         0.0          |      nan      |
| Epoch 25 |         nan          |      nan       |      nan      |         nan         |         0.0          |      nan      |
| Epoch 26 |         nan          |      nan       |      nan      |         nan         |         0.0          |      nan      |
| Epoch 27 |         nan          |      nan       |      nan      |         nan         |         0.0          |      nan      |
| Epoch 28 |         nan          |      nan       |      nan      |         nan         |         0.0          |      nan      |
| Epoch 29 |         nan          |      nan       |      nan      |         nan         |         0.0          |      nan      |
| Epoch 30 |         nan          |      nan       |      nan      |         nan         |         0.0          |      nan      |
+----------+----------------------+----------------+---------------+---------------------+----------------------+---------------+
_________________________________________________________________
+------------------------------------+-----------------------+---------+----------------------+--------------------+
|             Optimizer              |         decay         | epsilon |          lr          |        rho         |
+------------------------------------+-----------------------+---------+----------------------+--------------------+
| <class 'keras.optimizers.RMSprop'> | 9.999999747378752e-06 |  1e-08  | 0.009999999776482582 | 0.8999999761581421 |
+------------------------------------+-----------------------+---------+----------------------+--------------------+
_________________________________________________________________
+------------+
| Batch Size |
+------------+
|     16     |
+------------+
_________________________________________________________________
+--------------------+------+-----+-----------+--------+----------+
|      Metrics       | Loss | IoU | Precision | Recall | F1 Score |
+--------------------+------+-----+-----------+--------+----------+
|   Train Metrics    | nan  | nan |    nan    |  0.0   |   nan    |
| Validation Metrics | nan  | nan |    nan    |  0.0   |   nan    |
|    Test Metrics    | nan  | nan |    nan    |  0.0   |   nan    |
+--------------------+------+-----+-----------+--------+----------+
_________________________________________________________________
Time:
    Train Time              : 6:05:49.337701
    Dataset Loading Time    : 0:04:40.796388
    Metrics Evaluation Time : 0:20:12.441668
_________________________________________________________________
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         (None, 288, 288, 1)       0         
_________________________________________________________________
conv_1 (Conv2D)              (None, 288, 288, 32)      320       
_________________________________________________________________
norm_1 (BatchNormalization)  (None, 288, 288, 32)      128       
_________________________________________________________________
relu_1 (LeakyReLU)           (None, 288, 288, 32)      0         
_________________________________________________________________
pool_1 (MaxPooling2D)        (None, 144, 144, 32)      0         
_________________________________________________________________
conv_2 (Conv2D)              (None, 144, 144, 64)      18496     
_________________________________________________________________
norm_2 (BatchNormalization)  (None, 144, 144, 64)      256       
_________________________________________________________________
relu_2 (LeakyReLU)           (None, 144, 144, 64)      0         
_________________________________________________________________
pool_2 (MaxPooling2D)        (None, 72, 72, 64)        0         
_________________________________________________________________
conv_3 (Conv2D)              (None, 72, 72, 128)       73856     
_________________________________________________________________
norm_3 (BatchNormalization)  (None, 72, 72, 128)       512       
_________________________________________________________________
relu_3 (LeakyReLU)           (None, 72, 72, 128)       0         
_________________________________________________________________
conv_4 (Conv2D)              (None, 72, 72, 64)        8256      
_________________________________________________________________
norm_4 (BatchNormalization)  (None, 72, 72, 64)        256       
_________________________________________________________________
relu_4 (LeakyReLU)           (None, 72, 72, 64)        0         
_________________________________________________________________
conv_5 (Conv2D)              (None, 72, 72, 128)       73856     
_________________________________________________________________
norm_5 (BatchNormalization)  (None, 72, 72, 128)       512       
_________________________________________________________________
relu_5 (LeakyReLU)           (None, 72, 72, 128)       0         
_________________________________________________________________
pool_3 (MaxPooling2D)        (None, 36, 36, 128)       0         
_________________________________________________________________
conv_6 (Conv2D)              (None, 36, 36, 256)       295168    
_________________________________________________________________
norm_6 (BatchNormalization)  (None, 36, 36, 256)       1024      
_________________________________________________________________
relu_6 (LeakyReLU)           (None, 36, 36, 256)       0         
_________________________________________________________________
conv_7 (Conv2D)              (None, 36, 36, 128)       32896     
_________________________________________________________________
norm_7 (BatchNormalization)  (None, 36, 36, 128)       512       
_________________________________________________________________
relu_7 (LeakyReLU)           (None, 36, 36, 128)       0         
_________________________________________________________________
conv_8 (Conv2D)              (None, 36, 36, 256)       295168    
_________________________________________________________________
norm_8 (BatchNormalization)  (None, 36, 36, 256)       1024      
_________________________________________________________________
relu_8 (LeakyReLU)           (None, 36, 36, 256)       0         
_________________________________________________________________
pool_4 (MaxPooling2D)        (None, 18, 18, 256)       0         
_________________________________________________________________
conv_9 (Conv2D)              (None, 18, 18, 512)       1180160   
_________________________________________________________________
norm_9 (BatchNormalization)  (None, 18, 18, 512)       2048      
_________________________________________________________________
relu_9 (LeakyReLU)           (None, 18, 18, 512)       0         
_________________________________________________________________
conv_10 (Conv2D)             (None, 18, 18, 256)       131328    
_________________________________________________________________
norm_10 (BatchNormalization) (None, 18, 18, 256)       1024      
_________________________________________________________________
relu_10 (LeakyReLU)          (None, 18, 18, 256)       0         
_________________________________________________________________
conv_11 (Conv2D)             (None, 18, 18, 512)       1180160   
_________________________________________________________________
norm_11 (BatchNormalization) (None, 18, 18, 512)       2048      
_________________________________________________________________
relu_11 (LeakyReLU)          (None, 18, 18, 512)       0         
_________________________________________________________________
conv_12 (Conv2D)             (None, 18, 18, 256)       131328    
_________________________________________________________________
norm_12 (BatchNormalization) (None, 18, 18, 256)       1024      
_________________________________________________________________
relu_12 (LeakyReLU)          (None, 18, 18, 256)       0         
_________________________________________________________________
conv_13 (Conv2D)             (None, 18, 18, 512)       1180160   
_________________________________________________________________
norm_13 (BatchNormalization) (None, 18, 18, 512)       2048      
_________________________________________________________________
relu_13 (LeakyReLU)          (None, 18, 18, 512)       0         
_________________________________________________________________
pool_5 (MaxPooling2D)        (None, 9, 9, 512)         0         
_________________________________________________________________
conv_14 (Conv2D)             (None, 9, 9, 1024)        4719616   
_________________________________________________________________
norm_14 (BatchNormalization) (None, 9, 9, 1024)        4096      
_________________________________________________________________
relu_14 (LeakyReLU)          (None, 9, 9, 1024)        0         
_________________________________________________________________
conv_15 (Conv2D)             (None, 9, 9, 1024)        9438208   
_________________________________________________________________
norm_15 (BatchNormalization) (None, 9, 9, 1024)        4096      
_________________________________________________________________
relu_15 (LeakyReLU)          (None, 9, 9, 1024)        0         
_________________________________________________________________
conv_16 (Conv2D)             (None, 9, 9, 5)           5125      
_________________________________________________________________
reshape_1 (Reshape)          (None, 9, 9, 5)           0         
=================================================================
Total params: 18,784,709
Trainable params: 18,774,405
Non-trainable params: 10,304
_________________________________________________________________
+----------+----------------------+----------------+---------------+---------------------+---------------------+---------------+
|  Epoch   |       f1_score       |      iou       |      loss     |      precision      |        recall       |    val_loss   |
+----------+----------------------+----------------+---------------+---------------------+---------------------+---------------+
| Epoch 1  |         nan          |      nan       | 42.7280856228 |         nan         |         0.0         | 37.7042737274 |
| Epoch 2  |         nan          |      nan       | 31.9775299351 |         nan         |         0.0         |  31.141308136 |
| Epoch 3  | 0.013904982618771726 | 0.728244478388 | 30.1420732961 |  0.6666666666666666 | 0.00702576112412178 | 30.6655749207 |
| Epoch 4  | 0.006968641114982578 | 0.726401562455 | 29.0907083854 | 0.42857142857142855 | 0.00351288056206089 | 32.2335027924 |
| Epoch 5  | 0.023068050749711654 | 0.716823161157 | 28.1386309516 |  0.7692307692307693 |  0.0117096018735363 | 29.0859538879 |
| Epoch 6  | 0.09863588667366212  | 0.697601570078 | 27.3926428925 | 0.47474747474747475 | 0.05503512880562061 |  36.784703476 |
| Epoch 7  |  0.1316348195329087  | 0.682408224471 | 26.7548825861 |  0.7045454545454546 | 0.07259953161592506 | 27.0481393661 |
| Epoch 8  | 0.009291521486643438 | 0.697503497618 | 26.0002485491 |  0.5714285714285714 | 0.00468384074941452 | 48.8587560501 |
| Epoch 9  |  0.1511746680286006  | 0.667251331263 | 25.4242828521 |        0.592        | 0.08665105386416862 | 27.0879191284 |
| Epoch 10 | 0.18700787401574803  | 0.673334396185 | 24.8278585375 |  0.5864197530864198 | 0.11124121779859485 | 26.5743731155 |
| Epoch 11 |  0.2452471482889734  | 0.688857749248 | 24.1553800726 |  0.6515151515151515 | 0.15105386416861827 | 26.2366265717 |
| Epoch 12 | 0.26666666666666666  | 0.680961346401 | 23.4862677923 |  0.6371681415929203 |  0.1686182669789227 | 25.9140877457 |
| Epoch 13 |  0.2771929824561404  | 0.659792047597 | 22.8608232592 |  0.5524475524475524 | 0.18501170960187355 | 26.0034392967 |
| Epoch 14 |         0.26         | 0.672624011796 | 22.8655857609 |  0.5813008130081301 | 0.16744730679156908 |   28.6391791  |
| Epoch 15 | 0.23023791250959322  | 0.651082783421 | 22.8825566717 | 0.33407572383073497 |  0.1756440281030445 | 28.3031979599 |
| Epoch 16 | 0.11570247933884298  | 0.679171446869 | 22.7409089635 | 0.49122807017543857 | 0.06557377049180328 | 32.7359228668 |
| Epoch 17 |  0.2723404255319149  | 0.67432972933  | 22.5283122091 |  0.4984423676012461 |  0.1873536299765808 |  28.119501236 |
| Epoch 18 | 0.19499105545617176  | 0.633515853736 | 22.1430374212 |  0.4128787878787879 | 0.12763466042154567 | 29.4840986404 |
| Epoch 19 |  0.1904761904761905  | 0.692286615896 | 21.5993274732 | 0.38571428571428573 | 0.12646370023419204 | 35.9035847168 |
| Epoch 20 | 0.20531227566403445  | 0.644285170027 | 20.9432629842 |  0.2653061224489796 | 0.16744730679156908 | 29.9411376495 |
| Epoch 21 | 0.19330289193302894  | 0.639416074243 | 20.1983594537 | 0.27608695652173915 |  0.148711943793911  | 30.2301787338 |
| Epoch 22 |  0.2384105960264901  | 0.677365652517 | 19.3403965323 |  0.4067796610169492 |  0.1686182669789227 | 28.7026263809 |
| Epoch 23 |  0.2704918032786885  | 0.667004314177 | 18.3843398861 | 0.45081967213114754 | 0.19320843091334894 | 28.9070077133 |
| Epoch 24 | 0.23076923076923078  | 0.658216103155 | 17.5218849074 | 0.36548223350253806 |  0.1686182669789227 | 29.9008069305 |
| Epoch 25 |  0.1839080459770115  | 0.662895044384 | 16.4760729651 |  0.5052631578947369 | 0.11241217798594848 | 29.8942928162 |
| Epoch 26 | 0.23008849557522124  | 0.667243150825 | 15.6605362638 |  0.3676092544987147 | 0.16744730679156908 | 32.3183005371 |
| Epoch 27 | 0.17404351087771947  | 0.660134033733 | 14.9159152925 | 0.24217118997912318 |  0.1358313817330211 |  31.351468811 |
| Epoch 28 | 0.26119969627942297  | 0.654486403761 |  14.177825207 |  0.3714902807775378 | 0.20140515222482436 | 30.6389556656 |
| Epoch 29 | 0.23443815683104285  | 0.641059031734 | 13.5510592509 |  0.3785900783289817 | 0.16978922716627634 | 30.9472299881 |
| Epoch 30 |  0.2196144174350377  | 0.680886520409 | 12.9157853322 |  0.3864306784660767 | 0.15339578454332553 | 30.3700159836 |
| Epoch 31 |  0.1171251109139308  | 0.645944053117 | 12.4709034246 | 0.24175824175824176 | 0.07728337236533958 | 32.7040425339 |
| Epoch 32 | 0.13557046979865772  | 0.630688972965 | 11.7189230923 | 0.15880503144654087 | 0.11826697892271663 | 34.5924034042 |
| Epoch 33 | 0.23333333333333334  | 0.677120884838 | 10.9230339688 | 0.46503496503496505 |  0.1557377049180328 | 31.3114339981 |
| Epoch 34 |  0.1797752808988764  | 0.651418630935 |  10.390015851 |  0.2857142857142857 | 0.13114754098360656 |  31.703004097 |
| Epoch 35 | 0.20476610767872905  | 0.665816238797 | 9.87457312958 |  0.4157706093189964 |  0.1358313817330211 | 31.9692854385 |
+----------+----------------------+----------------+---------------+---------------------+---------------------+---------------+
_________________________________________________________________
+------------------------------------+-----------------------+---------+----------------------+--------------------+
|             Optimizer              |         decay         | epsilon |          lr          |        rho         |
+------------------------------------+-----------------------+---------+----------------------+--------------------+
| <class 'keras.optimizers.RMSprop'> | 0.0005000000237487257 |  1e-08  | 0.009999999776482582 | 0.8999999761581421 |
+------------------------------------+-----------------------+---------+----------------------+--------------------+
_________________________________________________________________
+------------+
| Batch Size |
+------------+
|     16     |
+------------+
_________________________________________________________________
+--------------------+---------------+----------------+--------------------+---------------------+---------------------+
|      Metrics       |      Loss     |      IoU       |     Precision      |        Recall       |       F1 Score      |
+--------------------+---------------+----------------+--------------------+---------------------+---------------------+
|   Train Metrics    | 20.5168771372 | 0.730899648451 | 0.7642009837014176 |  0.5343943889937955 |  0.6289637655276422 |
| Validation Metrics | 63.3205964355 | 0.665816238797 | 0.4157706093189964 |  0.1358313817330211 | 0.20476610767872905 |
|    Test Metrics    | 65.3897944946 | 0.66943882652  | 0.4271523178807947 | 0.14709236031927023 |  0.2188295165394402 |
+--------------------+---------------+----------------+--------------------+---------------------+---------------------+
_________________________________________________________________
Time:
    Train Time              : 7:03:51.874913
    Dataset Loading Time    : 0:05:33.155870
    Metrics Evaluation Time : 0:18:32.302342
_________________________________________________________________
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         (None, 288, 288, 1)       0         
_________________________________________________________________
conv_1 (Conv2D)              (None, 288, 288, 32)      320       
_________________________________________________________________
norm_1 (BatchNormalization)  (None, 288, 288, 32)      128       
_________________________________________________________________
relu_1 (LeakyReLU)           (None, 288, 288, 32)      0         
_________________________________________________________________
pool_1 (MaxPooling2D)        (None, 144, 144, 32)      0         
_________________________________________________________________
conv_2 (Conv2D)              (None, 144, 144, 64)      18496     
_________________________________________________________________
norm_2 (BatchNormalization)  (None, 144, 144, 64)      256       
_________________________________________________________________
relu_2 (LeakyReLU)           (None, 144, 144, 64)      0         
_________________________________________________________________
pool_2 (MaxPooling2D)        (None, 72, 72, 64)        0         
_________________________________________________________________
conv_3 (Conv2D)              (None, 72, 72, 128)       73856     
_________________________________________________________________
norm_3 (BatchNormalization)  (None, 72, 72, 128)       512       
_________________________________________________________________
relu_3 (LeakyReLU)           (None, 72, 72, 128)       0         
_________________________________________________________________
conv_4 (Conv2D)              (None, 72, 72, 64)        8256      
_________________________________________________________________
norm_4 (BatchNormalization)  (None, 72, 72, 64)        256       
_________________________________________________________________
relu_4 (LeakyReLU)           (None, 72, 72, 64)        0         
_________________________________________________________________
conv_5 (Conv2D)              (None, 72, 72, 128)       73856     
_________________________________________________________________
norm_5 (BatchNormalization)  (None, 72, 72, 128)       512       
_________________________________________________________________
relu_5 (LeakyReLU)           (None, 72, 72, 128)       0         
_________________________________________________________________
pool_3 (MaxPooling2D)        (None, 36, 36, 128)       0         
_________________________________________________________________
conv_6 (Conv2D)              (None, 36, 36, 256)       295168    
_________________________________________________________________
norm_6 (BatchNormalization)  (None, 36, 36, 256)       1024      
_________________________________________________________________
relu_6 (LeakyReLU)           (None, 36, 36, 256)       0         
_________________________________________________________________
conv_7 (Conv2D)              (None, 36, 36, 128)       32896     
_________________________________________________________________
norm_7 (BatchNormalization)  (None, 36, 36, 128)       512       
_________________________________________________________________
relu_7 (LeakyReLU)           (None, 36, 36, 128)       0         
_________________________________________________________________
conv_8 (Conv2D)              (None, 36, 36, 256)       295168    
_________________________________________________________________
norm_8 (BatchNormalization)  (None, 36, 36, 256)       1024      
_________________________________________________________________
relu_8 (LeakyReLU)           (None, 36, 36, 256)       0         
_________________________________________________________________
pool_4 (MaxPooling2D)        (None, 18, 18, 256)       0         
_________________________________________________________________
conv_9 (Conv2D)              (None, 18, 18, 512)       1180160   
_________________________________________________________________
norm_9 (BatchNormalization)  (None, 18, 18, 512)       2048      
_________________________________________________________________
relu_9 (LeakyReLU)           (None, 18, 18, 512)       0         
_________________________________________________________________
conv_10 (Conv2D)             (None, 18, 18, 256)       131328    
_________________________________________________________________
norm_10 (BatchNormalization) (None, 18, 18, 256)       1024      
_________________________________________________________________
relu_10 (LeakyReLU)          (None, 18, 18, 256)       0         
_________________________________________________________________
conv_11 (Conv2D)             (None, 18, 18, 512)       1180160   
_________________________________________________________________
norm_11 (BatchNormalization) (None, 18, 18, 512)       2048      
_________________________________________________________________
relu_11 (LeakyReLU)          (None, 18, 18, 512)       0         
_________________________________________________________________
conv_12 (Conv2D)             (None, 18, 18, 256)       131328    
_________________________________________________________________
norm_12 (BatchNormalization) (None, 18, 18, 256)       1024      
_________________________________________________________________
relu_12 (LeakyReLU)          (None, 18, 18, 256)       0         
_________________________________________________________________
conv_13 (Conv2D)             (None, 18, 18, 512)       1180160   
_________________________________________________________________
norm_13 (BatchNormalization) (None, 18, 18, 512)       2048      
_________________________________________________________________
relu_13 (LeakyReLU)          (None, 18, 18, 512)       0         
_________________________________________________________________
pool_5 (MaxPooling2D)        (None, 9, 9, 512)         0         
_________________________________________________________________
conv_14 (Conv2D)             (None, 9, 9, 1024)        4719616   
_________________________________________________________________
norm_14 (BatchNormalization) (None, 9, 9, 1024)        4096      
_________________________________________________________________
relu_14 (LeakyReLU)          (None, 9, 9, 1024)        0         
_________________________________________________________________
conv_15 (Conv2D)             (None, 9, 9, 1024)        9438208   
_________________________________________________________________
norm_15 (BatchNormalization) (None, 9, 9, 1024)        4096      
_________________________________________________________________
relu_15 (LeakyReLU)          (None, 9, 9, 1024)        0         
_________________________________________________________________
conv_16 (Conv2D)             (None, 9, 9, 5)           5125      
_________________________________________________________________
reshape_1 (Reshape)          (None, 9, 9, 5)           0         
=================================================================
Total params: 18,784,709
Trainable params: 18,774,405
Non-trainable params: 10,304
_________________________________________________________________
+----------+----------------------+----------------+---------------+---------------------+---------------------+---------------+
|  Epoch   |       f1_score       |      iou       |      loss     |      precision      |        recall       |    val_loss   |
+----------+----------------------+----------------+---------------+---------------------+---------------------+---------------+
| Epoch 1  |         nan          |      nan       | 41.9777807822 |         nan         |         0.0         | 59.8194589691 |
| Epoch 2  | 0.01978021978021978  | 0.645699518252 | 31.6791394455 | 0.16071428571428573 | 0.01053864168618267 | 50.0462597961 |
| Epoch 3  | 0.011627906976744186 | 0.823448091391 | 29.9808605591 |  0.8333333333333334 | 0.00585480093676815 | 29.6337893066 |
| Epoch 4  |  0.0873269435569755  | 0.727908481779 | 28.9508739691 |  0.4823529411764706 | 0.04800936768149883 | 34.4247446518 |
| Epoch 5  | 0.011600928074245941 | 0.732897862362 | 28.1511467364 |        0.625        | 0.00585480093676815 | 29.8360209045 |
| Epoch 6  | 0.10799136069114472  | 0.727266548162 | 27.3227232894 |  0.6944444444444444 |  0.0585480093676815 | 27.4556297073 |
| Epoch 7  | 0.10184182015167931  | 0.718796325826 | 26.6006522153 |  0.6811594202898551 | 0.05503512880562061 | 27.0292791977 |
| Epoch 8  | 0.013729977116704806 | 0.619731322421 | 25.9380445408 |         0.3         | 0.00702576112412178 | 40.6988113785 |
| Epoch 9  | 0.16895874263261296  | 0.695765744515 |  25.401800049 |  0.524390243902439  | 0.10070257611241218 |  27.034641758 |
| Epoch 10 |  0.1716566866267465  | 0.699820097616 | 24.7223177206 |  0.581081081081081  | 0.10070257611241218 |  27.109032753 |
| Epoch 11 |  0.2119460500963391  | 0.687028546638 | 24.0707438355 |  0.5978260869565217 |  0.1288056206088993 | 26.8198041077 |
| Epoch 12 | 0.22105263157894736  | 0.672393677274 | 23.4019913158 |  0.4405594405594406 | 0.14754098360655737 | 26.7304402924 |
| Epoch 13 | 0.21641791044776118  |  0.6720819902  | 22.7022339162 |  0.5321100917431193 |  0.1358313817330211 | 27.5880039482 |
| Epoch 14 | 0.24633936261843237  | 0.658531393671 | 22.7691736947 | 0.46579804560260585 | 0.16744730679156908 | 27.1202892265 |
| Epoch 15 |  0.192131747483989   | 0.682966766587 | 22.7083285984 |  0.4393305439330544 | 0.12295081967213115 | 28.1700782394 |
| Epoch 16 | 0.20606060606060606  | 0.673549426815 | 22.5742497251 |  0.3953488372093023 | 0.13934426229508196 | 27.7323548737 |
| Epoch 17 |  0.2713656387665198  | 0.686727117474 | 22.3716112715 |  0.5480427046263345 | 0.18032786885245902 | 27.2031767082 |
| Epoch 18 | 0.06013579049466538  | 0.603746317453 | 21.8846790683 |  0.1751412429378531 | 0.03629976580796253 | 37.2637782745 |
| Epoch 19 | 0.18845872899926952  | 0.636655641788 | 21.3544233819 |  0.2504854368932039 | 0.15105386416861827 | 30.0835529861 |
| Epoch 20 | 0.19056261343012704  | 0.679119866659 | 20.5752202553 | 0.42338709677419356 | 0.12295081967213115 |  30.829892971 |
| Epoch 21 |  0.2131147540983607  | 0.677757125059 | 19.8152362408 | 0.47950819672131145 | 0.13700234192037472 | 29.7740230789 |
| Epoch 22 | 0.15924657534246575  | 0.633000031733 | 18.8011618539 |  0.2961783439490446 | 0.10889929742388758 | 33.0628953781 |
| Epoch 23 |  0.2481751824817518  | 0.665580320843 | 17.9202883518 | 0.40369393139841686 |  0.1791569086651054 | 29.7664505157 |
| Epoch 24 | 0.19039869812855983  | 0.638934355678 | 17.1021246443 |        0.312        | 0.13700234192037472 |  30.823509903 |
| Epoch 25 | 0.23678332092330606  | 0.645078057967 | 16.1752859202 | 0.32515337423312884 | 0.18618266978922718 | 30.6520788803 |
| Epoch 26 | 0.18918918918918923  | 0.665842703189 | 15.4391954749 |  0.3393939393939394 | 0.13114754098360656 | 34.0726029739 |
| Epoch 27 |  0.1932624113475177  | 0.654183180926 | 14.5719139085 |  0.3978102189781022 | 0.12763466042154567 | 31.9801926422 |
| Epoch 28 | 0.20516836335160532  | 0.647171226747 | 13.9260702837 | 0.30969267139479906 | 0.15339578454332553 |  32.241386795 |
| Epoch 29 | 0.21439749608763695  | 0.651804227802 | 13.3879063507 |  0.3231132075471698 | 0.16042154566744732 | 31.6407398987 |
| Epoch 30 | 0.15838247683235046  | 0.649811670925 | 12.8176703625 |  0.2822822822822823 | 0.11007025761124122 | 31.9109981537 |
| Epoch 31 | 0.16339869281045752  | 0.650456663401 | 12.3022115679 |  0.2702702702702703 |  0.117096018735363  | 32.0056564407 |
| Epoch 32 | 0.17336907953529937  | 0.654454773397 | 11.5293180723 |  0.3660377358490566 | 0.11358313817330211 | 31.7179038162 |
| Epoch 33 |  0.1456953642384106  | 0.646778758407 |  10.881194475 |  0.3793103448275862 | 0.09016393442622951 | 32.0009642258 |
| Epoch 34 |  0.133953488372093   | 0.673423599793 | 10.2801335565 |  0.3257918552036199 | 0.08430913348946135 | 34.2926537323 |
| Epoch 35 |  0.1534090909090909  | 0.666678218393 |  9.7232833165 |  0.400990099009901  | 0.09484777517564402 | 31.8105568314 |
| Epoch 36 | 0.17037037037037037  | 0.665969806892 | 9.35474289343 | 0.40707964601769914 | 0.10772833723653395 | 31.6723219757 |
| Epoch 37 | 0.16747967479674794  | 0.642021261571 | 8.93233249555 | 0.27393617021276595 | 0.12060889929742388 | 32.3164308319 |
| Epoch 38 | 0.10945273631840796  | 0.690762574937 | 8.61984612499 | 0.36423841059602646 | 0.06440281030444965 | 32.3186595154 |
| Epoch 39 | 0.11685823754789272  | 0.654643339435 | 8.33428104444 | 0.32105263157894737 | 0.07142857142857142 | 31.6033783989 |
| Epoch 40 |  0.1671111111111111  | 0.651186971293 | 8.10912550985 | 0.34686346863468637 | 0.11007025761124122 | 32.4095059357 |
| Epoch 41 | 0.16819012797074953  | 0.665947142114 |  7.8525439815 | 0.38333333333333336 | 0.10772833723653395 | 31.3514989166 |
| Epoch 42 | 0.13606557377049178  | 0.630696268423 | 7.64720485845 |  0.226775956284153  | 0.09718969555035128 | 32.9229042358 |
| Epoch 43 | 0.13371537726838587  | 0.641544942135 | 7.45766584242 |  0.3626943005181347 | 0.08196721311475409 | 31.6495517578 |
| Epoch 44 | 0.16006884681583478  | 0.647823605935 | 7.38996169568 | 0.30194805194805197 | 0.10889929742388758 | 32.4516637535 |
| Epoch 45 | 0.16419213973799124  | 0.671420286182 |  7.1917908237 |  0.3230240549828179 | 0.11007025761124122 | 31.8079209747 |
| Epoch 46 | 0.11579980372914621  | 0.673622111573 |  7.0827143927 |  0.3575757575757576 | 0.06908665105386416 | 31.7188339195 |
| Epoch 47 | 0.16186046511627908  | 0.669368433327 | 7.04304614573 |  0.3936651583710407 | 0.10187353629976581 | 31.2146121902 |
| Epoch 48 |  0.1476754785779398  | 0.671637717736 | 6.88307251586 |  0.3333333333333333 | 0.09484777517564402 | 32.1492643967 |
| Epoch 49 |  0.1104868913857678  | 0.662866944921 | 6.82308682261 |  0.2757009345794392 | 0.06908665105386416 | 32.2696839256 |
| Epoch 50 | 0.13691026827012026  | 0.663076792573 | 6.68141653959 | 0.32599118942731276 | 0.08665105386416862 | 31.9462152786 |
| Epoch 51 | 0.14121800529567521  | 0.649918677138 | 6.62968492604 |  0.2867383512544803 |  0.0936768149882904 | 32.1435392227 |
| Epoch 52 | 0.11881188118811879  | 0.666286784734 | 6.53308904831 | 0.38461538461538464 |  0.0702576112412178 |  31.457642868 |
| Epoch 53 | 0.11946446961894956  | 0.647305233483 | 6.43648491502 | 0.49572649572649574 | 0.06791569086651054 | 31.4857477112 |
| Epoch 54 | 0.15954415954415957  | 0.649318018639 | 6.41494543319 |  0.4221105527638191 | 0.09836065573770492 |  31.264788147 |
| Epoch 55 | 0.14935622317596567  | 0.641211903899 | 6.35500909465 |  0.2797427652733119 | 0.10187353629976581 | 32.6414356384 |
| Epoch 56 | 0.12631578947368421  | 0.661595266836 | 6.29703815006 | 0.34554973821989526 | 0.07728337236533958 | 31.9583913002 |
| Epoch 57 | 0.13124387855044073  | 0.66405926156  | 6.24282787886 | 0.40119760479041916 | 0.07845433255269321 | 31.7320937805 |
| Epoch 58 |  0.1951219512195122  | 0.66946704146  | 6.20069693319 |  0.4268774703557312 | 0.12646370023419204 | 31.8471286545 |
| Epoch 59 |  0.1421616358325219  | 0.676758420993 | 6.13400316363 | 0.42196531791907516 | 0.08548009367681499 | 31.7618188782 |
| Epoch 60 | 0.18410041841004185  | 0.642287187406 | 6.11040951771 |  0.3225806451612903 |  0.1288056206088993 |  32.229135498 |
+----------+----------------------+----------------+---------------+---------------------+---------------------+---------------+
_________________________________________________________________
+------------------------------------+-----------------------+---------+----------------------+--------------------+
|             Optimizer              |         decay         | epsilon |          lr          |        rho         |
+------------------------------------+-----------------------+---------+----------------------+--------------------+
| <class 'keras.optimizers.RMSprop'> | 0.0005000000237487257 |  1e-08  | 0.009999999776482582 | 0.8999999761581421 |
+------------------------------------+-----------------------+---------+----------------------+--------------------+
_________________________________________________________________
+------------+
| Batch Size |
+------------+
|     16     |
+------------+
_________________________________________________________________
+--------------------+---------------+----------------+---------------------+---------------------+---------------------+
|      Metrics       |      Loss     |      IoU       |      Precision      |        Recall       |       F1 Score      |
+--------------------+---------------+----------------+---------------------+---------------------+---------------------+
|   Train Metrics    | 12.0476081258 | 0.812114160453 |  0.9118034948895483 |  0.7460210412732667 |  0.8206231454005933 |
| Validation Metrics | 63.7118540649 | 0.642287187406 |  0.3225806451612903 |  0.1288056206088993 | 0.18410041841004185 |
|    Test Metrics    | 65.2139985962 | 0.654915864058 | 0.36950146627565983 | 0.14367160775370583 | 0.20689655172413796 |
+--------------------+---------------+----------------+---------------------+---------------------+---------------------+
_________________________________________________________________
Time:
    Train Time              : 14:06:45.424320
    Dataset Loading Time    : 0:04:59.294051
    Metrics Evaluation Time : 0:32:19.033780
_________________________________________________________________
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         (None, 288, 288, 1)       0         
_________________________________________________________________
conv_1 (Conv2D)              (None, 288, 288, 32)      320       
_________________________________________________________________
norm_1 (BatchNormalization)  (None, 288, 288, 32)      128       
_________________________________________________________________
relu_1 (LeakyReLU)           (None, 288, 288, 32)      0         
_________________________________________________________________
pool_1 (MaxPooling2D)        (None, 144, 144, 32)      0         
_________________________________________________________________
conv_2 (Conv2D)              (None, 144, 144, 64)      18496     
_________________________________________________________________
norm_2 (BatchNormalization)  (None, 144, 144, 64)      256       
_________________________________________________________________
relu_2 (LeakyReLU)           (None, 144, 144, 64)      0         
_________________________________________________________________
pool_2 (MaxPooling2D)        (None, 72, 72, 64)        0         
_________________________________________________________________
conv_3 (Conv2D)              (None, 72, 72, 128)       73856     
_________________________________________________________________
norm_3 (BatchNormalization)  (None, 72, 72, 128)       512       
_________________________________________________________________
relu_3 (LeakyReLU)           (None, 72, 72, 128)       0         
_________________________________________________________________
conv_4 (Conv2D)              (None, 72, 72, 64)        8256      
_________________________________________________________________
norm_4 (BatchNormalization)  (None, 72, 72, 64)        256       
_________________________________________________________________
relu_4 (LeakyReLU)           (None, 72, 72, 64)        0         
_________________________________________________________________
conv_5 (Conv2D)              (None, 72, 72, 128)       73856     
_________________________________________________________________
norm_5 (BatchNormalization)  (None, 72, 72, 128)       512       
_________________________________________________________________
relu_5 (LeakyReLU)           (None, 72, 72, 128)       0         
_________________________________________________________________
pool_3 (MaxPooling2D)        (None, 36, 36, 128)       0         
_________________________________________________________________
conv_6 (Conv2D)              (None, 36, 36, 256)       295168    
_________________________________________________________________
norm_6 (BatchNormalization)  (None, 36, 36, 256)       1024      
_________________________________________________________________
relu_6 (LeakyReLU)           (None, 36, 36, 256)       0         
_________________________________________________________________
conv_7 (Conv2D)              (None, 36, 36, 128)       32896     
_________________________________________________________________
norm_7 (BatchNormalization)  (None, 36, 36, 128)       512       
_________________________________________________________________
relu_7 (LeakyReLU)           (None, 36, 36, 128)       0         
_________________________________________________________________
conv_8 (Conv2D)              (None, 36, 36, 256)       295168    
_________________________________________________________________
norm_8 (BatchNormalization)  (None, 36, 36, 256)       1024      
_________________________________________________________________
relu_8 (LeakyReLU)           (None, 36, 36, 256)       0         
_________________________________________________________________
pool_4 (MaxPooling2D)        (None, 18, 18, 256)       0         
_________________________________________________________________
conv_9 (Conv2D)              (None, 18, 18, 512)       1180160   
_________________________________________________________________
norm_9 (BatchNormalization)  (None, 18, 18, 512)       2048      
_________________________________________________________________
relu_9 (LeakyReLU)           (None, 18, 18, 512)       0         
_________________________________________________________________
conv_10 (Conv2D)             (None, 18, 18, 256)       131328    
_________________________________________________________________
norm_10 (BatchNormalization) (None, 18, 18, 256)       1024      
_________________________________________________________________
relu_10 (LeakyReLU)          (None, 18, 18, 256)       0         
_________________________________________________________________
conv_11 (Conv2D)             (None, 18, 18, 512)       1180160   
_________________________________________________________________
norm_11 (BatchNormalization) (None, 18, 18, 512)       2048      
_________________________________________________________________
relu_11 (LeakyReLU)          (None, 18, 18, 512)       0         
_________________________________________________________________
conv_12 (Conv2D)             (None, 18, 18, 256)       131328    
_________________________________________________________________
norm_12 (BatchNormalization) (None, 18, 18, 256)       1024      
_________________________________________________________________
relu_12 (LeakyReLU)          (None, 18, 18, 256)       0         
_________________________________________________________________
conv_13 (Conv2D)             (None, 18, 18, 512)       1180160   
_________________________________________________________________
norm_13 (BatchNormalization) (None, 18, 18, 512)       2048      
_________________________________________________________________
relu_13 (LeakyReLU)          (None, 18, 18, 512)       0         
_________________________________________________________________
pool_5 (MaxPooling2D)        (None, 9, 9, 512)         0         
_________________________________________________________________
conv_14 (Conv2D)             (None, 9, 9, 1024)        4719616   
_________________________________________________________________
norm_14 (BatchNormalization) (None, 9, 9, 1024)        4096      
_________________________________________________________________
relu_14 (LeakyReLU)          (None, 9, 9, 1024)        0         
_________________________________________________________________
drop_1 (Dropout)             (None, 9, 9, 1024)        0         
_________________________________________________________________
conv_15 (Conv2D)             (None, 9, 9, 1024)        9438208   
_________________________________________________________________
norm_15 (BatchNormalization) (None, 9, 9, 1024)        4096      
_________________________________________________________________
relu_15 (LeakyReLU)          (None, 9, 9, 1024)        0         
_________________________________________________________________
drop_2 (Dropout)             (None, 9, 9, 1024)        0         
_________________________________________________________________
conv_16 (Conv2D)             (None, 9, 9, 5)           5125      
_________________________________________________________________
reshape_1 (Reshape)          (None, 9, 9, 5)           0         
=================================================================
Total params: 18,784,709
Trainable params: 18,774,405
Non-trainable params: 10,304
_________________________________________________________________
+----------+----------------------+----------------+---------------+---------------------+----------------------+---------------+
|  Epoch   |       f1_score       |      iou       |      loss     |      precision      |        recall        |    val_loss   |
+----------+----------------------+----------------+---------------+---------------------+----------------------+---------------+
| Epoch 1  |         nan          |      nan       | 41.5311904914 |         nan         |         0.0          | 50.9240213394 |
| Epoch 2  |         nan          |      nan       | 32.2152421692 |         nan         |         0.0          | 32.6301857452 |
| Epoch 3  |         nan          |      nan       | 30.8083812312 |         nan         |         0.0          | 33.3872661514 |
| Epoch 4  |         nan          |      nan       | 29.9176298186 |         nan         |         0.0          | 32.9813399811 |
| Epoch 5  |         nan          |      nan       | 29.1324858918 |         nan         |         0.0          | 30.0772573242 |
| Epoch 6  | 0.02525832376578645  | 0.732925825079 | 28.4278552522 |  0.6470588235294118 | 0.01288056206088993  | 31.4429026947 |
| Epoch 7  | 0.047619047619047616 | 0.762173311284 | 27.8462184914 |         0.75        | 0.02459016393442623  |  27.572762558 |
| Epoch 8  | 0.055617352614015576 | 0.715905167755 | 27.2719347516 |  0.5555555555555556 | 0.02927400468384075  | 27.8251206589 |
| Epoch 9  |  0.0832420591456736  | 0.683151139219 | 26.7218224745 |  0.6440677966101694 | 0.04449648711943794  | 26.4593233109 |
| Epoch 10 | 0.07692307692307691  | 0.686655970079 | 26.2846266375 |        0.625        | 0.040983606557377046 | 26.7339060974 |
| Epoch 11 |  0.1781781781781782  | 0.668583440234 | 25.8048205257 |  0.6137931034482759 | 0.10421545667447307  | 26.8894872818 |
| Epoch 12 | 0.11205073995771671  | 0.689752931645 | 25.3825750855 |  0.5760869565217391 | 0.06206088992974239  |  26.463883461 |
| Epoch 13 |  0.1401673640167364  | 0.70566890072  | 24.8739255558 |  0.6568627450980392 | 0.07845433255269321  | 26.4156210022 |
| Epoch 14 |  0.0640176600441501  | 0.677433137424 | 25.0978922443 |  0.5576923076923077 | 0.03395784543325527  | 30.6276635971 |
| Epoch 15 |  0.1128526645768025  | 0.684146851795 | 25.1058354907 |  0.5242718446601942 | 0.06323185011709602  | 30.0895691681 |
| Epoch 16 | 0.16513761467889906  | 0.698055982526 | 25.2827392844 |  0.6377952755905512 | 0.09484777517564402  | 28.0790223312 |
| Epoch 17 | 0.10729613733905581  | 0.67742528613  | 25.0853738995 |  0.6410256410256411 |  0.0585480093676815  | 28.5546888046 |
| Epoch 18 |  0.0704070407040704  | 0.678449414034 |   25.0253054  |  0.5818181818181818 | 0.03747072599531616  | 29.5574123917 |
| Epoch 19 | 0.07415485278080698  | 0.637984402907 | 24.7986939763 |  0.5396825396825397 | 0.03981264637002342  | 28.9583097687 |
| Epoch 20 | 0.21527138914443425  | 0.640947811845 | 24.4307539603 |  0.5021459227467812 | 0.13700234192037472  | 27.9615227661 |
| Epoch 21 | 0.24064171122994654  | 0.666314737718 |  24.101398115 |  0.503731343283582  | 0.15807962529274006  | 27.9495167084 |
| Epoch 22 |  0.2397716460513796  | 0.675411782648 | 23.7039167369 |  0.6395939086294417 | 0.14754098360655737  | 27.6890041656 |
| Epoch 23 | 0.15618661257606492  | 0.678051272998 | 23.0665086385 |  0.5833333333333334 | 0.09016393442622951  | 28.8106364975 |
| Epoch 24 | 0.16383616383616384  | 0.652106262311 | 22.4040512361 |  0.5578231292517006 | 0.09601873536299765  | 28.9870207901 |
| Epoch 25 | 0.25884383088869717  | 0.662902723373 | 21.7785346251 |  0.4918032786885246 |  0.1756440281030445  |   28.2398013  |
| Epoch 26 | 0.12749003984063745  | 0.675247685597 | 21.1179245215 |  0.4266666666666667 | 0.07494145199063232  | 28.9512712402 |
| Epoch 27 | 0.14560161779575329  | 0.684504871395 | 20.1470885742 |  0.5333333333333333 | 0.08430913348946135  | 31.0930847778 |
| Epoch 28 |      0.17578125      | 0.688784791526 | 19.4601111186 |  0.5294117647058824 |  0.1053864168618267  | 30.7199203262 |
| Epoch 29 |  0.2530541012216405  | 0.663389463884 | 18.6204624083 |  0.4965753424657534 | 0.16978922716627634  | 32.6296974335 |
| Epoch 30 | 0.19255222524977295  | 0.653956360686 | 17.9203226208 |  0.4291497975708502 | 0.12412177985948478  | 31.4629648056 |
| Epoch 31 | 0.28325508607198746  | 0.667528468074 | 17.2480605139 |  0.4268867924528302 | 0.21194379391100704  | 30.3388254242 |
| Epoch 32 | 0.18248175182481752  | 0.665785265455 | 16.2610304103 |  0.4132231404958678 |  0.117096018735363   | 31.6176731567 |
| Epoch 33 | 0.15267175572519087  | 0.669103832993 | 15.4007746267 | 0.41237113402061853 |  0.0936768149882904  | 30.5105640106 |
| Epoch 34 |  0.1357664233576642  | 0.623144301693 | 14.5613237914 | 0.18023255813953487 | 0.10889929742388758  | 34.3851521683 |
| Epoch 35 | 0.09730848861283645  | 0.663882201953 | 13.9634225413 | 0.41964285714285715 | 0.05503512880562061  | 33.0975140381 |
| Epoch 36 |  0.2239382239382239  | 0.664239793889 | 13.3091991629 |  0.3287981859410431 | 0.16978922716627634  | 32.4999916344 |
| Epoch 37 | 0.22674933569530556  | 0.667390813829 | 12.7185802395 | 0.46545454545454545 | 0.14988290398126464  | 31.0438407669 |
| Epoch 38 | 0.17872340425531916  | 0.656256640286 | 12.2822782114 | 0.32710280373831774 | 0.12295081967213115  | 31.4261039124 |
| Epoch 39 | 0.16787003610108303  | 0.624887616474 | 11.7501184977 |  0.3661417322834646 | 0.10889929742388758  | 31.5369847641 |
| Epoch 40 | 0.19427580225498697  | 0.646469467901 | 11.4163376032 |  0.3745819397993311 | 0.13114754098360656  | 31.7467596664 |
| Epoch 41 | 0.19946571682991984  | 0.653752357023 | 11.0479288291 |  0.4163568773234201 | 0.13114754098360656  | 32.3974140244 |
| Epoch 42 | 0.16102332580887885  | 0.63853291459  | 10.7305112054 | 0.22526315789473683 |  0.1252927400468384  | 34.1633242111 |
| Epoch 43 |  0.1773913043478261  | 0.639594106356 | 10.4362095441 | 0.34459459459459457 | 0.11943793911007025  |  32.321949234 |
| Epoch 44 |  0.1534344335414808  | 0.662777820493 | 10.1624240184 | 0.32209737827715357 | 0.10070257611241218  | 31.5903721542 |
| Epoch 45 | 0.22222222222222224  | 0.657600384981 | 9.92097913529 | 0.42953020134228187 | 0.14988290398126464  | 32.2907830505 |
| Epoch 46 | 0.21138211382113822  | 0.651974954537 | 9.70519008923 | 0.34574468085106386 |  0.1522248243559719  | 32.0805820313 |
| Epoch 47 | 0.14015151515151514  | 0.661122551178 | 9.51870383611 | 0.36633663366336633 | 0.08665105386416862  | 31.5283434601 |
| Epoch 48 | 0.09560229445506692  | 0.662228914212 | 9.34088845305 |  0.2604166666666667 |  0.0585480093676815  | 32.2153082428 |
| Epoch 49 |  0.2191558441558442  | 0.653044871361 | 9.22560783856 | 0.35714285714285715 | 0.15807962529274006  | 32.0317670441 |
| Epoch 50 | 0.13640730067243037  | 0.650444743891 |  9.0376990804 | 0.37967914438502676 | 0.08313817330210772  | 32.7006483917 |
| Epoch 51 | 0.10666666666666666  | 0.656143186291 | 8.92100673376 |  0.2857142857142857 | 0.06557377049180328  | 32.1262901459 |
| Epoch 52 |  0.1618181818181818  | 0.663714313754 | 8.83909312265 |  0.3617886178861789 | 0.10421545667447307  | 31.9071245422 |
| Epoch 53 |  0.1308056872037915  | 0.634164899609 | 8.67293408688 | 0.34328358208955223 | 0.08079625292740047  | 32.1928063354 |
| Epoch 54 |  0.1593959731543624  | 0.639826603716 |  8.5580648557 | 0.28106508875739644 | 0.11124121779859485  | 33.7757687531 |
| Epoch 55 | 0.16187050359712232  | 0.656028728506 | 8.42379736475 |  0.3488372093023256 |  0.1053864168618267  | 32.7538340378 |
| Epoch 56 |  0.1655813953488372  | 0.64732332455  |  8.4170345634 | 0.40271493212669685 | 0.10421545667447307  | 32.2727803497 |
| Epoch 57 | 0.20226537216828477  | 0.652021655479 |  8.2666607805 | 0.32722513089005234 | 0.14637002341920374  |  32.493571907 |
| Epoch 58 |  0.1381267738883633  | 0.662616301133 | 8.09799410982 | 0.35960591133004927 | 0.08548009367681499  | 32.1849074631 |
| Epoch 59 | 0.18478260869565216  | 0.667654798197 |  8.0173122809 |        0.408        | 0.11943793911007025  | 31.7897941818 |
| Epoch 60 | 0.12392755004766444  | 0.650338954611 | 7.97068891427 |  0.3333333333333333 | 0.07611241217798595  | 31.9916321182 |
+----------+----------------------+----------------+---------------+---------------------+----------------------+---------------+
_________________________________________________________________
+------------------------------------+-----------------------+---------+----------------------+--------------------+
|             Optimizer              |         decay         | epsilon |          lr          |        rho         |
+------------------------------------+-----------------------+---------+----------------------+--------------------+
| <class 'keras.optimizers.RMSprop'> | 0.0005000000237487257 |  1e-08  | 0.009999999776482582 | 0.8999999761581421 |
+------------------------------------+-----------------------+---------+----------------------+--------------------+
_________________________________________________________________
+------------+
| Batch Size |
+------------+
|     16     |
+------------+
_________________________________________________________________
+--------------------+---------------+----------------+--------------------+---------------------+---------------------+
|      Metrics       |      Loss     |      IoU       |     Precision      |        Recall       |       F1 Score      |
+--------------------+---------------+----------------+--------------------+---------------------+---------------------+
|   Train Metrics    |  14.88118388  | 0.736667058474 | 0.8156330405465354 |  0.619975721607769  |  0.7044714356871911 |
| Validation Metrics | 63.3123860474 | 0.650338954611 | 0.3333333333333333 | 0.07611241217798595 | 0.12392755004766444 |
|    Test Metrics    | 64.7273945923 | 0.646921476278 | 0.4558139534883721 | 0.11174458380843785 |  0.1794871794871795 |
+--------------------+---------------+----------------+--------------------+---------------------+---------------------+
_________________________________________________________________
Time:
    Train Time              : 14:05:17.435923
    Dataset Loading Time    : 0:04:43.479455
    Metrics Evaluation Time : 0:30:27.336662
_________________________________________________________________
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         (None, 288, 288, 1)       0         
_________________________________________________________________
conv_1 (Conv2D)              (None, 288, 288, 32)      320       
_________________________________________________________________
norm_1 (BatchNormalization)  (None, 288, 288, 32)      128       
_________________________________________________________________
relu_1 (LeakyReLU)           (None, 288, 288, 32)      0         
_________________________________________________________________
pool_1 (MaxPooling2D)        (None, 144, 144, 32)      0         
_________________________________________________________________
conv_2 (Conv2D)              (None, 144, 144, 64)      18496     
_________________________________________________________________
norm_2 (BatchNormalization)  (None, 144, 144, 64)      256       
_________________________________________________________________
relu_2 (LeakyReLU)           (None, 144, 144, 64)      0         
_________________________________________________________________
pool_2 (MaxPooling2D)        (None, 72, 72, 64)        0         
_________________________________________________________________
conv_3 (Conv2D)              (None, 72, 72, 128)       73856     
_________________________________________________________________
norm_3 (BatchNormalization)  (None, 72, 72, 128)       512       
_________________________________________________________________
relu_3 (LeakyReLU)           (None, 72, 72, 128)       0         
_________________________________________________________________
conv_4 (Conv2D)              (None, 72, 72, 64)        8256      
_________________________________________________________________
norm_4 (BatchNormalization)  (None, 72, 72, 64)        256       
_________________________________________________________________
relu_4 (LeakyReLU)           (None, 72, 72, 64)        0         
_________________________________________________________________
conv_5 (Conv2D)              (None, 72, 72, 128)       73856     
_________________________________________________________________
norm_5 (BatchNormalization)  (None, 72, 72, 128)       512       
_________________________________________________________________
relu_5 (LeakyReLU)           (None, 72, 72, 128)       0         
_________________________________________________________________
pool_3 (MaxPooling2D)        (None, 36, 36, 128)       0         
_________________________________________________________________
conv_6 (Conv2D)              (None, 36, 36, 256)       295168    
_________________________________________________________________
norm_6 (BatchNormalization)  (None, 36, 36, 256)       1024      
_________________________________________________________________
relu_6 (LeakyReLU)           (None, 36, 36, 256)       0         
_________________________________________________________________
conv_7 (Conv2D)              (None, 36, 36, 128)       32896     
_________________________________________________________________
norm_7 (BatchNormalization)  (None, 36, 36, 128)       512       
_________________________________________________________________
relu_7 (LeakyReLU)           (None, 36, 36, 128)       0         
_________________________________________________________________
conv_8 (Conv2D)              (None, 36, 36, 256)       295168    
_________________________________________________________________
norm_8 (BatchNormalization)  (None, 36, 36, 256)       1024      
_________________________________________________________________
relu_8 (LeakyReLU)           (None, 36, 36, 256)       0         
_________________________________________________________________
pool_4 (MaxPooling2D)        (None, 18, 18, 256)       0         
_________________________________________________________________
conv_9 (Conv2D)              (None, 18, 18, 512)       1180160   
_________________________________________________________________
norm_9 (BatchNormalization)  (None, 18, 18, 512)       2048      
_________________________________________________________________
relu_9 (LeakyReLU)           (None, 18, 18, 512)       0         
_________________________________________________________________
conv_10 (Conv2D)             (None, 18, 18, 256)       131328    
_________________________________________________________________
norm_10 (BatchNormalization) (None, 18, 18, 256)       1024      
_________________________________________________________________
relu_10 (LeakyReLU)          (None, 18, 18, 256)       0         
_________________________________________________________________
conv_11 (Conv2D)             (None, 18, 18, 512)       1180160   
_________________________________________________________________
norm_11 (BatchNormalization) (None, 18, 18, 512)       2048      
_________________________________________________________________
relu_11 (LeakyReLU)          (None, 18, 18, 512)       0         
_________________________________________________________________
conv_12 (Conv2D)             (None, 18, 18, 256)       131328    
_________________________________________________________________
norm_12 (BatchNormalization) (None, 18, 18, 256)       1024      
_________________________________________________________________
relu_12 (LeakyReLU)          (None, 18, 18, 256)       0         
_________________________________________________________________
conv_13 (Conv2D)             (None, 18, 18, 512)       1180160   
_________________________________________________________________
norm_13 (BatchNormalization) (None, 18, 18, 512)       2048      
_________________________________________________________________
relu_13 (LeakyReLU)          (None, 18, 18, 512)       0         
_________________________________________________________________
pool_5 (MaxPooling2D)        (None, 9, 9, 512)         0         
_________________________________________________________________
conv_14 (Conv2D)             (None, 9, 9, 1024)        4719616   
_________________________________________________________________
norm_14 (BatchNormalization) (None, 9, 9, 1024)        4096      
_________________________________________________________________
relu_14 (LeakyReLU)          (None, 9, 9, 1024)        0         
_________________________________________________________________
drop_1 (Dropout)             (None, 9, 9, 1024)        0         
_________________________________________________________________
conv_15 (Conv2D)             (None, 9, 9, 1024)        9438208   
_________________________________________________________________
norm_15 (BatchNormalization) (None, 9, 9, 1024)        4096      
_________________________________________________________________
relu_15 (LeakyReLU)          (None, 9, 9, 1024)        0         
_________________________________________________________________
drop_2 (Dropout)             (None, 9, 9, 1024)        0         
_________________________________________________________________
conv_16 (Conv2D)             (None, 9, 9, 5)           5125      
_________________________________________________________________
reshape_1 (Reshape)          (None, 9, 9, 5)           0         
=================================================================
Total params: 18,784,709
Trainable params: 18,774,405
Non-trainable params: 10,304
_________________________________________________________________
+----------+-----------------------+----------------+---------------+---------------------+----------------------+---------------+
|  Epoch   |        f1_score       |      iou       |      loss     |      precision      |        recall        |    val_loss   |
+----------+-----------------------+----------------+---------------+---------------------+----------------------+---------------+
| Epoch 1  |          nan          |      nan       | 44.4269740571 |         nan         |         0.0          | 55.4420755157 |
| Epoch 2  |          nan          |      nan       | 32.9566528963 |         nan         |         0.0          | 33.3500129929 |
| Epoch 3  |          nan          |      nan       | 31.3375917558 |         nan         |         0.0          | 37.9843241959 |
| Epoch 4  | 0.0023391812865497076 | 0.837802599204 | 30.4515017779 |         1.0         | 0.00117096018735363  | 41.3305175781 |
| Epoch 5  |  0.002328288707799767 | 0.818197858464 | 29.5864301902 |         0.2         | 0.00117096018735363  | 31.2990237732 |
| Epoch 6  |  0.03211009174311927  | 0.740629423705 | 29.0758790741 |  0.7777777777777778 | 0.01639344262295082  | 28.3264589691 |
| Epoch 7  |  0.02534562211981567  | 0.767067105682 | 28.4517626673 |  0.7857142857142857 | 0.01288056206088993  | 31.4562987823 |
| Epoch 8  |          nan          |      nan       | 27.9863101216 |         nan         |         0.0          | 42.3012642059 |
| Epoch 9  |  0.12083333333333335  | 0.684970870399 | 27.4923601637 |  0.5471698113207547 | 0.06791569086651054  | 33.3953100433 |
| Epoch 10 |  0.02304147465437788  | 0.657517928916 | 27.1147163873 |  0.7142857142857143 |  0.0117096018735363  | 32.0233694916 |
| Epoch 11 |   0.0562429696287964  | 0.674367613522 | 26.7074382422 |  0.7142857142857143 | 0.02927400468384075  | 28.3087250443 |
| Epoch 12 |  0.12055974165769646  | 0.685432656068 | 26.3403787114 |  0.7466666666666667 | 0.06557377049180328  | 27.5725067596 |
| Epoch 13 |  0.12368972746331236  | 0.704039514964 | 25.9743621735 |         0.59        | 0.06908665105386416  | 29.7007767029 |
| Epoch 14 |  0.10392364793213149  | 0.649772700803 | 25.5936035297 |  0.550561797752809  | 0.05737704918032787  |  27.73411763  |
| Epoch 15 |  0.10669456066945607  | 0.658383341756 |  25.248317921 |         0.5         | 0.059718969555035126 | 27.7208000641 |
| Epoch 16 |  0.08436213991769546  | 0.670838986296 | 24.8577399998 |  0.3474576271186441 | 0.04800936768149883  | 28.6626447983 |
| Epoch 17 |  0.15112855740922473  | 0.668646157693 | 24.4893683436 |  0.4666666666666667 | 0.09016393442622951  | 28.1578603821 |
| Epoch 18 |  0.17992424242424243  | 0.677829700489 | 23.9946234883 | 0.47029702970297027 | 0.11124121779859485  | 26.8801748352 |
| Epoch 19 |  0.26251025430680885  | 0.669173952848 | 23.6938922933 |  0.4383561643835616 |  0.1873536299765808  | 27.1018111267 |
| Epoch 20 |  0.18467220683287167  | 0.661707580228 | 23.1699268195 |  0.4366812227074236 |  0.117096018735363   | 27.3711573944 |
| Epoch 21 |  0.21549421193232413  | 0.675206529385 | 22.7608141692 | 0.44981412639405205 | 0.14168618266978922  | 27.0826634979 |
| Epoch 22 |   0.2357930449533503  | 0.668291724474 | 22.2901400898 |  0.4276923076923077 | 0.16276346604215455  |  27.336543129 |
| Epoch 23 |  0.19981668194317143  | 0.673289104144 | 21.7874165432 |  0.459915611814346  | 0.12763466042154567  | 28.4616523972 |
| Epoch 24 |   0.2053494391716997  | 0.674899844072 | 21.2560095816 |  0.3901639344262295 | 0.13934426229508196  | 27.5197497635 |
| Epoch 25 |  0.20539599651871188  | 0.673380397876 |  20.689794085 |         0.4         | 0.13817330210772832  | 28.4350460281 |
| Epoch 26 |   0.2630272952853598  | 0.669247009135 | 20.2387108553 |  0.447887323943662  | 0.18618266978922718  | 28.2758338242 |
| Epoch 27 |   0.2698907956318253  | 0.675654905784 | 19.7148946019 | 0.40420560747663553 |  0.202576112412178   | 28.9507086563 |
| Epoch 28 |   0.2498060512024825  | 0.659115607383 | 19.2164166012 |  0.3701149425287356 |  0.1885245901639344  | 28.5879829941 |
| Epoch 29 |  0.22134387351778653  | 0.673438986242 |  18.681011842 |  0.340632603406326  | 0.16393442622950818  | 29.1540643845 |
| Epoch 30 |  0.24847560975609753  | 0.666430866039 | 18.1648685654 |  0.3558951965065502 | 0.19086651053864168  | 29.2758107376 |
+----------+-----------------------+----------------+---------------+---------------------+----------------------+---------------+
_________________________________________________________________
+------------------------------------+-----------------------+---------+-----------------------+--------------------+
|             Optimizer              |         decay         | epsilon |           lr          |        rho         |
+------------------------------------+-----------------------+---------+-----------------------+--------------------+
| <class 'keras.optimizers.RMSprop'> | 0.0005000000237487257 |  1e-08  | 0.0010000000474974513 | 0.8999999761581421 |
+------------------------------------+-----------------------+---------+-----------------------+--------------------+
_________________________________________________________________
+------------+
| Batch Size |
+------------+
|     16     |
+------------+
_________________________________________________________________
+--------------------+---------------+----------------+---------------------+---------------------+---------------------+
|      Metrics       |      Loss     |      IoU       |      Precision      |        Recall       |       F1 Score      |
+--------------------+---------------+----------------+---------------------+---------------------+---------------------+
|   Train Metrics    | 32.2598314365 | 0.698195897432 |  0.6366234756097561 | 0.45063393579714056 |  0.5277207392197125 |
| Validation Metrics | 58.1465806885 | 0.666430866039 |  0.3558951965065502 | 0.19086651053864168 | 0.24847560975609753 |
|    Test Metrics    | 57.9591879272 | 0.668554588242 | 0.41295546558704455 | 0.23261117445838084 |  0.2975929978118162 |
+--------------------+---------------+----------------+---------------------+---------------------+---------------------+
_________________________________________________________________
Time:
    Train Time              : 5:58:43.139034
    Dataset Loading Time    : 0:05:16.885551
    Metrics Evaluation Time : 0:20:07.015381
_________________________________________________________________
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         (None, 288, 288, 1)       0         
_________________________________________________________________
conv_1 (Conv2D)              (None, 288, 288, 32)      320       
_________________________________________________________________
norm_1 (BatchNormalization)  (None, 288, 288, 32)      128       
_________________________________________________________________
relu_1 (LeakyReLU)           (None, 288, 288, 32)      0         
_________________________________________________________________
pool_1 (MaxPooling2D)        (None, 144, 144, 32)      0         
_________________________________________________________________
conv_2 (Conv2D)              (None, 144, 144, 64)      18496     
_________________________________________________________________
norm_2 (BatchNormalization)  (None, 144, 144, 64)      256       
_________________________________________________________________
relu_2 (LeakyReLU)           (None, 144, 144, 64)      0         
_________________________________________________________________
pool_2 (MaxPooling2D)        (None, 72, 72, 64)        0         
_________________________________________________________________
conv_3 (Conv2D)              (None, 72, 72, 128)       73856     
_________________________________________________________________
norm_3 (BatchNormalization)  (None, 72, 72, 128)       512       
_________________________________________________________________
relu_3 (LeakyReLU)           (None, 72, 72, 128)       0         
_________________________________________________________________
conv_4 (Conv2D)              (None, 72, 72, 64)        8256      
_________________________________________________________________
norm_4 (BatchNormalization)  (None, 72, 72, 64)        256       
_________________________________________________________________
relu_4 (LeakyReLU)           (None, 72, 72, 64)        0         
_________________________________________________________________
conv_5 (Conv2D)              (None, 72, 72, 128)       73856     
_________________________________________________________________
norm_5 (BatchNormalization)  (None, 72, 72, 128)       512       
_________________________________________________________________
relu_5 (LeakyReLU)           (None, 72, 72, 128)       0         
_________________________________________________________________
pool_3 (MaxPooling2D)        (None, 36, 36, 128)       0         
_________________________________________________________________
conv_6 (Conv2D)              (None, 36, 36, 256)       295168    
_________________________________________________________________
norm_6 (BatchNormalization)  (None, 36, 36, 256)       1024      
_________________________________________________________________
relu_6 (LeakyReLU)           (None, 36, 36, 256)       0         
_________________________________________________________________
conv_7 (Conv2D)              (None, 36, 36, 128)       32896     
_________________________________________________________________
norm_7 (BatchNormalization)  (None, 36, 36, 128)       512       
_________________________________________________________________
relu_7 (LeakyReLU)           (None, 36, 36, 128)       0         
_________________________________________________________________
conv_8 (Conv2D)              (None, 36, 36, 256)       295168    
_________________________________________________________________
norm_8 (BatchNormalization)  (None, 36, 36, 256)       1024      
_________________________________________________________________
relu_8 (LeakyReLU)           (None, 36, 36, 256)       0         
_________________________________________________________________
pool_4 (MaxPooling2D)        (None, 18, 18, 256)       0         
_________________________________________________________________
conv_9 (Conv2D)              (None, 18, 18, 512)       1180160   
_________________________________________________________________
norm_9 (BatchNormalization)  (None, 18, 18, 512)       2048      
_________________________________________________________________
relu_9 (LeakyReLU)           (None, 18, 18, 512)       0         
_________________________________________________________________
conv_10 (Conv2D)             (None, 18, 18, 256)       131328    
_________________________________________________________________
norm_10 (BatchNormalization) (None, 18, 18, 256)       1024      
_________________________________________________________________
relu_10 (LeakyReLU)          (None, 18, 18, 256)       0         
_________________________________________________________________
conv_11 (Conv2D)             (None, 18, 18, 512)       1180160   
_________________________________________________________________
norm_11 (BatchNormalization) (None, 18, 18, 512)       2048      
_________________________________________________________________
relu_11 (LeakyReLU)          (None, 18, 18, 512)       0         
_________________________________________________________________
conv_12 (Conv2D)             (None, 18, 18, 256)       131328    
_________________________________________________________________
norm_12 (BatchNormalization) (None, 18, 18, 256)       1024      
_________________________________________________________________
relu_12 (LeakyReLU)          (None, 18, 18, 256)       0         
_________________________________________________________________
conv_13 (Conv2D)             (None, 18, 18, 512)       1180160   
_________________________________________________________________
norm_13 (BatchNormalization) (None, 18, 18, 512)       2048      
_________________________________________________________________
relu_13 (LeakyReLU)          (None, 18, 18, 512)       0         
_________________________________________________________________
pool_5 (MaxPooling2D)        (None, 9, 9, 512)         0         
_________________________________________________________________
conv_14 (Conv2D)             (None, 9, 9, 1024)        4719616   
_________________________________________________________________
norm_14 (BatchNormalization) (None, 9, 9, 1024)        4096      
_________________________________________________________________
relu_14 (LeakyReLU)          (None, 9, 9, 1024)        0         
_________________________________________________________________
drop_1 (Dropout)             (None, 9, 9, 1024)        0         
_________________________________________________________________
conv_15 (Conv2D)             (None, 9, 9, 1024)        9438208   
_________________________________________________________________
norm_15 (BatchNormalization) (None, 9, 9, 1024)        4096      
_________________________________________________________________
relu_15 (LeakyReLU)          (None, 9, 9, 1024)        0         
_________________________________________________________________
drop_2 (Dropout)             (None, 9, 9, 1024)        0         
_________________________________________________________________
conv_16 (Conv2D)             (None, 9, 9, 5)           5125      
_________________________________________________________________
reshape_1 (Reshape)          (None, 9, 9, 5)           0         
=================================================================
Total params: 18,784,709
Trainable params: 18,774,405
Non-trainable params: 10,304
_________________________________________________________________
+----------+----------------------+----------------+---------------+---------------------+---------------------+---------------+
|  Epoch   |       f1_score       |      iou       |      loss     |      precision      |        recall       |    val_loss   |
+----------+----------------------+----------------+---------------+---------------------+---------------------+---------------+
| Epoch 1  | 0.056433408577878104 | 0.692492722525 | 27.7528530758 |       0.78125       | 0.02927400468384075 | 29.1407252197 |
| Epoch 2  | 0.022988505747126436 | 0.642262546576 | 26.1242178351 |        0.625        |  0.0117096018735363 | 34.7236468811 |
| Epoch 3  | 0.12825651302605212  | 0.671912661081 | 24.5545683214 |  0.4444444444444444 | 0.07494145199063232 | 27.5414861832 |
| Epoch 4  |  0.1608738828202582  | 0.668285312523 | 23.0024701574 |  0.5294117647058824 | 0.09484777517564402 | 29.3053927841 |
| Epoch 5  | 0.16081330868761554  | 0.668033761767 | 21.6155447102 |  0.3815789473684211 | 0.10187353629976581 | 28.8831876755 |
| Epoch 6  | 0.14930875576036864  | 0.65945118288  |  20.246008023 | 0.35064935064935066 | 0.09484777517564402 | 28.7862648926 |
| Epoch 7  | 0.22222222222222224  | 0.664573674256 | 19.0827465429 |  0.3556701030927835 | 0.16159250585480095 |  29.575431076 |
| Epoch 8  |  0.1625441696113074  | 0.650769519862 | 17.8004842108 | 0.33093525179856115 | 0.10772833723653395 | 30.2905587769 |
| Epoch 9  | 0.25386493083807976  | 0.663652121892 |  16.935024802 |        0.416        | 0.18266978922716628 | 28.9314434357 |
| Epoch 10 | 0.20844099913867356  | 0.645832610992 | 15.9062138835 |  0.3941368078175896 | 0.14168618266978922 | 29.8040118332 |
| Epoch 11 | 0.13446969696969696  | 0.659210147599 |  15.054021593 | 0.35148514851485146 | 0.08313817330210772 | 30.1933556519 |
| Epoch 12 | 0.24964739069111425  | 0.656455918774 | 14.3157470909 | 0.31382978723404253 | 0.20725995316159251 | 31.1907461853 |
| Epoch 13 |  0.234006734006734   | 0.664537446829 | 13.7184809743 |  0.4161676646706587 | 0.16276346604215455 | 30.6798742905 |
| Epoch 14 | 0.24878836833602586  | 0.662030486181 | 13.1299804923 |  0.4010416666666667 | 0.18032786885245902 |  30.74901754  |
| Epoch 15 | 0.22735042735042735  |  0.6512451849  | 12.6040463674 |  0.4208860759493671 |  0.1557377049180328 | 31.1135764084 |
| Epoch 16 | 0.20159151193633953  | 0.665939276022 | 12.2413177059 | 0.41155234657039713 | 0.13348946135831383 | 30.6746648636 |
| Epoch 17 | 0.20333333333333334  | 0.652691428001 | 11.7784726438 | 0.35260115606936415 | 0.14285714285714285 | 31.2895639114 |
| Epoch 18 |  0.1763085399449036  | 0.655563327386 | 11.4611056668 |  0.4085106382978723 | 0.11241217798594848 |  31.419398819 |
| Epoch 19 | 0.18495013599274704  | 0.664526469574 |  11.178804469 | 0.40963855421686746 | 0.11943793911007025 |  30.890350235 |
| Epoch 20 | 0.20034843205574912  | 0.674865439193 | 10.8555526806 |  0.391156462585034  | 0.13466042154566746 | 31.1951590271 |
| Epoch 21 | 0.22202797202797203  | 0.665963779543 |  10.622995656 |  0.4379310344827586 |  0.148711943793911  | 31.6066522141 |
| Epoch 22 | 0.14828209764918626  | 0.672147031091 | 10.4417755135 |  0.3253968253968254 | 0.09601873536299765 | 31.4450245972 |
| Epoch 23 | 0.17826825127334464  | 0.654698276627 | 10.2287876105 | 0.32407407407407407 | 0.12295081967213115 | 31.8678543015 |
| Epoch 24 | 0.16489361702127658  | 0.664202238671 | 10.0538635915 | 0.33941605839416056 | 0.10889929742388758 | 31.4176306763 |
| Epoch 25 |  0.2034188034188034  | 0.666862436029 | 9.91658954416 | 0.37658227848101267 | 0.13934426229508196 | 31.5385158005 |
| Epoch 26 | 0.18115279048490393  | 0.676654239243 | 9.68945970494 | 0.41422594142259417 | 0.11592505854800937 | 31.3379436035 |
| Epoch 27 |  0.1450381679389313  | 0.67979126585  | 9.59334983068 |  0.3917525773195876 | 0.08899297423887588 | 31.6255310822 |
| Epoch 28 |  0.1951219512195122  | 0.666381602288 | 9.55903434637 | 0.38095238095238093 | 0.13114754098360656 | 31.8178849487 |
| Epoch 29 | 0.17570093457943928  | 0.655650247204 | 9.42075331939 |  0.4351851851851852 | 0.11007025761124122 | 31.2030658417 |
| Epoch 30 | 0.21818181818181817  | 0.668388884443 | 9.32563918206 |  0.4186046511627907 | 0.14754098360655737 | 31.5805147934 |
+----------+----------------------+----------------+---------------+---------------------+---------------------+---------------+
_________________________________________________________________
+------------------------------------+-----------------------+---------+-----------------------+--------------------+
|             Optimizer              |         decay         | epsilon |           lr          |        rho         |
+------------------------------------+-----------------------+---------+-----------------------+--------------------+
| <class 'keras.optimizers.RMSprop'> | 0.0005000000237487257 |  1e-08  | 0.0010000000474974513 | 0.8999999761581421 |
+------------------------------------+-----------------------+---------+-----------------------+--------------------+
_________________________________________________________________
+------------+
| Batch Size |
+------------+
|     16     |
+------------+
_________________________________________________________________
+--------------------+---------------+----------------+--------------------+---------------------+---------------------+
|      Metrics       |      Loss     |      IoU       |     Precision      |        Recall       |       F1 Score      |
+--------------------+---------------+----------------+--------------------+---------------------+---------------------+
|   Train Metrics    | 16.4399273542 | 0.731488082363 | 0.8167945906432749 |  0.6028459670892905 |  0.6936985876144653 |
| Validation Metrics | 62.6202807007 | 0.668388884443 | 0.4186046511627907 | 0.14754098360655737 | 0.21818181818181817 |
|    Test Metrics    | 63.2281137695 | 0.67511702346  | 0.4371069182389937 | 0.15849486887115166 | 0.23263598326359836 |
+--------------------+---------------+----------------+--------------------+---------------------+---------------------+
_________________________________________________________________
Time:
    Train Time              : 6:04:00.078980
    Dataset Loading Time    : 0:04:40.131787
    Metrics Evaluation Time : 0:17:18.583760
_________________________________________________________________
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         (None, 288, 288, 1)       0         
_________________________________________________________________
conv_1 (Conv2D)              (None, 288, 288, 32)      320       
_________________________________________________________________
norm_1 (BatchNormalization)  (None, 288, 288, 32)      128       
_________________________________________________________________
relu_1 (LeakyReLU)           (None, 288, 288, 32)      0         
_________________________________________________________________
pool_1 (MaxPooling2D)        (None, 144, 144, 32)      0         
_________________________________________________________________
conv_2 (Conv2D)              (None, 144, 144, 64)      18496     
_________________________________________________________________
norm_2 (BatchNormalization)  (None, 144, 144, 64)      256       
_________________________________________________________________
relu_2 (LeakyReLU)           (None, 144, 144, 64)      0         
_________________________________________________________________
pool_2 (MaxPooling2D)        (None, 72, 72, 64)        0         
_________________________________________________________________
conv_3 (Conv2D)              (None, 72, 72, 128)       73856     
_________________________________________________________________
norm_3 (BatchNormalization)  (None, 72, 72, 128)       512       
_________________________________________________________________
relu_3 (LeakyReLU)           (None, 72, 72, 128)       0         
_________________________________________________________________
conv_4 (Conv2D)              (None, 72, 72, 64)        8256      
_________________________________________________________________
norm_4 (BatchNormalization)  (None, 72, 72, 64)        256       
_________________________________________________________________
relu_4 (LeakyReLU)           (None, 72, 72, 64)        0         
_________________________________________________________________
conv_5 (Conv2D)              (None, 72, 72, 128)       73856     
_________________________________________________________________
norm_5 (BatchNormalization)  (None, 72, 72, 128)       512       
_________________________________________________________________
relu_5 (LeakyReLU)           (None, 72, 72, 128)       0         
_________________________________________________________________
pool_3 (MaxPooling2D)        (None, 36, 36, 128)       0         
_________________________________________________________________
conv_6 (Conv2D)              (None, 36, 36, 256)       295168    
_________________________________________________________________
norm_6 (BatchNormalization)  (None, 36, 36, 256)       1024      
_________________________________________________________________
relu_6 (LeakyReLU)           (None, 36, 36, 256)       0         
_________________________________________________________________
conv_7 (Conv2D)              (None, 36, 36, 128)       32896     
_________________________________________________________________
norm_7 (BatchNormalization)  (None, 36, 36, 128)       512       
_________________________________________________________________
relu_7 (LeakyReLU)           (None, 36, 36, 128)       0         
_________________________________________________________________
conv_8 (Conv2D)              (None, 36, 36, 256)       295168    
_________________________________________________________________
norm_8 (BatchNormalization)  (None, 36, 36, 256)       1024      
_________________________________________________________________
relu_8 (LeakyReLU)           (None, 36, 36, 256)       0         
_________________________________________________________________
pool_4 (MaxPooling2D)        (None, 18, 18, 256)       0         
_________________________________________________________________
conv_9 (Conv2D)              (None, 18, 18, 512)       1180160   
_________________________________________________________________
norm_9 (BatchNormalization)  (None, 18, 18, 512)       2048      
_________________________________________________________________
relu_9 (LeakyReLU)           (None, 18, 18, 512)       0         
_________________________________________________________________
conv_10 (Conv2D)             (None, 18, 18, 256)       131328    
_________________________________________________________________
norm_10 (BatchNormalization) (None, 18, 18, 256)       1024      
_________________________________________________________________
relu_10 (LeakyReLU)          (None, 18, 18, 256)       0         
_________________________________________________________________
conv_11 (Conv2D)             (None, 18, 18, 512)       1180160   
_________________________________________________________________
norm_11 (BatchNormalization) (None, 18, 18, 512)       2048      
_________________________________________________________________
relu_11 (LeakyReLU)          (None, 18, 18, 512)       0         
_________________________________________________________________
conv_12 (Conv2D)             (None, 18, 18, 256)       131328    
_________________________________________________________________
norm_12 (BatchNormalization) (None, 18, 18, 256)       1024      
_________________________________________________________________
relu_12 (LeakyReLU)          (None, 18, 18, 256)       0         
_________________________________________________________________
conv_13 (Conv2D)             (None, 18, 18, 512)       1180160   
_________________________________________________________________
norm_13 (BatchNormalization) (None, 18, 18, 512)       2048      
_________________________________________________________________
relu_13 (LeakyReLU)          (None, 18, 18, 512)       0         
_________________________________________________________________
pool_5 (MaxPooling2D)        (None, 9, 9, 512)         0         
_________________________________________________________________
conv_14 (Conv2D)             (None, 9, 9, 1024)        4719616   
_________________________________________________________________
norm_14 (BatchNormalization) (None, 9, 9, 1024)        4096      
_________________________________________________________________
relu_14 (LeakyReLU)          (None, 9, 9, 1024)        0         
_________________________________________________________________
drop_1 (Dropout)             (None, 9, 9, 1024)        0         
_________________________________________________________________
conv_15 (Conv2D)             (None, 9, 9, 1024)        9438208   
_________________________________________________________________
norm_15 (BatchNormalization) (None, 9, 9, 1024)        4096      
_________________________________________________________________
relu_15 (LeakyReLU)          (None, 9, 9, 1024)        0         
_________________________________________________________________
drop_2 (Dropout)             (None, 9, 9, 1024)        0         
_________________________________________________________________
conv_16 (Conv2D)             (None, 9, 9, 5)           5125      
_________________________________________________________________
reshape_1 (Reshape)          (None, 9, 9, 5)           0         
=================================================================
Total params: 18,784,709
Trainable params: 18,774,405
Non-trainable params: 10,304
_________________________________________________________________
+----------+----------------------+----------------+---------------+---------------------+---------------------+---------------+
|  Epoch   |       f1_score       |      iou       |      loss     |      precision      |        recall       |    val_loss   |
+----------+----------------------+----------------+---------------+---------------------+---------------------+---------------+
| Epoch 1  |         nan          |      nan       | 44.6310587884 |         nan         |         0.0         | 48.3291536407 |
| Epoch 2  |         nan          |      nan       | 33.8006170606 |         nan         |         0.0         | 46.0705858002 |
| Epoch 3  |         nan          |      nan       | 31.8585977737 |         nan         |         0.0         | 30.8655038605 |
| Epoch 4  |         nan          |      nan       | 30.7653886061 |         nan         |         0.0         | 30.6142167206 |
| Epoch 5  | 0.013969732246798603 | 0.721073704005 | 29.9543744415 |         1.2         | 0.00702576112412178 | 30.0272994995 |
| Epoch 6  | 0.013921113689095127 | 0.752119161515 | 29.2855964571 |         0.75        | 0.00702576112412178 | 28.8884541702 |
| Epoch 7  | 0.013937282229965157 | 0.675937192835 | 28.8283786641 |  0.8571428571428571 | 0.00702576112412178 | 31.2058969269 |
| Epoch 8  | 0.038857142857142854 | 0.768342013513 | 28.3442657041 |  0.8095238095238095 | 0.01990632318501171 | 28.8744461823 |
| Epoch 9  | 0.013937282229965157 | 0.762113859061 | 27.8718811084 |  0.8571428571428571 | 0.00702576112412178 | 28.7052806244 |
| Epoch 10 |  0.088008800880088   | 0.711788674731 | 27.4723931163 |  0.7272727272727273 |  0.0468384074941452 | 27.0000090866 |
| Epoch 11 | 0.020809248554913295 | 0.760490508002 | 27.0304668355 |  0.8181818181818182 | 0.01053864168618267 | 29.5156717224 |
| Epoch 12 | 0.06480446927374302  | 0.688109122052 |  26.677684504 |  0.7073170731707317 | 0.03395784543325527 |  27.270656662 |
| Epoch 13 | 0.13403141361256546  | 0.702444661524 | 26.2578595304 |  0.6336633663366337 | 0.07494145199063232 | 29.0539574814 |
| Epoch 14 | 0.11965811965811968  | 0.709461390388 | 25.9548782971 |  0.6829268292682927 | 0.06557377049180328 | 29.3658987579 |
| Epoch 15 | 0.11075612353567627  | 0.65148975062  | 25.5667199241 |  0.611764705882353  | 0.06088992974238876 | 29.3195617065 |
| Epoch 16 | 0.15306122448979592  | 0.681051265085 | 25.2128663206 |  0.5952380952380952 | 0.08782201405152225 | 27.1717077179 |
| Epoch 17 |         nan          |      nan       |  31.384825243 |         nan         |         0.0         | 32.3674895706 |
| Epoch 18 |  0.0389908256880734  | 0.701213316654 | 29.7336580507 |  0.9444444444444444 | 0.01990632318501171 | 30.2441862946 |
| Epoch 19 | 0.025316455696202535 | 0.719239661962 | 28.8031506577 |  0.7333333333333333 | 0.01288056206088993 | 31.7952067871 |
| Epoch 20 |         nan          |      nan       | 28.0378021374 |         0.0         |         0.0         | 35.9705195694 |
| Epoch 21 | 0.060948081264108354 | 0.713082017724 | 27.3950035069 |       0.84375       | 0.03161592505854801 | 27.2798542252 |
| Epoch 22 | 0.053392658509454946 | 0.679410835238 | 26.9138147665 |  0.5333333333333333 | 0.02810304449648712 | 27.3738495941 |
| Epoch 23 | 0.03416856492027334  | 0.734360048263 | 26.2388819948 |        0.625        | 0.01756440281030445 | 27.1257747955 |
| Epoch 24 | 0.11802575107296139  |  0.6645768306  | 25.7929689271 |  0.7051282051282052 | 0.06440281030444965 |  26.732719101 |
| Epoch 25 |  0.0923076923076923  | 0.697755324272 | 25.2812141459 |         0.75        | 0.04918032786885246 | 27.1015760307 |
| Epoch 26 | 0.13771186440677968  | 0.691182011478 | 24.7198174655 |  0.7222222222222222 | 0.07611241217798595 | 27.0214918289 |
| Epoch 27 |  0.1941354903943377  | 0.693375390637 | 24.1106331525 |  0.7111111111111111 | 0.11241217798594848 | 26.7080086212 |
| Epoch 28 | 0.14891416752843847  | 0.678576137083 |  23.529904699 |  0.6371681415929203 | 0.08430913348946135 | 27.2422099075 |
| Epoch 29 |  0.2238667900092507  | 0.670486074689 | 22.8693820198 |  0.5330396475770925 | 0.14168618266978922 | 26.5849329529 |
| Epoch 30 | 0.07958115183246074  | 0.705454948208 | 22.1378564315 | 0.37623762376237624 | 0.04449648711943794 | 27.7504382935 |
| Epoch 31 | 0.25067144136078784  | 0.672891456596 | 21.2823300207 |  0.532319391634981  | 0.16393442622950818 | 27.3526859894 |
| Epoch 32 | 0.20855614973262032  | 0.681242673986 | 20.3429573015 | 0.43656716417910446 | 0.13700234192037472 | 27.6563541794 |
| Epoch 33 | 0.20486985726280435  | 0.657535993503 | 19.4462059627 |  0.3620178041543027 | 0.14285714285714285 | 28.3484833794 |
| Epoch 34 |  0.1907308377896613  | 0.662996981224 |  18.430576433 | 0.39925373134328357 |  0.1252927400468384 | 28.7215466995 |
| Epoch 35 | 0.27732463295269166  | 0.664711805044 | 17.5177715924 | 0.45698924731182794 |  0.1990632318501171 | 29.3993964462 |
| Epoch 36 | 0.26320501342882724  | 0.669206791817 | 16.6817717837 |   0.55893536121673  |  0.1721311475409836 |  28.952339119 |
| Epoch 37 |  0.2397425583266291  | 0.665559657902 | 13.9395958412 | 0.38303341902313626 | 0.17447306791569087 | 29.5954435501 |
| Epoch 38 | 0.24271844660194175  | 0.660255652066 |  13.213059615 | 0.39267015706806285 |  0.1756440281030445 | 29.7949522247 |
| Epoch 39 |  0.255663430420712   | 0.662762514872 | 12.8662048415 | 0.41361256544502617 | 0.18501170960187355 | 29.8684955673 |
| Epoch 40 | 0.24374495560936238  | 0.650276052944 | 12.5915375339 |  0.3922077922077922 | 0.17681498829039813 | 30.0489293289 |
| Epoch 41 | 0.24302134646962237  | 0.656682281379 | 12.3227094255 |  0.4065934065934066 | 0.17330210772833723 | 30.0531667023 |
| Epoch 42 |  0.2514011208967174  | 0.652488383031 | 12.0985574272 | 0.39746835443037976 | 0.18384074941451992 | 30.4169043198 |
| Epoch 43 |  0.2449637389202256  | 0.649970248722 | 11.9019148128 | 0.39276485788113696 | 0.17798594847775176 | 30.4637811661 |
| Epoch 44 | 0.24466338259441708  | 0.659789327358 | 11.7378816741 | 0.40934065934065933 | 0.17447306791569087 | 30.3467937164 |
| Epoch 45 |  0.2505910165484634  | 0.652811776803 | 11.5413745912 | 0.38313253012048193 | 0.18618266978922718 | 30.7118738785 |
+----------+----------------------+----------------+---------------+---------------------+---------------------+---------------+
_________________________________________________________________
+------------------------------------+-----------------------+---------+-----------------------+--------------------+
|             Optimizer              |         decay         | epsilon |           lr          |        rho         |
+------------------------------------+-----------------------+---------+-----------------------+--------------------+
| <class 'keras.optimizers.RMSprop'> | 0.0005000000237487257 |  1e-08  | 0.0010000000474974513 | 0.8999999761581421 |
+------------------------------------+-----------------------+---------+-----------------------+--------------------+
_________________________________________________________________
+------------+
| Batch Size |
+------------+
|     16     |
+------------+
_________________________________________________________________
+--------------------+---------------+----------------+---------------------+---------------------+--------------------+
|      Metrics       |      Loss     |      IoU       |      Precision      |        Recall       |      F1 Score      |
+--------------------+---------------+----------------+---------------------+---------------------+--------------------+
|   Train Metrics    | 19.9221201559 | 0.719209318051 |  0.776794035414725  |  0.5621122201240896 | 0.6522419594647468 |
| Validation Metrics | 60.9454960327 | 0.652811776803 | 0.38313253012048193 | 0.18618266978922718 | 0.2505910165484634 |
|    Test Metrics    | 62.7336152344 | 0.666840328801 | 0.39864864864864863 | 0.20182440136830102 | 0.2679788039364118 |
+--------------------+---------------+----------------+---------------------+---------------------+--------------------+
_________________________________________________________________
Time:
    Train Time              : 10:02:26.943364
    Dataset Loading Time    : 0:04:45.001781
    Metrics Evaluation Time : 0:23:27.870689
_________________________________________________________________
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         (None, 288, 288, 1)       0         
_________________________________________________________________
conv_1 (Conv2D)              (None, 288, 288, 32)      320       
_________________________________________________________________
norm_1 (BatchNormalization)  (None, 288, 288, 32)      128       
_________________________________________________________________
relu_1 (LeakyReLU)           (None, 288, 288, 32)      0         
_________________________________________________________________
pool_1 (MaxPooling2D)        (None, 144, 144, 32)      0         
_________________________________________________________________
conv_2 (Conv2D)              (None, 144, 144, 64)      18496     
_________________________________________________________________
norm_2 (BatchNormalization)  (None, 144, 144, 64)      256       
_________________________________________________________________
relu_2 (LeakyReLU)           (None, 144, 144, 64)      0         
_________________________________________________________________
pool_2 (MaxPooling2D)        (None, 72, 72, 64)        0         
_________________________________________________________________
conv_3 (Conv2D)              (None, 72, 72, 128)       73856     
_________________________________________________________________
norm_3 (BatchNormalization)  (None, 72, 72, 128)       512       
_________________________________________________________________
relu_3 (LeakyReLU)           (None, 72, 72, 128)       0         
_________________________________________________________________
drop_1 (Dropout)             (None, 72, 72, 128)       0         
_________________________________________________________________
conv_4 (Conv2D)              (None, 72, 72, 64)        8256      
_________________________________________________________________
norm_4 (BatchNormalization)  (None, 72, 72, 64)        256       
_________________________________________________________________
relu_4 (LeakyReLU)           (None, 72, 72, 64)        0         
_________________________________________________________________
drop_2 (Dropout)             (None, 72, 72, 64)        0         
_________________________________________________________________
conv_5 (Conv2D)              (None, 72, 72, 128)       73856     
_________________________________________________________________
norm_5 (BatchNormalization)  (None, 72, 72, 128)       512       
_________________________________________________________________
relu_5 (LeakyReLU)           (None, 72, 72, 128)       0         
_________________________________________________________________
pool_3 (MaxPooling2D)        (None, 36, 36, 128)       0         
_________________________________________________________________
conv_6 (Conv2D)              (None, 36, 36, 256)       295168    
_________________________________________________________________
norm_6 (BatchNormalization)  (None, 36, 36, 256)       1024      
_________________________________________________________________
relu_6 (LeakyReLU)           (None, 36, 36, 256)       0         
_________________________________________________________________
drop_3 (Dropout)             (None, 36, 36, 256)       0         
_________________________________________________________________
conv_7 (Conv2D)              (None, 36, 36, 128)       32896     
_________________________________________________________________
norm_7 (BatchNormalization)  (None, 36, 36, 128)       512       
_________________________________________________________________
relu_7 (LeakyReLU)           (None, 36, 36, 128)       0         
_________________________________________________________________
drop_4 (Dropout)             (None, 36, 36, 128)       0         
_________________________________________________________________
conv_8 (Conv2D)              (None, 36, 36, 256)       295168    
_________________________________________________________________
norm_8 (BatchNormalization)  (None, 36, 36, 256)       1024      
_________________________________________________________________
relu_8 (LeakyReLU)           (None, 36, 36, 256)       0         
_________________________________________________________________
pool_4 (MaxPooling2D)        (None, 18, 18, 256)       0         
_________________________________________________________________
conv_9 (Conv2D)              (None, 18, 18, 512)       1180160   
_________________________________________________________________
norm_9 (BatchNormalization)  (None, 18, 18, 512)       2048      
_________________________________________________________________
relu_9 (LeakyReLU)           (None, 18, 18, 512)       0         
_________________________________________________________________
drop_5 (Dropout)             (None, 18, 18, 512)       0         
_________________________________________________________________
conv_10 (Conv2D)             (None, 18, 18, 256)       131328    
_________________________________________________________________
norm_10 (BatchNormalization) (None, 18, 18, 256)       1024      
_________________________________________________________________
relu_10 (LeakyReLU)          (None, 18, 18, 256)       0         
_________________________________________________________________
drop_6 (Dropout)             (None, 18, 18, 256)       0         
_________________________________________________________________
conv_11 (Conv2D)             (None, 18, 18, 512)       1180160   
_________________________________________________________________
norm_11 (BatchNormalization) (None, 18, 18, 512)       2048      
_________________________________________________________________
relu_11 (LeakyReLU)          (None, 18, 18, 512)       0         
_________________________________________________________________
drop_7 (Dropout)             (None, 18, 18, 512)       0         
_________________________________________________________________
conv_12 (Conv2D)             (None, 18, 18, 256)       131328    
_________________________________________________________________
norm_12 (BatchNormalization) (None, 18, 18, 256)       1024      
_________________________________________________________________
relu_12 (LeakyReLU)          (None, 18, 18, 256)       0         
_________________________________________________________________
drop_8 (Dropout)             (None, 18, 18, 256)       0         
_________________________________________________________________
conv_13 (Conv2D)             (None, 18, 18, 512)       1180160   
_________________________________________________________________
norm_13 (BatchNormalization) (None, 18, 18, 512)       2048      
_________________________________________________________________
relu_13 (LeakyReLU)          (None, 18, 18, 512)       0         
_________________________________________________________________
pool_5 (MaxPooling2D)        (None, 9, 9, 512)         0         
_________________________________________________________________
conv_14 (Conv2D)             (None, 9, 9, 1024)        4719616   
_________________________________________________________________
norm_14 (BatchNormalization) (None, 9, 9, 1024)        4096      
_________________________________________________________________
relu_14 (LeakyReLU)          (None, 9, 9, 1024)        0         
_________________________________________________________________
drop_9 (Dropout)             (None, 9, 9, 1024)        0         
_________________________________________________________________
conv_15 (Conv2D)             (None, 9, 9, 1024)        9438208   
_________________________________________________________________
norm_15 (BatchNormalization) (None, 9, 9, 1024)        4096      
_________________________________________________________________
relu_15 (LeakyReLU)          (None, 9, 9, 1024)        0         
_________________________________________________________________
drop_10 (Dropout)            (None, 9, 9, 1024)        0         
_________________________________________________________________
conv_16 (Conv2D)             (None, 9, 9, 5)           5125      
_________________________________________________________________
reshape_1 (Reshape)          (None, 9, 9, 5)           0         
=================================================================
Total params: 18,784,709
Trainable params: 18,774,405
Non-trainable params: 10,304
_________________________________________________________________
+----------+---------------------+----------------+---------------+--------------------+---------------------+---------------+
|  Epoch   |       f1_score      |      iou       |      loss     |     precision      |        recall       |    val_loss   |
+----------+---------------------+----------------+---------------+--------------------+---------------------+---------------+
| Epoch 1  |         nan         |      nan       | 31.5429352174 |        nan         |         0.0         |  92.497399484 |
| Epoch 2  |         nan         |      nan       | 17.1204196232 |        0.0         |         0.0         | 18.6312721622 |
| Epoch 3  | 0.42410714285714285 | 0.670628772018 | 14.9946903622 | 0.6012658227848101 |  0.3275862068965517 |  11.819322986 |
| Epoch 4  | 0.42953020134228187 | 0.670961376366 | 13.7474244489 | 0.6114649681528662 |  0.3310344827586207 | 10.9959844466 |
| Epoch 5  |  0.4950099800399201 | 0.65434349299  | 12.5734576603 | 0.5876777251184834 | 0.42758620689655175 |  8.9315423504 |
| Epoch 6  |  0.4218009478672986 | 0.673774466777 | 11.7868410741 | 0.6742424242424242 | 0.30689655172413793 | 11.5082990277 |
| Epoch 7  |  0.6191446028513238 | 0.669665834931 | 11.1715162725 | 0.7562189054726368 |  0.5241379310344828 | 8.91807293123 |
| Epoch 8  |  0.6305220883534137 | 0.679114879586 |  10.532497689 | 0.7548076923076923 |  0.5413793103448276 | 9.23281191241 |
| Epoch 9  |  0.634453781512605  | 0.687912743706 | 9.99650770995 | 0.8118279569892473 |  0.5206896551724138 | 8.90919040865 |
| Epoch 10 |  0.5702306079664571 | 0.681285676597 | 9.57910597173 | 0.7272727272727273 |  0.4689655172413793 | 9.81741722168 |
| Epoch 11 |  0.5188679245283019 | 0.684980167331 | 9.04863969411 | 0.8208955223880597 |  0.3793103448275862 | 11.0574952864 |
| Epoch 12 |  0.6495049504950494 | 0.69828734707  | 8.76350747058 | 0.7627906976744186 |  0.5655172413793104 | 8.24670174814 |
| Epoch 13 |  0.6586345381526104 | 0.68003881054  | 8.49749843891 | 0.7884615384615384 |  0.5655172413793104 | 8.62784010364 |
| Epoch 14 |  0.6639344262295082 | 0.690355243281 |  8.2478377281 | 0.8181818181818182 |  0.5586206896551724 | 8.43743777275 |
| Epoch 15 |  0.6537634408602151 | 0.694305178982 | 7.90766450337 | 0.8685714285714285 |  0.5241379310344828 | 9.22506899987 |
| Epoch 16 |  0.6779661016949152 | 0.698985578267 | 7.74414244045 | 0.8791208791208791 |  0.5517241379310345 |  8.8441438598 |
| Epoch 17 |  0.6639175257731958 | 0.697720553412 | 7.62860162159 | 0.8256410256410256 |  0.5551724137931034 | 8.73785560362 |
| Epoch 18 |  0.7137096774193548 | 0.702106837749 | 7.34801905617 | 0.8592233009708737 |  0.6103448275862069 | 8.02696197264 |
| Epoch 19 |  0.6653225806451613 | 0.692321666871 | 7.12614854493 | 0.8009708737864077 |  0.5689655172413793 | 8.45522749809 |
| Epoch 20 |  0.7161904761904762 | 0.690478148604 | 7.00519661246 |        0.8         |  0.6482758620689655 | 8.07759231137 |
| Epoch 21 |  0.6762295081967213 | 0.690277367325 | 6.92139461538 | 0.8333333333333334 |  0.5689655172413793 | 8.73592221352 |
| Epoch 22 |  0.670756646216769  | 0.703286176153 | 6.75992110092 | 0.8241206030150754 |  0.5655172413793104 | 8.32670085661 |
| Epoch 23 |        0.688        | 0.701482618802 | 6.71915524588 | 0.819047619047619  |  0.593103448275862  |  8.1464513348 |
| Epoch 24 |  0.661122661122661  | 0.703303822087 | 6.53199131612 | 0.8324607329842932 |  0.5482758620689655 | 8.84207216386 |
| Epoch 25 |  0.6652631578947368 | 0.704001101809 | 6.45473413516 | 0.8540540540540541 |  0.5448275862068965 | 9.19740313868 |
| Epoch 26 |  0.7222222222222223 | 0.698948826868 | 6.33663606482 |        0.78        |  0.6724137931034483 | 7.44936235489 |
| Epoch 27 |  0.6844262295081968 | 0.705518442219 |  6.2560041501 | 0.8434343434343434 |  0.5758620689655173 | 8.38918890492 |
| Epoch 28 |  0.6540084388185654 | 0.708091659461 | 6.22132070812 | 0.842391304347826  |  0.5344827586206896 | 9.06832716542 |
| Epoch 29 |         0.72        | 0.702385565963 | 6.02417121292 | 0.8042553191489362 |  0.6517241379310345 | 7.74003287285 |
| Epoch 30 |  0.6902286902286903 | 0.703662533981 | 6.01488600075 | 0.8691099476439791 |  0.5724137931034483 | 8.41792815731 |
+----------+---------------------+----------------+---------------+--------------------+---------------------+---------------+
_________________________________________________________________
+------------------------------------+-----------------------+---------+-----------------------+--------------------+
|             Optimizer              |         decay         | epsilon |           lr          |        rho         |
+------------------------------------+-----------------------+---------+-----------------------+--------------------+
| <class 'keras.optimizers.RMSprop'> | 0.0005000000237487257 |  1e-08  | 0.0010000000474974513 | 0.8999999761581421 |
+------------------------------------+-----------------------+---------+-----------------------+--------------------+
_________________________________________________________________
+------------+
| Batch Size |
+------------+
|     16     |
+------------+
_________________________________________________________________
+--------------------+---------------+----------------+--------------------+--------------------+--------------------+
|      Metrics       |      Loss     |      IoU       |     Precision      |       Recall       |      F1 Score      |
+--------------------+---------------+----------------+--------------------+--------------------+--------------------+
|   Train Metrics    | 16.8060850389 | 0.801903388408 |       0.948        | 0.6594483426082749 | 0.7778253424657534 |
| Validation Metrics | 16.8342440821 | 0.703662533981 | 0.8691099476439791 | 0.5724137931034483 | 0.6902286902286903 |
|    Test Metrics    | 21.0747121995 | 0.686107846137 | 0.8586387434554974 | 0.5307443365695793 |       0.656        |
+--------------------+---------------+----------------+--------------------+--------------------+--------------------+
_________________________________________________________________
Time:
    Train Time              : 3:04:30.935896
    Dataset Loading Time    : 0:00:39.184989
    Metrics Evaluation Time : 0:06:14.704982
_________________________________________________________________
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         (None, 288, 288, 1)       0         
_________________________________________________________________
conv_1 (Conv2D)              (None, 288, 288, 32)      320       
_________________________________________________________________
norm_1 (BatchNormalization)  (None, 288, 288, 32)      128       
_________________________________________________________________
relu_1 (LeakyReLU)           (None, 288, 288, 32)      0         
_________________________________________________________________
pool_1 (MaxPooling2D)        (None, 144, 144, 32)      0         
_________________________________________________________________
conv_2 (Conv2D)              (None, 144, 144, 64)      18496     
_________________________________________________________________
norm_2 (BatchNormalization)  (None, 144, 144, 64)      256       
_________________________________________________________________
relu_2 (LeakyReLU)           (None, 144, 144, 64)      0         
_________________________________________________________________
pool_2 (MaxPooling2D)        (None, 72, 72, 64)        0         
_________________________________________________________________
conv_3 (Conv2D)              (None, 72, 72, 128)       73856     
_________________________________________________________________
norm_3 (BatchNormalization)  (None, 72, 72, 128)       512       
_________________________________________________________________
relu_3 (LeakyReLU)           (None, 72, 72, 128)       0         
_________________________________________________________________
drop_1 (Dropout)             (None, 72, 72, 128)       0         
_________________________________________________________________
conv_4 (Conv2D)              (None, 72, 72, 64)        8256      
_________________________________________________________________
norm_4 (BatchNormalization)  (None, 72, 72, 64)        256       
_________________________________________________________________
relu_4 (LeakyReLU)           (None, 72, 72, 64)        0         
_________________________________________________________________
drop_2 (Dropout)             (None, 72, 72, 64)        0         
_________________________________________________________________
conv_5 (Conv2D)              (None, 72, 72, 128)       73856     
_________________________________________________________________
norm_5 (BatchNormalization)  (None, 72, 72, 128)       512       
_________________________________________________________________
relu_5 (LeakyReLU)           (None, 72, 72, 128)       0         
_________________________________________________________________
pool_3 (MaxPooling2D)        (None, 36, 36, 128)       0         
_________________________________________________________________
conv_6 (Conv2D)              (None, 36, 36, 256)       295168    
_________________________________________________________________
norm_6 (BatchNormalization)  (None, 36, 36, 256)       1024      
_________________________________________________________________
relu_6 (LeakyReLU)           (None, 36, 36, 256)       0         
_________________________________________________________________
drop_3 (Dropout)             (None, 36, 36, 256)       0         
_________________________________________________________________
conv_7 (Conv2D)              (None, 36, 36, 128)       32896     
_________________________________________________________________
norm_7 (BatchNormalization)  (None, 36, 36, 128)       512       
_________________________________________________________________
relu_7 (LeakyReLU)           (None, 36, 36, 128)       0         
_________________________________________________________________
drop_4 (Dropout)             (None, 36, 36, 128)       0         
_________________________________________________________________
conv_8 (Conv2D)              (None, 36, 36, 256)       295168    
_________________________________________________________________
norm_8 (BatchNormalization)  (None, 36, 36, 256)       1024      
_________________________________________________________________
relu_8 (LeakyReLU)           (None, 36, 36, 256)       0         
_________________________________________________________________
pool_4 (MaxPooling2D)        (None, 18, 18, 256)       0         
_________________________________________________________________
conv_9 (Conv2D)              (None, 18, 18, 512)       1180160   
_________________________________________________________________
norm_9 (BatchNormalization)  (None, 18, 18, 512)       2048      
_________________________________________________________________
relu_9 (LeakyReLU)           (None, 18, 18, 512)       0         
_________________________________________________________________
drop_5 (Dropout)             (None, 18, 18, 512)       0         
_________________________________________________________________
conv_10 (Conv2D)             (None, 18, 18, 256)       131328    
_________________________________________________________________
norm_10 (BatchNormalization) (None, 18, 18, 256)       1024      
_________________________________________________________________
relu_10 (LeakyReLU)          (None, 18, 18, 256)       0         
_________________________________________________________________
drop_6 (Dropout)             (None, 18, 18, 256)       0         
_________________________________________________________________
conv_11 (Conv2D)             (None, 18, 18, 512)       1180160   
_________________________________________________________________
norm_11 (BatchNormalization) (None, 18, 18, 512)       2048      
_________________________________________________________________
relu_11 (LeakyReLU)          (None, 18, 18, 512)       0         
_________________________________________________________________
drop_7 (Dropout)             (None, 18, 18, 512)       0         
_________________________________________________________________
conv_12 (Conv2D)             (None, 18, 18, 256)       131328    
_________________________________________________________________
norm_12 (BatchNormalization) (None, 18, 18, 256)       1024      
_________________________________________________________________
relu_12 (LeakyReLU)          (None, 18, 18, 256)       0         
_________________________________________________________________
drop_8 (Dropout)             (None, 18, 18, 256)       0         
_________________________________________________________________
conv_13 (Conv2D)             (None, 18, 18, 512)       1180160   
_________________________________________________________________
norm_13 (BatchNormalization) (None, 18, 18, 512)       2048      
_________________________________________________________________
relu_13 (LeakyReLU)          (None, 18, 18, 512)       0         
_________________________________________________________________
pool_5 (MaxPooling2D)        (None, 9, 9, 512)         0         
_________________________________________________________________
conv_14 (Conv2D)             (None, 9, 9, 1024)        4719616   
_________________________________________________________________
norm_14 (BatchNormalization) (None, 9, 9, 1024)        4096      
_________________________________________________________________
relu_14 (LeakyReLU)          (None, 9, 9, 1024)        0         
_________________________________________________________________
drop_9 (Dropout)             (None, 9, 9, 1024)        0         
_________________________________________________________________
conv_15 (Conv2D)             (None, 9, 9, 1024)        9438208   
_________________________________________________________________
norm_15 (BatchNormalization) (None, 9, 9, 1024)        4096      
_________________________________________________________________
relu_15 (LeakyReLU)          (None, 9, 9, 1024)        0         
_________________________________________________________________
drop_10 (Dropout)            (None, 9, 9, 1024)        0         
_________________________________________________________________
conv_16 (Conv2D)             (None, 9, 9, 5)           5125      
_________________________________________________________________
reshape_1 (Reshape)          (None, 9, 9, 5)           0         
=================================================================
Total params: 18,784,709
Trainable params: 18,774,405
Non-trainable params: 10,304
_________________________________________________________________
+----------+-----------------------+----------------+---------------+--------------------+---------------------+---------------+
|  Epoch   |        f1_score       |      iou       |      loss     |     precision      |        recall       |    val_loss   |
+----------+-----------------------+----------------+---------------+--------------------+---------------------+---------------+
| Epoch 1  |          nan          |      nan       |  44.527880985 |        nan         |         0.0         | 147.230514771 |
| Epoch 2  |          nan          |      nan       | 33.6847526615 |        nan         |         0.0         |  44.078281044 |
| Epoch 3  |          nan          |      nan       | 32.3903483436 |        nan         |         0.0         | 43.3834667206 |
| Epoch 4  |          nan          |      nan       | 31.3845276869 |        nan         |         0.0         | 33.4121112595 |
| Epoch 5  |          nan          |      nan       | 30.5422713447 |        nan         |         0.0         | 32.8766372986 |
| Epoch 6  |          nan          |      nan       | 30.0616390811 |        nan         |         0.0         | 30.6655162735 |
| Epoch 7  |          nan          |      nan       | 29.4919371489 |        nan         |         0.0         | 30.2744428635 |
| Epoch 8  |          nan          |      nan       | 29.1307869326 |        nan         |         0.0         | 30.0424769211 |
| Epoch 9  |          nan          |      nan       | 28.7517311683 |        nan         |         0.0         |  32.029914711 |
| Epoch 10 | 0.0023391812865497076 | 0.837928996416 | 28.5120033705 |        1.0         | 0.00117096018735363 | 28.8363867798 |
| Epoch 11 |          nan          |      nan       | 28.2148371492 |        nan         |         0.0         | 33.5950680161 |
| Epoch 12 |  0.002336448598130841 | 0.80415093359  | 27.9979124496 |        0.5         | 0.00117096018735363 | 28.1862303314 |
| Epoch 13 | 0.0023391812865497076 | 0.781718173751 | 27.7061043746 |        1.0         | 0.00117096018735363 | 28.1919875336 |
| Epoch 14 |  0.004662004662004662 | 0.689106205115 | 27.6327440367 |        0.5         | 0.00234192037470726 | 28.0374999771 |
| Epoch 15 |          nan          |      nan       | 27.4119964199 |        0.0         |         0.0         | 28.8909987717 |
| Epoch 16 |  0.009313154831199068 | 0.691811802804 | 27.2856882493 |        0.8         | 0.00468384074941452 | 28.4351394958 |
| Epoch 17 |          nan          |      nan       | 31.9123863581 |        nan         |         0.0         | 39.0917020264 |
| Epoch 18 |          nan          |      nan       | 30.3384519153 |        nan         |         0.0         |  31.748203331 |
| Epoch 19 |  0.004672897196261682 | 0.846527269354 | 29.3702213812 |        1.0         | 0.00234192037470726 | 29.2315082779 |
| Epoch 20 |  0.004672897196261682 | 0.889055068208 | 28.8372971978 |        1.0         | 0.00234192037470726 | 29.2022465744 |
| Epoch 21 |          nan          |      nan       | 28.5004589383 |        nan         |         0.0         | 28.2981945801 |
| Epoch 22 | 0.0023391812865497076 | 0.748698441425 | 28.0676284265 |        1.0         | 0.00117096018735363 | 31.1315508728 |
| Epoch 23 |  0.027554535017221583 | 0.708207711057 | 27.6543636713 | 0.7058823529411765 | 0.01405152224824356 | 30.5167318115 |
| Epoch 24 |  0.020809248554913295 | 0.729199211118 | 27.3296762783 | 0.8181818181818182 | 0.01053864168618267 | 27.9871031799 |
| Epoch 25 |  0.020761245674740483 | 0.657273128195 | 27.1375246802 | 0.6923076923076923 | 0.01053864168618267 | 28.6243979492 |
| Epoch 26 |  0.045300113250283124 | 0.689938304154 | 26.9003868441 | 0.6896551724137931 |  0.0234192037470726 |  27.673833931 |
| Epoch 27 |  0.07158836689038031  | 0.731159087249 | 26.5947410886 |        0.8         | 0.03747072599531616 | 26.6084521408 |
| Epoch 28 |  0.10663764961915126  | 0.705206320232 | 26.4217799148 | 0.7538461538461538 | 0.05737704918032787 |  26.01606884  |
| Epoch 29 |  0.06430155210643017  | 0.70930455665  |  26.135664234 | 0.6041666666666666 | 0.03395784543325527 | 28.8604174042 |
| Epoch 30 |   0.0955483170466884  | 0.727869971391 | 25.9056751105 | 0.6567164179104478 | 0.05152224824355972 | 27.6538045044 |
| Epoch 31 |  0.07938257993384784  | 0.691463668299 | 25.7579978068 | 0.6792452830188679 | 0.04215456674473068 | 25.9274036903 |
| Epoch 32 |  0.08590308370044053  | 0.733684704807 | 25.6135628786 | 0.7222222222222222 | 0.04566744730679157 | 26.7334935913 |
| Epoch 33 |   0.079484425349087   | 0.698615700419 | 25.4638472968 | 0.4805194805194805 | 0.04332552693208431 | 26.1114219093 |
| Epoch 34 |  0.10764262648008613  | 0.710188967524 | 25.1499197527 | 0.6666666666666666 |  0.0585480093676815 |  26.148262825 |
| Epoch 35 |  0.10832497492477432  | 0.652300653946 | 25.0620216673 | 0.3776223776223776 | 0.06323185011709602 | 27.3674643784 |
| Epoch 36 |  0.062360801781737196 | 0.758132439559 | 24.9567394721 | 0.6363636363636364 | 0.03278688524590164 | 27.5528887558 |
| Epoch 37 |  0.18947368421052632  | 0.706321859744 | 24.1181490088 | 0.518324607329843  | 0.11592505854800937 | 25.0408086472 |
| Epoch 38 |  0.21951219512195122  | 0.690140002062 | 23.8746479225 | 0.5518867924528302 | 0.13700234192037472 | 24.9366127663 |
| Epoch 39 |  0.22514071294559096  | 0.69255115788  | 23.7094595769 | 0.5660377358490566 |  0.1405152224824356 | 24.9666808853 |
| Epoch 40 |  0.24080882352941174  | 0.691322362285 | 23.6485662291 | 0.5598290598290598 | 0.15339578454332553 | 24.9555368004 |
| Epoch 41 |  0.20134228187919465  | 0.705845750671 | 23.6726877329 | 0.5555555555555556 | 0.12295081967213115 | 25.0915435524 |
| Epoch 42 |   0.2264840182648402  | 0.695145458526 | 23.5755889011 | 0.5145228215767634 |  0.1451990632318501 | 25.0039246368 |
| Epoch 43 |  0.21641791044776118  | 0.702422750586 | 23.5683037148 | 0.5321100917431193 |  0.1358313817330211 |  25.015622467 |
| Epoch 44 |  0.21771217712177118  | 0.698981858239 |  23.615364299 | 0.5130434782608696 | 0.13817330210772832 | 24.9550964584 |
| Epoch 45 |  0.23049001814882034  | 0.695919711385 | 23.5028589274 | 0.5120967741935484 |  0.148711943793911  | 24.9551647377 |
+----------+-----------------------+----------------+---------------+--------------------+---------------------+---------------+
_________________________________________________________________
+------------------------------------+-----------------------+---------+-----------------------+--------------------+
|             Optimizer              |         decay         | epsilon |           lr          |        rho         |
+------------------------------------+-----------------------+---------+-----------------------+--------------------+
| <class 'keras.optimizers.RMSprop'> | 0.0005000000237487257 |  1e-08  | 0.0010000000474974513 | 0.8999999761581421 |
+------------------------------------+-----------------------+---------+-----------------------+--------------------+
_________________________________________________________________
+------------+
| Batch Size |
+------------+
|     16     |
+------------+
_________________________________________________________________
+--------------------+---------------+----------------+--------------------+---------------------+---------------------+
|      Metrics       |      Loss     |      IoU       |     Precision      |        Recall       |       F1 Score      |
+--------------------+---------------+----------------+--------------------+---------------------+---------------------+
|   Train Metrics    | 43.7094283133 | 0.702857006583 | 0.641553480475382  | 0.20387105476126247 | 0.30941658137154554 |
| Validation Metrics | 49.4850637207 | 0.695919711385 | 0.5120967741935484 |  0.148711943793911  | 0.23049001814882034 |
|    Test Metrics    | 49.1346524963 |  0.7016585606  | 0.5277777777777778 |  0.1516533637400228 | 0.23560673162090345 |
+--------------------+---------------+----------------+--------------------+---------------------+---------------------+
_________________________________________________________________
Time:
    Train Time              : 10:12:43.357913
    Dataset Loading Time    : 0:04:36.119159
    Metrics Evaluation Time : 0:24:49.212729
_________________________________________________________________
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         (None, 288, 288, 1)       0         
_________________________________________________________________
conv_1 (Conv2D)              (None, 288, 288, 32)      320       
_________________________________________________________________
norm_1 (BatchNormalization)  (None, 288, 288, 32)      128       
_________________________________________________________________
relu_1 (LeakyReLU)           (None, 288, 288, 32)      0         
_________________________________________________________________
pool_1 (MaxPooling2D)        (None, 144, 144, 32)      0         
_________________________________________________________________
conv_2 (Conv2D)              (None, 144, 144, 64)      18496     
_________________________________________________________________
norm_2 (BatchNormalization)  (None, 144, 144, 64)      256       
_________________________________________________________________
relu_2 (LeakyReLU)           (None, 144, 144, 64)      0         
_________________________________________________________________
pool_2 (MaxPooling2D)        (None, 72, 72, 64)        0         
_________________________________________________________________
conv_3 (Conv2D)              (None, 72, 72, 128)       73856     
_________________________________________________________________
norm_3 (BatchNormalization)  (None, 72, 72, 128)       512       
_________________________________________________________________
relu_3 (LeakyReLU)           (None, 72, 72, 128)       0         
_________________________________________________________________
drop_1 (Dropout)             (None, 72, 72, 128)       0         
_________________________________________________________________
conv_4 (Conv2D)              (None, 72, 72, 64)        8256      
_________________________________________________________________
norm_4 (BatchNormalization)  (None, 72, 72, 64)        256       
_________________________________________________________________
relu_4 (LeakyReLU)           (None, 72, 72, 64)        0         
_________________________________________________________________
drop_2 (Dropout)             (None, 72, 72, 64)        0         
_________________________________________________________________
conv_5 (Conv2D)              (None, 72, 72, 128)       73856     
_________________________________________________________________
norm_5 (BatchNormalization)  (None, 72, 72, 128)       512       
_________________________________________________________________
relu_5 (LeakyReLU)           (None, 72, 72, 128)       0         
_________________________________________________________________
pool_3 (MaxPooling2D)        (None, 36, 36, 128)       0         
_________________________________________________________________
conv_6 (Conv2D)              (None, 36, 36, 256)       295168    
_________________________________________________________________
norm_6 (BatchNormalization)  (None, 36, 36, 256)       1024      
_________________________________________________________________
relu_6 (LeakyReLU)           (None, 36, 36, 256)       0         
_________________________________________________________________
drop_3 (Dropout)             (None, 36, 36, 256)       0         
_________________________________________________________________
conv_7 (Conv2D)              (None, 36, 36, 128)       32896     
_________________________________________________________________
norm_7 (BatchNormalization)  (None, 36, 36, 128)       512       
_________________________________________________________________
relu_7 (LeakyReLU)           (None, 36, 36, 128)       0         
_________________________________________________________________
drop_4 (Dropout)             (None, 36, 36, 128)       0         
_________________________________________________________________
conv_8 (Conv2D)              (None, 36, 36, 256)       295168    
_________________________________________________________________
norm_8 (BatchNormalization)  (None, 36, 36, 256)       1024      
_________________________________________________________________
relu_8 (LeakyReLU)           (None, 36, 36, 256)       0         
_________________________________________________________________
pool_4 (MaxPooling2D)        (None, 18, 18, 256)       0         
_________________________________________________________________
conv_9 (Conv2D)              (None, 18, 18, 512)       1180160   
_________________________________________________________________
norm_9 (BatchNormalization)  (None, 18, 18, 512)       2048      
_________________________________________________________________
relu_9 (LeakyReLU)           (None, 18, 18, 512)       0         
_________________________________________________________________
drop_5 (Dropout)             (None, 18, 18, 512)       0         
_________________________________________________________________
conv_10 (Conv2D)             (None, 18, 18, 256)       131328    
_________________________________________________________________
norm_10 (BatchNormalization) (None, 18, 18, 256)       1024      
_________________________________________________________________
relu_10 (LeakyReLU)          (None, 18, 18, 256)       0         
_________________________________________________________________
drop_6 (Dropout)             (None, 18, 18, 256)       0         
_________________________________________________________________
conv_11 (Conv2D)             (None, 18, 18, 512)       1180160   
_________________________________________________________________
norm_11 (BatchNormalization) (None, 18, 18, 512)       2048      
_________________________________________________________________
relu_11 (LeakyReLU)          (None, 18, 18, 512)       0         
_________________________________________________________________
drop_7 (Dropout)             (None, 18, 18, 512)       0         
_________________________________________________________________
conv_12 (Conv2D)             (None, 18, 18, 256)       131328    
_________________________________________________________________
norm_12 (BatchNormalization) (None, 18, 18, 256)       1024      
_________________________________________________________________
relu_12 (LeakyReLU)          (None, 18, 18, 256)       0         
_________________________________________________________________
drop_8 (Dropout)             (None, 18, 18, 256)       0         
_________________________________________________________________
conv_13 (Conv2D)             (None, 18, 18, 512)       1180160   
_________________________________________________________________
norm_13 (BatchNormalization) (None, 18, 18, 512)       2048      
_________________________________________________________________
relu_13 (LeakyReLU)          (None, 18, 18, 512)       0         
_________________________________________________________________
pool_5 (MaxPooling2D)        (None, 9, 9, 512)         0         
_________________________________________________________________
conv_14 (Conv2D)             (None, 9, 9, 1024)        4719616   
_________________________________________________________________
norm_14 (BatchNormalization) (None, 9, 9, 1024)        4096      
_________________________________________________________________
relu_14 (LeakyReLU)          (None, 9, 9, 1024)        0         
_________________________________________________________________
drop_9 (Dropout)             (None, 9, 9, 1024)        0         
_________________________________________________________________
conv_15 (Conv2D)             (None, 9, 9, 1024)        9438208   
_________________________________________________________________
norm_15 (BatchNormalization) (None, 9, 9, 1024)        4096      
_________________________________________________________________
relu_15 (LeakyReLU)          (None, 9, 9, 1024)        0         
_________________________________________________________________
drop_10 (Dropout)            (None, 9, 9, 1024)        0         
_________________________________________________________________
conv_16 (Conv2D)             (None, 9, 9, 5)           5125      
_________________________________________________________________
reshape_1 (Reshape)          (None, 9, 9, 5)           0         
=================================================================
Total params: 18,784,709
Trainable params: 18,774,405
Non-trainable params: 10,304
_________________________________________________________________
+----------+----------------------+----------------+---------------+----------------------+-----------------------+---------------+
|  Epoch   |       f1_score       |      iou       |      loss     |      precision       |         recall        |    val_loss   |
+----------+----------------------+----------------+---------------+----------------------+-----------------------+---------------+
| Epoch 1  |         nan          |      nan       | 39.1548352286 |         nan          |          0.0          | 129.990217811 |
| Epoch 2  |         nan          |      nan       | 28.9472202298 |         nan          |          0.0          | 137.717888817 |
| Epoch 3  |         nan          |      nan       | 27.4258037891 |         0.0          |          0.0          | 121.143983974 |
| Epoch 4  |         nan          |      nan       | 26.3488008166 |         0.0          |          0.0          | 105.627737361 |
| Epoch 5  |         nan          |      nan       | 25.4738530214 |         0.0          |          0.0          |  85.208405561 |
| Epoch 6  |         nan          |      nan       | 24.6997857238 |         0.0          |          0.0          | 67.3296198309 |
| Epoch 7  |         nan          |      nan       |  24.158884854 |         0.0          |          0.0          | 83.8733252051 |
| Epoch 8  |         nan          |      nan       | 23.5799510219 |         nan          |          0.0          | 79.0099156834 |
| Epoch 9  |         nan          |      nan       | 23.0518473489 |         0.0          |          0.0          | 52.8685169526 |
| Epoch 10 |         nan          |      nan       | 22.6516788215 |         0.0          |          0.0          | 72.3383372098 |
| Epoch 11 |         nan          |      nan       | 22.1998603422 |         0.0          |          0.0          | 61.6360394687 |
| Epoch 12 |         nan          |      nan       | 21.8513609339 |         0.0          |          0.0          | 62.1304745802 |
| Epoch 13 | 0.003182179793158313 | 0.58856020579  | 21.5785391006 | 0.017699115044247787 | 0.0017482517482517483 | 54.6775297685 |
| Epoch 14 | 0.01082753286929621  | 0.543869719519 | 21.3890282116 | 0.04697986577181208  |  0.006118881118881119 | 46.4403909285 |
| Epoch 15 | 0.002926115581565472 | 0.512665166631 | 21.0565636443 | 0.008968609865470852 | 0.0017482517482517483 |  48.717859564 |
| Epoch 16 |         nan          |      nan       | 20.8319144336 |         0.0          |          0.0          | 56.1714489779 |
| Epoch 17 | 0.01550387596899225  | 0.568168806713 | 20.5986142589 |         0.04         |  0.009615384615384616 | 46.2648565935 |
| Epoch 18 | 0.04032766225582861  | 0.585869990327 | 20.4648339402 | 0.07223476297968397  |  0.027972027972027972 | 40.8390194286 |
| Epoch 19 | 0.03674911660777385  | 0.575198523203 | 20.2303467247 |  0.0959409594095941  |  0.022727272727272728 | 43.1629658051 |
| Epoch 20 | 0.02702702702702703  | 0.573351080382 | 20.0048085333 | 0.05121951219512195  |  0.018356643356643356 | 43.1521338193 |
| Epoch 21 | 0.044661549197487785 | 0.605280519815 | 19.8411196099 | 0.11072664359861592  |  0.027972027972027972 | 38.2437712215 |
| Epoch 22 |  0.0580511402902557  | 0.599088570733 |  19.685433844 | 0.13861386138613863  |  0.03671328671328671  | 37.6636072455 |
| Epoch 23 | 0.04087193460490463  | 0.58075461428  | 19.5220004441 | 0.09259259259259259  |  0.026223776223776224 | 39.5311886487 |
| Epoch 24 |  0.0574300071787509  | 0.592844593566 | 19.3999898045 |  0.1606425702811245  |  0.03496503496503497  | 38.1405920447 |
| Epoch 25 | 0.08895478131949593  | 0.635442461357 | 19.2147211401 |  0.2926829268292683  |  0.05244755244755245  | 35.9097549112 |
| Epoch 26 | 0.09510290986515259  | 0.612922748892 | 19.1271453626 |  0.2528301886792453  |  0.05856643356643357  |  35.306588943 |
| Epoch 27 | 0.07659574468085106  | 0.624122807597 |  19.026634263 | 0.20300751879699247  |   0.0472027972027972  | 37.2640181047 |
| Epoch 28 | 0.015058179329226557 | 0.562714308285 | 18.9285491411 | 0.03470031545741325  |  0.009615384615384616 | 42.9749088185 |
| Epoch 29 | 0.05890603085553996  | 0.611525452917 | 18.7845895726 | 0.14893617021276595  |  0.03671328671328671  | 36.8331024252 |
| Epoch 30 | 0.10160055671537928  | 0.620594405902 | 18.6844871216 | 0.24914675767918087  |  0.06381118881118882  | 35.5308571168 |
+----------+----------------------+----------------+---------------+----------------------+-----------------------+---------------+
_________________________________________________________________
+---------------------------------+--------------------+--------------------+-----------------------+---------+-----------------------+
|            Optimizer            |       beta_1       |       beta_2       |         decay         | epsilon |           lr          |
+---------------------------------+--------------------+--------------------+-----------------------+---------+-----------------------+
| <class 'keras.optimizers.Adam'> | 0.8999999761581421 | 0.9990000128746033 | 0.0005000000237487257 |  1e-08  | 0.0010000000474974513 |
+---------------------------------+--------------------+--------------------+-----------------------+---------+-----------------------+
_________________________________________________________________
+------------+
| Batch Size |
+------------+
|     16     |
+------------+
_________________________________________________________________
+--------------------+---------------+----------------+---------------------+---------------------+---------------------+
|      Metrics       |      Loss     |      IoU       |      Precision      |        Recall       |       F1 Score      |
+--------------------+---------------+----------------+---------------------+---------------------+---------------------+
|   Train Metrics    |  72.690990168 | 0.62377095807  |  0.3460874568469505 | 0.10418290465055859 | 0.16015442987419293 |
| Validation Metrics | 70.7442456516 | 0.620594405902 | 0.24914675767918087 | 0.06381118881118882 | 0.10160055671537928 |
|    Test Metrics    | 73.6438472156 | 0.60703522848  |  0.2280130293159609 | 0.05902192242833052 | 0.09377093101138646 |
+--------------------+---------------+----------------+---------------------+---------------------+---------------------+
_________________________________________________________________
Time:
    Train Time              : 14:36:30.544440
    Dataset Loading Time    : 0:37:40.133613
    Metrics Evaluation Time : 0:43:28.021125
_________________________________________________________________
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         (None, 288, 288, 1)       0         
_________________________________________________________________
conv_1 (Conv2D)              (None, 288, 288, 32)      320       
_________________________________________________________________
norm_1 (BatchNormalization)  (None, 288, 288, 32)      128       
_________________________________________________________________
relu_1 (LeakyReLU)           (None, 288, 288, 32)      0         
_________________________________________________________________
pool_1 (MaxPooling2D)        (None, 144, 144, 32)      0         
_________________________________________________________________
conv_2 (Conv2D)              (None, 144, 144, 64)      18496     
_________________________________________________________________
norm_2 (BatchNormalization)  (None, 144, 144, 64)      256       
_________________________________________________________________
relu_2 (LeakyReLU)           (None, 144, 144, 64)      0         
_________________________________________________________________
pool_2 (MaxPooling2D)        (None, 72, 72, 64)        0         
_________________________________________________________________
conv_3 (Conv2D)              (None, 72, 72, 128)       73856     
_________________________________________________________________
norm_3 (BatchNormalization)  (None, 72, 72, 128)       512       
_________________________________________________________________
relu_3 (LeakyReLU)           (None, 72, 72, 128)       0         
_________________________________________________________________
conv_4 (Conv2D)              (None, 72, 72, 64)        8256      
_________________________________________________________________
norm_4 (BatchNormalization)  (None, 72, 72, 64)        256       
_________________________________________________________________
relu_4 (LeakyReLU)           (None, 72, 72, 64)        0         
_________________________________________________________________
conv_5 (Conv2D)              (None, 72, 72, 128)       73856     
_________________________________________________________________
norm_5 (BatchNormalization)  (None, 72, 72, 128)       512       
_________________________________________________________________
relu_5 (LeakyReLU)           (None, 72, 72, 128)       0         
_________________________________________________________________
pool_3 (MaxPooling2D)        (None, 36, 36, 128)       0         
_________________________________________________________________
conv_6 (Conv2D)              (None, 36, 36, 256)       295168    
_________________________________________________________________
norm_6 (BatchNormalization)  (None, 36, 36, 256)       1024      
_________________________________________________________________
relu_6 (LeakyReLU)           (None, 36, 36, 256)       0         
_________________________________________________________________
conv_7 (Conv2D)              (None, 36, 36, 128)       32896     
_________________________________________________________________
norm_7 (BatchNormalization)  (None, 36, 36, 128)       512       
_________________________________________________________________
relu_7 (LeakyReLU)           (None, 36, 36, 128)       0         
_________________________________________________________________
conv_8 (Conv2D)              (None, 36, 36, 256)       295168    
_________________________________________________________________
norm_8 (BatchNormalization)  (None, 36, 36, 256)       1024      
_________________________________________________________________
relu_8 (LeakyReLU)           (None, 36, 36, 256)       0         
_________________________________________________________________
pool_4 (MaxPooling2D)        (None, 18, 18, 256)       0         
_________________________________________________________________
conv_9 (Conv2D)              (None, 18, 18, 512)       1180160   
_________________________________________________________________
norm_9 (BatchNormalization)  (None, 18, 18, 512)       2048      
_________________________________________________________________
relu_9 (LeakyReLU)           (None, 18, 18, 512)       0         
_________________________________________________________________
conv_10 (Conv2D)             (None, 18, 18, 256)       131328    
_________________________________________________________________
norm_10 (BatchNormalization) (None, 18, 18, 256)       1024      
_________________________________________________________________
relu_10 (LeakyReLU)          (None, 18, 18, 256)       0         
_________________________________________________________________
conv_11 (Conv2D)             (None, 18, 18, 512)       1180160   
_________________________________________________________________
norm_11 (BatchNormalization) (None, 18, 18, 512)       2048      
_________________________________________________________________
relu_11 (LeakyReLU)          (None, 18, 18, 512)       0         
_________________________________________________________________
conv_12 (Conv2D)             (None, 18, 18, 256)       131328    
_________________________________________________________________
norm_12 (BatchNormalization) (None, 18, 18, 256)       1024      
_________________________________________________________________
relu_12 (LeakyReLU)          (None, 18, 18, 256)       0         
_________________________________________________________________
conv_13 (Conv2D)             (None, 18, 18, 512)       1180160   
_________________________________________________________________
norm_13 (BatchNormalization) (None, 18, 18, 512)       2048      
_________________________________________________________________
relu_13 (LeakyReLU)          (None, 18, 18, 512)       0         
_________________________________________________________________
pool_5 (MaxPooling2D)        (None, 9, 9, 512)         0         
_________________________________________________________________
conv_14 (Conv2D)             (None, 9, 9, 1024)        4719616   
_________________________________________________________________
norm_14 (BatchNormalization) (None, 9, 9, 1024)        4096      
_________________________________________________________________
relu_14 (LeakyReLU)          (None, 9, 9, 1024)        0         
_________________________________________________________________
drop_1 (Dropout)             (None, 9, 9, 1024)        0         
_________________________________________________________________
conv_15 (Conv2D)             (None, 9, 9, 1024)        9438208   
_________________________________________________________________
norm_15 (BatchNormalization) (None, 9, 9, 1024)        4096      
_________________________________________________________________
relu_15 (LeakyReLU)          (None, 9, 9, 1024)        0         
_________________________________________________________________
drop_2 (Dropout)             (None, 9, 9, 1024)        0         
_________________________________________________________________
conv_16 (Conv2D)             (None, 9, 9, 5)           5125      
_________________________________________________________________
reshape_1 (Reshape)          (None, 9, 9, 5)           0         
=================================================================
Total params: 18,784,709
Trainable params: 18,774,405
Non-trainable params: 10,304
_________________________________________________________________
+----------+---------------------+----------------+---------------+---------------------+---------------------+---------------+
|  Epoch   |       f1_score      |      iou       |      loss     |      precision      |        recall       |    val_loss   |
+----------+---------------------+----------------+---------------+---------------------+---------------------+---------------+
| Epoch 1  | 0.11223694466095091 | 0.63151472665  | 54.3083020181 |  0.5179856115107914 | 0.06293706293706294 | 32.7910812704 |
| Epoch 2  | 0.22408963585434175 | 0.65822319264  | 35.7752115858 |  0.5633802816901409 | 0.13986013986013987 | 29.5059361483 |
| Epoch 3  |  0.2201215395003376 | 0.649732421897 | 31.3233611367 |  0.4836795252225519 | 0.14248251748251747 | 28.0779252282 |
| Epoch 4  |  0.2660098522167488 | 0.694173074484 | 28.0148569751 |  0.6823104693140795 |  0.1652097902097902 | 24.8640157832 |
| Epoch 5  | 0.17424826522744796 | 0.697581253621 | 26.6557177469 |  0.738562091503268  | 0.09877622377622378 | 25.1625415119 |
| Epoch 6  |  0.2684469430780042 | 0.689366115271 |  25.711701163 |  0.6845878136200717 | 0.16695804195804195 | 23.9865189925 |
| Epoch 7  |  0.1892103205629398 | 0.703457163279 | 24.6855101584 |  0.8962962962962963 | 0.10576923076923077 | 25.0787628806 |
| Epoch 8  | 0.29525718102872406 | 0.692907392305 | 23.8002389043 |  0.6260623229461756 | 0.19318181818181818 | 24.5895889048 |
| Epoch 9  | 0.27247191011235955 | 0.719174677317 | 22.8877249236 |  0.6928571428571428 | 0.16958041958041958 | 23.7709688044 |
| Epoch 10 |  0.2730978260869565 | 0.691701381829 | 22.0367498917 |  0.6128048780487805 |  0.1756993006993007 | 24.0269622803 |
| Epoch 11 |  0.2842035690680767 | 0.691837880808 | 21.1066920385 |  0.5826558265582655 | 0.18793706293706294 | 23.5397321987 |
| Epoch 12 | 0.31201044386422977 | 0.697414312464 | 20.0965829143 |  0.615979381443299  |  0.2089160839160839 | 23.4161406175 |
| Epoch 13 |  0.3078817733990148 | 0.703118898757 | 18.9326619655 |  0.5208333333333334 | 0.21853146853146854 | 24.4588527628 |
| Epoch 14 |  0.2673726009265387 | 0.692047656438 | 17.6138015316 |  0.5504087193460491 | 0.17657342657342656 | 24.7285026917 |
| Epoch 15 |  0.288153681963714  | 0.705343649311 | 16.1747776023 |  0.3698630136986301 | 0.23601398601398602 | 25.8089871636 |
| Epoch 16 |  0.2847571189279732 | 0.687472080257 | 14.8792365806 |  0.3941267387944359 |  0.2229020979020979 |  26.152589594 |
| Epoch 17 |  0.3094170403587444 | 0.68033428388  | 13.6757364494 |       0.43125       | 0.24125874125874125 | 25.9220833549 |
| Epoch 18 |  0.2626970227670753 | 0.682375638228 | 12.5511324711 |  0.3954305799648506 | 0.19667832167832167 | 26.4712727287 |
| Epoch 19 |  0.2788006312467123 | 0.696951468904 |  11.53680528  | 0.35006605019815057 | 0.23164335664335664 | 26.8908033524 |
| Epoch 20 | 0.28455284552845533 | 0.665593323033 | 10.8329384811 | 0.42387543252595156 | 0.21416083916083917 | 26.4459883848 |
| Epoch 21 | 0.25773195876288657 | 0.686413021704 | 10.1307461061 | 0.37375415282392027 | 0.19667832167832167 | 27.1145814498 |
| Epoch 22 |  0.2852664576802507 | 0.685838072427 | 9.61302205284 | 0.35454545454545455 | 0.23863636363636365 | 27.1886126268 |
| Epoch 23 | 0.27043701799485864 | 0.690044391514 | 9.10246679581 |  0.3283395755305868 |  0.2298951048951049 |  27.256623416 |
| Epoch 24 |  0.2729836435420192 | 0.691865848265 | 8.72644137645 |  0.3847376788553259 | 0.21153846153846154 | 26.6807922832 |
| Epoch 25 |  0.2718446601941748 | 0.688192781973 | 8.35510673787 | 0.32718327183271834 | 0.23251748251748253 | 27.7654455409 |
| Epoch 26 | 0.20947075208913649 |  0.716630135   | 7.93577641032 |  0.2887864823348694 | 0.16433566433566432 | 28.3531749338 |
| Epoch 27 | 0.24539170506912442 | 0.694439259083 | 7.73989185393 |  0.3597972972972973 |  0.1861888111888112 | 27.4649116394 |
| Epoch 28 | 0.26044226044226043 | 0.688914718453 | 7.45270888151 | 0.29741863075196406 | 0.23164335664335664 | 28.1024437257 |
| Epoch 29 | 0.25258323765786456 | 0.708587893483 |  7.2300908394 | 0.36789297658862874 | 0.19230769230769232 | 27.0142658254 |
| Epoch 30 | 0.26583000570450654 | 0.67408590779  | 7.04779748041 |  0.3825944170771757 | 0.20367132867132867 | 27.3594450211 |
+----------+---------------------+----------------+---------------+---------------------+---------------------+---------------+
_________________________________________________________________
+---------------------------------+--------------------+--------------------+-----------------------+---------+-----------------------+
|            Optimizer            |       beta_1       |       beta_2       |         decay         | epsilon |           lr          |
+---------------------------------+--------------------+--------------------+-----------------------+---------+-----------------------+
| <class 'keras.optimizers.Adam'> | 0.8999999761581421 | 0.9990000128746033 | 4.999999873689376e-05 |  1e-08  | 9.999999747378752e-05 |
+---------------------------------+--------------------+--------------------+-----------------------+---------+-----------------------+
_________________________________________________________________
+------------+
| Batch Size |
+------------+
|     16     |
+------------+
_________________________________________________________________
+--------------------+---------------+----------------+---------------------+---------------------+---------------------+
|      Metrics       |      Loss     |      IoU       |      Precision      |        Recall       |       F1 Score      |
+--------------------+---------------+----------------+---------------------+---------------------+---------------------+
|   Train Metrics    | 13.0419485513 | 0.733111716341 |  0.7882275400527277 |  0.6732051615138132 |  0.7261899201270495 |
| Validation Metrics | 54.4803601535 | 0.67408590779  |  0.3825944170771757 | 0.20367132867132867 | 0.26583000570450654 |
|    Test Metrics    | 56.4446743644 | 0.679441339251 | 0.40237691001697795 | 0.19983136593591905 |  0.2670422535211267 |
+--------------------+---------------+----------------+---------------------+---------------------+---------------------+
_________________________________________________________________
Time:
    Train Time              : 16:41:48.096932
    Dataset Loading Time    : 0:45:39.621965
    Metrics Evaluation Time : 0:56:15.860865
_________________________________________________________________
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         (None, 288, 288, 1)       0         
_________________________________________________________________
conv_1 (Conv2D)              (None, 288, 288, 32)      320       
_________________________________________________________________
norm_1 (BatchNormalization)  (None, 288, 288, 32)      128       
_________________________________________________________________
relu_1 (LeakyReLU)           (None, 288, 288, 32)      0         
_________________________________________________________________
pool_1 (MaxPooling2D)        (None, 144, 144, 32)      0         
_________________________________________________________________
conv_2 (Conv2D)              (None, 144, 144, 64)      18496     
_________________________________________________________________
norm_2 (BatchNormalization)  (None, 144, 144, 64)      256       
_________________________________________________________________
relu_2 (LeakyReLU)           (None, 144, 144, 64)      0         
_________________________________________________________________
pool_2 (MaxPooling2D)        (None, 72, 72, 64)        0         
_________________________________________________________________
conv_3 (Conv2D)              (None, 72, 72, 128)       73856     
_________________________________________________________________
norm_3 (BatchNormalization)  (None, 72, 72, 128)       512       
_________________________________________________________________
relu_3 (LeakyReLU)           (None, 72, 72, 128)       0         
_________________________________________________________________
conv_4 (Conv2D)              (None, 72, 72, 64)        8256      
_________________________________________________________________
norm_4 (BatchNormalization)  (None, 72, 72, 64)        256       
_________________________________________________________________
relu_4 (LeakyReLU)           (None, 72, 72, 64)        0         
_________________________________________________________________
conv_5 (Conv2D)              (None, 72, 72, 128)       73856     
_________________________________________________________________
norm_5 (BatchNormalization)  (None, 72, 72, 128)       512       
_________________________________________________________________
relu_5 (LeakyReLU)           (None, 72, 72, 128)       0         
_________________________________________________________________
pool_3 (MaxPooling2D)        (None, 36, 36, 128)       0         
_________________________________________________________________
conv_6 (Conv2D)              (None, 36, 36, 256)       295168    
_________________________________________________________________
norm_6 (BatchNormalization)  (None, 36, 36, 256)       1024      
_________________________________________________________________
relu_6 (LeakyReLU)           (None, 36, 36, 256)       0         
_________________________________________________________________
conv_7 (Conv2D)              (None, 36, 36, 128)       32896     
_________________________________________________________________
norm_7 (BatchNormalization)  (None, 36, 36, 128)       512       
_________________________________________________________________
relu_7 (LeakyReLU)           (None, 36, 36, 128)       0         
_________________________________________________________________
conv_8 (Conv2D)              (None, 36, 36, 256)       295168    
_________________________________________________________________
norm_8 (BatchNormalization)  (None, 36, 36, 256)       1024      
_________________________________________________________________
relu_8 (LeakyReLU)           (None, 36, 36, 256)       0         
_________________________________________________________________
pool_4 (MaxPooling2D)        (None, 18, 18, 256)       0         
_________________________________________________________________
conv_9 (Conv2D)              (None, 18, 18, 512)       1180160   
_________________________________________________________________
norm_9 (BatchNormalization)  (None, 18, 18, 512)       2048      
_________________________________________________________________
relu_9 (LeakyReLU)           (None, 18, 18, 512)       0         
_________________________________________________________________
conv_10 (Conv2D)             (None, 18, 18, 256)       131328    
_________________________________________________________________
norm_10 (BatchNormalization) (None, 18, 18, 256)       1024      
_________________________________________________________________
relu_10 (LeakyReLU)          (None, 18, 18, 256)       0         
_________________________________________________________________
conv_11 (Conv2D)             (None, 18, 18, 512)       1180160   
_________________________________________________________________
norm_11 (BatchNormalization) (None, 18, 18, 512)       2048      
_________________________________________________________________
relu_11 (LeakyReLU)          (None, 18, 18, 512)       0         
_________________________________________________________________
conv_12 (Conv2D)             (None, 18, 18, 256)       131328    
_________________________________________________________________
norm_12 (BatchNormalization) (None, 18, 18, 256)       1024      
_________________________________________________________________
relu_12 (LeakyReLU)          (None, 18, 18, 256)       0         
_________________________________________________________________
conv_13 (Conv2D)             (None, 18, 18, 512)       1180160   
_________________________________________________________________
norm_13 (BatchNormalization) (None, 18, 18, 512)       2048      
_________________________________________________________________
relu_13 (LeakyReLU)          (None, 18, 18, 512)       0         
_________________________________________________________________
pool_5 (MaxPooling2D)        (None, 9, 9, 512)         0         
_________________________________________________________________
conv_14 (Conv2D)             (None, 9, 9, 1024)        4719616   
_________________________________________________________________
norm_14 (BatchNormalization) (None, 9, 9, 1024)        4096      
_________________________________________________________________
relu_14 (LeakyReLU)          (None, 9, 9, 1024)        0         
_________________________________________________________________
drop_1 (Dropout)             (None, 9, 9, 1024)        0         
_________________________________________________________________
conv_15 (Conv2D)             (None, 9, 9, 1024)        9438208   
_________________________________________________________________
norm_15 (BatchNormalization) (None, 9, 9, 1024)        4096      
_________________________________________________________________
relu_15 (LeakyReLU)          (None, 9, 9, 1024)        0         
_________________________________________________________________
drop_2 (Dropout)             (None, 9, 9, 1024)        0         
_________________________________________________________________
conv_16 (Conv2D)             (None, 9, 9, 5)           5125      
_________________________________________________________________
reshape_1 (Reshape)          (None, 9, 9, 5)           0         
=================================================================
Total params: 18,784,709
Trainable params: 18,774,405
Non-trainable params: 10,304
_________________________________________________________________
+---------+--------------------+----------------+------------------+--------------------+---------------------+-------------------+
|  Epoch  |      f1_score      |      iou       |       loss       |     precision      |        recall       |      val_loss     |
+---------+--------------------+----------------+------------------+--------------------+---------------------+-------------------+
| Epoch 1 | 0.5304518664047152 | 0.657505334272 | 0.00290700220105 | 0.6164383561643836 | 0.46551724137931033 |  0.00198549233497 |
| Epoch 2 | 0.8218181818181818 | 0.712132376259 | 0.00180626733308 | 0.8692307692307693 |  0.7793103448275862 | 0.000903680677443 |
+---------+--------------------+----------------+------------------+--------------------+---------------------+-------------------+
_________________________________________________________________
+---------------------------------+--------------------+--------------------+-----------------------+---------+-----------------------+
|            Optimizer            |       beta_1       |       beta_2       |         decay         | epsilon |           lr          |
+---------------------------------+--------------------+--------------------+-----------------------+---------+-----------------------+
| <class 'keras.optimizers.Adam'> | 0.8999999761581421 | 0.9990000128746033 | 4.999999873689376e-05 |  1e-08  | 9.999999747378752e-05 |
+---------------------------------+--------------------+--------------------+-----------------------+---------+-----------------------+
_________________________________________________________________
+------------+
| Batch Size |
+------------+
|     16     |
+------------+
_________________________________________________________________
+--------------------+-------------------+----------------+--------------------+--------------------+--------------------+
|      Metrics       |        Loss       |      IoU       |     Precision      |       Recall       |      F1 Score      |
+--------------------+-------------------+----------------+--------------------+--------------------+--------------------+
|   Train Metrics    |  0.00158389931344 | 0.806395489141 | 0.9506257500428595 | 0.6708202274376965 | 0.7865806085537981 |
| Validation Metrics | 0.000903680676504 | 0.712132376259 | 0.8692307692307693 | 0.7793103448275862 | 0.8218181818181818 |
|    Test Metrics    |  0.00109288645458 | 0.703927981271 | 0.8446969696969697 | 0.7216828478964401 | 0.7783595113438045 |
+--------------------+-------------------+----------------+--------------------+--------------------+--------------------+
_________________________________________________________________
Time:
    Train Time              : 0:12:29.702859
    Dataset Loading Time    : 0:00:38.977558
    Metrics Evaluation Time : 0:04:21.894486
_________________________________________________________________
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         (None, 288, 288, 1)       0         
_________________________________________________________________
conv_1 (Conv2D)              (None, 288, 288, 32)      320       
_________________________________________________________________
norm_1 (BatchNormalization)  (None, 288, 288, 32)      128       
_________________________________________________________________
relu_1 (LeakyReLU)           (None, 288, 288, 32)      0         
_________________________________________________________________
pool_1 (MaxPooling2D)        (None, 144, 144, 32)      0         
_________________________________________________________________
conv_2 (Conv2D)              (None, 144, 144, 64)      18496     
_________________________________________________________________
norm_2 (BatchNormalization)  (None, 144, 144, 64)      256       
_________________________________________________________________
relu_2 (LeakyReLU)           (None, 144, 144, 64)      0         
_________________________________________________________________
pool_2 (MaxPooling2D)        (None, 72, 72, 64)        0         
_________________________________________________________________
conv_3 (Conv2D)              (None, 72, 72, 128)       73856     
_________________________________________________________________
norm_3 (BatchNormalization)  (None, 72, 72, 128)       512       
_________________________________________________________________
relu_3 (LeakyReLU)           (None, 72, 72, 128)       0         
_________________________________________________________________
drop_1 (Dropout)             (None, 72, 72, 128)       0         
_________________________________________________________________
conv_4 (Conv2D)              (None, 72, 72, 64)        8256      
_________________________________________________________________
norm_4 (BatchNormalization)  (None, 72, 72, 64)        256       
_________________________________________________________________
relu_4 (LeakyReLU)           (None, 72, 72, 64)        0         
_________________________________________________________________
drop_2 (Dropout)             (None, 72, 72, 64)        0         
_________________________________________________________________
conv_5 (Conv2D)              (None, 72, 72, 128)       73856     
_________________________________________________________________
norm_5 (BatchNormalization)  (None, 72, 72, 128)       512       
_________________________________________________________________
relu_5 (LeakyReLU)           (None, 72, 72, 128)       0         
_________________________________________________________________
pool_3 (MaxPooling2D)        (None, 36, 36, 128)       0         
_________________________________________________________________
conv_6 (Conv2D)              (None, 36, 36, 256)       295168    
_________________________________________________________________
norm_6 (BatchNormalization)  (None, 36, 36, 256)       1024      
_________________________________________________________________
relu_6 (LeakyReLU)           (None, 36, 36, 256)       0         
_________________________________________________________________
drop_3 (Dropout)             (None, 36, 36, 256)       0         
_________________________________________________________________
conv_7 (Conv2D)              (None, 36, 36, 128)       32896     
_________________________________________________________________
norm_7 (BatchNormalization)  (None, 36, 36, 128)       512       
_________________________________________________________________
relu_7 (LeakyReLU)           (None, 36, 36, 128)       0         
_________________________________________________________________
drop_4 (Dropout)             (None, 36, 36, 128)       0         
_________________________________________________________________
conv_8 (Conv2D)              (None, 36, 36, 256)       295168    
_________________________________________________________________
norm_8 (BatchNormalization)  (None, 36, 36, 256)       1024      
_________________________________________________________________
relu_8 (LeakyReLU)           (None, 36, 36, 256)       0         
_________________________________________________________________
pool_4 (MaxPooling2D)        (None, 18, 18, 256)       0         
_________________________________________________________________
conv_9 (Conv2D)              (None, 18, 18, 512)       1180160   
_________________________________________________________________
norm_9 (BatchNormalization)  (None, 18, 18, 512)       2048      
_________________________________________________________________
relu_9 (LeakyReLU)           (None, 18, 18, 512)       0         
_________________________________________________________________
drop_5 (Dropout)             (None, 18, 18, 512)       0         
_________________________________________________________________
conv_10 (Conv2D)             (None, 18, 18, 256)       131328    
_________________________________________________________________
norm_10 (BatchNormalization) (None, 18, 18, 256)       1024      
_________________________________________________________________
relu_10 (LeakyReLU)          (None, 18, 18, 256)       0         
_________________________________________________________________
drop_6 (Dropout)             (None, 18, 18, 256)       0         
_________________________________________________________________
conv_11 (Conv2D)             (None, 18, 18, 512)       1180160   
_________________________________________________________________
norm_11 (BatchNormalization) (None, 18, 18, 512)       2048      
_________________________________________________________________
relu_11 (LeakyReLU)          (None, 18, 18, 512)       0         
_________________________________________________________________
drop_7 (Dropout)             (None, 18, 18, 512)       0         
_________________________________________________________________
conv_12 (Conv2D)             (None, 18, 18, 256)       131328    
_________________________________________________________________
norm_12 (BatchNormalization) (None, 18, 18, 256)       1024      
_________________________________________________________________
relu_12 (LeakyReLU)          (None, 18, 18, 256)       0         
_________________________________________________________________
drop_8 (Dropout)             (None, 18, 18, 256)       0         
_________________________________________________________________
conv_13 (Conv2D)             (None, 18, 18, 512)       1180160   
_________________________________________________________________
norm_13 (BatchNormalization) (None, 18, 18, 512)       2048      
_________________________________________________________________
relu_13 (LeakyReLU)          (None, 18, 18, 512)       0         
_________________________________________________________________
pool_5 (MaxPooling2D)        (None, 9, 9, 512)         0         
_________________________________________________________________
conv_14 (Conv2D)             (None, 9, 9, 1024)        4719616   
_________________________________________________________________
norm_14 (BatchNormalization) (None, 9, 9, 1024)        4096      
_________________________________________________________________
relu_14 (LeakyReLU)          (None, 9, 9, 1024)        0         
_________________________________________________________________
drop_9 (Dropout)             (None, 9, 9, 1024)        0         
_________________________________________________________________
conv_15 (Conv2D)             (None, 9, 9, 1024)        9438208   
_________________________________________________________________
norm_15 (BatchNormalization) (None, 9, 9, 1024)        4096      
_________________________________________________________________
relu_15 (LeakyReLU)          (None, 9, 9, 1024)        0         
_________________________________________________________________
drop_10 (Dropout)            (None, 9, 9, 1024)        0         
_________________________________________________________________
conv_16 (Conv2D)             (None, 9, 9, 5)           5125      
_________________________________________________________________
reshape_1 (Reshape)          (None, 9, 9, 5)           0         
=================================================================
Total params: 18,784,709
Trainable params: 18,774,405
Non-trainable params: 10,304
_________________________________________________________________
+----------+----------------------+----------------+------------------+----------------------+-----------------------+------------------+
|  Epoch   |       f1_score       |      iou       |       loss       |      precision       |         recall        |     val_loss     |
+----------+----------------------+----------------+------------------+----------------------+-----------------------+------------------+
| Epoch 1  |         nan          |      nan       | 0.00622930527957 |         nan          |          0.0          | 0.0216605263478  |
| Epoch 2  |         nan          |      nan       | 0.00452289931347 |         0.0          |          0.0          | 0.0194830842476  |
| Epoch 3  |         nan          |      nan       | 0.00430364204591 |         0.0          |          0.0          | 0.0203517962466  |
| Epoch 4  |         nan          |      nan       | 0.00412105091776 |         0.0          |          0.0          | 0.0187862880209  |
| Epoch 5  |         nan          |      nan       | 0.00397148601847 |         0.0          |          0.0          | 0.0149780138231  |
| Epoch 6  |         nan          |      nan       | 0.00387431369357 |         0.0          |          0.0          | 0.0146236266084  |
| Epoch 7  |         nan          |      nan       | 0.0037623866342  |         0.0          |          0.0          | 0.0145040074074  |
| Epoch 8  |         nan          |      nan       | 0.00367334922373 |         0.0          |          0.0          | 0.00864988669036 |
| Epoch 9  | 0.020602218700475437 | 0.552145502659 | 0.00360141657786 | 0.11016949152542373  |  0.011363636363636364 | 0.00776468463401 |
| Epoch 10 | 0.004866180048661801 | 0.516910363511 | 0.00351740605178 | 0.033707865168539325 | 0.0026223776223776225 | 0.00790648618066 |
| Epoch 11 | 0.037037037037037035 | 0.594172564963 | 0.00346334167599 | 0.12135922330097088  |  0.021853146853146852 | 0.00623564333481 |
| Epoch 12 | 0.032716927453769556 | 0.570928500387 | 0.00341121450586 | 0.08778625954198473  |  0.020104895104895104 | 0.00603788148084 |
| Epoch 13 | 0.020618556701030927 | 0.565824752029 | 0.00334686374047 |  0.1111111111111111  |  0.011363636363636364 | 0.00680343086338 |
| Epoch 14 | 0.007880220646178094 | 0.553401986986 | 0.00332249659762 |         0.04         |  0.004370629370629371 | 0.00727974504412 |
| Epoch 15 | 0.015625000000000003 | 0.567497539342 | 0.00327068361565 | 0.07352941176470588  |  0.008741258741258742 | 0.00626797286823 |
| Epoch 16 | 0.07065609228550829  | 0.615843948161 | 0.00322673261699 | 0.20164609053497942  |  0.04283216783216783  | 0.00587607964993 |
| Epoch 17 | 0.09377186843946816  | 0.644031153721 | 0.00320078518491 | 0.23508771929824562  |  0.05856643356643357  | 0.00607732150524 |
| Epoch 18 | 0.10111524163568775  | 0.636115690638 | 0.00318176259584 |  0.3383084577114428  |  0.05944055944055944  | 0.00529505365234 |
| Epoch 19 | 0.14244186046511628  | 0.674969440353 | 0.00314298191883 |  0.4224137931034483  |  0.08566433566433566  | 0.00508407486931 |
| Epoch 20 | 0.059770114942528735 | 0.63533295668  | 0.00311499520415 |  0.2422360248447205  |  0.03409090909090909  | 0.0063638982119  |
| Epoch 21 |  0.1379310344827586  | 0.687658995611 | 0.00308666507269 |  0.4292237442922374  |  0.08216783216783216  | 0.00515479404469 |
| Epoch 22 | 0.07633587786259542  | 0.655780374352 | 0.00306423071181 | 0.30120481927710846  |  0.043706293706293704 | 0.00572900762682 |
| Epoch 23 | 0.16754716981132078  | 0.687397110057 | 0.00303693212488 |  0.6132596685082873  |  0.09702797202797203  | 0.00440238778763 |
| Epoch 24 | 0.09216589861751152  | 0.660996560903 | 0.00301719496432 |  0.379746835443038   |  0.05244755244755245  | 0.00555021651737 |
| Epoch 25 |  0.1059190031152648  | 0.673003701774 | 0.00299630324243 |  0.4857142857142857  |  0.05944055944055944  | 0.00525790068724 |
| Epoch 26 | 0.14743112434847355  | 0.679039359316 | 0.00297728777236 | 0.49748743718592964  |  0.08653846153846154  | 0.00523393309332 |
| Epoch 27 | 0.18262806236080179  | 0.711907985334 | 0.00294822382643 |  0.6059113300492611  |  0.10751748251748251  | 0.00470948372445 |
| Epoch 28 | 0.19664967225054625  | 0.703196012941 | 0.00293212055964 |  0.5895196506550219  |  0.11800699300699301  | 0.00464055688434 |
| Epoch 29 | 0.19880418535127056  | 0.72672955854  | 0.00291941279552 |  0.6855670103092784  |  0.11625874125874126  | 0.00456149716622 |
| Epoch 30 | 0.14531835205992508  | 0.711849687215 | 0.00291120604985 |  0.5078534031413613  |  0.08479020979020979  | 0.00513180982157 |
+----------+----------------------+----------------+------------------+----------------------+-----------------------+------------------+
_________________________________________________________________
+---------------------------------+--------------------+--------------------+-----------------------+---------+-----------------------+
|            Optimizer            |       beta_1       |       beta_2       |         decay         | epsilon |           lr          |
+---------------------------------+--------------------+--------------------+-----------------------+---------+-----------------------+
| <class 'keras.optimizers.Adam'> | 0.8999999761581421 | 0.9990000128746033 | 0.0005000000237487257 |  1e-08  | 0.0010000000474974513 |
+---------------------------------+--------------------+--------------------+-----------------------+---------+-----------------------+
_________________________________________________________________
+------------+
| Batch Size |
+------------+
|     16     |
+------------+
_________________________________________________________________
+--------------------+------------------+----------------+--------------------+---------------------+---------------------+
|      Metrics       |       Loss       |      IoU       |     Precision      |        Recall       |       F1 Score      |
+--------------------+------------------+----------------+--------------------+---------------------+---------------------+
|   Train Metrics    | 0.00514888510136 | 0.70405987552  | 0.7825781524411661 |  0.1929505499263878 |  0.3095734333750173 |
| Validation Metrics | 0.00513181008179 | 0.711849687215 | 0.5078534031413613 | 0.08479020979020979 | 0.14531835205992508 |
|    Test Metrics    | 0.00549509321006 | 0.699623726797 |        0.52        | 0.08768971332209106 | 0.15007215007215008 |
+--------------------+------------------+----------------+--------------------+---------------------+---------------------+
_________________________________________________________________
Time:
    Train Time              : 13:58:01.129655
    Dataset Loading Time    : 0:37:02.923155
    Metrics Evaluation Time : 0:41:17.845125
_________________________________________________________________
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         (None, 288, 288, 1)       0         
_________________________________________________________________
conv_1 (Conv2D)              (None, 288, 288, 32)      320       
_________________________________________________________________
norm_1 (BatchNormalization)  (None, 288, 288, 32)      128       
_________________________________________________________________
relu_1 (LeakyReLU)           (None, 288, 288, 32)      0         
_________________________________________________________________
pool_1 (MaxPooling2D)        (None, 144, 144, 32)      0         
_________________________________________________________________
conv_2 (Conv2D)              (None, 144, 144, 64)      18496     
_________________________________________________________________
norm_2 (BatchNormalization)  (None, 144, 144, 64)      256       
_________________________________________________________________
relu_2 (LeakyReLU)           (None, 144, 144, 64)      0         
_________________________________________________________________
pool_2 (MaxPooling2D)        (None, 72, 72, 64)        0         
_________________________________________________________________
conv_3 (Conv2D)              (None, 72, 72, 128)       73856     
_________________________________________________________________
norm_3 (BatchNormalization)  (None, 72, 72, 128)       512       
_________________________________________________________________
relu_3 (LeakyReLU)           (None, 72, 72, 128)       0         
_________________________________________________________________
drop_1 (Dropout)             (None, 72, 72, 128)       0         
_________________________________________________________________
conv_4 (Conv2D)              (None, 72, 72, 64)        8256      
_________________________________________________________________
norm_4 (BatchNormalization)  (None, 72, 72, 64)        256       
_________________________________________________________________
relu_4 (LeakyReLU)           (None, 72, 72, 64)        0         
_________________________________________________________________
drop_2 (Dropout)             (None, 72, 72, 64)        0         
_________________________________________________________________
conv_5 (Conv2D)              (None, 72, 72, 128)       73856     
_________________________________________________________________
norm_5 (BatchNormalization)  (None, 72, 72, 128)       512       
_________________________________________________________________
relu_5 (LeakyReLU)           (None, 72, 72, 128)       0         
_________________________________________________________________
pool_3 (MaxPooling2D)        (None, 36, 36, 128)       0         
_________________________________________________________________
conv_6 (Conv2D)              (None, 36, 36, 256)       295168    
_________________________________________________________________
norm_6 (BatchNormalization)  (None, 36, 36, 256)       1024      
_________________________________________________________________
relu_6 (LeakyReLU)           (None, 36, 36, 256)       0         
_________________________________________________________________
drop_3 (Dropout)             (None, 36, 36, 256)       0         
_________________________________________________________________
conv_7 (Conv2D)              (None, 36, 36, 128)       32896     
_________________________________________________________________
norm_7 (BatchNormalization)  (None, 36, 36, 128)       512       
_________________________________________________________________
relu_7 (LeakyReLU)           (None, 36, 36, 128)       0         
_________________________________________________________________
drop_4 (Dropout)             (None, 36, 36, 128)       0         
_________________________________________________________________
conv_8 (Conv2D)              (None, 36, 36, 256)       295168    
_________________________________________________________________
norm_8 (BatchNormalization)  (None, 36, 36, 256)       1024      
_________________________________________________________________
relu_8 (LeakyReLU)           (None, 36, 36, 256)       0         
_________________________________________________________________
pool_4 (MaxPooling2D)        (None, 18, 18, 256)       0         
_________________________________________________________________
conv_9 (Conv2D)              (None, 18, 18, 512)       1180160   
_________________________________________________________________
norm_9 (BatchNormalization)  (None, 18, 18, 512)       2048      
_________________________________________________________________
relu_9 (LeakyReLU)           (None, 18, 18, 512)       0         
_________________________________________________________________
drop_5 (Dropout)             (None, 18, 18, 512)       0         
_________________________________________________________________
conv_10 (Conv2D)             (None, 18, 18, 256)       131328    
_________________________________________________________________
norm_10 (BatchNormalization) (None, 18, 18, 256)       1024      
_________________________________________________________________
relu_10 (LeakyReLU)          (None, 18, 18, 256)       0         
_________________________________________________________________
drop_6 (Dropout)             (None, 18, 18, 256)       0         
_________________________________________________________________
conv_11 (Conv2D)             (None, 18, 18, 512)       1180160   
_________________________________________________________________
norm_11 (BatchNormalization) (None, 18, 18, 512)       2048      
_________________________________________________________________
relu_11 (LeakyReLU)          (None, 18, 18, 512)       0         
_________________________________________________________________
drop_7 (Dropout)             (None, 18, 18, 512)       0         
_________________________________________________________________
conv_12 (Conv2D)             (None, 18, 18, 256)       131328    
_________________________________________________________________
norm_12 (BatchNormalization) (None, 18, 18, 256)       1024      
_________________________________________________________________
relu_12 (LeakyReLU)          (None, 18, 18, 256)       0         
_________________________________________________________________
drop_8 (Dropout)             (None, 18, 18, 256)       0         
_________________________________________________________________
conv_13 (Conv2D)             (None, 18, 18, 512)       1180160   
_________________________________________________________________
norm_13 (BatchNormalization) (None, 18, 18, 512)       2048      
_________________________________________________________________
relu_13 (LeakyReLU)          (None, 18, 18, 512)       0         
_________________________________________________________________
pool_5 (MaxPooling2D)        (None, 9, 9, 512)         0         
_________________________________________________________________
conv_14 (Conv2D)             (None, 9, 9, 1024)        4719616   
_________________________________________________________________
norm_14 (BatchNormalization) (None, 9, 9, 1024)        4096      
_________________________________________________________________
relu_14 (LeakyReLU)          (None, 9, 9, 1024)        0         
_________________________________________________________________
drop_9 (Dropout)             (None, 9, 9, 1024)        0         
_________________________________________________________________
conv_15 (Conv2D)             (None, 9, 9, 1024)        9438208   
_________________________________________________________________
norm_15 (BatchNormalization) (None, 9, 9, 1024)        4096      
_________________________________________________________________
relu_15 (LeakyReLU)          (None, 9, 9, 1024)        0         
_________________________________________________________________
drop_10 (Dropout)            (None, 9, 9, 1024)        0         
_________________________________________________________________
conv_16 (Conv2D)             (None, 9, 9, 5)           5125      
_________________________________________________________________
reshape_1 (Reshape)          (None, 9, 9, 5)           0         
=================================================================
Total params: 18,784,709
Trainable params: 18,774,405
Non-trainable params: 10,304
_________________________________________________________________
+----------+---------------------+----------------+------------------+---------------------+----------------------+------------------+
|  Epoch   |       f1_score      |      iou       |       loss       |      precision      |        recall        |     val_loss     |
+----------+---------------------+----------------+------------------+---------------------+----------------------+------------------+
| Epoch 1  |  0.1645390070921986 | 0.707899857675 | 0.00288959439876 | 0.43609022556390975 | 0.10139860139860139  | 0.00523016569927 |
| Epoch 2  |  0.1605301914580265 | 0.720414134062 | 0.00287589756254 |  0.5093457943925234 | 0.09527972027972027  | 0.00503468215167 |
| Epoch 3  | 0.15305371596762327 | 0.724285415323 | 0.00286124167375 | 0.48372093023255813 | 0.09090909090909091  | 0.00495501572794 |
| Epoch 4  | 0.13343108504398826 | 0.720023081462 | 0.00283694916758 | 0.41363636363636364 | 0.07954545454545454  | 0.00542653511642 |
| Epoch 5  | 0.14591009579955785 | 0.703217134157 | 0.00282662250257 |  0.4647887323943662 | 0.08653846153846154  | 0.00538345920868 |
| Epoch 6  |  0.0990990990990991 | 0.682501229049 | 0.00281930953177 | 0.35106382978723405 | 0.057692307692307696 | 0.0059951024882  |
| Epoch 7  | 0.18999274836838287 | 0.716687675821 | 0.00280162903134 |  0.5574468085106383 |  0.1145104895104895  | 0.00469830680644 |
| Epoch 8  | 0.18394160583941607 | 0.718173486682 | 0.00279823139496 |  0.5575221238938053 | 0.11013986013986014  | 0.00460567629777 |
| Epoch 9  | 0.27406886858749124 | 0.722990612915 | 0.00278281450346 |  0.6989247311827957 | 0.17045454545454544  | 0.0041331159571  |
| Epoch 10 |  0.2028985507246377 | 0.719477008351 | 0.00276580346329 |  0.5932203389830508 | 0.12237762237762238  | 0.00456381947011 |
| Epoch 11 |  0.192667145938174  | 0.720872651412 | 0.00275651079536 |  0.5425101214574899 | 0.11713286713286714  | 0.00487149477174 |
| Epoch 12 |  0.2863157894736842 | 0.724371289126 | 0.00275033595211 |  0.7259786476868327 | 0.17832167832167833  | 0.00402041891948 |
| Epoch 13 | 0.19501466275659826 | 0.713174006254 | 0.00273725065725 |  0.6045454545454545 | 0.11625874125874126  | 0.00491658519246 |
| Epoch 14 | 0.19327129563350035 | 0.717970983462 | 0.00272167132224 |  0.5335968379446641 | 0.11800699300699301  | 0.00467181275723 |
| Epoch 15 | 0.19400855920114124 | 0.719650951554 | 0.00272260621154 |  0.5271317829457365 | 0.11888111888111888  | 0.00486561096831 |
| Epoch 16 |  0.2047584715212689 | 0.719400804012 | 0.00269954469841 |  0.5843621399176955 | 0.12412587412587413  | 0.0047973903932  |
| Epoch 17 | 0.23612087139845397 | 0.717448022658 | 0.00269694209319 |  0.6021505376344086 | 0.14685314685314685  | 0.00458471027806 |
| Epoch 18 | 0.26366120218579236 | 0.715881374531 | 0.00268613843382 |       0.603125      |  0.1687062937062937  | 0.00438647352428 |
| Epoch 19 | 0.23317140874392783 | 0.714960957262 | 0.00268419286408 |  0.5656565656565656 | 0.14685314685314685  | 0.00430731838918 |
| Epoch 20 | 0.21398002853067047 | 0.717500387608 | 0.00266075977168 |  0.5813953488372093 | 0.13111888111888112  | 0.0047390890248  |
| Epoch 21 | 0.27479892761394104 | 0.718851956244 | 0.00265164737332 |  0.5890804597701149 |  0.1791958041958042  | 0.00410650460483 |
| Epoch 22 | 0.24407252440725247 | 0.719794322052 | 0.00264973125424 |  0.603448275862069  | 0.15297202797202797  | 0.00443509668685 |
| Epoch 23 | 0.22394366197183102 | 0.718044851659 | 0.00264331417919 |  0.5760869565217391 | 0.13898601398601398  | 0.00446487178423 |
| Epoch 24 |  0.2282157676348548 | 0.727462098257 | 0.00262907050986 |  0.5463576158940397 | 0.14423076923076922  | 0.00459407529679 |
| Epoch 25 | 0.20986796386379433 | 0.719449031141 | 0.0026298489903  |  0.511864406779661  |  0.131993006993007   | 0.00478730912515 |
| Epoch 26 | 0.27751196172248804 | 0.722996189134 | 0.00262162576324 |  0.6363636363636364 | 0.17744755244755245  | 0.00412778938712 |
| Epoch 27 |  0.2534059945504087 | 0.720758648775 | 0.00261738508872 |  0.5740740740740741 | 0.16258741258741258  | 0.00428175019663 |
| Epoch 28 | 0.25745257452574527 | 0.707762011162 | 0.00260417881863 |  0.572289156626506  |  0.1660839160839161  | 0.00440924422801 |
| Epoch 29 |  0.276797829036635  | 0.714808503729 | 0.00259212518955 |  0.6181818181818182 | 0.17832167832167833  | 0.0042409709453  |
| Epoch 30 | 0.22562674094707522 | 0.721758583309 | 0.00258653610693 |  0.5547945205479452 | 0.14160839160839161  | 0.00456113470743 |
+----------+---------------------+----------------+------------------+---------------------+----------------------+------------------+
_________________________________________________________________
+---------------------------------+--------------------+--------------------+----------------------+---------+----------------------+
|            Optimizer            |       beta_1       |       beta_2       |        decay         | epsilon |          lr          |
+---------------------------------+--------------------+--------------------+----------------------+---------+----------------------+
| <class 'keras.optimizers.Adam'> | 0.8999999761581421 | 0.9990000128746033 | 0.004999999888241291 |  1e-08  | 0.009999999776482582 |
+---------------------------------+--------------------+--------------------+----------------------+---------+----------------------+
_________________________________________________________________
+------------+
| Batch Size |
+------------+
|     16     |
+------------+
_________________________________________________________________
+--------------------+------------------+----------------+--------------------+---------------------+---------------------+
|      Metrics       |       Loss       |      IoU       |     Precision      |        Recall       |       F1 Score      |
+--------------------+------------------+----------------+--------------------+---------------------+---------------------+
|   Train Metrics    | 0.00418787022726 | 0.725069178561 | 0.7654983309489747 |  0.2780375855200485 | 0.40791563433072864 |
| Validation Metrics | 0.0045611348668  | 0.721758583309 | 0.5547945205479452 | 0.14160839160839161 | 0.22562674094707522 |
|    Test Metrics    | 0.00482181647175 | 0.72245267698  | 0.5816326530612245 | 0.14418212478920742 | 0.23108108108108108 |
+--------------------+------------------+----------------+--------------------+---------------------+---------------------+
_________________________________________________________________
Time:
    Train Time              : 17:14:56.354756
    Dataset Loading Time    : 0:31:44.792705
    Metrics Evaluation Time : 1:16:32.389442
_________________________________________________________________
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         (None, 288, 288, 1)       0         
_________________________________________________________________
conv_1 (Conv2D)              (None, 288, 288, 32)      320       
_________________________________________________________________
norm_1 (BatchNormalization)  (None, 288, 288, 32)      128       
_________________________________________________________________
relu_1 (LeakyReLU)           (None, 288, 288, 32)      0         
_________________________________________________________________
pool_1 (MaxPooling2D)        (None, 144, 144, 32)      0         
_________________________________________________________________
conv_2 (Conv2D)              (None, 144, 144, 64)      18496     
_________________________________________________________________
norm_2 (BatchNormalization)  (None, 144, 144, 64)      256       
_________________________________________________________________
relu_2 (LeakyReLU)           (None, 144, 144, 64)      0         
_________________________________________________________________
pool_2 (MaxPooling2D)        (None, 72, 72, 64)        0         
_________________________________________________________________
conv_3 (Conv2D)              (None, 72, 72, 128)       73856     
_________________________________________________________________
norm_3 (BatchNormalization)  (None, 72, 72, 128)       512       
_________________________________________________________________
relu_3 (LeakyReLU)           (None, 72, 72, 128)       0         
_________________________________________________________________
conv_4 (Conv2D)              (None, 72, 72, 64)        8256      
_________________________________________________________________
norm_4 (BatchNormalization)  (None, 72, 72, 64)        256       
_________________________________________________________________
relu_4 (LeakyReLU)           (None, 72, 72, 64)        0         
_________________________________________________________________
conv_5 (Conv2D)              (None, 72, 72, 128)       73856     
_________________________________________________________________
norm_5 (BatchNormalization)  (None, 72, 72, 128)       512       
_________________________________________________________________
relu_5 (LeakyReLU)           (None, 72, 72, 128)       0         
_________________________________________________________________
pool_3 (MaxPooling2D)        (None, 36, 36, 128)       0         
_________________________________________________________________
conv_6 (Conv2D)              (None, 36, 36, 256)       295168    
_________________________________________________________________
norm_6 (BatchNormalization)  (None, 36, 36, 256)       1024      
_________________________________________________________________
relu_6 (LeakyReLU)           (None, 36, 36, 256)       0         
_________________________________________________________________
conv_7 (Conv2D)              (None, 36, 36, 128)       32896     
_________________________________________________________________
norm_7 (BatchNormalization)  (None, 36, 36, 128)       512       
_________________________________________________________________
relu_7 (LeakyReLU)           (None, 36, 36, 128)       0         
_________________________________________________________________
conv_8 (Conv2D)              (None, 36, 36, 256)       295168    
_________________________________________________________________
norm_8 (BatchNormalization)  (None, 36, 36, 256)       1024      
_________________________________________________________________
relu_8 (LeakyReLU)           (None, 36, 36, 256)       0         
_________________________________________________________________
pool_4 (MaxPooling2D)        (None, 18, 18, 256)       0         
_________________________________________________________________
conv_9 (Conv2D)              (None, 18, 18, 512)       1180160   
_________________________________________________________________
norm_9 (BatchNormalization)  (None, 18, 18, 512)       2048      
_________________________________________________________________
relu_9 (LeakyReLU)           (None, 18, 18, 512)       0         
_________________________________________________________________
conv_10 (Conv2D)             (None, 18, 18, 256)       131328    
_________________________________________________________________
norm_10 (BatchNormalization) (None, 18, 18, 256)       1024      
_________________________________________________________________
relu_10 (LeakyReLU)          (None, 18, 18, 256)       0         
_________________________________________________________________
conv_11 (Conv2D)             (None, 18, 18, 512)       1180160   
_________________________________________________________________
norm_11 (BatchNormalization) (None, 18, 18, 512)       2048      
_________________________________________________________________
relu_11 (LeakyReLU)          (None, 18, 18, 512)       0         
_________________________________________________________________
conv_12 (Conv2D)             (None, 18, 18, 256)       131328    
_________________________________________________________________
norm_12 (BatchNormalization) (None, 18, 18, 256)       1024      
_________________________________________________________________
relu_12 (LeakyReLU)          (None, 18, 18, 256)       0         
_________________________________________________________________
conv_13 (Conv2D)             (None, 18, 18, 512)       1180160   
_________________________________________________________________
norm_13 (BatchNormalization) (None, 18, 18, 512)       2048      
_________________________________________________________________
relu_13 (LeakyReLU)          (None, 18, 18, 512)       0         
_________________________________________________________________
pool_5 (MaxPooling2D)        (None, 9, 9, 512)         0         
_________________________________________________________________
conv_14 (Conv2D)             (None, 9, 9, 1024)        4719616   
_________________________________________________________________
norm_14 (BatchNormalization) (None, 9, 9, 1024)        4096      
_________________________________________________________________
relu_14 (LeakyReLU)          (None, 9, 9, 1024)        0         
_________________________________________________________________
drop_1 (Dropout)             (None, 9, 9, 1024)        0         
_________________________________________________________________
conv_15 (Conv2D)             (None, 9, 9, 1024)        9438208   
_________________________________________________________________
norm_15 (BatchNormalization) (None, 9, 9, 1024)        4096      
_________________________________________________________________
relu_15 (LeakyReLU)          (None, 9, 9, 1024)        0         
_________________________________________________________________
drop_2 (Dropout)             (None, 9, 9, 1024)        0         
_________________________________________________________________
conv_16 (Conv2D)             (None, 9, 9, 5)           5125      
_________________________________________________________________
reshape_1 (Reshape)          (None, 9, 9, 5)           0         
=================================================================
Total params: 18,784,709
Trainable params: 18,774,405
Non-trainable params: 10,304
_________________________________________________________________
+----------+---------------------+----------------+-------------------+---------------------+---------------------+------------------+
|  Epoch   |       f1_score      |      iou       |        loss       |      precision      |        recall       |     val_loss     |
+----------+---------------------+----------------+-------------------+---------------------+---------------------+------------------+
| Epoch 1  |         nan         |      nan       |   0.010202270435  |         nan         |         0.0         | 0.00392805744383 |
| Epoch 2  | 0.38787878787878793 | 0.646653328733 |  0.00424221220752 |  0.4682926829268293 |  0.3310344827586207 | 0.00222979431161 |
| Epoch 3  |  0.5614035087719298 | 0.675533971109 |  0.00332499907308 |  0.5222551928783383 |  0.6068965517241379 | 0.00241317165144 |
| Epoch 4  |  0.5416666666666667 | 0.689980082138 |  0.00281764162289 | 0.47643979057591623 |  0.6275862068965518 | 0.00229954424374 |
| Epoch 5  |  0.5709828393135726 | 0.669612002128 |  0.0023674716455  |  0.5213675213675214 |  0.6310344827586207 | 0.00209552583645 |
| Epoch 6  |  0.6091549295774649 | 0.674230020081 |  0.00203598948876 |  0.6223021582733813 |  0.596551724137931  | 0.00186637486707 |
| Epoch 7  |  0.5984251968503937 | 0.692659803764 |  0.0017420543997  |  0.5507246376811594 |  0.6551724137931034 | 0.00200682365891 |
| Epoch 8  |  0.530421216848674  | 0.678211225247 |  0.00150554421648 |  0.4843304843304843 |  0.5862068965517241 | 0.00197456381284 |
| Epoch 9  |  0.5555555555555555 | 0.684110761327 |  0.0012753513224  |  0.5279503105590062 |  0.5862068965517241 | 0.00194485588074 |
| Epoch 10 |  0.6194690265486726 | 0.685802386127 |  0.00109840894023 |  0.6363636363636364 |  0.603448275862069  | 0.00184093366542 |
| Epoch 11 |  0.5746031746031746 | 0.695804611155 | 0.000945007090795 |  0.5323529411764706 |  0.6241379310344828 | 0.00190933800167 |
| Epoch 12 |  0.5502063273727648 | 0.692039299219 | 0.000813388467649 |  0.4576659038901602 |  0.6896551724137931 | 0.00221397310886 |
| Epoch 13 |  0.5575959933222037 | 0.692922585955 | 0.000700513732487 |  0.540453074433657  |  0.5758620689655173 | 0.00193770592957 |
| Epoch 14 |  0.5544217687074829 | 0.689226460314 | 0.000616290283489 |  0.5469798657718121 |  0.5620689655172414 | 0.0018327140039  |
| Epoch 15 |  0.5526770293609672 | 0.695678994937 | 0.000565446167023 |  0.5536332179930796 |  0.5517241379310345 | 0.0020263896534  |
| Epoch 16 |  0.5599999999999998 | 0.695030504453 | 0.000514509050313 |  0.5923076923076923 |  0.5310344827586206 | 0.00194255631011 |
| Epoch 17 |  0.5775401069518717 | 0.691510867599 | 0.000455235998886 |  0.5977859778597786 |  0.5586206896551724 | 0.00191529768129 |
| Epoch 18 |  0.5736434108527132 | 0.692490123276 | 0.000410694051133 |  0.6548672566371682 |  0.5103448275862069 | 0.00188874408993 |
| Epoch 19 |  0.5714285714285715 | 0.694143645842 |  0.00038877593211 |  0.6007604562737643 |  0.5448275862068965 | 0.00192390874614 |
| Epoch 20 |  0.5886792452830187 | 0.70094908594  | 0.000357064100542 |         0.65        |  0.5379310344827586 | 0.00186096899767 |
| Epoch 21 |  0.5567010309278351 | 0.692534786542 |  0.00033207321819 |  0.5547945205479452 |  0.5586206896551724 | 0.00186740569094 |
| Epoch 22 |  0.5544933078393882 | 0.685717142727 | 0.000328431968191 |  0.6223175965665236 |         0.5         | 0.00184669409082 |
| Epoch 23 |  0.5740072202166064 | 0.693228331973 | 0.000296605225081 |  0.6022727272727273 |  0.5482758620689655 | 0.00198494142387 |
| Epoch 24 |  0.5611015490533563 | 0.693563918207 | 0.000287646320955 |  0.5601374570446735 |  0.5620689655172414 | 0.00205632512863 |
| Epoch 25 |  0.5044404973357016 | 0.685770317716 | 0.000272461132453 |  0.5201465201465202 |  0.4896551724137931 | 0.00205300543683 |
| Epoch 26 |  0.5563636363636364 | 0.694262738428 | 0.000248352422838 |  0.5884615384615385 |  0.5275862068965518 | 0.00196916951738 |
| Epoch 27 |  0.562390158172232  | 0.697665142573 | 0.000256634451959 |  0.5734767025089605 |  0.5517241379310345 | 0.00195762235296 |
| Epoch 28 |  0.5085388994307399 | 0.684186206138 | 0.000262064180362 |  0.5654008438818565 | 0.46206896551724136 | 0.00207918398683 |
| Epoch 29 |  0.5996592844974447 | 0.692901406541 | 0.000243272248352 |  0.5925925925925926 |  0.6068965517241379 | 0.00192469138757 |
| Epoch 30 |  0.5846702317290553 | 0.685125635418 | 0.000226325435463 |  0.6051660516605166 |  0.5655172413793104 | 0.00197252161395 |
| Epoch 31 |  0.5092936802973977 | 0.692213372499 | 0.000227170144312 |  0.5524193548387096 |  0.4724137931034483 | 0.00214636532755 |
| Epoch 32 | 0.49898580121703856 | 0.703412974217 | 0.000214464914288 |  0.6059113300492611 |  0.4241379310344828 | 0.0020768010741  |
| Epoch 33 |  0.5300751879699247 | 0.691709000101 | 0.000198835061578 |  0.5826446280991735 |  0.4862068965517241 | 0.00202527756788 |
| Epoch 34 |  0.5606060606060606 | 0.703007849369 | 0.000201781779231 |  0.6218487394957983 |  0.5103448275862069 | 0.00195726826637 |
| Epoch 35 |  0.5843478260869566 | 0.691561831249 | 0.000185631624883 |  0.5894736842105263 |  0.5793103448275863 | 0.00200328634181 |
| Epoch 36 |  0.570915619389587  | 0.686252368022 | 0.000196063302974 |  0.5955056179775281 |  0.5482758620689655 | 0.0019262692508  |
| Epoch 37 |  0.5408560311284046 | 0.690687275402 | 0.000185739911057 |  0.6205357142857143 |  0.4793103448275862 | 0.00187370580276 |
| Epoch 38 |  0.5899814471243043 | 0.701984081925 | 0.000181626405444 |  0.6385542168674698 |  0.5482758620689655 | 0.00184550820174 |
| Epoch 39 |   0.60431654676259  | 0.684076248533 | 0.000180971057026 |  0.631578947368421  |  0.5793103448275863 | 0.00183920385391 |
| Epoch 40 |  0.5789473684210527 | 0.697648713751 | 0.000178610021515 |  0.6363636363636364 |  0.5310344827586206 | 0.00192329092252 |
| Epoch 41 |  0.5354969574036511 | 0.695399896519 | 0.000164622405643 |  0.6502463054187192 | 0.45517241379310347 | 0.00198139866341 |
| Epoch 42 |  0.6150943396226416 | 0.696313541335 |  0.00015997855587 |  0.6791666666666667 |  0.5620689655172414 | 0.00181897111507 |
| Epoch 43 |  0.574074074074074  | 0.683756219514 | 0.000161621938911 |         0.62        |  0.5344827586206896 | 0.00182817684441 |
| Epoch 44 |  0.5795053003533569 | 0.694383112773 | 0.000166046224553 |  0.5942028985507246 |  0.5655172413793104 | 0.00192909752725 |
| Epoch 45 | 0.48888888888888893 | 0.691145124882 | 0.000166545728047 |  0.5902439024390244 | 0.41724137931034483 | 0.00207611754341 |
| Epoch 46 |  0.5592233009708738 | 0.689991411546 | 0.000163797137267 |         0.64        |  0.496551724137931  | 0.00201476992093 |
| Epoch 47 |  0.5742574257425743 | 0.697369700861 | 0.000152950252467 |  0.6744186046511628 |         0.5         | 0.0018565014245  |
| Epoch 48 |  0.5243128964059196 | 0.693666556083 | 0.000142514632425 |  0.6775956284153005 | 0.42758620689655175 | 0.00202180899214 |
| Epoch 49 |       0.609375      | 0.697396950929 | 0.000145023757663 |  0.7027027027027027 |  0.5379310344827586 | 0.00181806734162 |
| Epoch 50 |  0.6091954022988506 | 0.694742304421 | 0.000142552888324 |  0.6853448275862069 |  0.5482758620689655 | 0.00186360989427 |
+----------+---------------------+----------------+-------------------+---------------------+---------------------+------------------+
_________________________________________________________________
+---------------------------------+--------------------+--------------------+-----------------------+---------+-----------------------+
|            Optimizer            |       beta_1       |       beta_2       |         decay         | epsilon |           lr          |
+---------------------------------+--------------------+--------------------+-----------------------+---------+-----------------------+
| <class 'keras.optimizers.Adam'> | 0.8999999761581421 | 0.9990000128746033 | 4.999999873689376e-05 |  1e-08  | 9.999999747378752e-05 |
+---------------------------------+--------------------+--------------------+-----------------------+---------+-----------------------+
_________________________________________________________________
+------------+
| Batch Size |
+------------+
|     16     |
+------------+
_________________________________________________________________
+--------------------+-------------------+----------------+--------------------+--------------------+--------------------+
|      Metrics       |        Loss       |      IoU       |     Precision      |       Recall       |      F1 Score      |
+--------------------+-------------------+----------------+--------------------+--------------------+--------------------+
|   Train Metrics    | 0.000108327581652 | 0.817144069762 | 0.9649101505585236 | 0.9614081780788774 | 0.9631559810932008 |
| Validation Metrics |  0.00186360990929 | 0.694742304421 | 0.6853448275862069 | 0.5482758620689655 | 0.6091954022988506 |
|    Test Metrics    |  0.00203063701009 | 0.680361579957 | 0.6779661016949152 | 0.517799352750809  | 0.5871559633027522 |
+--------------------+-------------------+----------------+--------------------+--------------------+--------------------+
_________________________________________________________________
Time:
    Train Time              : 4:59:29.452935
    Dataset Loading Time    : 0:00:38.227356
    Metrics Evaluation Time : 0:08:22.041961
_________________________________________________________________
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         (None, 288, 288, 1)       0         
_________________________________________________________________
conv_1 (Conv2D)              (None, 288, 288, 32)      320       
_________________________________________________________________
norm_1 (BatchNormalization)  (None, 288, 288, 32)      128       
_________________________________________________________________
relu_1 (LeakyReLU)           (None, 288, 288, 32)      0         
_________________________________________________________________
pool_1 (MaxPooling2D)        (None, 144, 144, 32)      0         
_________________________________________________________________
conv_2 (Conv2D)              (None, 144, 144, 64)      18496     
_________________________________________________________________
norm_2 (BatchNormalization)  (None, 144, 144, 64)      256       
_________________________________________________________________
relu_2 (LeakyReLU)           (None, 144, 144, 64)      0         
_________________________________________________________________
pool_2 (MaxPooling2D)        (None, 72, 72, 64)        0         
_________________________________________________________________
conv_3 (Conv2D)              (None, 72, 72, 128)       73856     
_________________________________________________________________
norm_3 (BatchNormalization)  (None, 72, 72, 128)       512       
_________________________________________________________________
relu_3 (LeakyReLU)           (None, 72, 72, 128)       0         
_________________________________________________________________
conv_4 (Conv2D)              (None, 72, 72, 64)        8256      
_________________________________________________________________
norm_4 (BatchNormalization)  (None, 72, 72, 64)        256       
_________________________________________________________________
relu_4 (LeakyReLU)           (None, 72, 72, 64)        0         
_________________________________________________________________
conv_5 (Conv2D)              (None, 72, 72, 128)       73856     
_________________________________________________________________
norm_5 (BatchNormalization)  (None, 72, 72, 128)       512       
_________________________________________________________________
relu_5 (LeakyReLU)           (None, 72, 72, 128)       0         
_________________________________________________________________
pool_3 (MaxPooling2D)        (None, 36, 36, 128)       0         
_________________________________________________________________
conv_6 (Conv2D)              (None, 36, 36, 256)       295168    
_________________________________________________________________
norm_6 (BatchNormalization)  (None, 36, 36, 256)       1024      
_________________________________________________________________
relu_6 (LeakyReLU)           (None, 36, 36, 256)       0         
_________________________________________________________________
conv_7 (Conv2D)              (None, 36, 36, 128)       32896     
_________________________________________________________________
norm_7 (BatchNormalization)  (None, 36, 36, 128)       512       
_________________________________________________________________
relu_7 (LeakyReLU)           (None, 36, 36, 128)       0         
_________________________________________________________________
conv_8 (Conv2D)              (None, 36, 36, 256)       295168    
_________________________________________________________________
norm_8 (BatchNormalization)  (None, 36, 36, 256)       1024      
_________________________________________________________________
relu_8 (LeakyReLU)           (None, 36, 36, 256)       0         
_________________________________________________________________
pool_4 (MaxPooling2D)        (None, 18, 18, 256)       0         
_________________________________________________________________
conv_9 (Conv2D)              (None, 18, 18, 512)       1180160   
_________________________________________________________________
norm_9 (BatchNormalization)  (None, 18, 18, 512)       2048      
_________________________________________________________________
relu_9 (LeakyReLU)           (None, 18, 18, 512)       0         
_________________________________________________________________
conv_10 (Conv2D)             (None, 18, 18, 256)       131328    
_________________________________________________________________
norm_10 (BatchNormalization) (None, 18, 18, 256)       1024      
_________________________________________________________________
relu_10 (LeakyReLU)          (None, 18, 18, 256)       0         
_________________________________________________________________
conv_11 (Conv2D)             (None, 18, 18, 512)       1180160   
_________________________________________________________________
norm_11 (BatchNormalization) (None, 18, 18, 512)       2048      
_________________________________________________________________
relu_11 (LeakyReLU)          (None, 18, 18, 512)       0         
_________________________________________________________________
conv_12 (Conv2D)             (None, 18, 18, 256)       131328    
_________________________________________________________________
norm_12 (BatchNormalization) (None, 18, 18, 256)       1024      
_________________________________________________________________
relu_12 (LeakyReLU)          (None, 18, 18, 256)       0         
_________________________________________________________________
conv_13 (Conv2D)             (None, 18, 18, 512)       1180160   
_________________________________________________________________
norm_13 (BatchNormalization) (None, 18, 18, 512)       2048      
_________________________________________________________________
relu_13 (LeakyReLU)          (None, 18, 18, 512)       0         
_________________________________________________________________
pool_5 (MaxPooling2D)        (None, 9, 9, 512)         0         
_________________________________________________________________
conv_14 (Conv2D)             (None, 9, 9, 1024)        4719616   
_________________________________________________________________
norm_14 (BatchNormalization) (None, 9, 9, 1024)        4096      
_________________________________________________________________
relu_14 (LeakyReLU)          (None, 9, 9, 1024)        0         
_________________________________________________________________
drop_1 (Dropout)             (None, 9, 9, 1024)        0         
_________________________________________________________________
conv_15 (Conv2D)             (None, 9, 9, 1024)        9438208   
_________________________________________________________________
norm_15 (BatchNormalization) (None, 9, 9, 1024)        4096      
_________________________________________________________________
relu_15 (LeakyReLU)          (None, 9, 9, 1024)        0         
_________________________________________________________________
drop_2 (Dropout)             (None, 9, 9, 1024)        0         
_________________________________________________________________
conv_16 (Conv2D)             (None, 9, 9, 5)           5125      
_________________________________________________________________
reshape_1 (Reshape)          (None, 9, 9, 5)           0         
=================================================================
Total params: 18,784,709
Trainable params: 18,774,405
Non-trainable params: 10,304
_________________________________________________________________
+----------+----------------------+--------------+------------------+--------------------+---------------------+------------------+
|  Epoch   |       f1_score       |     iou      |       loss       |     precision      |        recall       |     val_loss     |
+----------+----------------------+--------------+------------------+--------------------+---------------------+------------------+
| Epoch 1  |         nan          |     nan      | 0.00701767993793 |        nan         |         0.0         | 0.00518735678121 |
| Epoch 2  |         nan          |     nan      |  0.005082730481  |        nan         |         0.0         | 0.00708680548891 |
| Epoch 3  | 0.004667444574095683 | 0.7515872793 | 0.00488183760975 | 0.6666666666666666 | 0.00234192037470726 | 0.00648639988899 |
| Epoch 4  |         nan          |     nan      |       nan        |        nan         |         0.0         |       nan        |
| Epoch 5  |         nan          |     nan      |       nan        |        nan         |         0.0         |       nan        |
| Epoch 6  |         nan          |     nan      |       nan        |        nan         |         0.0         |       nan        |
| Epoch 7  |         nan          |     nan      |       nan        |        nan         |         0.0         |       nan        |
| Epoch 8  |         nan          |     nan      |       nan        |        nan         |         0.0         |       nan        |
| Epoch 9  |         nan          |     nan      |       nan        |        nan         |         0.0         |       nan        |
| Epoch 10 |         nan          |     nan      |       nan        |        nan         |         0.0         |       nan        |
| Epoch 11 |         nan          |     nan      |       nan        |        nan         |         0.0         |       nan        |
| Epoch 12 |         nan          |     nan      |       nan        |        nan         |         0.0         |       nan        |
| Epoch 13 |         nan          |     nan      |       nan        |        nan         |         0.0         |       nan        |
| Epoch 14 |         nan          |     nan      |       nan        |        nan         |         0.0         |       nan        |
| Epoch 15 |         nan          |     nan      |       nan        |        nan         |         0.0         |       nan        |
| Epoch 16 |         nan          |     nan      |       nan        |        nan         |         0.0         |       nan        |
| Epoch 17 |         nan          |     nan      |       nan        |        nan         |         0.0         |       nan        |
| Epoch 18 |         nan          |     nan      |       nan        |        nan         |         0.0         |       nan        |
| Epoch 19 |         nan          |     nan      |       nan        |        nan         |         0.0         |       nan        |
| Epoch 20 |         nan          |     nan      |       nan        |        nan         |         0.0         |       nan        |
| Epoch 21 |         nan          |     nan      |       nan        |        nan         |         0.0         |       nan        |
| Epoch 22 |         nan          |     nan      |       nan        |        nan         |         0.0         |       nan        |
| Epoch 23 |         nan          |     nan      |       nan        |        nan         |         0.0         |       nan        |
| Epoch 24 |         nan          |     nan      |       nan        |        nan         |         0.0         |       nan        |
| Epoch 25 |         nan          |     nan      |       nan        |        nan         |         0.0         |       nan        |
| Epoch 26 |         nan          |     nan      |       nan        |        nan         |         0.0         |       nan        |
| Epoch 27 |         nan          |     nan      |       nan        |        nan         |         0.0         |       nan        |
| Epoch 28 |         nan          |     nan      |       nan        |        nan         |         0.0         |       nan        |
| Epoch 29 |         nan          |     nan      |       nan        |        nan         |         0.0         |       nan        |
| Epoch 30 |         nan          |     nan      |       nan        |        nan         |         0.0         |       nan        |
+----------+----------------------+--------------+------------------+--------------------+---------------------+------------------+
_________________________________________________________________
+---------------------------------+--------------------+--------------------+-----------------------+---------+-----------------------+
|            Optimizer            |       beta_1       |       beta_2       |         decay         | epsilon |           lr          |
+---------------------------------+--------------------+--------------------+-----------------------+---------+-----------------------+
| <class 'keras.optimizers.Adam'> | 0.8999999761581421 | 0.9990000128746033 | 0.0005000000237487257 |  1e-08  | 0.0010000000474974513 |
+---------------------------------+--------------------+--------------------+-----------------------+---------+-----------------------+
_________________________________________________________________
+------------+
| Batch Size |
+------------+
|     16     |
+------------+
_________________________________________________________________
+--------------------+------+-----+-----------+--------+----------+
|      Metrics       | Loss | IoU | Precision | Recall | F1 Score |
+--------------------+------+-----+-----------+--------+----------+
|   Train Metrics    | nan  | nan |    nan    |  0.0   |   nan    |
| Validation Metrics | nan  | nan |    nan    |  0.0   |   nan    |
|    Test Metrics    | nan  | nan |    nan    |  0.0   |   nan    |
+--------------------+------+-----+-----------+--------+----------+
_________________________________________________________________
Time:
    Train Time              : 5:53:52.297997
    Dataset Loading Time    : 0:08:04.420542
    Metrics Evaluation Time : 0:19:12.215657
_________________________________________________________________
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         (None, 288, 288, 1)       0         
_________________________________________________________________
conv_1 (Conv2D)              (None, 288, 288, 32)      320       
_________________________________________________________________
norm_1 (BatchNormalization)  (None, 288, 288, 32)      128       
_________________________________________________________________
relu_1 (LeakyReLU)           (None, 288, 288, 32)      0         
_________________________________________________________________
pool_1 (MaxPooling2D)        (None, 144, 144, 32)      0         
_________________________________________________________________
conv_2 (Conv2D)              (None, 144, 144, 64)      18496     
_________________________________________________________________
norm_2 (BatchNormalization)  (None, 144, 144, 64)      256       
_________________________________________________________________
relu_2 (LeakyReLU)           (None, 144, 144, 64)      0         
_________________________________________________________________
pool_2 (MaxPooling2D)        (None, 72, 72, 64)        0         
_________________________________________________________________
conv_3 (Conv2D)              (None, 72, 72, 128)       73856     
_________________________________________________________________
norm_3 (BatchNormalization)  (None, 72, 72, 128)       512       
_________________________________________________________________
relu_3 (LeakyReLU)           (None, 72, 72, 128)       0         
_________________________________________________________________
drop_1 (Dropout)             (None, 72, 72, 128)       0         
_________________________________________________________________
conv_4 (Conv2D)              (None, 72, 72, 64)        8256      
_________________________________________________________________
norm_4 (BatchNormalization)  (None, 72, 72, 64)        256       
_________________________________________________________________
relu_4 (LeakyReLU)           (None, 72, 72, 64)        0         
_________________________________________________________________
conv_5 (Conv2D)              (None, 72, 72, 128)       73856     
_________________________________________________________________
norm_5 (BatchNormalization)  (None, 72, 72, 128)       512       
_________________________________________________________________
relu_5 (LeakyReLU)           (None, 72, 72, 128)       0         
_________________________________________________________________
pool_3 (MaxPooling2D)        (None, 36, 36, 128)       0         
_________________________________________________________________
conv_6 (Conv2D)              (None, 36, 36, 256)       295168    
_________________________________________________________________
norm_6 (BatchNormalization)  (None, 36, 36, 256)       1024      
_________________________________________________________________
relu_6 (LeakyReLU)           (None, 36, 36, 256)       0         
_________________________________________________________________
drop_2 (Dropout)             (None, 36, 36, 256)       0         
_________________________________________________________________
conv_7 (Conv2D)              (None, 36, 36, 128)       32896     
_________________________________________________________________
norm_7 (BatchNormalization)  (None, 36, 36, 128)       512       
_________________________________________________________________
relu_7 (LeakyReLU)           (None, 36, 36, 128)       0         
_________________________________________________________________
conv_8 (Conv2D)              (None, 36, 36, 256)       295168    
_________________________________________________________________
norm_8 (BatchNormalization)  (None, 36, 36, 256)       1024      
_________________________________________________________________
relu_8 (LeakyReLU)           (None, 36, 36, 256)       0         
_________________________________________________________________
pool_4 (MaxPooling2D)        (None, 18, 18, 256)       0         
_________________________________________________________________
conv_9 (Conv2D)              (None, 18, 18, 512)       1180160   
_________________________________________________________________
norm_9 (BatchNormalization)  (None, 18, 18, 512)       2048      
_________________________________________________________________
relu_9 (LeakyReLU)           (None, 18, 18, 512)       0         
_________________________________________________________________
drop_3 (Dropout)             (None, 18, 18, 512)       0         
_________________________________________________________________
conv_10 (Conv2D)             (None, 18, 18, 256)       131328    
_________________________________________________________________
norm_10 (BatchNormalization) (None, 18, 18, 256)       1024      
_________________________________________________________________
relu_10 (LeakyReLU)          (None, 18, 18, 256)       0         
_________________________________________________________________
conv_11 (Conv2D)             (None, 18, 18, 512)       1180160   
_________________________________________________________________
norm_11 (BatchNormalization) (None, 18, 18, 512)       2048      
_________________________________________________________________
relu_11 (LeakyReLU)          (None, 18, 18, 512)       0         
_________________________________________________________________
conv_12 (Conv2D)             (None, 18, 18, 256)       131328    
_________________________________________________________________
norm_12 (BatchNormalization) (None, 18, 18, 256)       1024      
_________________________________________________________________
relu_12 (LeakyReLU)          (None, 18, 18, 256)       0         
_________________________________________________________________
conv_13 (Conv2D)             (None, 18, 18, 512)       1180160   
_________________________________________________________________
norm_13 (BatchNormalization) (None, 18, 18, 512)       2048      
_________________________________________________________________
relu_13 (LeakyReLU)          (None, 18, 18, 512)       0         
_________________________________________________________________
pool_5 (MaxPooling2D)        (None, 9, 9, 512)         0         
_________________________________________________________________
conv_14 (Conv2D)             (None, 9, 9, 1024)        4719616   
_________________________________________________________________
norm_14 (BatchNormalization) (None, 9, 9, 1024)        4096      
_________________________________________________________________
relu_14 (LeakyReLU)          (None, 9, 9, 1024)        0         
_________________________________________________________________
drop_4 (Dropout)             (None, 9, 9, 1024)        0         
_________________________________________________________________
conv_15 (Conv2D)             (None, 9, 9, 1024)        9438208   
_________________________________________________________________
norm_15 (BatchNormalization) (None, 9, 9, 1024)        4096      
_________________________________________________________________
relu_15 (LeakyReLU)          (None, 9, 9, 1024)        0         
_________________________________________________________________
drop_5 (Dropout)             (None, 9, 9, 1024)        0         
_________________________________________________________________
conv_16 (Conv2D)             (None, 9, 9, 5)           5125      
_________________________________________________________________
reshape_1 (Reshape)          (None, 9, 9, 5)           0         
=================================================================
Total params: 18,784,709
Trainable params: 18,774,405
Non-trainable params: 10,304
_________________________________________________________________
+----------+-----------------------+----------------+------------------+---------------------+---------------------+------------------+
|  Epoch   |        f1_score       |      iou       |       loss       |      precision      |        recall       |     val_loss     |
+----------+-----------------------+----------------+------------------+---------------------+---------------------+------------------+
| Epoch 1  |          nan          |      nan       |  0.011221901944  |         nan         |         0.0         | 0.0104372905791  |
| Epoch 2  |          nan          |      nan       |  0.007379860337  |         nan         |         0.0         | 0.0209088948667  |
| Epoch 3  |          nan          |      nan       | 0.00644588467746 |         nan         |         0.0         | 0.0147126479968  |
| Epoch 4  |          nan          |      nan       | 0.00597647598173 |         nan         |         0.0         | 0.0153340963721  |
| Epoch 5  |          nan          |      nan       | 0.00537321076986 |         nan         |         0.0         |  0.016308736816  |
| Epoch 6  |          nan          |      nan       | 0.00516506058779 |         nan         |         0.0         | 0.0172986419201  |
| Epoch 7  |          nan          |      nan       | 0.00508435364739 |         nan         |         0.0         | 0.0181416584998  |
| Epoch 8  |          nan          |      nan       | 0.00500160962739 |         nan         |         0.0         | 0.0164447425306  |
| Epoch 9  |          nan          |      nan       | 0.00494264958235 |         nan         |         0.0         | 0.0185896267444  |
| Epoch 10 |          nan          |      nan       | 0.00488362134991 |         nan         |         0.0         |  0.013004304409  |
| Epoch 11 |          nan          |      nan       | 0.00483087110832 |         nan         |         0.0         | 0.0116035511643  |
| Epoch 12 |          nan          |      nan       | 0.00478260984056 |         nan         |         0.0         | 0.0123210280761  |
| Epoch 13 |          nan          |      nan       | 0.00474427683038 |         nan         |         0.0         | 0.0100142261013  |
| Epoch 14 |          nan          |      nan       | 0.00468562396218 |         nan         |         0.0         | 0.00947489758581 |
| Epoch 15 |          nan          |      nan       | 0.00464794685402 |         nan         |         0.0         | 0.0107674797401  |
| Epoch 16 |  0.002320185614849188 | 0.59514434862  | 0.00460128677076 |        0.125        | 0.00117096018735363 | 0.0087070075646  |
| Epoch 17 |  0.01775804661487236  | 0.615209575558 | 0.0045676924979  |  0.1702127659574468 | 0.00936768149882904 | 0.00741265258193 |
| Epoch 18 |  0.052980132450331126 | 0.609995489708 | 0.00453436362205 | 0.46153846153846156 | 0.02810304449648712 | 0.00636524087191 |
| Epoch 19 | 0.0023014959723820483 | 0.617977354188 | 0.0044825692772  | 0.06666666666666667 | 0.00117096018735363 | 0.00802082490176 |
| Epoch 20 |  0.024971623155505107 | 0.598554612978 | 0.00444854874194 |  0.4074074074074074 | 0.01288056206088993 | 0.00592485563457 |
| Epoch 21 |  0.03181818181818182  | 0.647088390576 | 0.00441680704614 |  0.5384615384615384 | 0.01639344262295082 | 0.00586694239825 |
| Epoch 22 |  0.032036613272311214 | 0.681325247133 | 0.00437392044958 |         0.7         | 0.01639344262295082 | 0.00566838989407 |
| Epoch 23 |  0.011248593925759281 | 0.610555241251 | 0.00435874472249 | 0.14285714285714285 | 0.00585480093676815 | 0.00690127467364 |
| Epoch 24 |   0.0836734693877551  | 0.656953982028 | 0.00431022455291 |  0.3253968253968254 | 0.04800936768149883 | 0.00557207092643 |
| Epoch 25 |  0.05966850828729282  | 0.619386210074 | 0.00428552475382 |  0.5294117647058824 | 0.03161592505854801 | 0.00569696550816 |
| Epoch 26 |  0.04255319148936171  | 0.654687166236 | 0.00424931595736 | 0.48717948717948717 | 0.02224824355971897 | 0.00555603771284 |
| Epoch 27 |  0.04237288135593221  | 0.624487899201 | 0.00422466896132 |  0.2222222222222222 |  0.0234192037470726 | 0.00586541139334 |
| Epoch 28 |  0.09462365591397849  | 0.674454485452 | 0.00419648766864 |  0.5789473684210527 | 0.05152224824355972 | 0.00487201760337 |
| Epoch 29 |  0.030735455543358943 | 0.629526875921 | 0.00416363810143 | 0.24561403508771928 | 0.01639344262295082 | 0.00583136723191 |
| Epoch 30 |  0.08221993833504625  | 0.648613423523 | 0.00413172410382 | 0.33613445378151263 |  0.0468384074941452 | 0.00514785069227 |
+----------+-----------------------+----------------+------------------+---------------------+---------------------+------------------+
_________________________________________________________________
+---------------------------------+--------------------+--------------------+-----------------------+---------+-----------------------+
|            Optimizer            |       beta_1       |       beta_2       |         decay         | epsilon |           lr          |
+---------------------------------+--------------------+--------------------+-----------------------+---------+-----------------------+
| <class 'keras.optimizers.Adam'> | 0.8999999761581421 | 0.9990000128746033 | 4.999999873689376e-05 |  1e-08  | 9.999999747378752e-05 |
+---------------------------------+--------------------+--------------------+-----------------------+---------+-----------------------+
_________________________________________________________________
+------------+
| Batch Size |
+------------+
|     16     |
+------------+
_________________________________________________________________
+--------------------+------------------+----------------+---------------------+----------------------+---------------------+
|      Metrics       |       Loss       |      IoU       |      Precision      |        Recall        |       F1 Score      |
+--------------------+------------------+----------------+---------------------+----------------------+---------------------+
|   Train Metrics    | 0.00488957721317 | 0.648455908317 | 0.43689765947682424 | 0.06420285945508497  | 0.11195390133474452 |
| Validation Metrics | 0.00514785018563 | 0.648613423523 | 0.33613445378151263 |  0.0468384074941452  | 0.08221993833504625 |
|    Test Metrics    | 0.00519416810572 | 0.655820569174 |  0.3821138211382114 | 0.053591790193842644 | 0.09399999999999999 |
+--------------------+------------------+----------------+---------------------+----------------------+---------------------+
_________________________________________________________________
Time:
    Train Time              : 6:14:25.222214
    Dataset Loading Time    : 0:08:02.069197
    Metrics Evaluation Time : 0:18:04.924432
_________________________________________________________________
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         (None, 288, 288, 1)       0         
_________________________________________________________________
conv_1 (Conv2D)              (None, 288, 288, 32)      320       
_________________________________________________________________
norm_1 (BatchNormalization)  (None, 288, 288, 32)      128       
_________________________________________________________________
relu_1 (LeakyReLU)           (None, 288, 288, 32)      0         
_________________________________________________________________
pool_1 (MaxPooling2D)        (None, 144, 144, 32)      0         
_________________________________________________________________
conv_2 (Conv2D)              (None, 144, 144, 64)      18496     
_________________________________________________________________
norm_2 (BatchNormalization)  (None, 144, 144, 64)      256       
_________________________________________________________________
relu_2 (LeakyReLU)           (None, 144, 144, 64)      0         
_________________________________________________________________
pool_2 (MaxPooling2D)        (None, 72, 72, 64)        0         
_________________________________________________________________
conv_3 (Conv2D)              (None, 72, 72, 128)       73856     
_________________________________________________________________
norm_3 (BatchNormalization)  (None, 72, 72, 128)       512       
_________________________________________________________________
relu_3 (LeakyReLU)           (None, 72, 72, 128)       0         
_________________________________________________________________
drop_1 (Dropout)             (None, 72, 72, 128)       0         
_________________________________________________________________
conv_4 (Conv2D)              (None, 72, 72, 64)        8256      
_________________________________________________________________
norm_4 (BatchNormalization)  (None, 72, 72, 64)        256       
_________________________________________________________________
relu_4 (LeakyReLU)           (None, 72, 72, 64)        0         
_________________________________________________________________
conv_5 (Conv2D)              (None, 72, 72, 128)       73856     
_________________________________________________________________
norm_5 (BatchNormalization)  (None, 72, 72, 128)       512       
_________________________________________________________________
relu_5 (LeakyReLU)           (None, 72, 72, 128)       0         
_________________________________________________________________
pool_3 (MaxPooling2D)        (None, 36, 36, 128)       0         
_________________________________________________________________
conv_6 (Conv2D)              (None, 36, 36, 256)       295168    
_________________________________________________________________
norm_6 (BatchNormalization)  (None, 36, 36, 256)       1024      
_________________________________________________________________
relu_6 (LeakyReLU)           (None, 36, 36, 256)       0         
_________________________________________________________________
drop_2 (Dropout)             (None, 36, 36, 256)       0         
_________________________________________________________________
conv_7 (Conv2D)              (None, 36, 36, 128)       32896     
_________________________________________________________________
norm_7 (BatchNormalization)  (None, 36, 36, 128)       512       
_________________________________________________________________
relu_7 (LeakyReLU)           (None, 36, 36, 128)       0         
_________________________________________________________________
conv_8 (Conv2D)              (None, 36, 36, 256)       295168    
_________________________________________________________________
norm_8 (BatchNormalization)  (None, 36, 36, 256)       1024      
_________________________________________________________________
relu_8 (LeakyReLU)           (None, 36, 36, 256)       0         
_________________________________________________________________
pool_4 (MaxPooling2D)        (None, 18, 18, 256)       0         
_________________________________________________________________
conv_9 (Conv2D)              (None, 18, 18, 512)       1180160   
_________________________________________________________________
norm_9 (BatchNormalization)  (None, 18, 18, 512)       2048      
_________________________________________________________________
relu_9 (LeakyReLU)           (None, 18, 18, 512)       0         
_________________________________________________________________
drop_3 (Dropout)             (None, 18, 18, 512)       0         
_________________________________________________________________
conv_10 (Conv2D)             (None, 18, 18, 256)       131328    
_________________________________________________________________
norm_10 (BatchNormalization) (None, 18, 18, 256)       1024      
_________________________________________________________________
relu_10 (LeakyReLU)          (None, 18, 18, 256)       0         
_________________________________________________________________
conv_11 (Conv2D)             (None, 18, 18, 512)       1180160   
_________________________________________________________________
norm_11 (BatchNormalization) (None, 18, 18, 512)       2048      
_________________________________________________________________
relu_11 (LeakyReLU)          (None, 18, 18, 512)       0         
_________________________________________________________________
conv_12 (Conv2D)             (None, 18, 18, 256)       131328    
_________________________________________________________________
norm_12 (BatchNormalization) (None, 18, 18, 256)       1024      
_________________________________________________________________
relu_12 (LeakyReLU)          (None, 18, 18, 256)       0         
_________________________________________________________________
conv_13 (Conv2D)             (None, 18, 18, 512)       1180160   
_________________________________________________________________
norm_13 (BatchNormalization) (None, 18, 18, 512)       2048      
_________________________________________________________________
relu_13 (LeakyReLU)          (None, 18, 18, 512)       0         
_________________________________________________________________
pool_5 (MaxPooling2D)        (None, 9, 9, 512)         0         
_________________________________________________________________
conv_14 (Conv2D)             (None, 9, 9, 1024)        4719616   
_________________________________________________________________
norm_14 (BatchNormalization) (None, 9, 9, 1024)        4096      
_________________________________________________________________
relu_14 (LeakyReLU)          (None, 9, 9, 1024)        0         
_________________________________________________________________
drop_4 (Dropout)             (None, 9, 9, 1024)        0         
_________________________________________________________________
conv_15 (Conv2D)             (None, 9, 9, 1024)        9438208   
_________________________________________________________________
norm_15 (BatchNormalization) (None, 9, 9, 1024)        4096      
_________________________________________________________________
relu_15 (LeakyReLU)          (None, 9, 9, 1024)        0         
_________________________________________________________________
drop_5 (Dropout)             (None, 9, 9, 1024)        0         
_________________________________________________________________
conv_16 (Conv2D)             (None, 9, 9, 5)           5125      
_________________________________________________________________
reshape_1 (Reshape)          (None, 9, 9, 5)           0         
=================================================================
Total params: 18,784,709
Trainable params: 18,774,405
Non-trainable params: 10,304
_________________________________________________________________
+----------+---------------------+----------------+------------------+---------------------+----------------------+------------------+
|  Epoch   |       f1_score      |      iou       |       loss       |      precision      |        recall        |     val_loss     |
+----------+---------------------+----------------+------------------+---------------------+----------------------+------------------+
| Epoch 1  | 0.05530973451327433 | 0.648631424388 | 0.00410759932272 |         0.5         | 0.02927400468384075  | 0.00537991247326 |
| Epoch 2  | 0.04264870931537598 | 0.674050819109 | 0.00407475962142 |  0.5135135135135135 | 0.02224824355971897  | 0.0051352227442  |
| Epoch 3  | 0.06540084388185653 | 0.683669268618 | 0.00404099273256 | 0.32978723404255317 | 0.03629976580796253  | 0.00519166851789 |
| Epoch 4  | 0.07851239669421488 | 0.66104684878  | 0.00400813654041 |  0.3333333333333333 | 0.04449648711943794  | 0.00497434205189 |
| Epoch 5  | 0.10621062106210621 | 0.658080239137 | 0.00397835311602 | 0.22957198443579765 | 0.06908665105386416  | 0.00514725224674 |
| Epoch 6  | 0.07531380753138076 | 0.632246745623 | 0.00396361238433 | 0.35294117647058826 | 0.04215456674473068  | 0.00539242695272 |
| Epoch 7  | 0.08806262230919765 | 0.637736743025 | 0.00392875624813 | 0.26785714285714285 | 0.05269320843091335  | 0.0052386110276  |
| Epoch 8  | 0.08720379146919431 | 0.63136763708  | 0.00389552259066 | 0.22885572139303484 | 0.053864168618266976 | 0.00523050253093 |
| Epoch 9  | 0.11742777260018639 | 0.646208157105 | 0.00386760097525 |  0.2876712328767123 | 0.07377049180327869  | 0.0047680792436  |
| Epoch 10 | 0.09655172413793105 | 0.67214910829  | 0.00384573156578 | 0.30434782608695654 | 0.05737704918032787  | 0.00456959678233 |
| Epoch 11 | 0.10110294117647058 | 0.638632386722 | 0.00381436556724 | 0.23504273504273504 | 0.06440281030444965  | 0.00524481660128 |
| Epoch 12 | 0.16834400731930466 | 0.684056969003 | 0.00378487897639 | 0.38493723849372385 | 0.10772833723653395  | 0.00449672617391 |
| Epoch 13 |  0.0938566552901024 | 0.63892344269  | 0.00375429569714 | 0.17295597484276728 | 0.06440281030444965  | 0.00543041570485 |
| Epoch 14 | 0.14768683274021352 | 0.639632410303 | 0.00372164640069 |  0.3074074074074074 | 0.09718969555035128  | 0.0047384916693  |
| Epoch 15 | 0.14902624894157496 | 0.64587407741  | 0.00371040925505 |  0.2691131498470948 | 0.10304449648711944  | 0.00482338416204 |
| Epoch 16 | 0.13725490196078433 | 0.647018842215 | 0.00366500059654 |  0.2873134328358209 | 0.09016393442622951  | 0.00474782775342 |
| Epoch 17 | 0.18858560794044663 | 0.677021421282 | 0.0036289946122  |  0.3211267605633803 | 0.13348946135831383  | 0.00462347803265 |
| Epoch 18 | 0.13506493506493505 | 0.64558768105  | 0.00360375302333 |  0.2591362126245847 | 0.09133489461358314  | 0.00491618607193 |
| Epoch 19 |  0.2125984251968504 | 0.662570977534 | 0.00356146985182 |  0.3245192307692308 | 0.15807962529274006  | 0.00461505766213 |
| Epoch 20 | 0.18839487565938207 | 0.651290195524 | 0.00354036054617 |  0.2642706131078224 | 0.14637002341920374  | 0.00469397284836 |
| Epoch 21 |  0.2068416865552904 | 0.662016767989 | 0.00350630203139 |  0.3225806451612903 |  0.1522248243559719  | 0.00458605223522 |
| Epoch 22 | 0.18156028368794325 | 0.649249412478 | 0.00348236129614 |  0.2302158273381295 | 0.14988290398126464  | 0.00484956100211 |
| Epoch 23 | 0.15705128205128205 | 0.639210111955 | 0.00344522626519 | 0.24873096446700507 | 0.11475409836065574  | 0.00496192148328 |
| Epoch 24 | 0.17733990147783255 | 0.656033223656 | 0.00342154143437 |  0.2967032967032967 | 0.12646370023419204  | 0.00475962695479 |
| Epoch 25 | 0.20826446280991734 | 0.662860489439 | 0.00337899647624 |  0.3539325842696629 | 0.14754098360655737  | 0.00457454311848 |
| Epoch 26 |  0.1876675603217158 | 0.643531922699 | 0.00334627016352 |  0.219435736677116  | 0.16393442622950818  | 0.00492498382926 |
| Epoch 27 |  0.1780185758513932 | 0.629889379534 | 0.00330956850174 |  0.2625570776255708 | 0.13466042154566746  | 0.00499325758219 |
| Epoch 28 |  0.1689933872152829 | 0.647204618895 | 0.00327768406418 | 0.22682445759368836 | 0.13466042154566746  | 0.0049783777222  |
| Epoch 29 | 0.22943722943722947 | 0.659186891564 | 0.0032487575368  | 0.29887218045112784 | 0.18618266978922718  | 0.0047016130425  |
| Epoch 30 |  0.2217453505007153 | 0.654723599497 | 0.00320439494305 |  0.2849264705882353 | 0.18149882903981265  | 0.00480382324383 |
+----------+---------------------+----------------+------------------+---------------------+----------------------+------------------+
_________________________________________________________________
+---------------------------------+--------------------+--------------------+-----------------------+---------+-----------------------+
|            Optimizer            |       beta_1       |       beta_2       |         decay         | epsilon |           lr          |
+---------------------------------+--------------------+--------------------+-----------------------+---------+-----------------------+
| <class 'keras.optimizers.Adam'> | 0.8999999761581421 | 0.9990000128746033 | 0.0005000000237487257 |  1e-08  | 0.0010000000474974513 |
+---------------------------------+--------------------+--------------------+-----------------------+---------+-----------------------+
_________________________________________________________________
+------------+
| Batch Size |
+------------+
|     16     |
+------------+
_________________________________________________________________
+--------------------+------------------+----------------+---------------------+---------------------+---------------------+
|      Metrics       |       Loss       |      IoU       |      Precision      |        Recall       |       F1 Score      |
+--------------------+------------------+----------------+---------------------+---------------------+---------------------+
|   Train Metrics    | 0.00331436748105 | 0.669334630785 |  0.4633661491859144 |  0.3301186943620178 |  0.3855545053560176 |
| Validation Metrics | 0.00480382324755 | 0.654723599497 |  0.2849264705882353 | 0.18149882903981265 |  0.2217453505007153 |
|    Test Metrics    | 0.00484085623175 | 0.654579004887 | 0.26334519572953735 | 0.16875712656784492 | 0.20569840166782488 |
+--------------------+------------------+----------------+---------------------+---------------------+---------------------+
_________________________________________________________________
Time:
    Train Time              : 6:39:26.716113
    Dataset Loading Time    : 0:09:16.052675
    Metrics Evaluation Time : 0:22:04.440540
_________________________________________________________________
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         (None, 288, 288, 1)       0         
_________________________________________________________________
conv_1 (Conv2D)              (None, 288, 288, 32)      320       
_________________________________________________________________
norm_1 (BatchNormalization)  (None, 288, 288, 32)      128       
_________________________________________________________________
relu_1 (LeakyReLU)           (None, 288, 288, 32)      0         
_________________________________________________________________
pool_1 (MaxPooling2D)        (None, 144, 144, 32)      0         
_________________________________________________________________
conv_2 (Conv2D)              (None, 144, 144, 64)      18496     
_________________________________________________________________
norm_2 (BatchNormalization)  (None, 144, 144, 64)      256       
_________________________________________________________________
relu_2 (LeakyReLU)           (None, 144, 144, 64)      0         
_________________________________________________________________
pool_2 (MaxPooling2D)        (None, 72, 72, 64)        0         
_________________________________________________________________
conv_3 (Conv2D)              (None, 72, 72, 128)       73856     
_________________________________________________________________
norm_3 (BatchNormalization)  (None, 72, 72, 128)       512       
_________________________________________________________________
relu_3 (LeakyReLU)           (None, 72, 72, 128)       0         
_________________________________________________________________
drop_1 (Dropout)             (None, 72, 72, 128)       0         
_________________________________________________________________
conv_4 (Conv2D)              (None, 72, 72, 64)        8256      
_________________________________________________________________
norm_4 (BatchNormalization)  (None, 72, 72, 64)        256       
_________________________________________________________________
relu_4 (LeakyReLU)           (None, 72, 72, 64)        0         
_________________________________________________________________
conv_5 (Conv2D)              (None, 72, 72, 128)       73856     
_________________________________________________________________
norm_5 (BatchNormalization)  (None, 72, 72, 128)       512       
_________________________________________________________________
relu_5 (LeakyReLU)           (None, 72, 72, 128)       0         
_________________________________________________________________
pool_3 (MaxPooling2D)        (None, 36, 36, 128)       0         
_________________________________________________________________
conv_6 (Conv2D)              (None, 36, 36, 256)       295168    
_________________________________________________________________
norm_6 (BatchNormalization)  (None, 36, 36, 256)       1024      
_________________________________________________________________
relu_6 (LeakyReLU)           (None, 36, 36, 256)       0         
_________________________________________________________________
drop_2 (Dropout)             (None, 36, 36, 256)       0         
_________________________________________________________________
conv_7 (Conv2D)              (None, 36, 36, 128)       32896     
_________________________________________________________________
norm_7 (BatchNormalization)  (None, 36, 36, 128)       512       
_________________________________________________________________
relu_7 (LeakyReLU)           (None, 36, 36, 128)       0         
_________________________________________________________________
conv_8 (Conv2D)              (None, 36, 36, 256)       295168    
_________________________________________________________________
norm_8 (BatchNormalization)  (None, 36, 36, 256)       1024      
_________________________________________________________________
relu_8 (LeakyReLU)           (None, 36, 36, 256)       0         
_________________________________________________________________
pool_4 (MaxPooling2D)        (None, 18, 18, 256)       0         
_________________________________________________________________
conv_9 (Conv2D)              (None, 18, 18, 512)       1180160   
_________________________________________________________________
norm_9 (BatchNormalization)  (None, 18, 18, 512)       2048      
_________________________________________________________________
relu_9 (LeakyReLU)           (None, 18, 18, 512)       0         
_________________________________________________________________
drop_3 (Dropout)             (None, 18, 18, 512)       0         
_________________________________________________________________
conv_10 (Conv2D)             (None, 18, 18, 256)       131328    
_________________________________________________________________
norm_10 (BatchNormalization) (None, 18, 18, 256)       1024      
_________________________________________________________________
relu_10 (LeakyReLU)          (None, 18, 18, 256)       0         
_________________________________________________________________
conv_11 (Conv2D)             (None, 18, 18, 512)       1180160   
_________________________________________________________________
norm_11 (BatchNormalization) (None, 18, 18, 512)       2048      
_________________________________________________________________
relu_11 (LeakyReLU)          (None, 18, 18, 512)       0         
_________________________________________________________________
conv_12 (Conv2D)             (None, 18, 18, 256)       131328    
_________________________________________________________________
norm_12 (BatchNormalization) (None, 18, 18, 256)       1024      
_________________________________________________________________
relu_12 (LeakyReLU)          (None, 18, 18, 256)       0         
_________________________________________________________________
conv_13 (Conv2D)             (None, 18, 18, 512)       1180160   
_________________________________________________________________
norm_13 (BatchNormalization) (None, 18, 18, 512)       2048      
_________________________________________________________________
relu_13 (LeakyReLU)          (None, 18, 18, 512)       0         
_________________________________________________________________
pool_5 (MaxPooling2D)        (None, 9, 9, 512)         0         
_________________________________________________________________
conv_14 (Conv2D)             (None, 9, 9, 1024)        4719616   
_________________________________________________________________
norm_14 (BatchNormalization) (None, 9, 9, 1024)        4096      
_________________________________________________________________
relu_14 (LeakyReLU)          (None, 9, 9, 1024)        0         
_________________________________________________________________
drop_4 (Dropout)             (None, 9, 9, 1024)        0         
_________________________________________________________________
conv_15 (Conv2D)             (None, 9, 9, 1024)        9438208   
_________________________________________________________________
norm_15 (BatchNormalization) (None, 9, 9, 1024)        4096      
_________________________________________________________________
relu_15 (LeakyReLU)          (None, 9, 9, 1024)        0         
_________________________________________________________________
drop_5 (Dropout)             (None, 9, 9, 1024)        0         
_________________________________________________________________
conv_16 (Conv2D)             (None, 9, 9, 5)           5125      
_________________________________________________________________
reshape_1 (Reshape)          (None, 9, 9, 5)           0         
=================================================================
Total params: 18,784,709
Trainable params: 18,774,405
Non-trainable params: 10,304
_________________________________________________________________
+----------+---------------------+----------------+------------------+---------------------+---------------------+------------------+
|  Epoch   |       f1_score      |      iou       |       loss       |      precision      |        recall       |     val_loss     |
+----------+---------------------+----------------+------------------+---------------------+---------------------+------------------+
| Epoch 1  | 0.19846153846153847 | 0.668857375529 | 0.00318767934993 |  0.289237668161435  | 0.15105386416861827 | 0.00475149658322 |
| Epoch 2  | 0.18503401360544217 | 0.627795953476 | 0.0031307263314  | 0.22077922077922077 |  0.1592505854800937 | 0.0049742462635  |
| Epoch 3  | 0.18633540372670807 | 0.654805711354 | 0.0031075309142  |  0.226890756302521  | 0.15807962529274006 | 0.00494906501472 |
| Epoch 4  |  0.2064935064935065 | 0.645775123528 | 0.00307904627705 | 0.23177842565597667 | 0.18618266978922718 | 0.00497782119364 |
| Epoch 5  | 0.24383164005805516 | 0.66673662209  | 0.00303466292817 | 0.32061068702290074 | 0.19672131147540983 | 0.00471215377748 |
| Epoch 6  |  0.2387301587301587 | 0.656364458692 | 0.00302046663998 |  0.260748959778086  | 0.22014051522248243 | 0.00489696118608 |
| Epoch 7  | 0.20147058823529412 | 0.659528103514 | 0.00297793754474 |  0.2707509881422925 | 0.16042154566744732 | 0.00483662338927 |
| Epoch 8  | 0.24162836506894284 | 0.652708576013 | 0.0029409287422  |  0.2750373692077728 |  0.2154566744730679 | 0.00483548863977 |
| Epoch 9  | 0.23032904148783975 | 0.649896735504 | 0.00289161313481 |  0.2959558823529412 |  0.1885245901639344 | 0.00486189794168 |
| Epoch 10 |  0.2340720221606648 | 0.659258061432 | 0.00287426751333 |  0.2864406779661017 | 0.19789227166276346 | 0.00484474958107 |
| Epoch 11 | 0.23944636678200693 | 0.66075954698  | 0.00283100628364 |  0.2927241962774958 |  0.202576112412178  | 0.0047946407944  |
| Epoch 12 | 0.23914590747330958 | 0.657719687244 | 0.00281740632103 | 0.30490018148820325 | 0.19672131147540983 | 0.00474831265211 |
| Epoch 13 | 0.21736249171636846 | 0.654723555707 | 0.00278167165419 |  0.250381679389313  |  0.1920374707259953 | 0.00495043855906 |
| Epoch 14 | 0.24945612762871647 | 0.66450168859  | 0.00275412239989 | 0.32761904761904764 | 0.20140515222482436 | 0.00477559967339 |
| Epoch 15 | 0.23669467787114845 | 0.661503071942 | 0.00272188031439 | 0.29442508710801396 | 0.19789227166276346 | 0.00485612387955 |
| Epoch 16 |  0.2467263955892488 | 0.650889524171 | 0.00269229340183 |  0.2998324958123953 | 0.20960187353629978 | 0.00482826349512 |
| Epoch 17 | 0.23249490142760026 | 0.657646767698 | 0.00267365735002 |  0.2771474878444084 | 0.20023419203747073 | 0.0049298587963  |
| Epoch 18 | 0.24787997390737115 | 0.649064777351 | 0.00262864590021 | 0.27982326951399117 |  0.2224824355971897 | 0.00491678794101 |
| Epoch 19 | 0.23246217331499314 | 0.666052439848 | 0.00261146061857 |  0.2816666666666667 | 0.19789227166276346 | 0.00486108907312 |
| Epoch 20 | 0.24102911306702776 | 0.653024735304 | 0.00256227732731 |  0.2857142857142857 | 0.20843091334894615 | 0.00491293780878 |
| Epoch 21 | 0.21864050455501052 | 0.65637703591  | 0.00253484417996 | 0.27225130890052357 | 0.18266978922716628 | 0.00497293822467 |
| Epoch 22 |  0.2511505588428665 | 0.655881341072 | 0.00252003303005 |  0.2863568215892054 | 0.22365339578454332 | 0.00492983055487 |
| Epoch 23 | 0.25686813186813184 | 0.665016252431 | 0.00248127857448 |  0.3106312292358804 |  0.2189695550351288 | 0.00485408572108 |
| Epoch 24 | 0.24258064516129033 | 0.653850211222 | 0.00246582306646 | 0.27011494252873564 | 0.22014051522248243 | 0.00496840805933 |
| Epoch 25 |  0.2519083969465649 | 0.649624549564 | 0.00243677430833 |  0.2757660167130919 | 0.23185011709601874 | 0.00497293232381 |
| Epoch 26 | 0.24277456647398846 | 0.658079459702 | 0.00240868697854 | 0.26884779516358465 | 0.22131147540983606 | 0.00502618049085 |
| Epoch 27 | 0.22529069767441862 | 0.663145068533 | 0.00237866621267 | 0.29693486590038315 | 0.18149882903981265 | 0.00483635877073 |
| Epoch 28 | 0.22133863485752153 | 0.658156183431 | 0.00235220744936 |  0.2549618320610687 |  0.1955503512880562 | 0.00503264537826 |
| Epoch 29 | 0.22125543816034804 | 0.659660558089 | 0.00233508896332 | 0.23576158940397351 | 0.20843091334894615 | 0.00507120433822 |
| Epoch 30 | 0.23342175066312998 | 0.655574339742 | 0.00230457890262 |  0.2691131498470948 | 0.20608899297423888 | 0.00498044692352 |
+----------+---------------------+----------------+------------------+---------------------+---------------------+------------------+
_________________________________________________________________
+---------------------------------+--------------------+--------------------+----------------------+---------+----------------------+
|            Optimizer            |       beta_1       |       beta_2       |        decay         | epsilon |          lr          |
+---------------------------------+--------------------+--------------------+----------------------+---------+----------------------+
| <class 'keras.optimizers.Adam'> | 0.8999999761581421 | 0.9990000128746033 | 0.004999999888241291 |  1e-08  | 0.009999999776482582 |
+---------------------------------+--------------------+--------------------+----------------------+---------+----------------------+
_________________________________________________________________
+------------+
| Batch Size |
+------------+
|     16     |
+------------+
_________________________________________________________________
+--------------------+------------------+----------------+--------------------+---------------------+---------------------+
|      Metrics       |       Loss       |      IoU       |     Precision      |        Recall       |       F1 Score      |
+--------------------+------------------+----------------+--------------------+---------------------+---------------------+
|   Train Metrics    | 0.00202305543238 | 0.699199541055 | 0.6082474226804123 |  0.537159428108983  |  0.5704974393868854 |
| Validation Metrics | 0.0049804463014  | 0.655574339742 | 0.2691131498470948 | 0.20608899297423888 | 0.23342175066312998 |
|    Test Metrics    | 0.00502334584296 | 0.650358211916 | 0.2790346907993967 | 0.21094640820980615 | 0.24025974025974026 |
+--------------------+------------------+----------------+--------------------+---------------------+---------------------+
_________________________________________________________________
Time:
    Train Time              : 6:38:17.072727
    Dataset Loading Time    : 0:08:10.627263
    Metrics Evaluation Time : 0:20:38.917446
_________________________________________________________________
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         (None, 288, 288, 1)       0         
_________________________________________________________________
conv_1 (Conv2D)              (None, 288, 288, 32)      320       
_________________________________________________________________
norm_1 (BatchNormalization)  (None, 288, 288, 32)      128       
_________________________________________________________________
relu_1 (LeakyReLU)           (None, 288, 288, 32)      0         
_________________________________________________________________
pool_1 (MaxPooling2D)        (None, 144, 144, 32)      0         
_________________________________________________________________
conv_2 (Conv2D)              (None, 144, 144, 64)      18496     
_________________________________________________________________
norm_2 (BatchNormalization)  (None, 144, 144, 64)      256       
_________________________________________________________________
relu_2 (LeakyReLU)           (None, 144, 144, 64)      0         
_________________________________________________________________
pool_2 (MaxPooling2D)        (None, 72, 72, 64)        0         
_________________________________________________________________
conv_3 (Conv2D)              (None, 72, 72, 128)       73856     
_________________________________________________________________
norm_3 (BatchNormalization)  (None, 72, 72, 128)       512       
_________________________________________________________________
relu_3 (LeakyReLU)           (None, 72, 72, 128)       0         
_________________________________________________________________
drop_1 (Dropout)             (None, 72, 72, 128)       0         
_________________________________________________________________
conv_4 (Conv2D)              (None, 72, 72, 64)        8256      
_________________________________________________________________
norm_4 (BatchNormalization)  (None, 72, 72, 64)        256       
_________________________________________________________________
relu_4 (LeakyReLU)           (None, 72, 72, 64)        0         
_________________________________________________________________
conv_5 (Conv2D)              (None, 72, 72, 128)       73856     
_________________________________________________________________
norm_5 (BatchNormalization)  (None, 72, 72, 128)       512       
_________________________________________________________________
relu_5 (LeakyReLU)           (None, 72, 72, 128)       0         
_________________________________________________________________
pool_3 (MaxPooling2D)        (None, 36, 36, 128)       0         
_________________________________________________________________
conv_6 (Conv2D)              (None, 36, 36, 256)       295168    
_________________________________________________________________
norm_6 (BatchNormalization)  (None, 36, 36, 256)       1024      
_________________________________________________________________
relu_6 (LeakyReLU)           (None, 36, 36, 256)       0         
_________________________________________________________________
drop_2 (Dropout)             (None, 36, 36, 256)       0         
_________________________________________________________________
conv_7 (Conv2D)              (None, 36, 36, 128)       32896     
_________________________________________________________________
norm_7 (BatchNormalization)  (None, 36, 36, 128)       512       
_________________________________________________________________
relu_7 (LeakyReLU)           (None, 36, 36, 128)       0         
_________________________________________________________________
conv_8 (Conv2D)              (None, 36, 36, 256)       295168    
_________________________________________________________________
norm_8 (BatchNormalization)  (None, 36, 36, 256)       1024      
_________________________________________________________________
relu_8 (LeakyReLU)           (None, 36, 36, 256)       0         
_________________________________________________________________
pool_4 (MaxPooling2D)        (None, 18, 18, 256)       0         
_________________________________________________________________
conv_9 (Conv2D)              (None, 18, 18, 512)       1180160   
_________________________________________________________________
norm_9 (BatchNormalization)  (None, 18, 18, 512)       2048      
_________________________________________________________________
relu_9 (LeakyReLU)           (None, 18, 18, 512)       0         
_________________________________________________________________
drop_3 (Dropout)             (None, 18, 18, 512)       0         
_________________________________________________________________
conv_10 (Conv2D)             (None, 18, 18, 256)       131328    
_________________________________________________________________
norm_10 (BatchNormalization) (None, 18, 18, 256)       1024      
_________________________________________________________________
relu_10 (LeakyReLU)          (None, 18, 18, 256)       0         
_________________________________________________________________
conv_11 (Conv2D)             (None, 18, 18, 512)       1180160   
_________________________________________________________________
norm_11 (BatchNormalization) (None, 18, 18, 512)       2048      
_________________________________________________________________
relu_11 (LeakyReLU)          (None, 18, 18, 512)       0         
_________________________________________________________________
conv_12 (Conv2D)             (None, 18, 18, 256)       131328    
_________________________________________________________________
norm_12 (BatchNormalization) (None, 18, 18, 256)       1024      
_________________________________________________________________
relu_12 (LeakyReLU)          (None, 18, 18, 256)       0         
_________________________________________________________________
conv_13 (Conv2D)             (None, 18, 18, 512)       1180160   
_________________________________________________________________
norm_13 (BatchNormalization) (None, 18, 18, 512)       2048      
_________________________________________________________________
relu_13 (LeakyReLU)          (None, 18, 18, 512)       0         
_________________________________________________________________
pool_5 (MaxPooling2D)        (None, 9, 9, 512)         0         
_________________________________________________________________
conv_14 (Conv2D)             (None, 9, 9, 1024)        4719616   
_________________________________________________________________
norm_14 (BatchNormalization) (None, 9, 9, 1024)        4096      
_________________________________________________________________
relu_14 (LeakyReLU)          (None, 9, 9, 1024)        0         
_________________________________________________________________
drop_4 (Dropout)             (None, 9, 9, 1024)        0         
_________________________________________________________________
conv_15 (Conv2D)             (None, 9, 9, 1024)        9438208   
_________________________________________________________________
norm_15 (BatchNormalization) (None, 9, 9, 1024)        4096      
_________________________________________________________________
relu_15 (LeakyReLU)          (None, 9, 9, 1024)        0         
_________________________________________________________________
drop_5 (Dropout)             (None, 9, 9, 1024)        0         
_________________________________________________________________
conv_16 (Conv2D)             (None, 9, 9, 5)           5125      
_________________________________________________________________
reshape_1 (Reshape)          (None, 9, 9, 5)           0         
=================================================================
Total params: 18,784,709
Trainable params: 18,774,405
Non-trainable params: 10,304
_________________________________________________________________
+----------+---------------------+----------------+------------------+---------------------+---------------------+------------------+
|  Epoch   |       f1_score      |      iou       |       loss       |      precision      |        recall       |     val_loss     |
+----------+---------------------+----------------+------------------+---------------------+---------------------+------------------+
| Epoch 1  | 0.24605678233438483 | 0.668719527315 | 0.00229096972706 |  0.2667578659370725 | 0.22833723653395785 | 0.00498507171497 |
| Epoch 2  | 0.21601941747572814 | 0.65429554132  | 0.00227084293231 | 0.22418136020151133 | 0.20843091334894615 | 0.00521236722544 |
| Epoch 3  |  0.2303523035230352 | 0.656486033702 | 0.00223776067645 |  0.2733118971061093 |  0.1990632318501171 | 0.0049681318514  |
| Epoch 4  |  0.2488658457550227 | 0.656175038774 | 0.00222963779733 | 0.27866473149492016 | 0.22482435597189696 | 0.00499561625347 |
| Epoch 5  | 0.19850187265917602 | 0.656460865302 | 0.00218875944153 | 0.21256684491978609 | 0.18618266978922718 | 0.00522806352004 |
| Epoch 6  |  0.2561826252377932 | 0.66007982501  | 0.00216895672005 |  0.2793914246196404 | 0.23653395784543327 | 0.00500807573274 |
| Epoch 7  | 0.22466107165913493 | 0.665225049459 | 0.00214979667349 |  0.2503597122302158 | 0.20374707259953162 | 0.00507313190773 |
| Epoch 8  |  0.2542030934767989 | 0.663654080508 | 0.00212198024727 |  0.2985781990521327 | 0.22131147540983606 | 0.00492539337277 |
| Epoch 9  | 0.24730500951173115 | 0.657519272564 | 0.0021021229644  |  0.2697095435684647 | 0.22833723653395785 | 0.00505217757821 |
| Epoch 10 | 0.24405506883604502 | 0.665846356461 | 0.00209474954598 |  0.2620967741935484 | 0.22833723653395785 | 0.0050382950753  |
| Epoch 11 |  0.2329974811083123 | 0.66083587072  | 0.00206682746028 | 0.25204359673024523 | 0.21662763466042154 | 0.00515183266252 |
| Epoch 12 | 0.26515151515151514 | 0.658659014044 | 0.00204995054578 |  0.2876712328767123 |  0.2459016393442623 | 0.00503862415254 |
| Epoch 13 | 0.23434593924364536 | 0.657033902494 | 0.00203643800189 |  0.2490118577075099 | 0.22131147540983606 | 0.00506436693668 |
| Epoch 14 | 0.20747422680412375 | 0.667372596701 | 0.00201581115517 | 0.23065902578796563 |  0.1885245901639344 | 0.00510633123294 |
| Epoch 15 |  0.2506887052341598 | 0.661448670523 | 0.00199893869436 | 0.30434782608695654 | 0.21311475409836064 | 0.00500259754807 |
| Epoch 16 | 0.25339366515837103 | 0.662151297089 | 0.00198987452669 |  0.2828282828282828 | 0.22950819672131148 | 0.00506111748517 |
| Epoch 17 | 0.25034387895460797 | 0.66976011103  | 0.00195572313268 | 0.30333333333333334 | 0.21311475409836064 | 0.00493203215301 |
| Epoch 18 | 0.21941992433795712 | 0.665257751643 | 0.00195244853887 | 0.23770491803278687 | 0.20374707259953162 | 0.00513237557933 |
| Epoch 19 |  0.2364394993045897 | 0.66789625566  | 0.00193792968503 |  0.2910958904109589 |  0.1990632318501171 | 0.00498908472806 |
| Epoch 20 |  0.2509907529722589 | 0.659592276889 | 0.00191579171415 |  0.2878787878787879 |  0.2224824355971897 |  0.005017091427  |
| Epoch 21 |  0.231237322515213  | 0.652862541445 | 0.00189636500546 |        0.2736       | 0.20023419203747073 | 0.00501321107894 |
| Epoch 22 |  0.2310188189487346 | 0.662630835436 | 0.0019021375784  |  0.2590975254730713 | 0.20843091334894615 | 0.00507925333083 |
| Epoch 23 | 0.22845691382765532 |  0.6594368066  | 0.0018728772476  | 0.26594090202177295 | 0.20023419203747073 | 0.00507170863822 |
| Epoch 24 | 0.22792736380713835 | 0.66019135982  | 0.00186590291701 |  0.2449528936742934 | 0.21311475409836064 | 0.00520104399696 |
| Epoch 25 |      0.22265625     | 0.656395440183 | 0.00183240696479 |  0.250733137829912  | 0.20023419203747073 | 0.00512246614695 |
| Epoch 26 | 0.22297297297297294 | 0.661754566107 | 0.00182051853039 | 0.26357827476038337 | 0.19320843091334894 | 0.00503621437773 |
| Epoch 27 | 0.25080385852090037 | 0.662897281066 | 0.00180973902892 |  0.2781740370898716 | 0.22833723653395785 | 0.00511961581931 |
| Epoch 28 | 0.23411371237458192 | 0.654254128903 | 0.00180677123837 | 0.27301092043681746 | 0.20491803278688525 | 0.00511743104458 |
| Epoch 29 | 0.22121014964216007 | 0.659053538457 | 0.00178442500628 | 0.24890190336749635 |  0.1990632318501171 | 0.0051000075601  |
| Epoch 30 |  0.2368421052631579 | 0.657642020333 | 0.00177721569919 |  0.2702702702702703 |  0.2107728337236534 | 0.00514702611789 |
+----------+---------------------+----------------+------------------+---------------------+---------------------+------------------+
_________________________________________________________________
+---------------------------------+--------------------+--------------------+---------------------+---------+---------------------+
|            Optimizer            |       beta_1       |       beta_2       |        decay        | epsilon |          lr         |
+---------------------------------+--------------------+--------------------+---------------------+---------+---------------------+
| <class 'keras.optimizers.Adam'> | 0.8999999761581421 | 0.9990000128746033 | 0.05000000074505806 |  1e-08  | 0.10000000149011612 |
+---------------------------------+--------------------+--------------------+---------------------+---------+---------------------+
_________________________________________________________________
+------------+
| Batch Size |
+------------+
|     16     |
+------------+
_________________________________________________________________
+--------------------+------------------+----------------+--------------------+---------------------+---------------------+
|      Metrics       |       Loss       |      IoU       |     Precision      |        Recall       |       F1 Score      |
+--------------------+------------------+----------------+--------------------+---------------------+---------------------+
|   Train Metrics    | 0.00155677707445 | 0.705333222919 | 0.6721689059500959 |  0.5904370110601564 |  0.6286575952321114 |
| Validation Metrics | 0.0051470259726  | 0.657642020333 | 0.2702702702702703 |  0.2107728337236534 |  0.2368421052631579 |
|    Test Metrics    | 0.0051324358955  | 0.660356160055 | 0.2720125786163522 | 0.19726339794754846 | 0.22868473231989425 |
+--------------------+------------------+----------------+--------------------+---------------------+---------------------+
_________________________________________________________________
Time:
    Train Time              : 6:35:33.109619
    Dataset Loading Time    : 0:08:17.110800
    Metrics Evaluation Time : 0:21:07.141284
_________________________________________________________________
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         (None, 288, 288, 1)       0         
_________________________________________________________________
conv_1 (Conv2D)              (None, 288, 288, 32)      320       
_________________________________________________________________
norm_1 (BatchNormalization)  (None, 288, 288, 32)      128       
_________________________________________________________________
relu_1 (LeakyReLU)           (None, 288, 288, 32)      0         
_________________________________________________________________
pool_1 (MaxPooling2D)        (None, 144, 144, 32)      0         
_________________________________________________________________
conv_2 (Conv2D)              (None, 144, 144, 64)      18496     
_________________________________________________________________
norm_2 (BatchNormalization)  (None, 144, 144, 64)      256       
_________________________________________________________________
relu_2 (LeakyReLU)           (None, 144, 144, 64)      0         
_________________________________________________________________
pool_2 (MaxPooling2D)        (None, 72, 72, 64)        0         
_________________________________________________________________
conv_3 (Conv2D)              (None, 72, 72, 128)       73856     
_________________________________________________________________
norm_3 (BatchNormalization)  (None, 72, 72, 128)       512       
_________________________________________________________________
relu_3 (LeakyReLU)           (None, 72, 72, 128)       0         
_________________________________________________________________
drop_1 (Dropout)             (None, 72, 72, 128)       0         
_________________________________________________________________
conv_4 (Conv2D)              (None, 72, 72, 64)        8256      
_________________________________________________________________
norm_4 (BatchNormalization)  (None, 72, 72, 64)        256       
_________________________________________________________________
relu_4 (LeakyReLU)           (None, 72, 72, 64)        0         
_________________________________________________________________
conv_5 (Conv2D)              (None, 72, 72, 128)       73856     
_________________________________________________________________
norm_5 (BatchNormalization)  (None, 72, 72, 128)       512       
_________________________________________________________________
relu_5 (LeakyReLU)           (None, 72, 72, 128)       0         
_________________________________________________________________
pool_3 (MaxPooling2D)        (None, 36, 36, 128)       0         
_________________________________________________________________
conv_6 (Conv2D)              (None, 36, 36, 256)       295168    
_________________________________________________________________
norm_6 (BatchNormalization)  (None, 36, 36, 256)       1024      
_________________________________________________________________
relu_6 (LeakyReLU)           (None, 36, 36, 256)       0         
_________________________________________________________________
drop_2 (Dropout)             (None, 36, 36, 256)       0         
_________________________________________________________________
conv_7 (Conv2D)              (None, 36, 36, 128)       32896     
_________________________________________________________________
norm_7 (BatchNormalization)  (None, 36, 36, 128)       512       
_________________________________________________________________
relu_7 (LeakyReLU)           (None, 36, 36, 128)       0         
_________________________________________________________________
conv_8 (Conv2D)              (None, 36, 36, 256)       295168    
_________________________________________________________________
norm_8 (BatchNormalization)  (None, 36, 36, 256)       1024      
_________________________________________________________________
relu_8 (LeakyReLU)           (None, 36, 36, 256)       0         
_________________________________________________________________
pool_4 (MaxPooling2D)        (None, 18, 18, 256)       0         
_________________________________________________________________
conv_9 (Conv2D)              (None, 18, 18, 512)       1180160   
_________________________________________________________________
norm_9 (BatchNormalization)  (None, 18, 18, 512)       2048      
_________________________________________________________________
relu_9 (LeakyReLU)           (None, 18, 18, 512)       0         
_________________________________________________________________
drop_3 (Dropout)             (None, 18, 18, 512)       0         
_________________________________________________________________
conv_10 (Conv2D)             (None, 18, 18, 256)       131328    
_________________________________________________________________
norm_10 (BatchNormalization) (None, 18, 18, 256)       1024      
_________________________________________________________________
relu_10 (LeakyReLU)          (None, 18, 18, 256)       0         
_________________________________________________________________
conv_11 (Conv2D)             (None, 18, 18, 512)       1180160   
_________________________________________________________________
norm_11 (BatchNormalization) (None, 18, 18, 512)       2048      
_________________________________________________________________
relu_11 (LeakyReLU)          (None, 18, 18, 512)       0         
_________________________________________________________________
conv_12 (Conv2D)             (None, 18, 18, 256)       131328    
_________________________________________________________________
norm_12 (BatchNormalization) (None, 18, 18, 256)       1024      
_________________________________________________________________
relu_12 (LeakyReLU)          (None, 18, 18, 256)       0         
_________________________________________________________________
conv_13 (Conv2D)             (None, 18, 18, 512)       1180160   
_________________________________________________________________
norm_13 (BatchNormalization) (None, 18, 18, 512)       2048      
_________________________________________________________________
relu_13 (LeakyReLU)          (None, 18, 18, 512)       0         
_________________________________________________________________
pool_5 (MaxPooling2D)        (None, 9, 9, 512)         0         
_________________________________________________________________
conv_14 (Conv2D)             (None, 9, 9, 1024)        4719616   
_________________________________________________________________
norm_14 (BatchNormalization) (None, 9, 9, 1024)        4096      
_________________________________________________________________
relu_14 (LeakyReLU)          (None, 9, 9, 1024)        0         
_________________________________________________________________
drop_4 (Dropout)             (None, 9, 9, 1024)        0         
_________________________________________________________________
conv_15 (Conv2D)             (None, 9, 9, 1024)        9438208   
_________________________________________________________________
norm_15 (BatchNormalization) (None, 9, 9, 1024)        4096      
_________________________________________________________________
relu_15 (LeakyReLU)          (None, 9, 9, 1024)        0         
_________________________________________________________________
drop_5 (Dropout)             (None, 9, 9, 1024)        0         
_________________________________________________________________
conv_16 (Conv2D)             (None, 9, 9, 5)           5125      
_________________________________________________________________
reshape_1 (Reshape)          (None, 9, 9, 5)           0         
=================================================================
Total params: 18,784,709
Trainable params: 18,774,405
Non-trainable params: 10,304
_________________________________________________________________
+----------+---------------------+----------------+------------------+---------------------+---------------------+------------------+
|  Epoch   |       f1_score      |      iou       |       loss       |      precision      |        recall       |     val_loss     |
+----------+---------------------+----------------+------------------+---------------------+---------------------+------------------+
| Epoch 1  | 0.19793814432989693 | 0.657365227062 | 0.00318068582956 | 0.23960066555740434 |  0.1686182669789227 | 0.00482097766921 |
| Epoch 2  | 0.18480492813141683 | 0.630110678128 | 0.00314035049408 | 0.22240527182866557 | 0.15807962529274006 | 0.00495002552867 |
| Epoch 3  | 0.18601297764960348 | 0.648862452371 | 0.00310265266888 | 0.24202626641651032 | 0.15105386416861827 | 0.00484993609041 |
| Epoch 4  | 0.23745583038869258 | 0.660771420023 | 0.00307735857699 |  0.2994652406417112 | 0.19672131147540983 | 0.00472948403284 |
| Epoch 5  | 0.23054331864904556 | 0.658776916573 | 0.00303687261313 |  0.3090551181102362 | 0.18384074941451992 | 0.00476755657047 |
| Epoch 6  | 0.20471464019851116 | 0.650806135712 | 0.00300384327426 | 0.21767810026385223 | 0.19320843091334894 | 0.00503755308688 |
| Epoch 7  | 0.21778084079944868 | 0.657607094702 | 0.00297476001291 |  0.2646566164154104 | 0.18501170960187355 | 0.00481387712434 |
| Epoch 8  |  0.2029520295202952 | 0.647150474415 | 0.0029416139009  | 0.21373056994818654 | 0.19320843091334894 | 0.0049554309845  |
| Epoch 9  | 0.25251846877098727 | 0.659529921971 | 0.00291402760507 | 0.29606299212598425 | 0.22014051522248243 | 0.00481636842713 |
| Epoch 10 | 0.19322990126939352 | 0.635068346629 | 0.00288464237018 |  0.2429078014184397 | 0.16042154566744732 | 0.00491710239649 |
| Epoch 11 | 0.20341296928327646 | 0.638689789874 | 0.00284418135639 | 0.24386252045826515 | 0.17447306791569087 | 0.00505446344614 |
| Epoch 12 | 0.22926500337154415 | 0.656333537588 | 0.00281285649599 |  0.2702702702702703 |  0.1990632318501171 | 0.00488674965128 |
| Epoch 13 | 0.22964509394572025 | 0.657702853823 | 0.00278071374231 |  0.2830188679245283 | 0.19320843091334894 | 0.00486795226485 |
| Epoch 14 | 0.22357723577235772 | 0.65554380017  | 0.00275827142422 |  0.2652733118971061 | 0.19320843091334894 | 0.00496208748594 |
| Epoch 15 | 0.23503325942350334 | 0.65464002993  | 0.0027265931852  |  0.3186372745490982 | 0.18618266978922718 | 0.00479909317195 |
| Epoch 16 | 0.25280898876404495 | 0.664782588301 | 0.00269570070479 |  0.3157894736842105 |  0.2107728337236534 | 0.0048268045336  |
| Epoch 17 |  0.2243243243243243 | 0.65405344376  | 0.00265551468898 | 0.26517571884984026 | 0.19437939110070257 | 0.00491685406119 |
| Epoch 18 | 0.22946175637393768 | 0.651994079326 | 0.00262718838312 |  0.2903225806451613 | 0.18969555035128804 | 0.00484832675755 |
| Epoch 19 | 0.25331564986737404 | 0.659349091242 | 0.00260734688091 | 0.29204892966360857 | 0.22365339578454332 | 0.00496379422769 |
| Epoch 20 |  0.2282608695652174 | 0.667212021199 | 0.00257251160576 | 0.27184466019417475 | 0.19672131147540983 | 0.0049239558652  |
| Epoch 21 |  0.2354515050167224 | 0.664849489282 | 0.00255469467679 |  0.2745709828393136 | 0.20608899297423888 | 0.00491870075837 |
| Epoch 22 | 0.23671155209071582 | 0.668488562278 | 0.00250173573026 |  0.2998204667863555 |  0.1955503512880562 | 0.00484280208871 |
| Epoch 23 | 0.25415070242656446 | 0.658760909352 | 0.00248476311275 |  0.2794943820224719 | 0.23302107728337237 | 0.00499811683595 |
| Epoch 24 | 0.23658872077028886 | 0.653770712267 | 0.00245832353712 |  0.2866666666666667 | 0.20140515222482436 | 0.00492664726824 |
| Epoch 25 | 0.25254582484725047 | 0.657364130623 | 0.00245151471069 | 0.30048465266558966 | 0.21779859484777517 | 0.00490856615081 |
| Epoch 26 | 0.22733423545331527 | 0.666613850883 | 0.00240632651579 |  0.2692307692307692 | 0.19672131147540983 |  0.004930131495  |
| Epoch 27 |  0.2219215155615697 | 0.660569072458 | 0.00238663757888 | 0.26282051282051283 |  0.1920374707259953 | 0.00494535596296 |
| Epoch 28 |  0.2421052631578947 | 0.656537548214 | 0.00234299052451 | 0.27627627627627627 |  0.2154566744730679 | 0.00497881139442 |
| Epoch 29 | 0.25815808556925307 | 0.66456959926  | 0.00233389530483 | 0.33904761904761904 | 0.20843091334894615 | 0.00487281927094 |
| Epoch 30 | 0.23391003460207613 | 0.664380618724 | 0.00230553761637 |  0.2859560067681895 | 0.19789227166276346 | 0.00498744068295 |
+----------+---------------------+----------------+------------------+---------------------+---------------------+------------------+
_________________________________________________________________
+---------------------------------+--------------------+--------------------+-----------------------+---------+-----------------------+
|            Optimizer            |       beta_1       |       beta_2       |         decay         | epsilon |           lr          |
+---------------------------------+--------------------+--------------------+-----------------------+---------+-----------------------+
| <class 'keras.optimizers.Adam'> | 0.8999999761581421 | 0.9990000128746033 | 0.0005000000237487257 |  1e-08  | 0.0010000000474974513 |
+---------------------------------+--------------------+--------------------+-----------------------+---------+-----------------------+
_________________________________________________________________
+------------+
| Batch Size |
+------------+
|     16     |
+------------+
_________________________________________________________________
+--------------------+------------------+----------------+---------------------+---------------------+---------------------+
|      Metrics       |       Loss       |      IoU       |      Precision      |        Recall       |       F1 Score      |
+--------------------+------------------+----------------+---------------------+---------------------+---------------------+
|   Train Metrics    | 0.00212591645535 | 0.691502770663 |  0.6016496846191169 |  0.5017534394388994 |  0.5471795248951974 |
| Validation Metrics | 0.00498744048178 | 0.664380618724 |  0.2859560067681895 | 0.19789227166276346 | 0.23391003460207613 |
|    Test Metrics    | 0.00501799172163 | 0.65966330416  | 0.28183361629881154 | 0.18928164196123148 | 0.22646657571623466 |
+--------------------+------------------+----------------+---------------------+---------------------+---------------------+
_________________________________________________________________
Time:
    Train Time              : 6:38:53.701414
    Dataset Loading Time    : 0:07:29.979569
    Metrics Evaluation Time : 0:22:44.946745
_________________________________________________________________
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         (None, 288, 288, 1)       0         
_________________________________________________________________
conv_1 (Conv2D)              (None, 288, 288, 32)      288       
_________________________________________________________________
norm_1 (BatchNormalization)  (None, 288, 288, 32)      128       
_________________________________________________________________
relu_1 (LeakyReLU)           (None, 288, 288, 32)      0         
_________________________________________________________________
pool_1 (MaxPooling2D)        (None, 144, 144, 32)      0         
_________________________________________________________________
conv_2 (Conv2D)              (None, 144, 144, 64)      18432     
_________________________________________________________________
norm_2 (BatchNormalization)  (None, 144, 144, 64)      256       
_________________________________________________________________
relu_2 (LeakyReLU)           (None, 144, 144, 64)      0         
_________________________________________________________________
pool_2 (MaxPooling2D)        (None, 72, 72, 64)        0         
_________________________________________________________________
conv_3 (Conv2D)              (None, 72, 72, 128)       73728     
_________________________________________________________________
norm_3 (BatchNormalization)  (None, 72, 72, 128)       512       
_________________________________________________________________
relu_3 (LeakyReLU)           (None, 72, 72, 128)       0         
_________________________________________________________________
drop_1 (Dropout)             (None, 72, 72, 128)       0         
_________________________________________________________________
conv_4 (Conv2D)              (None, 72, 72, 64)        8192      
_________________________________________________________________
norm_4 (BatchNormalization)  (None, 72, 72, 64)        256       
_________________________________________________________________
relu_4 (LeakyReLU)           (None, 72, 72, 64)        0         
_________________________________________________________________
conv_5 (Conv2D)              (None, 72, 72, 128)       73728     
_________________________________________________________________
norm_5 (BatchNormalization)  (None, 72, 72, 128)       512       
_________________________________________________________________
relu_5 (LeakyReLU)           (None, 72, 72, 128)       0         
_________________________________________________________________
pool_3 (MaxPooling2D)        (None, 36, 36, 128)       0         
_________________________________________________________________
conv_6 (Conv2D)              (None, 36, 36, 256)       294912    
_________________________________________________________________
norm_6 (BatchNormalization)  (None, 36, 36, 256)       1024      
_________________________________________________________________
relu_6 (LeakyReLU)           (None, 36, 36, 256)       0         
_________________________________________________________________
drop_2 (Dropout)             (None, 36, 36, 256)       0         
_________________________________________________________________
conv_7 (Conv2D)              (None, 36, 36, 128)       32768     
_________________________________________________________________
norm_7 (BatchNormalization)  (None, 36, 36, 128)       512       
_________________________________________________________________
relu_7 (LeakyReLU)           (None, 36, 36, 128)       0         
_________________________________________________________________
conv_8 (Conv2D)              (None, 36, 36, 256)       294912    
_________________________________________________________________
norm_8 (BatchNormalization)  (None, 36, 36, 256)       1024      
_________________________________________________________________
relu_8 (LeakyReLU)           (None, 36, 36, 256)       0         
_________________________________________________________________
pool_4 (MaxPooling2D)        (None, 18, 18, 256)       0         
_________________________________________________________________
conv_9 (Conv2D)              (None, 18, 18, 512)       1179648   
_________________________________________________________________
norm_9 (BatchNormalization)  (None, 18, 18, 512)       2048      
_________________________________________________________________
relu_9 (LeakyReLU)           (None, 18, 18, 512)       0         
_________________________________________________________________
drop_3 (Dropout)             (None, 18, 18, 512)       0         
_________________________________________________________________
conv_10 (Conv2D)             (None, 18, 18, 256)       131072    
_________________________________________________________________
norm_10 (BatchNormalization) (None, 18, 18, 256)       1024      
_________________________________________________________________
relu_10 (LeakyReLU)          (None, 18, 18, 256)       0         
_________________________________________________________________
conv_11 (Conv2D)             (None, 18, 18, 512)       1179648   
_________________________________________________________________
norm_11 (BatchNormalization) (None, 18, 18, 512)       2048      
_________________________________________________________________
relu_11 (LeakyReLU)          (None, 18, 18, 512)       0         
_________________________________________________________________
conv_12 (Conv2D)             (None, 18, 18, 256)       131072    
_________________________________________________________________
norm_12 (BatchNormalization) (None, 18, 18, 256)       1024      
_________________________________________________________________
relu_12 (LeakyReLU)          (None, 18, 18, 256)       0         
_________________________________________________________________
conv_13 (Conv2D)             (None, 18, 18, 512)       1179648   
_________________________________________________________________
norm_13 (BatchNormalization) (None, 18, 18, 512)       2048      
_________________________________________________________________
relu_13 (LeakyReLU)          (None, 18, 18, 512)       0         
_________________________________________________________________
pool_5 (MaxPooling2D)        (None, 9, 9, 512)         0         
_________________________________________________________________
conv_14 (Conv2D)             (None, 9, 9, 1024)        4718592   
_________________________________________________________________
norm_14 (BatchNormalization) (None, 9, 9, 1024)        4096      
_________________________________________________________________
relu_14 (LeakyReLU)          (None, 9, 9, 1024)        0         
_________________________________________________________________
drop_4 (Dropout)             (None, 9, 9, 1024)        0         
_________________________________________________________________
conv_15 (Conv2D)             (None, 9, 9, 1024)        9437184   
_________________________________________________________________
norm_15 (BatchNormalization) (None, 9, 9, 1024)        4096      
_________________________________________________________________
relu_15 (LeakyReLU)          (None, 9, 9, 1024)        0         
_________________________________________________________________
drop_5 (Dropout)             (None, 9, 9, 1024)        0         
_________________________________________________________________
conv_16 (Conv2D)             (None, 9, 9, 5)           5120      
_________________________________________________________________
reshape_1 (Reshape)          (None, 9, 9, 5)           0         
=================================================================
Total params: 18,779,552
Trainable params: 18,769,248
Non-trainable params: 10,304
_________________________________________________________________
+----------+-----------------------+----------------+------------------+----------------------+---------------------+------------------+
|  Epoch   |        f1_score       |      iou       |       loss       |      precision       |        recall       |     val_loss     |
+----------+-----------------------+----------------+------------------+----------------------+---------------------+------------------+
| Epoch 1  |          nan          |      nan       | 0.0105638968622  |         nan          |         0.0         | 0.0115619311109  |
| Epoch 2  |          nan          |      nan       | 0.00734395560271 |         nan          |         0.0         | 0.0204117656127  |
| Epoch 3  |          nan          |      nan       | 0.00638548191371 |         nan          |         0.0         | 0.0252955356091  |
| Epoch 4  |          nan          |      nan       | 0.00587616322364 |         nan          |         0.0         | 0.0186029716358  |
| Epoch 5  |          nan          |      nan       | 0.00546139972454 |         nan          |         0.0         | 0.0168872822449  |
| Epoch 6  |          nan          |      nan       | 0.00519942338586 |         nan          |         0.0         | 0.0188598506451  |
| Epoch 7  |          nan          |      nan       | 0.00509700300621 |         nan          |         0.0         | 0.0185507857203  |
| Epoch 8  |          nan          |      nan       | 0.00500710911454 |         nan          |         0.0         |  0.017649823606  |
| Epoch 9  |          nan          |      nan       | 0.00492740762876 |         nan          |         0.0         | 0.0156303505972  |
| Epoch 10 |          nan          |      nan       | 0.00487441618308 |         nan          |         0.0         | 0.0149880004004  |
| Epoch 11 |          nan          |      nan       | 0.00483267835198 |         0.0          |         0.0         | 0.0134088745192  |
| Epoch 12 |          nan          |      nan       | 0.00479470803167 |         0.0          |         0.0         | 0.0142594276667  |
| Epoch 13 |          nan          |      nan       | 0.00474560797485 |         0.0          |         0.0         | 0.0126533717662  |
| Epoch 14 |          nan          |      nan       | 0.00470726727722 |         0.0          |         0.0         | 0.0121520368457  |
| Epoch 15 |          nan          |      nan       | 0.00465903980324 |         0.0          |         0.0         |  0.010533426635  |
| Epoch 16 |          nan          |      nan       | 0.00462839024625 |         0.0          |         0.0         | 0.0101955680177  |
| Epoch 17 |  0.00211864406779661  | 0.501017235241 | 0.00459032194897 | 0.011111111111111112 | 0.00117096018735363 | 0.00888135671616 |
| Epoch 18 |  0.002244668911335578 | 0.54118111556  | 0.00456124512096 | 0.02702702702702703  | 0.00117096018735363 | 0.00776658026874 |
| Epoch 19 |          nan          |      nan       | 0.0045276452801  |         0.0          |         0.0         | 0.00830266924948 |
| Epoch 20 |  0.004149377593360996 | 0.589012358581 | 0.00448629150964 | 0.01818181818181818  | 0.00234192037470726 | 0.00732139021158 |
| Epoch 21 | 0.0021505376344086026 | 0.507377010102 | 0.00444456386823 | 0.013157894736842105 | 0.00117096018735363 | 0.00745264936984 |
| Epoch 22 |  0.01731601731601732  | 0.622353832801 | 0.00440751146935 | 0.11428571428571428  | 0.00936768149882904 | 0.00724217377603 |
| Epoch 23 |  0.041407867494824016 | 0.578584415251 | 0.00437249357784 | 0.17857142857142858  |  0.0234192037470726 | 0.00628545632213 |
| Epoch 24 |  0.03440860215053764  | 0.588984151948 | 0.0043356574372  | 0.21052631578947367  | 0.01873536299765808 | 0.00651015626639 |
| Epoch 25 |  0.05726405090137859  | 0.648805912717 | 0.00431764994868 | 0.30337078651685395  | 0.03161592505854801 | 0.00575008560717 |
| Epoch 26 |  0.025945945945945948 | 0.611637758354 | 0.00427355089888 | 0.16901408450704225  | 0.01405152224824356 | 0.00638582762331 |
| Epoch 27 |  0.06570841889117043  | 0.621591454908 | 0.0042448054942  | 0.26666666666666666  | 0.03747072599531616 | 0.00551315869763 |
| Epoch 28 |  0.05107252298263534  | 0.628958286198 | 0.00422553160609 |         0.2          | 0.02927400468384075 | 0.00632494699955 |
| Epoch 29 |  0.05911330049261083  | 0.641293119151 | 0.00417773242833 | 0.18633540372670807  |  0.0351288056206089 | 0.00546255607903 |
| Epoch 30 |   0.0842754367934224  | 0.663392315412 | 0.00415359327802 |  0.3445378151260504  | 0.04800936768149883 | 0.00514482603222 |
+----------+-----------------------+----------------+------------------+----------------------+---------------------+------------------+
_________________________________________________________________
+---------------------------------+--------------------+--------------------+-----------------------+---------+-----------------------+
|            Optimizer            |       beta_1       |       beta_2       |         decay         | epsilon |           lr          |
+---------------------------------+--------------------+--------------------+-----------------------+---------+-----------------------+
| <class 'keras.optimizers.Adam'> | 0.8999999761581421 | 0.9990000128746033 | 4.999999873689376e-05 |  1e-08  | 9.999999747378752e-05 |
+---------------------------------+--------------------+--------------------+-----------------------+---------+-----------------------+
_________________________________________________________________
+------------+
| Batch Size |
+------------+
|     16     |
+------------+
_________________________________________________________________
+--------------------+------------------+----------------+---------------------+----------------------+---------------------+
|      Metrics       |       Loss       |      IoU       |      Precision      |        Recall        |       F1 Score      |
+--------------------+------------------+----------------+---------------------+----------------------+---------------------+
|   Train Metrics    | 0.00486005340946 | 0.660601510379 | 0.44137224782386075 | 0.058133261397356355 |  0.1027352362791252 |
| Validation Metrics | 0.00514482593536 | 0.663392315412 |  0.3445378151260504 | 0.04800936768149883  |  0.0842754367934224 |
|    Test Metrics    |  0.005117216371  | 0.709779019918 | 0.36036036036036034 | 0.04561003420752566  | 0.08097165991902834 |
+--------------------+------------------+----------------+---------------------+----------------------+---------------------+
_________________________________________________________________
Time:
    Train Time              : 5:56:54.419220
    Dataset Loading Time    : 0:08:40.544627
    Metrics Evaluation Time : 0:18:08.624705
_________________________________________________________________
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         (None, 288, 288, 1)       0         
_________________________________________________________________
conv_1 (Conv2D)              (None, 288, 288, 32)      288       
_________________________________________________________________
norm_1 (BatchNormalization)  (None, 288, 288, 32)      128       
_________________________________________________________________
relu_1 (LeakyReLU)           (None, 288, 288, 32)      0         
_________________________________________________________________
pool_1 (MaxPooling2D)        (None, 144, 144, 32)      0         
_________________________________________________________________
conv_2 (Conv2D)              (None, 144, 144, 64)      18432     
_________________________________________________________________
norm_2 (BatchNormalization)  (None, 144, 144, 64)      256       
_________________________________________________________________
relu_2 (LeakyReLU)           (None, 144, 144, 64)      0         
_________________________________________________________________
pool_2 (MaxPooling2D)        (None, 72, 72, 64)        0         
_________________________________________________________________
conv_3 (Conv2D)              (None, 72, 72, 128)       73728     
_________________________________________________________________
norm_3 (BatchNormalization)  (None, 72, 72, 128)       512       
_________________________________________________________________
relu_3 (LeakyReLU)           (None, 72, 72, 128)       0         
_________________________________________________________________
drop_1 (Dropout)             (None, 72, 72, 128)       0         
_________________________________________________________________
conv_4 (Conv2D)              (None, 72, 72, 64)        8192      
_________________________________________________________________
norm_4 (BatchNormalization)  (None, 72, 72, 64)        256       
_________________________________________________________________
relu_4 (LeakyReLU)           (None, 72, 72, 64)        0         
_________________________________________________________________
conv_5 (Conv2D)              (None, 72, 72, 128)       73728     
_________________________________________________________________
norm_5 (BatchNormalization)  (None, 72, 72, 128)       512       
_________________________________________________________________
relu_5 (LeakyReLU)           (None, 72, 72, 128)       0         
_________________________________________________________________
pool_3 (MaxPooling2D)        (None, 36, 36, 128)       0         
_________________________________________________________________
conv_6 (Conv2D)              (None, 36, 36, 256)       294912    
_________________________________________________________________
norm_6 (BatchNormalization)  (None, 36, 36, 256)       1024      
_________________________________________________________________
relu_6 (LeakyReLU)           (None, 36, 36, 256)       0         
_________________________________________________________________
drop_2 (Dropout)             (None, 36, 36, 256)       0         
_________________________________________________________________
conv_7 (Conv2D)              (None, 36, 36, 128)       32768     
_________________________________________________________________
norm_7 (BatchNormalization)  (None, 36, 36, 128)       512       
_________________________________________________________________
relu_7 (LeakyReLU)           (None, 36, 36, 128)       0         
_________________________________________________________________
conv_8 (Conv2D)              (None, 36, 36, 256)       294912    
_________________________________________________________________
norm_8 (BatchNormalization)  (None, 36, 36, 256)       1024      
_________________________________________________________________
relu_8 (LeakyReLU)           (None, 36, 36, 256)       0         
_________________________________________________________________
pool_4 (MaxPooling2D)        (None, 18, 18, 256)       0         
_________________________________________________________________
conv_9 (Conv2D)              (None, 18, 18, 512)       1179648   
_________________________________________________________________
norm_9 (BatchNormalization)  (None, 18, 18, 512)       2048      
_________________________________________________________________
relu_9 (LeakyReLU)           (None, 18, 18, 512)       0         
_________________________________________________________________
drop_3 (Dropout)             (None, 18, 18, 512)       0         
_________________________________________________________________
conv_10 (Conv2D)             (None, 18, 18, 256)       131072    
_________________________________________________________________
norm_10 (BatchNormalization) (None, 18, 18, 256)       1024      
_________________________________________________________________
relu_10 (LeakyReLU)          (None, 18, 18, 256)       0         
_________________________________________________________________
conv_11 (Conv2D)             (None, 18, 18, 512)       1179648   
_________________________________________________________________
norm_11 (BatchNormalization) (None, 18, 18, 512)       2048      
_________________________________________________________________
relu_11 (LeakyReLU)          (None, 18, 18, 512)       0         
_________________________________________________________________
conv_12 (Conv2D)             (None, 18, 18, 256)       131072    
_________________________________________________________________
norm_12 (BatchNormalization) (None, 18, 18, 256)       1024      
_________________________________________________________________
relu_12 (LeakyReLU)          (None, 18, 18, 256)       0         
_________________________________________________________________
conv_13 (Conv2D)             (None, 18, 18, 512)       1179648   
_________________________________________________________________
norm_13 (BatchNormalization) (None, 18, 18, 512)       2048      
_________________________________________________________________
relu_13 (LeakyReLU)          (None, 18, 18, 512)       0         
_________________________________________________________________
pool_5 (MaxPooling2D)        (None, 9, 9, 512)         0         
_________________________________________________________________
conv_14 (Conv2D)             (None, 9, 9, 1024)        4718592   
_________________________________________________________________
norm_14 (BatchNormalization) (None, 9, 9, 1024)        4096      
_________________________________________________________________
relu_14 (LeakyReLU)          (None, 9, 9, 1024)        0         
_________________________________________________________________
drop_4 (Dropout)             (None, 9, 9, 1024)        0         
_________________________________________________________________
conv_15 (Conv2D)             (None, 9, 9, 1024)        9437184   
_________________________________________________________________
norm_15 (BatchNormalization) (None, 9, 9, 1024)        4096      
_________________________________________________________________
relu_15 (LeakyReLU)          (None, 9, 9, 1024)        0         
_________________________________________________________________
drop_5 (Dropout)             (None, 9, 9, 1024)        0         
_________________________________________________________________
conv_16 (Conv2D)             (None, 9, 9, 5)           5120      
_________________________________________________________________
reshape_1 (Reshape)          (None, 9, 9, 5)           0         
=================================================================
Total params: 18,779,552
Trainable params: 18,769,248
Non-trainable params: 10,304
_________________________________________________________________
+----------+---------------------+----------------+------------------+---------------------+---------------------+------------------+
|  Epoch   |       f1_score      |      iou       |       loss       |      precision      |        recall       |     val_loss     |
+----------+---------------------+----------------+------------------+---------------------+---------------------+------------------+
| Epoch 1  |  0.112094395280236  | 0.663352635843 | 0.00412042451858 |  0.3496932515337423 | 0.06674473067915691 | 0.0050189133957  |
| Epoch 2  | 0.13384321223709367 | 0.649466360639 | 0.00408681622491 |  0.3645833333333333 | 0.08196721311475409 | 0.00496703465283 |
| Epoch 3  | 0.08849557522123894 | 0.647091565534 | 0.00406650057579 | 0.27607361963190186 | 0.05269320843091335 | 0.00494173379242 |
| Epoch 4  | 0.10779595765158806 | 0.646174635271 | 0.00404544216767 |  0.3027027027027027 | 0.06557377049180328 | 0.00497547825426 |
| Epoch 5  |  0.124031007751938  | 0.643473953176 | 0.00401416629933 |  0.3595505617977528 | 0.07494145199063232 | 0.00478279416263 |
| Epoch 6  | 0.11865864144454001 | 0.646312134729 |  0.003986817173  | 0.22330097087378642 | 0.08079625292740047 | 0.00535829032212 |
| Epoch 7  | 0.14380321665089876 | 0.656662492963 | 0.00395728397392 | 0.37438423645320196 | 0.08899297423887588 | 0.00475521916896 |
| Epoch 8  | 0.14801762114537445 | 0.673519899032 | 0.00392406171536 |  0.298932384341637  | 0.09836065573770492 | 0.00487240553647 |
| Epoch 9  | 0.14586994727592267 | 0.655571815595 | 0.00389261685863 | 0.29225352112676056 | 0.09718969555035128 | 0.00480641406402 |
| Epoch 10 | 0.11153846153846154 | 0.648755274278 | 0.00386400689606 |  0.3118279569892473 | 0.06791569086651054 | 0.00488535902649 |
| Epoch 11 |  0.1892583120204604 | 0.663240795022 | 0.00383555529904 | 0.34796238244514105 | 0.12997658079625293 | 0.00461224265024 |
| Epoch 12 | 0.11528384279475984 | 0.649066374012 | 0.00380446020706 |  0.2268041237113402 | 0.07728337236533958 | 0.00502928646654 |
| Epoch 13 | 0.19106047326906223 | 0.65897671227  | 0.00378233229405 |  0.3797909407665505 | 0.12763466042154567 | 0.00452910381183 |
| Epoch 14 | 0.19188767550702027 | 0.647840510874 | 0.00373739418971 | 0.28738317757009346 | 0.14402810304449648 | 0.00467955219746 |
| Epoch 15 | 0.21760797342192692 | 0.662167556316 | 0.00370087838036 |  0.3742857142857143 | 0.15339578454332553 | 0.00460442573577 |
| Epoch 16 |  0.2263856362217018 | 0.651193661981 | 0.00369430819922 |  0.3395784543325527 | 0.16978922716627634 | 0.00460242741182 |
| Epoch 17 | 0.16952209197475201 | 0.648682930803 | 0.00366228906438 |  0.3686274509803922 | 0.11007025761124122 | 0.00482166733593 |
| Epoch 18 | 0.20091324200913244 | 0.657131938418 | 0.0036128362879  | 0.28695652173913044 | 0.15456674473067916 | 0.00472689647973 |
| Epoch 19 |  0.2421812349639134 | 0.658492066118 | 0.00358773373471 |  0.3842239185750636 | 0.17681498829039813 | 0.0045465294756  |
| Epoch 20 | 0.21129032258064517 | 0.658856331662 | 0.00355537901232 |  0.3393782383419689 | 0.15339578454332553 | 0.00463694538549 |
| Epoch 21 | 0.19419087136929464 | 0.638510422682 | 0.00353422845578 |  0.3333333333333333 | 0.13700234192037472 | 0.00461030428857 |
| Epoch 22 | 0.24439624005784524 | 0.645837822669 | 0.00349131629692 | 0.31947069943289225 | 0.19789227166276346 | 0.00463372994587 |
| Epoch 23 | 0.23218574859887908 | 0.660348642752 | 0.00344956231516 |  0.3670886075949367 | 0.16978922716627634 | 0.00462839313596 |
| Epoch 24 |  0.2586989409984871 | 0.662440427036 | 0.00342043976418 | 0.36538461538461536 | 0.20023419203747073 | 0.00456917771697 |
| Epoch 25 |  0.2471395881006865 | 0.668268183196 | 0.00339656584829 |  0.3544857768052516 | 0.18969555035128804 | 0.00452444119379 |
| Epoch 26 | 0.23908045977011497 | 0.654270452819 | 0.00335335969545 |  0.3458980044345898 | 0.18266978922716628 | 0.00460214443505 |
| Epoch 27 | 0.21962313190383365 | 0.653604969102 | 0.00332817580803 | 0.24671532846715327 | 0.19789227166276346 | 0.00483315487206 |
| Epoch 28 |  0.2284887924801157 | 0.656437100184 | 0.00328985173302 | 0.29867674858223064 | 0.18501170960187355 | 0.00474284636974 |
| Epoch 29 | 0.22052067381316998 | 0.647194204833 | 0.00324394045817 |  0.3185840707964602 |  0.1686182669789227 | 0.0046539292708  |
| Epoch 30 | 0.23367697594501718 | 0.656793776212 | 0.00321996461568 | 0.28286189683860236 |  0.1990632318501171 | 0.00471434356645 |
+----------+---------------------+----------------+------------------+---------------------+---------------------+------------------+
_________________________________________________________________
+---------------------------------+--------------------+--------------------+-----------------------+---------+-----------------------+
|            Optimizer            |       beta_1       |       beta_2       |         decay         | epsilon |           lr          |
+---------------------------------+--------------------+--------------------+-----------------------+---------+-----------------------+
| <class 'keras.optimizers.Adam'> | 0.8999999761581421 | 0.9990000128746033 | 0.0005000000237487257 |  1e-08  | 0.0010000000474974513 |
+---------------------------------+--------------------+--------------------+-----------------------+---------+-----------------------+
_________________________________________________________________
+------------+
| Batch Size |
+------------+
|     16     |
+------------+
_________________________________________________________________
+--------------------+------------------+----------------+---------------------+---------------------+---------------------+
|      Metrics       |       Loss       |      IoU       |      Precision      |        Recall       |       F1 Score      |
+--------------------+------------------+----------------+---------------------+---------------------+---------------------+
|   Train Metrics    | 0.00315391130026 | 0.677763133924 | 0.48478935698447895 | 0.36862692203938496 |  0.4188024365015515 |
| Validation Metrics | 0.00471434352547 | 0.656793776212 | 0.28286189683860236 |  0.1990632318501171 | 0.23367697594501718 |
|    Test Metrics    | 0.00471203133464 | 0.63927679484  |  0.3006535947712418 | 0.20980615735461802 | 0.24714573539288112 |
+--------------------+------------------+----------------+---------------------+---------------------+---------------------+
_________________________________________________________________
Time:
    Train Time              : 6:14:59.247120
    Dataset Loading Time    : 0:07:53.669698
    Metrics Evaluation Time : 0:20:37.899702
_________________________________________________________________
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         (None, 288, 288, 1)       0         
_________________________________________________________________
conv_1 (Conv2D)              (None, 288, 288, 32)      288       
_________________________________________________________________
norm_1 (BatchNormalization)  (None, 288, 288, 32)      128       
_________________________________________________________________
relu_1 (LeakyReLU)           (None, 288, 288, 32)      0         
_________________________________________________________________
pool_1 (MaxPooling2D)        (None, 144, 144, 32)      0         
_________________________________________________________________
conv_2 (Conv2D)              (None, 144, 144, 64)      18432     
_________________________________________________________________
norm_2 (BatchNormalization)  (None, 144, 144, 64)      256       
_________________________________________________________________
relu_2 (LeakyReLU)           (None, 144, 144, 64)      0         
_________________________________________________________________
pool_2 (MaxPooling2D)        (None, 72, 72, 64)        0         
_________________________________________________________________
conv_3 (Conv2D)              (None, 72, 72, 128)       73728     
_________________________________________________________________
norm_3 (BatchNormalization)  (None, 72, 72, 128)       512       
_________________________________________________________________
relu_3 (LeakyReLU)           (None, 72, 72, 128)       0         
_________________________________________________________________
drop_1 (Dropout)             (None, 72, 72, 128)       0         
_________________________________________________________________
conv_4 (Conv2D)              (None, 72, 72, 64)        8192      
_________________________________________________________________
norm_4 (BatchNormalization)  (None, 72, 72, 64)        256       
_________________________________________________________________
relu_4 (LeakyReLU)           (None, 72, 72, 64)        0         
_________________________________________________________________
conv_5 (Conv2D)              (None, 72, 72, 128)       73728     
_________________________________________________________________
norm_5 (BatchNormalization)  (None, 72, 72, 128)       512       
_________________________________________________________________
relu_5 (LeakyReLU)           (None, 72, 72, 128)       0         
_________________________________________________________________
pool_3 (MaxPooling2D)        (None, 36, 36, 128)       0         
_________________________________________________________________
conv_6 (Conv2D)              (None, 36, 36, 256)       294912    
_________________________________________________________________
norm_6 (BatchNormalization)  (None, 36, 36, 256)       1024      
_________________________________________________________________
relu_6 (LeakyReLU)           (None, 36, 36, 256)       0         
_________________________________________________________________
drop_2 (Dropout)             (None, 36, 36, 256)       0         
_________________________________________________________________
conv_7 (Conv2D)              (None, 36, 36, 128)       32768     
_________________________________________________________________
norm_7 (BatchNormalization)  (None, 36, 36, 128)       512       
_________________________________________________________________
relu_7 (LeakyReLU)           (None, 36, 36, 128)       0         
_________________________________________________________________
conv_8 (Conv2D)              (None, 36, 36, 256)       294912    
_________________________________________________________________
norm_8 (BatchNormalization)  (None, 36, 36, 256)       1024      
_________________________________________________________________
relu_8 (LeakyReLU)           (None, 36, 36, 256)       0         
_________________________________________________________________
pool_4 (MaxPooling2D)        (None, 18, 18, 256)       0         
_________________________________________________________________
conv_9 (Conv2D)              (None, 18, 18, 512)       1179648   
_________________________________________________________________
norm_9 (BatchNormalization)  (None, 18, 18, 512)       2048      
_________________________________________________________________
relu_9 (LeakyReLU)           (None, 18, 18, 512)       0         
_________________________________________________________________
drop_3 (Dropout)             (None, 18, 18, 512)       0         
_________________________________________________________________
conv_10 (Conv2D)             (None, 18, 18, 256)       131072    
_________________________________________________________________
norm_10 (BatchNormalization) (None, 18, 18, 256)       1024      
_________________________________________________________________
relu_10 (LeakyReLU)          (None, 18, 18, 256)       0         
_________________________________________________________________
conv_11 (Conv2D)             (None, 18, 18, 512)       1179648   
_________________________________________________________________
norm_11 (BatchNormalization) (None, 18, 18, 512)       2048      
_________________________________________________________________
relu_11 (LeakyReLU)          (None, 18, 18, 512)       0         
_________________________________________________________________
conv_12 (Conv2D)             (None, 18, 18, 256)       131072    
_________________________________________________________________
norm_12 (BatchNormalization) (None, 18, 18, 256)       1024      
_________________________________________________________________
relu_12 (LeakyReLU)          (None, 18, 18, 256)       0         
_________________________________________________________________
conv_13 (Conv2D)             (None, 18, 18, 512)       1179648   
_________________________________________________________________
norm_13 (BatchNormalization) (None, 18, 18, 512)       2048      
_________________________________________________________________
relu_13 (LeakyReLU)          (None, 18, 18, 512)       0         
_________________________________________________________________
pool_5 (MaxPooling2D)        (None, 9, 9, 512)         0         
_________________________________________________________________
conv_14 (Conv2D)             (None, 9, 9, 1024)        4718592   
_________________________________________________________________
norm_14 (BatchNormalization) (None, 9, 9, 1024)        4096      
_________________________________________________________________
relu_14 (LeakyReLU)          (None, 9, 9, 1024)        0         
_________________________________________________________________
drop_4 (Dropout)             (None, 9, 9, 1024)        0         
_________________________________________________________________
conv_15 (Conv2D)             (None, 9, 9, 1024)        9437184   
_________________________________________________________________
norm_15 (BatchNormalization) (None, 9, 9, 1024)        4096      
_________________________________________________________________
relu_15 (LeakyReLU)          (None, 9, 9, 1024)        0         
_________________________________________________________________
drop_5 (Dropout)             (None, 9, 9, 1024)        0         
_________________________________________________________________
conv_16 (Conv2D)             (None, 9, 9, 5)           5120      
_________________________________________________________________
reshape_1 (Reshape)          (None, 9, 9, 5)           0         
=================================================================
Total params: 18,779,552
Trainable params: 18,769,248
Non-trainable params: 10,304
_________________________________________________________________
+----------+---------------------+----------------+------------------+---------------------+---------------------+------------------+
|  Epoch   |       f1_score      |      iou       |       loss       |      precision      |        recall       |     val_loss     |
+----------+---------------------+----------------+------------------+---------------------+---------------------+------------------+
| Epoch 1  | 0.08835341365461848 | 0.660691905071 | 0.00412459958682 | 0.30985915492957744 | 0.05152224824355972 | 0.00503623629734 |
| Epoch 2  | 0.11388611388611389 | 0.656630788267 | 0.00410031775536 |  0.3877551020408163 | 0.06674473067915691 | 0.00528772448748 |
| Epoch 3  | 0.07676767676767676 | 0.666970411228 | 0.00406489103667 | 0.27941176470588236 | 0.04449648711943794 | 0.00535112441331 |
| Epoch 4  | 0.07645875251509054 | 0.651567424776 | 0.00404919735632 |  0.2714285714285714 | 0.04449648711943794 | 0.00515119483322 |
| Epoch 5  | 0.12878048780487805 | 0.64187953016  | 0.00401737252362 | 0.38596491228070173 | 0.07728337236533958 | 0.00501719129086 |
| Epoch 6  | 0.11574952561669827 | 0.663145444208 | 0.00398046004991 |        0.305        | 0.07142857142857142 | 0.00495638989657 |
| Epoch 7  | 0.14893617021276595 | 0.634942550834 | 0.00394351464369 | 0.42777777777777776 | 0.09016393442622951 | 0.00484066786245 |
| Epoch 8  | 0.14781834372217276 | 0.632836821049 | 0.00392524938629 | 0.30855018587360594 | 0.09718969555035128 | 0.00498491736501 |
| Epoch 9  | 0.12000000000000001 | 0.629169956619 | 0.00390258614341 |  0.2682926829268293 | 0.07728337236533958 | 0.00508464498818 |
| Epoch 10 | 0.15597920277296362 | 0.656446851317 | 0.0038748627399  |         0.3         |  0.1053864168618267 | 0.00470728794858 |
| Epoch 11 | 0.11481481481481481 | 0.647285404461 | 0.0038294732553  |  0.2743362831858407 | 0.07259953161592506 | 0.0051868455559  |
| Epoch 12 |  0.1826771653543307 | 0.643411216544 | 0.0037952777055  | 0.27884615384615385 |  0.1358313817330211 | 0.00483579770103 |
| Epoch 13 |  0.1675774134790528 | 0.663569981891 | 0.00376976848643 |  0.3770491803278688 | 0.10772833723653395 | 0.00467650275305 |
| Epoch 14 | 0.18382978723404259 | 0.64528368834  | 0.00375139227775 |  0.3364485981308411 | 0.12646370023419204 | 0.00459046532586 |
| Epoch 15 | 0.17615658362989323 | 0.650578103975 | 0.00372010061653 | 0.36666666666666664 | 0.11592505854800937 | 0.00463474440575 |
| Epoch 16 |  0.1746160064672595 | 0.651274722801 | 0.00367665356388 |  0.2819843342036554 | 0.12646370023419204 | 0.0046858775802  |
| Epoch 17 | 0.18556701030927836 | 0.656781814139 | 0.00365706281203 | 0.28746928746928746 | 0.13700234192037472 | 0.00469502764568 |
| Epoch 18 | 0.21931260229132568 | 0.65159179348  | 0.00362878830968 |  0.3641304347826087 | 0.15690866510538642 | 0.00453996546566 |
| Epoch 19 | 0.19936708860759494 | 0.649936986607 | 0.00357353923068 |  0.3073170731707317 | 0.14754098360655737 | 0.00465828823671 |
| Epoch 20 | 0.18312101910828027 | 0.64983317601  | 0.0035588422002  |  0.2860696517412935 | 0.13466042154566746 | 0.00479577192292 |
| Epoch 21 | 0.23376623376623376 | 0.654483653766 | 0.00351945867384 | 0.30451127819548873 | 0.18969555035128804 |  0.004709047921  |
| Epoch 22 | 0.18585526315789475 | 0.642438667698 | 0.00348718349611 | 0.31215469613259667 |  0.1323185011709602 | 0.00479714434221 |
| Epoch 23 |  0.2203898050974513 | 0.65085844516  | 0.00346193845399 |       0.30625       |  0.1721311475409836 | 0.00467916930839 |
| Epoch 24 | 0.24543462381300218 | 0.657436335561 | 0.00343000189258 |  0.3262135922330097 | 0.19672131147540983 | 0.00459138662368 |
| Epoch 25 | 0.24405218726016883 | 0.651136902254 | 0.0033978886459  | 0.35412026726057905 | 0.18618266978922718 | 0.00459000696987 |
| Epoch 26 | 0.23705926481620404 | 0.643908692251 | 0.00335514238385 |  0.3298538622129436 | 0.18501170960187355 | 0.00463606240228 |
| Epoch 27 | 0.25541795665634676 | 0.65675871825  | 0.00331438984597 |  0.3767123287671233 | 0.19320843091334894 | 0.00455904993787 |
| Epoch 28 | 0.21964423820572312 | 0.648674585659 |  0.00328339203   |  0.3234624145785877 | 0.16627634660421545 | 0.0047471900396  |
| Epoch 29 | 0.24049650892164473 | 0.65359226399  | 0.00324701934962 |  0.3563218390804598 | 0.18149882903981265 | 0.00465975282341 |
| Epoch 30 | 0.22665716322166787 | 0.654201260004 | 0.00322449617064 |  0.2896174863387978 | 0.18618266978922718 | 0.00471449575573 |
+----------+---------------------+----------------+------------------+---------------------+---------------------+------------------+
_________________________________________________________________
+---------------------------------+--------------------+--------------------+-----------------------+---------+-----------------------+
|            Optimizer            |       beta_1       |       beta_2       |         decay         | epsilon |           lr          |
+---------------------------------+--------------------+--------------------+-----------------------+---------+-----------------------+
| <class 'keras.optimizers.Adam'> | 0.8999999761581421 | 0.9990000128746033 | 4.999999873689376e-05 |  1e-08  | 9.999999747378752e-05 |
+---------------------------------+--------------------+--------------------+-----------------------+---------+-----------------------+
_________________________________________________________________
+------------+
| Batch Size |
+------------+
|     16     |
+------------+
_________________________________________________________________
+--------------------+------------------+----------------+---------------------+---------------------+---------------------+
|      Metrics       |       Loss       |      IoU       |      Precision      |        Recall       |       F1 Score      |
+--------------------+------------------+----------------+---------------------+---------------------+---------------------+
|   Train Metrics    | 0.00323882901901 | 0.675484311452 |  0.4925269031486648 |  0.3333558133261397 |  0.3976029601029601 |
| Validation Metrics | 0.00471449608356 | 0.654201260004 |  0.2896174863387978 | 0.18618266978922718 | 0.22665716322166787 |
|    Test Metrics    | 0.00471521497518 | 0.642688968347 | 0.31203007518796994 | 0.18928164196123148 | 0.23562810503903478 |
+--------------------+------------------+----------------+---------------------+---------------------+---------------------+
_________________________________________________________________
Time:
    Train Time              : 6:28:26.958541
    Dataset Loading Time    : 0:07:41.303402
    Metrics Evaluation Time : 0:20:47.428400
_________________________________________________________________
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         (None, 288, 288, 1)       0         
_________________________________________________________________
conv_1 (Conv2D)              (None, 288, 288, 32)      288       
_________________________________________________________________
norm_1 (BatchNormalization)  (None, 288, 288, 32)      128       
_________________________________________________________________
relu_1 (LeakyReLU)           (None, 288, 288, 32)      0         
_________________________________________________________________
pool_1 (MaxPooling2D)        (None, 144, 144, 32)      0         
_________________________________________________________________
conv_2 (Conv2D)              (None, 144, 144, 64)      18432     
_________________________________________________________________
norm_2 (BatchNormalization)  (None, 144, 144, 64)      256       
_________________________________________________________________
relu_2 (LeakyReLU)           (None, 144, 144, 64)      0         
_________________________________________________________________
pool_2 (MaxPooling2D)        (None, 72, 72, 64)        0         
_________________________________________________________________
conv_3 (Conv2D)              (None, 72, 72, 128)       73728     
_________________________________________________________________
norm_3 (BatchNormalization)  (None, 72, 72, 128)       512       
_________________________________________________________________
relu_3 (LeakyReLU)           (None, 72, 72, 128)       0         
_________________________________________________________________
drop_1 (Dropout)             (None, 72, 72, 128)       0         
_________________________________________________________________
conv_4 (Conv2D)              (None, 72, 72, 64)        8192      
_________________________________________________________________
norm_4 (BatchNormalization)  (None, 72, 72, 64)        256       
_________________________________________________________________
relu_4 (LeakyReLU)           (None, 72, 72, 64)        0         
_________________________________________________________________
conv_5 (Conv2D)              (None, 72, 72, 128)       73728     
_________________________________________________________________
norm_5 (BatchNormalization)  (None, 72, 72, 128)       512       
_________________________________________________________________
relu_5 (LeakyReLU)           (None, 72, 72, 128)       0         
_________________________________________________________________
pool_3 (MaxPooling2D)        (None, 36, 36, 128)       0         
_________________________________________________________________
conv_6 (Conv2D)              (None, 36, 36, 256)       294912    
_________________________________________________________________
norm_6 (BatchNormalization)  (None, 36, 36, 256)       1024      
_________________________________________________________________
relu_6 (LeakyReLU)           (None, 36, 36, 256)       0         
_________________________________________________________________
drop_2 (Dropout)             (None, 36, 36, 256)       0         
_________________________________________________________________
conv_7 (Conv2D)              (None, 36, 36, 128)       32768     
_________________________________________________________________
norm_7 (BatchNormalization)  (None, 36, 36, 128)       512       
_________________________________________________________________
relu_7 (LeakyReLU)           (None, 36, 36, 128)       0         
_________________________________________________________________
conv_8 (Conv2D)              (None, 36, 36, 256)       294912    
_________________________________________________________________
norm_8 (BatchNormalization)  (None, 36, 36, 256)       1024      
_________________________________________________________________
relu_8 (LeakyReLU)           (None, 36, 36, 256)       0         
_________________________________________________________________
pool_4 (MaxPooling2D)        (None, 18, 18, 256)       0         
_________________________________________________________________
conv_9 (Conv2D)              (None, 18, 18, 512)       1179648   
_________________________________________________________________
norm_9 (BatchNormalization)  (None, 18, 18, 512)       2048      
_________________________________________________________________
relu_9 (LeakyReLU)           (None, 18, 18, 512)       0         
_________________________________________________________________
drop_3 (Dropout)             (None, 18, 18, 512)       0         
_________________________________________________________________
conv_10 (Conv2D)             (None, 18, 18, 256)       131072    
_________________________________________________________________
norm_10 (BatchNormalization) (None, 18, 18, 256)       1024      
_________________________________________________________________
relu_10 (LeakyReLU)          (None, 18, 18, 256)       0         
_________________________________________________________________
conv_11 (Conv2D)             (None, 18, 18, 512)       1179648   
_________________________________________________________________
norm_11 (BatchNormalization) (None, 18, 18, 512)       2048      
_________________________________________________________________
relu_11 (LeakyReLU)          (None, 18, 18, 512)       0         
_________________________________________________________________
conv_12 (Conv2D)             (None, 18, 18, 256)       131072    
_________________________________________________________________
norm_12 (BatchNormalization) (None, 18, 18, 256)       1024      
_________________________________________________________________
relu_12 (LeakyReLU)          (None, 18, 18, 256)       0         
_________________________________________________________________
conv_13 (Conv2D)             (None, 18, 18, 512)       1179648   
_________________________________________________________________
norm_13 (BatchNormalization) (None, 18, 18, 512)       2048      
_________________________________________________________________
relu_13 (LeakyReLU)          (None, 18, 18, 512)       0         
_________________________________________________________________
pool_5 (MaxPooling2D)        (None, 9, 9, 512)         0         
_________________________________________________________________
conv_14 (Conv2D)             (None, 9, 9, 1024)        4718592   
_________________________________________________________________
norm_14 (BatchNormalization) (None, 9, 9, 1024)        4096      
_________________________________________________________________
relu_14 (LeakyReLU)          (None, 9, 9, 1024)        0         
_________________________________________________________________
drop_4 (Dropout)             (None, 9, 9, 1024)        0         
_________________________________________________________________
conv_15 (Conv2D)             (None, 9, 9, 1024)        9437184   
_________________________________________________________________
norm_15 (BatchNormalization) (None, 9, 9, 1024)        4096      
_________________________________________________________________
relu_15 (LeakyReLU)          (None, 9, 9, 1024)        0         
_________________________________________________________________
drop_5 (Dropout)             (None, 9, 9, 1024)        0         
_________________________________________________________________
conv_16 (Conv2D)             (None, 9, 9, 5)           5120      
_________________________________________________________________
reshape_1 (Reshape)          (None, 9, 9, 5)           0         
=================================================================
Total params: 18,779,552
Trainable params: 18,769,248
Non-trainable params: 10,304
_________________________________________________________________
+----------+-----------------------+----------------+------------------+----------------------+----------------------+------------------+
|  Epoch   |        f1_score       |      iou       |       loss       |      precision       |        recall        |     val_loss     |
+----------+-----------------------+----------------+------------------+----------------------+----------------------+------------------+
| Epoch 1  |          nan          |      nan       |  0.012220745346  |         nan          |         0.0          | 0.0117025760785  |
| Epoch 2  |          nan          |      nan       | 0.00697283548678 |         nan          |         0.0          | 0.0159921248481  |
| Epoch 3  |          nan          |      nan       | 0.0060168740522  |         nan          |         0.0          | 0.0143221232146  |
| Epoch 4  |          nan          |      nan       | 0.0054352708683  |         nan          |         0.0          |  0.018633434698  |
| Epoch 5  |          nan          |      nan       | 0.00524361955567 |         nan          |         0.0          | 0.0171185137331  |
| Epoch 6  |          nan          |      nan       | 0.00513533825688 |         nan          |         0.0          | 0.0203041705787  |
| Epoch 7  |          nan          |      nan       | 0.0050305201483  |         nan          |         0.0          | 0.0219984992743  |
| Epoch 8  |          nan          |      nan       | 0.00494094692291 |         nan          |         0.0          | 0.0192582480758  |
| Epoch 9  |          nan          |      nan       | 0.00489270022292 |         nan          |         0.0          | 0.0178959450722  |
| Epoch 10 |          nan          |      nan       | 0.0048493491591  |         nan          |         0.0          | 0.0143319307417  |
| Epoch 11 |          nan          |      nan       | 0.00481497711565 |         nan          |         0.0          |  0.013194101043  |
| Epoch 12 |          nan          |      nan       | 0.00476856066064 |         nan          |         0.0          |  0.016304886803  |
| Epoch 13 |          nan          |      nan       | 0.00471683230751 |         nan          |         0.0          | 0.0112459749952  |
| Epoch 14 |          nan          |      nan       | 0.00468885594562 |         nan          |         0.0          | 0.0126363030449  |
| Epoch 15 |          nan          |      nan       | 0.00463515371983 |         nan          |         0.0          | 0.0121289311796  |
| Epoch 16 |  0.002331002331002331 | 0.601754025875 | 0.00460653132531 |         0.25         | 0.00117096018735363  | 0.00933040631562 |
| Epoch 17 |  0.004634994206257242 | 0.627209616184 | 0.0045519239034  |  0.2222222222222222  | 0.00234192037470726  | 0.00923764257878 |
| Epoch 18 |  0.006936416184971098 | 0.635284863197 | 0.0045120817559  |  0.2727272727272727  | 0.00351288056206089  | 0.00834137392789 |
| Epoch 19 |  0.004571428571428571 | 0.513611571632 | 0.00446359889386 | 0.09523809523809523  | 0.00234192037470726  | 0.00819717166573 |
| Epoch 20 | 0.0069284064665127015 | 0.578735567036 | 0.00444458999513 |         0.25         | 0.00351288056206089  | 0.00834847118706 |
| Epoch 21 |          nan          |      nan       | 0.00439981439486 |         0.0          |         0.0          | 0.00663005457819 |
| Epoch 22 |  0.004449388209121246 | 0.780210756874 | 0.00436836346263 | 0.044444444444444446 | 0.00234192037470726  | 0.0070694508031  |
| Epoch 23 |  0.00681044267877412  | 0.610889830395 | 0.00433242117617 |  0.1111111111111111  | 0.00351288056206089  | 0.00678707065433 |
| Epoch 24 |  0.01807909604519774  | 0.589521090322 | 0.00428246508939 | 0.25806451612903225  | 0.00936768149882904  | 0.00619524812698 |
| Epoch 25 |  0.010989010989010988 | 0.583117591384 | 0.00425091640129 | 0.08928571428571429  | 0.00585480093676815  | 0.00647069454193 |
| Epoch 26 |  0.10113519091847264  | 0.656053534254 | 0.00422392443033 |  0.4260869565217391  | 0.05737704918032787  | 0.00524329300597 |
| Epoch 27 |  0.04494382022471911  | 0.613246738853 | 0.00420475705621 |        0.176         | 0.02576112412177986  | 0.00597477252781 |
| Epoch 28 |  0.04291845493562232  | 0.623558007037 | 0.00416772207815 |  0.2564102564102564  |  0.0234192037470726  | 0.00576418842375 |
| Epoch 29 |  0.05015673981191223  | 0.62771704353  | 0.00414263337251 | 0.23300970873786409  | 0.02810304449648712  | 0.00543852113187 |
| Epoch 30 |  0.07566462167689161  | 0.637714456681 | 0.00409843317611 | 0.29838709677419356  | 0.04332552693208431  | 0.00530239578336 |
| Epoch 31 |  0.08958130477117818  | 0.641290699879 | 0.00408216240527 |  0.2658959537572254  | 0.053864168618266976 | 0.00508423550427 |
| Epoch 32 |   0.070935960591133   | 0.630147993569 | 0.00405693533869 |  0.2236024844720497  | 0.04215456674473068  | 0.00536542554945 |
| Epoch 33 |   0.1222444889779559  | 0.671799103695 | 0.00402074839855 |  0.4236111111111111  | 0.07142857142857142  | 0.00489972484857 |
| Epoch 34 |  0.11857707509881422  | 0.643299530777 | 0.00398728182018 |  0.379746835443038   |  0.0702576112412178  | 0.00475502677634 |
| Epoch 35 |  0.07272727272727272  | 0.646532651042 | 0.00397119182745 |  0.2647058823529412  | 0.04215456674473068  | 0.00526949248463 |
| Epoch 36 |   0.1942257217847769  | 0.641999103234 | 0.00392518958785 | 0.38408304498269896  | 0.12997658079625293  | 0.00475906516612 |
| Epoch 37 |  0.12534562211981568  | 0.657623753533 | 0.00390607887357 |  0.2943722943722944  | 0.07962529274004684  | 0.0048662879765  |
| Epoch 38 |  0.18029739776951673  | 0.647443266922 | 0.00387680273298 |  0.4369369369369369  | 0.11358313817330211  | 0.00471328763664 |
| Epoch 39 |   0.1479591836734694  | 0.640929645351 | 0.00384070224863 |  0.2701863354037267  | 0.10187353629976581  | 0.00478947650641 |
| Epoch 40 |  0.15508885298869143  | 0.63347127724  | 0.00382198752549 |         0.25         | 0.11241217798594848  | 0.00488900233805 |
| Epoch 41 |  0.22425249169435216  | 0.661906702434 | 0.00378135117067 | 0.38571428571428573  | 0.15807962529274006  | 0.00458714255691 |
| Epoch 42 |  0.21190893169877406  | 0.672006223626 | 0.00376352832795 |  0.4201388888888889  | 0.14168618266978922  | 0.00462350800261 |
| Epoch 43 |  0.20149253731343286  | 0.638064176057 | 0.00372839749504 |  0.2777777777777778  | 0.15807962529274006  | 0.00471149350703 |
| Epoch 44 |   0.2078740157480315  | 0.648659640424 | 0.00369597052801 |  0.3173076923076923  | 0.15456674473067916  | 0.00468847990036 |
| Epoch 45 |   0.1917381137957911  | 0.636727884416 | 0.00368038742293 |  0.2867132867132867  | 0.14402810304449648  | 0.00478544193506 |
| Epoch 46 |  0.20833333333333334  | 0.650972149642 | 0.00363334394873 |  0.2857142857142857  | 0.16393442622950818  | 0.00478332871571 |
| Epoch 47 |  0.21766561514195584  | 0.655959295348 | 0.00359525689119 |  0.3333333333333333  | 0.16159250585480095  | 0.00459208114445 |
| Epoch 48 |  0.22490566037735849  | 0.649703600232 | 0.00357760471203 | 0.31634819532908703  | 0.17447306791569087  | 0.00465524849668 |
| Epoch 49 |   0.1938690969345485  | 0.648321424552 | 0.00354433450901 |  0.3314447592067989  | 0.13700234192037472  | 0.00471092801169 |
| Epoch 50 |  0.22635658914728682  | 0.645469443346 | 0.00351870599924 |  0.3348623853211009  | 0.17096018735362997  | 0.00465729028732 |
| Epoch 51 |  0.21670802315963608  | 0.664095159594 | 0.0034870984421  | 0.36901408450704226  | 0.15339578454332553  | 0.00460076902807 |
| Epoch 52 |   0.2525399129172714  | 0.657759478979 | 0.00346287089712 |  0.3320610687022901  | 0.20374707259953162  | 0.0046219224222  |
| Epoch 53 |         0.2096        | 0.653167956085 | 0.00341897639659 | 0.33080808080808083  | 0.15339578454332553  | 0.00474100121856 |
| Epoch 54 |  0.20091324200913244  | 0.650161380163 | 0.00338313575108 | 0.28695652173913044  | 0.15456674473067916  | 0.00483328392357 |
| Epoch 55 |  0.22421524663677128  | 0.65169375649  | 0.00335003785973 | 0.30991735537190085  |  0.1756440281030445  | 0.00467306963354 |
| Epoch 56 |  0.22131814483319776  | 0.662894987454 | 0.00331413028991 |  0.3626666666666667  |  0.1592505854800937  | 0.00446566523612 |
| Epoch 57 |  0.22508960573476705  | 0.65803358029  | 0.00328177877455 |  0.2902033271719039  | 0.18384074941451992  | 0.00470642616972 |
| Epoch 58 |  0.23236514522821575  | 0.653957763414 | 0.0032419483657  | 0.28378378378378377  | 0.19672131147540983  | 0.00469962124899 |
| Epoch 59 |  0.25787106446776614  | 0.657431025933 | 0.00322333729177 | 0.35833333333333334  | 0.20140515222482436  | 0.00453569684178 |
| Epoch 60 |   0.2228530872959546  | 0.652703985155 | 0.00318063309584 |  0.2828828828828829  | 0.18384074941451992  | 0.00474429645017 |
+----------+-----------------------+----------------+------------------+----------------------+----------------------+------------------+
_________________________________________________________________
+---------------------------------+--------------------+--------------------+-----------------------+---------+-----------------------+
|            Optimizer            |       beta_1       |       beta_2       |         decay         | epsilon |           lr          |
+---------------------------------+--------------------+--------------------+-----------------------+---------+-----------------------+
| <class 'keras.optimizers.Adam'> | 0.8999999761581421 | 0.9990000128746033 | 4.999999873689376e-05 |  1e-08  | 9.999999747378752e-05 |
+---------------------------------+--------------------+--------------------+-----------------------+---------+-----------------------+
_________________________________________________________________
+------------+
| Batch Size |
+------------+
|     16     |
+------------+
_________________________________________________________________
+--------------------+------------------+----------------+--------------------+---------------------+---------------------+
|      Metrics       |       Loss       |      IoU       |     Precision      |        Recall       |       F1 Score      |
+--------------------+------------------+----------------+--------------------+---------------------+---------------------+
|   Train Metrics    | 0.00319291476052 | 0.667927918767 | 0.4651288520454136 |  0.348125168599946  | 0.39821029082774057 |
| Validation Metrics | 0.00474429603666 | 0.652703985155 | 0.2828828828828829 | 0.18384074941451992 |  0.2228530872959546 |
|    Test Metrics    | 0.00470591183752 | 0.647922419278 | 0.2910321489001692 |  0.1961231470923603 | 0.23433242506811988 |
+--------------------+------------------+----------------+--------------------+---------------------+---------------------+
_________________________________________________________________
Time:
    Train Time              : 14:10:16.224238
    Dataset Loading Time    : 0:08:04.914674
    Metrics Evaluation Time : 0:31:44.271692
_________________________________________________________________
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         (None, 288, 288, 1)       0         
_________________________________________________________________
conv_1 (Conv2D)              (None, 288, 288, 32)      288       
_________________________________________________________________
norm_1 (BatchNormalization)  (None, 288, 288, 32)      128       
_________________________________________________________________
relu_1 (LeakyReLU)           (None, 288, 288, 32)      0         
_________________________________________________________________
pool_1 (MaxPooling2D)        (None, 144, 144, 32)      0         
_________________________________________________________________
conv_2 (Conv2D)              (None, 144, 144, 64)      18432     
_________________________________________________________________
norm_2 (BatchNormalization)  (None, 144, 144, 64)      256       
_________________________________________________________________
relu_2 (LeakyReLU)           (None, 144, 144, 64)      0         
_________________________________________________________________
pool_2 (MaxPooling2D)        (None, 72, 72, 64)        0         
_________________________________________________________________
conv_3 (Conv2D)              (None, 72, 72, 128)       73728     
_________________________________________________________________
norm_3 (BatchNormalization)  (None, 72, 72, 128)       512       
_________________________________________________________________
relu_3 (LeakyReLU)           (None, 72, 72, 128)       0         
_________________________________________________________________
drop_1 (Dropout)             (None, 72, 72, 128)       0         
_________________________________________________________________
conv_4 (Conv2D)              (None, 72, 72, 64)        8192      
_________________________________________________________________
norm_4 (BatchNormalization)  (None, 72, 72, 64)        256       
_________________________________________________________________
relu_4 (LeakyReLU)           (None, 72, 72, 64)        0         
_________________________________________________________________
conv_5 (Conv2D)              (None, 72, 72, 128)       73728     
_________________________________________________________________
norm_5 (BatchNormalization)  (None, 72, 72, 128)       512       
_________________________________________________________________
relu_5 (LeakyReLU)           (None, 72, 72, 128)       0         
_________________________________________________________________
pool_3 (MaxPooling2D)        (None, 36, 36, 128)       0         
_________________________________________________________________
conv_6 (Conv2D)              (None, 36, 36, 256)       294912    
_________________________________________________________________
norm_6 (BatchNormalization)  (None, 36, 36, 256)       1024      
_________________________________________________________________
relu_6 (LeakyReLU)           (None, 36, 36, 256)       0         
_________________________________________________________________
drop_2 (Dropout)             (None, 36, 36, 256)       0         
_________________________________________________________________
conv_7 (Conv2D)              (None, 36, 36, 128)       32768     
_________________________________________________________________
norm_7 (BatchNormalization)  (None, 36, 36, 128)       512       
_________________________________________________________________
relu_7 (LeakyReLU)           (None, 36, 36, 128)       0         
_________________________________________________________________
conv_8 (Conv2D)              (None, 36, 36, 256)       294912    
_________________________________________________________________
norm_8 (BatchNormalization)  (None, 36, 36, 256)       1024      
_________________________________________________________________
relu_8 (LeakyReLU)           (None, 36, 36, 256)       0         
_________________________________________________________________
pool_4 (MaxPooling2D)        (None, 18, 18, 256)       0         
_________________________________________________________________
conv_9 (Conv2D)              (None, 18, 18, 512)       1179648   
_________________________________________________________________
norm_9 (BatchNormalization)  (None, 18, 18, 512)       2048      
_________________________________________________________________
relu_9 (LeakyReLU)           (None, 18, 18, 512)       0         
_________________________________________________________________
drop_3 (Dropout)             (None, 18, 18, 512)       0         
_________________________________________________________________
conv_10 (Conv2D)             (None, 18, 18, 256)       131072    
_________________________________________________________________
norm_10 (BatchNormalization) (None, 18, 18, 256)       1024      
_________________________________________________________________
relu_10 (LeakyReLU)          (None, 18, 18, 256)       0         
_________________________________________________________________
conv_11 (Conv2D)             (None, 18, 18, 512)       1179648   
_________________________________________________________________
norm_11 (BatchNormalization) (None, 18, 18, 512)       2048      
_________________________________________________________________
relu_11 (LeakyReLU)          (None, 18, 18, 512)       0         
_________________________________________________________________
conv_12 (Conv2D)             (None, 18, 18, 256)       131072    
_________________________________________________________________
norm_12 (BatchNormalization) (None, 18, 18, 256)       1024      
_________________________________________________________________
relu_12 (LeakyReLU)          (None, 18, 18, 256)       0         
_________________________________________________________________
conv_13 (Conv2D)             (None, 18, 18, 512)       1179648   
_________________________________________________________________
norm_13 (BatchNormalization) (None, 18, 18, 512)       2048      
_________________________________________________________________
relu_13 (LeakyReLU)          (None, 18, 18, 512)       0         
_________________________________________________________________
pool_5 (MaxPooling2D)        (None, 9, 9, 512)         0         
_________________________________________________________________
conv_14 (Conv2D)             (None, 9, 9, 1024)        4718592   
_________________________________________________________________
norm_14 (BatchNormalization) (None, 9, 9, 1024)        4096      
_________________________________________________________________
relu_14 (LeakyReLU)          (None, 9, 9, 1024)        0         
_________________________________________________________________
drop_4 (Dropout)             (None, 9, 9, 1024)        0         
_________________________________________________________________
conv_15 (Conv2D)             (None, 9, 9, 1024)        9437184   
_________________________________________________________________
norm_15 (BatchNormalization) (None, 9, 9, 1024)        4096      
_________________________________________________________________
relu_15 (LeakyReLU)          (None, 9, 9, 1024)        0         
_________________________________________________________________
drop_5 (Dropout)             (None, 9, 9, 1024)        0         
_________________________________________________________________
conv_16 (Conv2D)             (None, 9, 9, 5)           5120      
_________________________________________________________________
reshape_1 (Reshape)          (None, 9, 9, 5)           0         
=================================================================
Total params: 18,779,552
Trainable params: 18,769,248
Non-trainable params: 10,304
_________________________________________________________________
+----------+----------------------+----------------+---------------+---------------------+---------------------+---------------+
|  Epoch   |       f1_score       |      iou       |      loss     |      precision      |        recall       |    val_loss   |
+----------+----------------------+----------------+---------------+---------------------+---------------------+---------------+
| Epoch 1  |         nan          |      nan       | 43.9821478122 |         nan         |         0.0         |  133.77680545 |
| Epoch 2  |         nan          |      nan       | 33.6922604762 |         nan         |         0.0         | 138.442057571 |
| Epoch 3  |         nan          |      nan       | 32.1698262702 |         nan         |         0.0         | 87.9289282532 |
| Epoch 4  |         nan          |      nan       | 31.2755207378 |         nan         |         0.0         | 64.9244204483 |
| Epoch 5  |         nan          |      nan       | 30.6111099171 |         nan         |         0.0         | 52.0407870026 |
| Epoch 6  |         nan          |      nan       | 30.0238642152 |         nan         |         0.0         | 41.1679006119 |
| Epoch 7  | 0.01388888888888889  | 0.660297793927 | 29.4565632462 |         0.6         | 0.00702576112412178 | 31.1080730057 |
| Epoch 8  | 0.02525832376578645  | 0.70556485073  | 28.9684529481 |  0.6470588235294118 | 0.01288056206088993 | 31.6840999069 |
| Epoch 9  | 0.004662004662004662 | 0.616375433498 | 28.4308626199 |         0.5         | 0.00234192037470726 | 31.1086837921 |
| Epoch 10 | 0.023014959723820484 | 0.696010905064 |  28.261276964 |  0.6666666666666666 |  0.0117096018735363 | 29.3374987717 |
| Epoch 11 | 0.07391304347826086  | 0.656643427743 | 27.7079454056 |  0.5151515151515151 | 0.03981264637002342 | 28.4825694122 |
| Epoch 12 | 0.08991228070175439  | 0.711588220565 | 27.3084621356 |  0.7068965517241379 | 0.04800936768149883 | 28.5128864059 |
| Epoch 13 |  0.1171634121274409  | 0.693798686511 | 26.8664339837 |  0.4789915966386555 | 0.06674473067915691 | 27.4313331528 |
| Epoch 14 |       0.09375        | 0.674499384462 | 26.5012045932 | 0.42452830188679247 | 0.05269320843091335 | 28.2729534454 |
| Epoch 15 | 0.20614469772051533  | 0.686908150318 | 26.0481668533 |  0.6709677419354839 | 0.12177985948477751 | 27.2311427994 |
| Epoch 16 | 0.22878932316491898  | 0.680049992467 | 25.6044753897 |  0.6153846153846154 |  0.1405152224824356 | 26.9136941147 |
| Epoch 17 | 0.22651448639157157  | 0.662469007175 | 25.2746166918 | 0.45263157894736844 | 0.15105386416861827 | 27.1517970581 |
| Epoch 18 |  0.2786157941437445  | 0.674610602767 | 24.8235826375 |  0.575091575091575  | 0.18384074941451992 | 26.3136051407 |
| Epoch 19 |  0.1941896024464832  | 0.657361650602 | 24.4612167181 | 0.27973568281938327 |  0.148711943793911  | 28.4953794479 |
| Epoch 20 |  0.3062645011600928  | 0.661402783976 | 23.9685209684 |  0.4510250569476082 | 0.23185011709601874 |  26.644010025 |
| Epoch 21 | 0.25238095238095243  | 0.646804896826 |  23.542380186 |  0.3916256157635468 | 0.18618266978922718 | 27.4533221436 |
| Epoch 22 |  0.265472312703583   | 0.655717160397 | 23.0533308187 |  0.4358288770053476 | 0.19086651053864168 | 26.9582335663 |
| Epoch 23 |  0.2999198075380914  | 0.661642112884 | 22.5765932616 |  0.4758269720101781 |  0.2189695550351288 | 26.3645151215 |
| Epoch 24 |  0.2839756592292089  | 0.651759452984 | 21.9828712766 |        0.336        |  0.2459016393442623 | 28.5314863586 |
| Epoch 25 |  0.3254139668826494  | 0.662342668391 | 21.4368138313 |  0.4224299065420561 |  0.2646370023419204 | 27.0517647629 |
| Epoch 26 |  0.289763779527559   | 0.668246465389 | 20.8277935913 |  0.4423076923076923 |  0.2154566744730679 | 27.3812081833 |
| Epoch 27 | 0.29181004817618716  | 0.657685591083 | 20.2246653362 | 0.35392320534223703 | 0.24824355971896955 | 28.0633182831 |
| Epoch 28 | 0.31556503198294245  | 0.675297759782 | 19.6705824629 |  0.4014466546112116 | 0.25995316159250587 | 27.3229077606 |
| Epoch 29 |  0.2670886075949367  | 0.651959109171 | 19.0795339922 |  0.290633608815427  | 0.24707259953161592 | 29.1072365723 |
| Epoch 30 | 0.31835686777920413  | 0.66502576549  | 18.4450531508 |  0.3522727272727273 |  0.2903981264637002 | 28.3360850296 |
| Epoch 31 | 0.29098360655737704  | 0.65996810086  | 17.9024577034 | 0.34918032786885245 | 0.24941451990632318 | 28.9386725693 |
| Epoch 32 |  0.2763246143527834  | 0.663155208867 | 17.2516112644 | 0.32339089481946626 | 0.24121779859484777 | 28.9378746414 |
| Epoch 33 |  0.2730118973074515  | 0.665302016316 | 16.7076351075 |  0.2934051144010767 | 0.25526932084309134 | 29.0324056015 |
| Epoch 34 |  0.2868686868686869  | 0.660415157338 | 16.2628261175 |  0.3375594294770206 | 0.24941451990632318 | 29.4124713974 |
| Epoch 35 |  0.2741935483870967  | 0.655156442697 | 15.6942049289 |  0.3217665615141956 |  0.2388758782201405 | 29.8538490982 |
| Epoch 36 |  0.3113854595336077  | 0.664479868231 | 15.1308320997 |  0.3758278145695364 |  0.265807962529274  | 29.3110284958 |
| Epoch 37 | 0.22523744911804613  | 0.636964950126 |  14.790582783 |  0.267741935483871  | 0.19437939110070257 |  31.882784462 |
| Epoch 38 |  0.2857142857142857  | 0.657817625618 | 14.2596172928 |  0.3692022263450835 | 0.23302107728337237 | 29.3521053238 |
| Epoch 39 |  0.2553485162180814  | 0.653085432928 | 13.9065807387 | 0.31092436974789917 | 0.21662763466042154 | 30.2261180954 |
| Epoch 40 |  0.2664853840924541  | 0.649388859305 | 13.4616272721 | 0.31766612641815234 | 0.22950819672131148 | 30.1104567719 |
+----------+----------------------+----------------+---------------+---------------------+---------------------+---------------+
_________________________________________________________________
+---------------------------------+--------------------+--------------------+-----------------------+---------+-----------------------+
|            Optimizer            |       beta_1       |       beta_2       |         decay         | epsilon |           lr          |
+---------------------------------+--------------------+--------------------+-----------------------+---------+-----------------------+
| <class 'keras.optimizers.Adam'> | 0.8999999761581421 | 0.9990000128746033 | 0.0005000000237487257 |  1e-08  | 0.0010000000474974513 |
+---------------------------------+--------------------+--------------------+-----------------------+---------+-----------------------+
_________________________________________________________________
+------------+
| Batch Size |
+------------+
|     16     |
+------------+
_________________________________________________________________
+--------------------+---------------+----------------+---------------------+---------------------+---------------------+
|      Metrics       |      Loss     |      IoU       |      Precision      |        Recall       |       F1 Score      |
+--------------------+---------------+----------------+---------------------+---------------------+---------------------+
|   Train Metrics    | 21.4883992211 | 0.700927613286 |  0.6888649900727994 |  0.5615727002967359 |  0.6187397830286818 |
| Validation Metrics | 59.6922640381 | 0.649388859305 | 0.31766612641815234 | 0.22950819672131148 |  0.2664853840924541 |
|    Test Metrics    | 58.3707762451 | 0.649873310408 |  0.3724770642201835 |  0.2314709236031927 | 0.28551336146272854 |
+--------------------+---------------+----------------+---------------------+---------------------+---------------------+
_________________________________________________________________
Time:
    Train Time              : 8:10:35.209751
    Dataset Loading Time    : 0:07:19.895473
    Metrics Evaluation Time : 0:22:52.674576
_________________________________________________________________
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         (None, 288, 288, 1)       0         
_________________________________________________________________
conv_1 (Conv2D)              (None, 288, 288, 32)      288       
_________________________________________________________________
norm_1 (BatchNormalization)  (None, 288, 288, 32)      128       
_________________________________________________________________
relu_1 (LeakyReLU)           (None, 288, 288, 32)      0         
_________________________________________________________________
pool_1 (MaxPooling2D)        (None, 144, 144, 32)      0         
_________________________________________________________________
conv_2 (Conv2D)              (None, 144, 144, 64)      18432     
_________________________________________________________________
norm_2 (BatchNormalization)  (None, 144, 144, 64)      256       
_________________________________________________________________
relu_2 (LeakyReLU)           (None, 144, 144, 64)      0         
_________________________________________________________________
pool_2 (MaxPooling2D)        (None, 72, 72, 64)        0         
_________________________________________________________________
conv_3 (Conv2D)              (None, 72, 72, 128)       73728     
_________________________________________________________________
norm_3 (BatchNormalization)  (None, 72, 72, 128)       512       
_________________________________________________________________
relu_3 (LeakyReLU)           (None, 72, 72, 128)       0         
_________________________________________________________________
conv_4 (Conv2D)              (None, 72, 72, 64)        8192      
_________________________________________________________________
norm_4 (BatchNormalization)  (None, 72, 72, 64)        256       
_________________________________________________________________
relu_4 (LeakyReLU)           (None, 72, 72, 64)        0         
_________________________________________________________________
drop_1 (Dropout)             (None, 72, 72, 64)        0         
_________________________________________________________________
conv_5 (Conv2D)              (None, 72, 72, 128)       73728     
_________________________________________________________________
norm_5 (BatchNormalization)  (None, 72, 72, 128)       512       
_________________________________________________________________
relu_5 (LeakyReLU)           (None, 72, 72, 128)       0         
_________________________________________________________________
pool_3 (MaxPooling2D)        (None, 36, 36, 128)       0         
_________________________________________________________________
conv_6 (Conv2D)              (None, 36, 36, 256)       294912    
_________________________________________________________________
norm_6 (BatchNormalization)  (None, 36, 36, 256)       1024      
_________________________________________________________________
relu_6 (LeakyReLU)           (None, 36, 36, 256)       0         
_________________________________________________________________
conv_7 (Conv2D)              (None, 36, 36, 128)       32768     
_________________________________________________________________
norm_7 (BatchNormalization)  (None, 36, 36, 128)       512       
_________________________________________________________________
relu_7 (LeakyReLU)           (None, 36, 36, 128)       0         
_________________________________________________________________
drop_2 (Dropout)             (None, 36, 36, 128)       0         
_________________________________________________________________
conv_8 (Conv2D)              (None, 36, 36, 256)       294912    
_________________________________________________________________
norm_8 (BatchNormalization)  (None, 36, 36, 256)       1024      
_________________________________________________________________
relu_8 (LeakyReLU)           (None, 36, 36, 256)       0         
_________________________________________________________________
pool_4 (MaxPooling2D)        (None, 18, 18, 256)       0         
_________________________________________________________________
conv_9 (Conv2D)              (None, 18, 18, 512)       1179648   
_________________________________________________________________
norm_9 (BatchNormalization)  (None, 18, 18, 512)       2048      
_________________________________________________________________
relu_9 (LeakyReLU)           (None, 18, 18, 512)       0         
_________________________________________________________________
conv_10 (Conv2D)             (None, 18, 18, 256)       131072    
_________________________________________________________________
norm_10 (BatchNormalization) (None, 18, 18, 256)       1024      
_________________________________________________________________
relu_10 (LeakyReLU)          (None, 18, 18, 256)       0         
_________________________________________________________________
drop_3 (Dropout)             (None, 18, 18, 256)       0         
_________________________________________________________________
conv_11 (Conv2D)             (None, 18, 18, 512)       1179648   
_________________________________________________________________
norm_11 (BatchNormalization) (None, 18, 18, 512)       2048      
_________________________________________________________________
relu_11 (LeakyReLU)          (None, 18, 18, 512)       0         
_________________________________________________________________
drop_4 (Dropout)             (None, 18, 18, 512)       0         
_________________________________________________________________
conv_12 (Conv2D)             (None, 18, 18, 256)       131072    
_________________________________________________________________
norm_12 (BatchNormalization) (None, 18, 18, 256)       1024      
_________________________________________________________________
relu_12 (LeakyReLU)          (None, 18, 18, 256)       0         
_________________________________________________________________
drop_5 (Dropout)             (None, 18, 18, 256)       0         
_________________________________________________________________
conv_13 (Conv2D)             (None, 18, 18, 512)       1179648   
_________________________________________________________________
norm_13 (BatchNormalization) (None, 18, 18, 512)       2048      
_________________________________________________________________
relu_13 (LeakyReLU)          (None, 18, 18, 512)       0         
_________________________________________________________________
drop_13 (Dropout)            (None, 18, 18, 512)       0         
_________________________________________________________________
pool_5 (MaxPooling2D)        (None, 9, 9, 512)         0         
_________________________________________________________________
conv_14 (Conv2D)             (None, 9, 9, 1024)        4718592   
_________________________________________________________________
norm_14 (BatchNormalization) (None, 9, 9, 1024)        4096      
_________________________________________________________________
relu_14 (LeakyReLU)          (None, 9, 9, 1024)        0         
_________________________________________________________________
drop_6 (Dropout)             (None, 9, 9, 1024)        0         
_________________________________________________________________
conv_15 (Conv2D)             (None, 9, 9, 1024)        9437184   
_________________________________________________________________
norm_15 (BatchNormalization) (None, 9, 9, 1024)        4096      
_________________________________________________________________
relu_15 (LeakyReLU)          (None, 9, 9, 1024)        0         
_________________________________________________________________
drop_7 (Dropout)             (None, 9, 9, 1024)        0         
_________________________________________________________________
conv_16 (Conv2D)             (None, 9, 9, 5)           5120      
_________________________________________________________________
reshape_1 (Reshape)          (None, 9, 9, 5)           0         
=================================================================
Total params: 18,779,552
Trainable params: 18,769,248
Non-trainable params: 10,304
_________________________________________________________________
+----------+-----------------------+----------------+---------------+----------------------+---------------------+---------------+
|  Epoch   |        f1_score       |      iou       |      loss     |      precision       |        recall       |    val_loss   |
+----------+-----------------------+----------------+---------------+----------------------+---------------------+---------------+
| Epoch 1  |          nan          |      nan       | 49.0947497847 |         nan          |         0.0         | 126.808280029 |
| Epoch 2  |          nan          |      nan       | 35.3405487253 |         nan          |         0.0         |  91.624166687 |
| Epoch 3  |          nan          |      nan       | 32.9987903117 |         nan          |         0.0         | 101.788231079 |
| Epoch 4  |          nan          |      nan       | 32.0608459816 |         nan          |         0.0         | 112.979366318 |
| Epoch 5  |          nan          |      nan       | 31.4897756255 |         nan          |         0.0         | 109.572675842 |
| Epoch 6  |          nan          |      nan       | 30.9422468209 |         nan          |         0.0         | 99.5916270294 |
| Epoch 7  |          nan          |      nan       | 30.4407202155 |         nan          |         0.0         | 76.2909514999 |
| Epoch 8  |          nan          |      nan       | 29.9917585832 |         nan          |         0.0         | 90.9381638794 |
| Epoch 9  |          nan          |      nan       | 29.6501145588 |         nan          |         0.0         | 57.6430722046 |
| Epoch 10 |          nan          |      nan       | 29.1758248612 |         nan          |         0.0         | 59.8494299011 |
| Epoch 11 |          nan          |      nan       | 28.8267331898 |         nan          |         0.0         | 64.7471453781 |
| Epoch 12 |          nan          |      nan       | 28.4589367413 |         nan          |         0.0         | 49.2596657562 |
| Epoch 13 |          nan          |      nan       | 28.1025230886 |         nan          |         0.0         | 54.1767921295 |
| Epoch 14 |          nan          |      nan       | 27.7672574655 |         nan          |         0.0         | 56.8139342041 |
| Epoch 15 |          nan          |      nan       | 27.4805351181 |         nan          |         0.0         | 54.2398183823 |
| Epoch 16 |          nan          |      nan       | 27.2787268284 |         nan          |         0.0         | 66.8520588684 |
| Epoch 17 |          nan          |      nan       | 26.9464568502 |         nan          |         0.0         | 53.7804832001 |
| Epoch 18 |          nan          |      nan       | 26.6860822377 |         nan          |         0.0         | 51.2948852692 |
| Epoch 19 |          nan          |      nan       | 26.4616324805 |         nan          |         0.0         |  45.740616806 |
| Epoch 20 |          nan          |      nan       | 26.2872761483 |         nan          |         0.0         | 53.0496856003 |
| Epoch 21 |          nan          |      nan       | 26.0144000788 |         nan          |         0.0         | 47.7283499374 |
| Epoch 22 |          nan          |      nan       | 25.9379044397 |         nan          |         0.0         | 46.4152020798 |
| Epoch 23 |          nan          |      nan       | 25.5272442646 |         nan          |         0.0         | 50.1909304199 |
| Epoch 24 |          nan          |      nan       | 25.3959018879 |         nan          |         0.0         | 48.0822380371 |
| Epoch 25 |          nan          |      nan       | 25.1778374745 |         nan          |         0.0         | 45.1250240936 |
| Epoch 26 |          nan          |      nan       | 24.9516175112 |         nan          |         0.0         |  42.867074707 |
| Epoch 27 |          nan          |      nan       | 24.7388488206 |         nan          |         0.0         | 50.5521353073 |
| Epoch 28 |          nan          |      nan       | 24.6048427023 |         nan          |         0.0         | 44.0090970993 |
| Epoch 29 |          nan          |      nan       | 24.4369087496 |         nan          |         0.0         |  43.428837265 |
| Epoch 30 |          nan          |      nan       | 24.2667166141 |         nan          |         0.0         | 49.1817226791 |
| Epoch 31 |          nan          |      nan       | 24.0861776618 |         nan          |         0.0         | 48.5480441513 |
| Epoch 32 |          nan          |      nan       | 23.9290525018 |         nan          |         0.0         | 47.0910799103 |
| Epoch 33 |          nan          |      nan       | 23.6433652111 |         nan          |         0.0         | 39.5579229736 |
| Epoch 34 |          nan          |      nan       | 23.5547919428 |         0.0          |         0.0         | 46.3644534149 |
| Epoch 35 | 0.0023337222870478415 | 0.606451376083 | 23.3832339132 |  0.3333333333333333  | 0.00117096018735363 | 46.7523486023 |
| Epoch 36 |          nan          |      nan       | 23.3151081807 |         0.0          |         0.0         | 43.4773037643 |
| Epoch 37 |          nan          |      nan       | 23.1630167167 |         nan          |         0.0         | 38.8660942993 |
| Epoch 38 |          nan          |      nan       | 23.0245575121 |         nan          |         0.0         |   45.6441903  |
| Epoch 39 |          nan          |      nan       | 22.8464780925 |         0.0          |         0.0         | 39.8669304352 |
| Epoch 40 |          nan          |      nan       |  22.624509853 |         0.0          |         0.0         | 39.6765759354 |
| Epoch 41 |          nan          |      nan       | 22.4863680518 |         nan          |         0.0         |  40.68794384  |
| Epoch 42 |          nan          |      nan       | 22.4627646749 |         0.0          |         0.0         | 46.9198311768 |
| Epoch 43 |          nan          |      nan       | 22.3085062561 |         0.0          |         0.0         | 48.9669587708 |
| Epoch 44 |          nan          |      nan       | 22.1482866196 |         0.0          |         0.0         | 46.3079567795 |
| Epoch 45 |          nan          |      nan       | 22.0196671871 |         0.0          |         0.0         | 40.8795477295 |
| Epoch 46 |  0.002336448598130841 | 0.602419712789 | 21.8386908739 |         0.5          | 0.00117096018735363 | 40.2291606293 |
| Epoch 47 |          nan          |      nan       | 21.7759142309 |         0.0          |         0.0         | 41.6596138535 |
| Epoch 48 |          nan          |      nan       | 21.6379538698 |         0.0          |         0.0         | 42.4541256638 |
| Epoch 49 |          nan          |      nan       | 21.4750591822 |         0.0          |         0.0         | 42.6674344635 |
| Epoch 50 |  0.004651162790697674 | 0.518938742398 | 21.3992976967 |  0.3333333333333333  | 0.00234192037470726 | 42.7928049164 |
| Epoch 51 |          nan          |      nan       | 21.2754726323 |         0.0          |         0.0         | 45.2626304398 |
| Epoch 52 |  0.002317497103128621 | 0.804740804445 | 21.1601546418 |  0.1111111111111111  | 0.00117096018735363 |  38.909768959 |
| Epoch 53 |  0.002331002331002331 | 0.67032229852  | 21.1038156315 |         0.25         | 0.00117096018735363 | 40.9265361633 |
| Epoch 54 | 0.0023014959723820483 | 0.752488908667 | 20.9105179315 | 0.06666666666666667  | 0.00117096018735363 | 42.8552897949 |
| Epoch 55 |  0.004624277456647398 | 0.587046070394 | 20.7516829628 | 0.18181818181818182  | 0.00234192037470726 | 38.3407158508 |
| Epoch 56 |  0.004613610149942329 | 0.630279010783 |  20.682395661 | 0.15384615384615385  | 0.00234192037470726 | 40.5175713806 |
| Epoch 57 | 0.0022727272727272726 | 0.673624333678 | 20.5688491123 | 0.038461538461538464 | 0.00117096018735363 | 41.7957179184 |
| Epoch 58 |          nan          |      nan       | 20.5216018085 |         0.0          |         0.0         | 39.4664393845 |
| Epoch 59 |          nan          |      nan       | 20.2848244996 |         0.0          |         0.0         | 41.7883415604 |
| Epoch 60 | 0.0023094688221709007 | 0.598519874608 | 20.2723069316 | 0.08333333333333333  | 0.00117096018735363 |  41.011925972 |
+----------+-----------------------+----------------+---------------+----------------------+---------------------+---------------+
_________________________________________________________________
+---------------------------------+--------------------+--------------------+-----------------------+---------+-----------------------+
|            Optimizer            |       beta_1       |       beta_2       |         decay         | epsilon |           lr          |
+---------------------------------+--------------------+--------------------+-----------------------+---------+-----------------------+
| <class 'keras.optimizers.Adam'> | 0.8999999761581421 | 0.9990000128746033 | 0.0005000000237487257 |  1e-08  | 0.0010000000474974513 |
+---------------------------------+--------------------+--------------------+-----------------------+---------+-----------------------+
_________________________________________________________________
+------------+
| Batch Size |
+------------+
|     16     |
+------------+
_________________________________________________________________
+--------------------+---------------+----------------+---------------------+-----------------------+-----------------------+
|      Metrics       |      Loss     |      IoU       |      Precision      |         Recall        |        F1 Score       |
+--------------------+---------------+----------------+---------------------+-----------------------+-----------------------+
|   Train Metrics    | 79.3798794349 | 0.592937868766 | 0.09090909090909091 | 0.0016859994604801727 | 0.0033106005429384892 |
| Validation Metrics | 81.0739125671 | 0.598519874608 | 0.08333333333333333 |  0.00117096018735363  | 0.0023094688221709007 |
|    Test Metrics    | 83.5829764404 |      nan       |         0.0         |          0.0          |          nan          |
+--------------------+---------------+----------------+---------------------+-----------------------+-----------------------+
_________________________________________________________________
Time:
    Train Time              : 14:22:04.462186
    Dataset Loading Time    : 0:06:40.563378
    Metrics Evaluation Time : 0:32:17.333429
_________________________________________________________________
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
